CLEAN REPO EXPORT
Generated: 2026-01-03 21:38:05Z
Root: C:\Dev\scv-repo

============================================================

===== FILE: .gitignore =====
# AI / ChatGPT exports
exports/
*.repo-export.txt
repo-export.txt



===== FILE: app_backend\__init__.py =====


===== FILE: app_backend\bff\router.py =====
from fastapi import APIRouter, HTTPException
from sqlalchemy import text
from database import SessionLocal

router = APIRouter(prefix="/bff", tags=["bff"])


@router.get("/clients")
def list_clients():
    db = SessionLocal()
    try:
        rows = db.execute(
            text("""
                SELECT
                    id, external_id, full_name, email, phone,
                    primary_address, country, tax_id, segment,
                    risk_rating
                FROM clients
                ORDER BY id
            """)
        ).fetchall()

        return {"clients": [dict(r._mapping) for r in rows]}
    finally:
        db.close()


@router.get("/clients/{client_id}")
def get_client_detail(client_id: int):
    db = SessionLocal()
    try:
        client = db.execute(
            text("SELECT * FROM clients WHERE id = :id"),
            {"id": client_id},
        ).fetchone()

        if not client:
            raise HTTPException(status_code=404, detail="Client not found")

        accounts = db.execute(
            text("SELECT * FROM accounts WHERE client_id = :id"),
            {"id": client_id},
        ).fetchall()

        operational_state = db.execute(
            text("""
                SELECT *
                FROM client_operational_state
                WHERE client_id = :id
                ORDER BY as_of DESC
                LIMIT 1
            """),
            {"id": client_id},
        ).fetchone()

        match_decisions = db.execute(
            text("""
                SELECT *
                FROM match_decisions
                WHERE matched_client_id = :id
                ORDER BY decided_at DESC
                LIMIT 10
            """),
            {"id": client_id},
        ).fetchall()

        return {
            "client": dict(client._mapping),
            "accounts": [dict(r._mapping) for r in accounts],
            "operational_state": dict(operational_state._mapping) if operational_state else None,
            "recent_match_decisions": [dict(r._mapping) for r in match_decisions],
        }

    finally:
        db.close()


===== FILE: app_backend\db.py =====
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, declarative_base

SQLALCHEMY_DATABASE_URL = "sqlite:///./scv_sources.db"

engine = create_engine(
    SQLALCHEMY_DATABASE_URL,
    connect_args={"check_same_thread": False},
)

SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

Base = declarative_base()


===== FILE: app_backend\main.py =====
import os  # <-- Added the os import

from app_backend.bff.router import router as bff_router
from fastapi import FastAPI, Depends, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from sqlalchemy.orm import Session
import json

from .db import Base, engine, SessionLocal
from . import models, schemas
from src.services.client_profile.service import ClientProfileService

# Initialise database
Base.metadata.create_all(bind=engine)

app = FastAPI(title="Single Client View (SCV) Backend")
app.include_router(bff_router)


# CORS (for frontend dev server access)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173", "http://127.0.0.1:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Serve frontend static files (React app)
FRONTEND_DIST = "app_frontend/dist"
if os.path.isdir(FRONTEND_DIST):
    app.mount("/assets", StaticFiles(directory=os.path.join(FRONTEND_DIST, "assets")), name="assets")

    @app.get("/", include_in_schema=False)
    async def serve_index():
        index_path = os.path.join(FRONTEND_DIST, "index.html")
        return FileResponse(index_path)

# Serve MissionLog status snapshot JSON file
MISSIONLOG_PUBLIC = "app_frontend/public/missionlog"
if os.path.isdir(MISSIONLOG_PUBLIC):
    app.mount("/missionlog", StaticFiles(directory=MISSIONLOG_PUBLIC), name="missionlog")

# Dependency to get database session
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# Health check endpoint
@app.get("/health", tags=["system"])
def health_check():
    return {"status": "ok"}

# ------------------------------------
# Load raw records for a client
# ------------------------------------
def _load_raw_records_for_client(db: Session, client_id: str) -> list[dict[str, any]]:
    rows: list[models.SourceRecord] = (
        db.query(models.SourceRecord)
        .filter(models.SourceRecord.client_id == client_id)
        .all()
    )

    records: list[dict[str, any]] = []
    for row in rows:
        try:
            payload = json.loads(row.payload_json)
        except json.JSONDecodeError:
            continue

        if "_source" not in payload:
            payload["_source"] = row.system

        records.append(payload)

    return records

# Endpoint to get client profile
@app.get("/clients/{client_id}/profile", tags=["clients"])
def get_client_profile(client_id: str, db: Session = Depends(get_db)):
    raw_records = _load_raw_records_for_client(db, client_id)

    service = ClientProfileService()
    profile = service.assemble_base_profile(client_id, raw_records)

    if not profile:
        raise HTTPException(status_code=404, detail="Profile could not be assembled")

    return profile

# ------------------------------------
# Endpoint to get client sources
# ------------------------------------
@app.get("/clients/{client_id}/sources", tags=["clients"])
def get_client_sources(client_id: str, db: Session = Depends(get_db)):
    # Query the source records for the given client_id
    rows = db.query(models.SourceRecord).filter(models.SourceRecord.client_id == client_id).all()

    # If no sources found, return an empty list
    if not rows:
        return []

    # Otherwise, return the source records
    return rows






===== FILE: app_backend\MissionSmith-M7-SingleClientView.html =====
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>MissionSmith</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <script crossorigin src="https://unpkg.com/react@18/umd/react.development.js"></script>
  <script crossorigin src="https://unpkg.com/react-dom@18/umd/react-dom.development.js"></script>
  <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>

  <style>
    :root{ --lp-border:#d9e2ea; --lp-text:#243745; }
    #launchpad .lp-actions > .lp-pill{
      appearance:none;display:inline-flex;align-items:center;justify-content:center;
      height:34px;padding:0 12px;width:132px;border-radius:999px;border:1px solid var(--lp-border);
      background:#f5f9fb;color:var(--lp-text);font-weight:600;font-size:13.5px;white-space:nowrap;
      transition:transform .06s ease,background .15s ease,border-color .15s ease;cursor:pointer;
    }
    #launchpad .lp-actions > .lp-pill:hover{ transform:translateY(-1px); background:#eef5f8; border-color:#c9d6e1; }
  </style>


  <style>
    :root{ --lp-border:#d9e2ea; --lp-text:#243745; }
    header.sticky.top-0 { background: rgba(255,255,255,.70); backdrop-filter: blur(4px); border-bottom:1px solid #e5e7eb; }
    header.sticky.top-0 > .mx-auto { max-width: 80rem; padding-left: 1rem; padding-right: 1rem; }
    header.sticky.top-0 .flex.items-center.gap-2 > button,
    header.sticky.top-0 .msx-framework-btn{
      appearance:none; display:inline-flex; align-items:center; justify-content:center;
      height:34px; padding:0 14px; min-width:220px;
      border-radius:999px; border:1px solid var(--lp-border);
      background:#f5f9fb; color:var(--lp-text); font-weight:600; font-size:13.5px; white-space:nowrap;
      transition:transform .06s ease, border-color .15s ease, background .15s ease; cursor:pointer;
    }
    header.sticky.top-0 .flex.items-center.gap-2 > button:hover,
    header.sticky.top-0 .msx-framework-btn:hover { transform:translateY(-1px); border-color:#c9d6e1; background:#eef5f8; }
    /* Teal badge gloss (if present) */
    header.sticky.top-0 .flex.items-center.gap-3 .h-7.w-7.rounded-xl{
      border-radius:9999px !important;
      background: radial-gradient(ellipse at 65% 35%, rgba(255,255,255,.22), rgba(255,255,255,0) 40%), #1ba39c !important;
      box-shadow: inset 0 0 0 1px rgba(0,0,0,.05), 0 1px 2px rgba(0,0,0,.06);
    }
  </style>

</head>
<body class="min-h-screen bg-gray-50">
  
<!-- ms-actions removed by request -->
</div>


<!-- ===== LaunchPad (functional shortcuts) ===== -->
<div id="launchpad" style="position:sticky;top:0;z-index:60;background:#fff;border-bottom:1px solid #d9e2ea;backdrop-filter:blur(4px);">
  <div class="inner" style="max-width:80rem;margin:0 auto;padding:0 1rem;">
    <div class="bar" style="display:flex;align-items:center;gap:8px;padding:10px 0;">
      <div class="lp-title" style="font-weight:700;color:#5e6b77;">LaunchPad</div>
      <div style="flex:1 1 auto;"></div>
      <div class="lp-actions" style="display:inline-flex;gap:8px;align-items:center;">
        <button onclick="try{MS_actions.generateAgents&&MS_actions.generateAgents()}catch(e){console.error(e)}" class="lp-pill">Agents</button>
        <button onclick="try{MS_actions.generateScaffold&&MS_actions.generateScaffold()}catch(e){console.error(e)}" class="lp-pill">Microservices</button>
        <button onclick="try{MS_actions.generateCICD&&MS_actions.generateCICD()}catch(e){console.error(e)}" class="lp-pill">CI/CD</button>
        <button onclick="try{MS_actions.generateDeploy&&MS_actions.generateDeploy()}catch(e){console.error(e)}" class="lp-pill">IaC</button>
        <button onclick="try{MS_actions.generatePolicies&&MS_actions.generatePolicies()}catch(e){console.error(e)}" class="lp-pill">Policies</button>
        <button onclick="try{MS_actions.generateLineage&&MS_actions.generateLineage()}catch(e){console.error(e)}" class="lp-pill">Lineage</button>
        <button onclick="(window.MS_actions&&MS_actions.generateAnalytics)?MS_actions.generateAnalytics():console.warn('Analytics handler missing')" class="lp-pill">Analytics</button>
      </div>
    </div>
  </div>
</div>

<div id="root"></div>
  <script type="text/babel" data-presets="env,react">

const { useMemo, useState, useEffect } = React;

/********************
 * CSV helpers + tests
 ********************/
const LB_RE = new RegExp("\\r\\n?|\\r", "g");
function splitLines(raw) {
  // Normalize CRLF || CR to LF, then split
  return raw.replace(LB_RE, "\n").split("\n");
}

function parseCSVSimple(text) {
  const lines = splitLines(text).filter(Boolean);
  if (lines.length < 2) return { headers: [], rows: [] };
  const headers = lines[0].split(",").map((h) => h.trim());
  const rows = lines.slice(1).map((line) => {
    const cells = line.split(",");
    const obj = {};
    headers.forEach((h, i) => (obj[h] = cells[i] ?? ""));
    return obj;
  });
  return { headers, rows };
}

// Self-tests (console)
(function runSelfTests() {
  const inputs = [
    { label: "LF", text: "a,b\\n1,2\\n3,4" },
    { label: "CRLF", text: "a,b\\r\\n1,2\\r\\n3,4" },
    { label: "CR", text: "a,b\\r1,2\\r3,4" },
  ];
  inputs.forEach(({ label, text }) => {
    const real = text
      .split("\\r\\n").join("\\r\\n")
      .split("\\n").join("\\n")
      .split("\\r").join("\\r");
    const { headers, rows } = parseCSVSimple(real
      .replace(/\\r\\n/g, "\r\n")
      .replace(/\\n/g, "\n")
      .replace(/\\r/g, "\r"));
    const ok = headers.length === 2 && rows.length === 2;
    // eslint-disable-next-line no-console
    console.log("CSV " + label + " split test: " + (ok ? "pass" : "fail"));
  });
})();

/********************
 * Initial data
 ********************/
const today = new Date().toISOString().split("T")[0];

const initialData = {
  "missionInfo": {
    "title": "M7 Single Client View",
    "sponsor": "Leon Orr",
    "owner": "Leon Orr",
    "stakeholders": "Leon Orr",
    "version": "v0.1",
    "description": "M7 Single Client View",
    "date": "2025-10-04"
  },
  "serviceConfig": {
    "default_service_name": "example-service",
    "default_backend_language": "java",
    "default_backend_framework": "spring-boot",
    "default_ui_language": "react18",
    "default_ui_framework": "nextjs",
    "default_database": "postgres",
    "default_migration_tool": "flyway",
    "default_outbox_enabled": true,
    "observability": {
      "tracing": "otel",
      "metrics": "red",
      "logs": "json",
      "otel_sampler": "parentbased_traceidratio",
      "otel_sampler_arg": 0.1
    },
    "security": {
      "authn": [
        "jwt"
      ],
      "authz": [
        "opa"
      ],
      "cors_allowlist": [
        "http://localhost:3000",
        "http://localhost:5173"
      ],
      "secrets_management": "vault",
      "image_signing": "cosign",
      "base_image_registry": "ghcr.io"
    },
    "nfr": {
      "slo": [
        {
          "name": "http_p95_ms",
          "target": 150
        },
        {
          "name": "error_rate",
          "target": "0.5%"
        },
        {
          "name": "availability",
          "target": "99.9%"
        },
        {
          "name": "throughput_rps",
          "target": ">=50"
        }
      ],
      "resilience": {
        "circuit_breaker": true,
        "retries": {
          "max": 3,
          "strategy": "exponential-jitter"
        },
        "idempotency_policy": "mutations_required",
        "graceful_shutdown_timeout_s": 20
      }
    },
    "governance": {
      "lineage": "required",
      "policy_packs": [
        "no-wildcard-iam",
        "no-plaintext-internal",
        "no-pii-in-logs",
        "signed-images-only",
        "mission-labels-required"
      ],
      "adr_required": true
    },
    "ci": {
      "gates": [
        "typecheck",
        "unit",
        "contract",
        "integration",
        "property",
        "sast",
        "sbom",
        "iac",
        "schema-compat",
        "docker-scan",
        "policy"
      ],
      "coverage_min": 0.8,
      "lint_required": true,
      "evidence_artifacts": [
        "junit.xml",
        "coverage.json",
        "conftest.json",
        "sbom.spdx.json",
        "lineage.json"
      ]
    },
    "deploy": {
      "default_strategy": "canary",
      "feature_flags": true,
      "namespace": "mission",
      "require_labels": {
        "mission/reference": true,
        "mission/theme": true,
        "mission/topic": true
      },
      "admission_policies": [
        "sigstore-verify",
        "mission-labels",
        "health-endpoints"
      ],
      "rollback": {
        "enabled": true,
        "validate_quarterly": true
      }
    },
    "ownership": {
      "owner": ""
    },
    "api": {
      "require_openapi": true,
      "contract_path": "openapi.yaml",
      "health_endpoints": [
        "/health",
        "/ready",
        "/version"
      ]
    },
    "data": {
      "golden_source_required": true,
      "openapi_tag": "x-golden-source",
      "allowed_topics": [
        "pricing",
        "counterparty",
        "orders",
        "trades"
      ]
    },
    "images": {
      "signed_only": true,
      "max_image_size_mb": 500,
      "approved_bases": [
        "ghcr.io/distroless",
        "gcr.io/distroless",
        "alpine:3"
      ]
    }
  },
  "objectives": [
    {
      "ref": "OBJ-001",
      "category": "Mission Objectives",
      "theme": "Data Integrity",
      "topic": "Golden Source",
      "codify": "API contract registry; OpenAPI refs include `x-golden-source=true`.",
      "automate": "OPA rule validates data-source tags during build.",
      "intercept": "CI fails if endpoint lacks `x-golden-source` tag.",
      "prove": "Build report confirming \u201cAll data sources validated as golden.\u201d",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Ensure all services consume and publish data only via golden-source APIs or message topics.",
      "decision": true
    },
    {
      "ref": "OBJ-002",
      "category": "Mission Objectives",
      "theme": "Automation & Delivery",
      "topic": "CI/CD Coverage",
      "codify": "`ci.yml` template required in every repo.",
      "automate": "GitHub Action executes on push and publishes artefact hash.",
      "intercept": "Pipeline missing \u2192 auto-raise issue or block merge.",
      "prove": "Successful workflow badge and artefact hash stored.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Every deployable unit must have a complete CI/CD pipeline that builds, tests, and produces a signed image.",
      "decision": true
    },
    {
      "ref": "OBJ-003",
      "category": "Mission Objectives",
      "theme": "Observability",
      "topic": "Telemetry",
      "codify": "Shared `otel-config.yaml` schema with standard field names.",
      "automate": "Build injects OpenTelemetry library and exporters.",
      "intercept": "Missing OTEL fields trigger alert in CI.",
      "prove": "Grafana dashboard shows active traces and metrics per service.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Standardise and auto-collect logs, metrics, and traces via OpenTelemetry.",
      "decision": true
    },
    {
      "ref": "OBJ-004",
      "category": "Mission Objectives",
      "theme": "Lineage & Traceability",
      "topic": "Artefact Discoverability",
      "codify": "`lineage.json` template emitted by pipeline.",
      "automate": "CI publishes lineage metadata to registry.",
      "intercept": "Missing lineage \u2192 build blocked or flagged.",
      "prove": "Lineage entry visible in OpenLineage UI.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Every artefact must be registered in the lineage registry with declared inputs and outputs.",
      "decision": true
    },
    {
      "ref": "OBJ-005",
      "category": "Mission Objectives",
      "theme": "Infrastructure as Code",
      "topic": "Declarative Systems",
      "codify": "Terraform, Rego, and Helm templates committed in repo.",
      "automate": "Terraform plan/apply and policy lint run in CI.",
      "intercept": "Missing IaC directory \u2192 CI warning.",
      "prove": "Verified `.tf` or `.rego` artefacts committed and validated.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "All infrastructure and policy must be declarative and stored as code.",
      "decision": true
    },
    {
      "ref": "OBJ-006",
      "category": "Mission Objectives",
      "theme": "Reliability",
      "topic": "Health Endpoints",
      "codify": "OpenAPI annotations define standard health contracts.",
      "automate": "CI test job queries these endpoints on every build.",
      "intercept": "Non-200 status blocks deploy.",
      "prove": "Automated test report shows uptime and response success.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Each service must expose `/health`, `/ready`, and `/version` endpoints.",
      "decision": true
    },
    {
      "ref": "OBJ-007",
      "category": "Mission Objectives",
      "theme": "Change Control",
      "topic": "Auditability",
      "codify": "Git commit metadata and versioned deployment manifests.",
      "automate": "CI annotates releases with actor and change reason.",
      "intercept": "Missing rollback metadata triggers warning.",
      "prove": "Version history and audit log linked to commit.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "All changes must be observable, reversible, and logged with human and agent attribution.",
      "decision": true
    }
  ],
  "principles": [
    {
      "ref": "PRI-001",
      "category": "Mission Principles",
      "theme": "Delivery Discipline",
      "topic": "Trunk-Based Development",
      "codify": "Branch protection rules; PR merge policy in GitHub.",
      "automate": "CI enforces merge checks and tests before commit to trunk.",
      "intercept": "Attempt to merge failing branch \u2192 PR blocked.",
      "prove": "Commit history shows <24h branch lifespan and green pipeline.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Maintain a single mainline branch; minimise long-lived feature branches.",
      "decision": true
    },
    {
      "ref": "PRI-002",
      "category": "Mission Principles",
      "theme": "Quality Assurance",
      "topic": "Evidence Before Release",
      "codify": "Release workflow requires `evidence.json` or build artefacts with test results.",
      "automate": "CI release job checks for evidence hash or signature.",
      "intercept": "Missing evidence file halts release job.",
      "prove": "Evidence artefact stored with release tag.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Deploy only when verifiable proof of readiness exists.",
      "decision": true
    },
    {
      "ref": "PRI-003",
      "category": "Mission Principles",
      "theme": "Design Integrity",
      "topic": "Everything as Code",
      "codify": "Repo structure includes `/infra`, `/policy`, `/docs` folders.",
      "automate": "Linter checks required directories and file patterns.",
      "intercept": "Missing directory \u2192 build warning or failure.",
      "prove": "Manifest of artefact types generated at build time.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "All infrastructure, policy, lineage, and documentation must be expressed as code.",
      "decision": true
    },
    {
      "ref": "PRI-004",
      "category": "Mission Principles",
      "theme": "Governance",
      "topic": "Guardrails Over Gates",
      "codify": "Rego/OPA rules define policy severity levels (`warn` vs `deny`).",
      "automate": "CI runs policy checks on each commit.",
      "intercept": "Exceeded threshold triggers issue but doesn\u2019t block build unless critical.",
      "prove": "Policy status log showing zero critical violations.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Automate compliance and quality controls without manual approval steps.",
      "decision": true
    },
    {
      "ref": "PRI-005",
      "category": "Mission Principles",
      "theme": "Automation",
      "topic": "Automate Where Evidence Exists",
      "codify": "Define measurable metrics in `mission-metrics.yaml`.",
      "automate": "CI executes tests or validations tied to those metrics.",
      "intercept": "Manual step found without automation tag \u2192 flag warning.",
      "prove": "Automated test coverage and metric dashboard.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Any measurable or testable requirement must be automated.",
      "decision": true
    },
    {
      "ref": "PRI-006",
      "category": "Mission Principles",
      "theme": "Observability",
      "topic": "Built-In Telemetry",
      "codify": "Shared instrumentation library (`otel-lib`).",
      "automate": "Static analysis ensures import of `otel-lib` or env var presence.",
      "intercept": "Missing instrumentation triggers build warning.",
      "prove": "Grafana dashboard populated automatically.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Embed observability hooks (logs, traces, metrics) in every template.",
      "decision": true
    },
    {
      "ref": "PRI-007",
      "category": "Mission Principles",
      "theme": "Stability & Reversibility",
      "topic": "Reproducible and Reversible Change",
      "codify": "Version manifests, Docker image digests, Terraform state snapshots.",
      "automate": "CI captures and archives state at build time.",
      "intercept": "Missing snapshot blocks promotion.",
      "prove": "Redeploy previous version reproduces same artefact hash.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Every artefact and deployment must be rebuildable and rollback-capable.",
      "decision": true
    }
  ],
  "guardrails": [
    {
      "ref": "GR-001",
      "category": "Mission Guardrails",
      "theme": "Logging Standards",
      "topic": "Structured JSON Logging",
      "codify": "Central `logging.jsonschema` published for all services.",
      "automate": "Linter or static analysis ensures schema compliance in CI.",
      "intercept": "CI fails if logs deviate from schema.",
      "prove": "Log sample validated against schema and included in evidence pack.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "All application logs must be structured JSON including request ID, user, and service context.",
      "decision": true
    },
    {
      "ref": "GR-002",
      "category": "Mission Guardrails",
      "theme": "Secrets Management",
      "topic": "No Hard-Coded Secrets",
      "codify": "`.secretlint.yml` or regex/entropy patterns in repo root.",
      "automate": "Secret scanner runs pre-commit and in CI.",
      "intercept": "Match found \u2192 merge blocked and issue created.",
      "prove": "CI artefact confirms \u201c0 secrets found.\u201d",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Repositories must not contain plaintext secrets or credentials.",
      "decision": true
    },
    {
      "ref": "GR-003",
      "category": "Mission Guardrails",
      "theme": "Testing Standards",
      "topic": "Automated Test Coverage",
      "codify": "Required `tests/` folder; test framework config present.",
      "automate": "CI runs test suite and reports coverage.",
      "intercept": "Test failures or missing coverage block pipeline.",
      "prove": "Test report attached to build artefacts.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Each repository must include automated unit and integration tests.",
      "decision": true
    },
    {
      "ref": "GR-004",
      "category": "Mission Guardrails",
      "theme": "API Governance",
      "topic": "Machine-Readable Contracts",
      "codify": "Presence of `openapi.yaml` or `schema.graphql`.",
      "automate": "Linter verifies schema syntax and completeness.",
      "intercept": "Missing or invalid schema \u2192 CI fails.",
      "prove": "Spec validated and linked in artefact manifest.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "All APIs must expose OpenAPI or GraphQL schema in repo root.",
      "decision": true
    },
    {
      "ref": "GR-005",
      "category": "Mission Guardrails",
      "theme": "Supply Chain Security",
      "topic": "Signed Base Images",
      "codify": "`Dockerfile` FROM statement restricted to whitelisted registries.",
      "automate": "CI verifies signature with Cosign/Sigstore.",
      "intercept": "Unsigned or unverified image blocks deployment.",
      "prove": "Signature verification log stored with image tag.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "All containers must originate from signed, approved base images.",
      "decision": true
    },
    {
      "ref": "GR-006",
      "category": "Mission Guardrails",
      "theme": "Data Lineage",
      "topic": "Source and Destination Tracking",
      "codify": "`lineage.json` or metadata annotations in code.",
      "automate": "CI publishes lineage metadata to OpenLineage registry.",
      "intercept": "Missing lineage entry triggers policy violation.",
      "prove": "Lineage visible in registry dashboard.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Every data pipeline or transformation must declare its source and destination.",
      "decision": true
    },
    {
      "ref": "GR-007",
      "category": "Mission Guardrails",
      "theme": "Operational Safety",
      "topic": "Rollback Readiness",
      "codify": "Rollback scripts or Helm history retained per environment.",
      "automate": "CI executes rollback dry-run quarterly.",
      "intercept": "Failed rollback test triggers alert.",
      "prove": "Report showing rollback simulation success.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "All deployments must have a defined and tested rollback mechanism.",
      "decision": true
    }
  ],
  "ground": [
    {
      "ref": "TOOL-001",
      "category": "Mission Tooling",
      "theme": "Source Control & Flow",
      "topic": "GitHub",
      "codify": "Repo initialised with `.github` config and branch protection rules.",
      "automate": "Enforce branch protection, required reviews, and signed commits.",
      "intercept": "PR fails if checks or reviews missing.",
      "prove": "Audit log of merges and signed commits.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Manage version control with branch protection and PR checks.",
      "decision": true
    },
    {
      "ref": "TOOL-002",
      "category": "Mission Tooling",
      "theme": "CI/CD",
      "topic": "GitHub Actions",
      "codify": "Standard `.github/workflows/ci.yml` templates.",
      "automate": "Actions triggered on push and pull requests.",
      "intercept": "Workflow failure blocks merge.",
      "prove": "CI badges and artefact hashes attached to releases.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Automate build, test, and deployment workflows.",
      "decision": true
    },
    {
      "ref": "TOOL-003",
      "category": "Mission Tooling",
      "theme": "IaC / Config",
      "topic": "Terraform",
      "codify": "`main.tf` defines environments and resources.",
      "automate": "Terraform plan/apply in pipeline.",
      "intercept": "Drift detection alerts in CI.",
      "prove": "Terraform plan output archived with build.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Provision cloud and infrastructure declaratively.",
      "decision": true
    },
    {
      "ref": "TOOL-004",
      "category": "Mission Tooling",
      "theme": "Policy Enforcement",
      "topic": "OPA / Conftest",
      "codify": "Policy packs in `/policy` folder.",
      "automate": "Conftest executes Rego policies in CI.",
      "intercept": "Violations flagged with severity.",
      "prove": "Conftest JSON output stored in build artefacts.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Enforce Mission Principles and Guardrails programmatically.",
      "decision": true
    },
    {
      "ref": "TOOL-005",
      "category": "Mission Tooling",
      "theme": "Observability",
      "topic": "OpenTelemetry + Grafana",
      "codify": "Shared `otel-config.yaml`; Grafana dashboards.",
      "automate": "Collector agents deployed automatically.",
      "intercept": "Missing OTEL data triggers alert.",
      "prove": "Dashboards display live telemetry.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Centralise logs, metrics, and traces across services.",
      "decision": true
    },
    {
      "ref": "TOOL-006",
      "category": "Mission Tooling",
      "theme": "Security / Secrets",
      "topic": "Trivy + Sigstore + Vault",
      "codify": "`trivy.yml` and Cosign key config.",
      "automate": "Trivy scan and Cosign signature in CI.",
      "intercept": "Vulnerabilities or unsigned images block deploy.",
      "prove": "Signed image logs + scan report stored.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Scan containers, sign images, and manage secrets.",
      "decision": true
    },
    {
      "ref": "TOOL-007",
      "category": "Mission Tooling",
      "theme": "Lineage & Metadata",
      "topic": "OpenLineage + Marquez",
      "codify": "`lineage.json` generated per pipeline.",
      "automate": "Pipeline publishes lineage metadata to registry.",
      "intercept": "Missing lineage raises CI warning.",
      "prove": "Lineage entries visible in Marquez UI.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Capture and visualise data lineage and build provenance.",
      "decision": true
    },
    {
      "ref": "TOOL-008",
      "category": "Mission Tooling",
      "theme": "Documentation",
      "topic": "MkDocs + Markdown ADRs",
      "codify": "`/docs` folder with Markdown and `mkdocs.yml`.",
      "automate": "Docs auto-built on merge to main.",
      "intercept": "Missing or broken link triggers warning.",
      "prove": "Published site and changelog per release.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Generate human-readable mission documentation.",
      "decision": true
    },
    {
      "ref": "TOOL-009",
      "category": "Mission Tooling",
      "theme": "AI Assist",
      "topic": "Copilot / ChatGPT / Gemini",
      "codify": "`.copilot` config and access policy.",
      "automate": "Inline AI suggestions enabled for approved repos.",
      "intercept": "None (advisory only).",
      "prove": "Generated docs and code reviews logged.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Support developers with contextual AI code and doc generation.",
      "decision": true
    },
    {
      "ref": "TOOL-010",
      "category": "Mission Tooling",
      "theme": "Containerisation",
      "topic": "Docker / Podman",
      "codify": "`Dockerfile` in each repo with approved base image.",
      "automate": "CI builds container images on every push.",
      "intercept": "Linting ensures image size and layer limits.",
      "prove": "Image digest and metadata captured in release.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Ensure consistent build artefacts and portable environments.",
      "decision": true
    },
    {
      "ref": "TOOL-011",
      "category": "Mission Tooling",
      "theme": "Deployment",
      "topic": "Kubernetes / Render / Cloud Run",
      "codify": "Helm charts or deployment manifests in `/deploy`.",
      "automate": "GitOps or CD workflow applies manifests.",
      "intercept": "Admission controller denies non-compliant deploys.",
      "prove": "Successful rollout recorded and observable.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Deploy applications in reproducible environments.",
      "decision": true
    },
    {
      "ref": "TOOL-012",
      "category": "Mission Tooling",
      "theme": "Testing",
      "topic": "Unit Tests",
      "codify": "`testing.md` lists per-lang defaults (Jest/Vitest, Pytest, JUnit, Go test).",
      "automate": "CI step runs `npm test` / `pytest` / `mvn test` / `go test`.",
      "intercept": "Non-zero exit blocks merge.",
      "prove": "JUnit/JSON test report uploaded.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Standardise on free unit-test frameworks per language.",
      "decision": true
    },
    {
      "ref": "TOOL-013",
      "category": "Mission Tooling",
      "theme": "Testing",
      "topic": "Contract Tests",
      "codify": "Pact files in `/contracts`; OpenAPI as source of truth.",
      "automate": "Pact tests run in CI; broker verification (OSS).",
      "intercept": "Failed verification blocks release.",
      "prove": "Pact verification report stored.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Enforce producer/consumer API contracts.",
      "decision": true
    },
    {
      "ref": "TOOL-014",
      "category": "Mission Tooling",
      "theme": "Testing",
      "topic": "API Tests",
      "codify": "Postman collections or `.http` specs in repo.",
      "automate": "Newman runs collections in CI.",
      "intercept": "Failing requests block pipeline.",
      "prove": "Newman HTML/JSON report artefact.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Automate API regression via collections.",
      "decision": true
    },
    {
      "ref": "TOOL-015",
      "category": "Mission Tooling",
      "theme": "Testing",
      "topic": "Integration (Containers)",
      "codify": "Testcontainers in test code; docker-compose for local.",
      "automate": "CI launches ephemeral containers for suites.",
      "intercept": "Startup/health failure fails job.",
      "prove": "Logs + container list archived.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Spin up real dependencies in tests.",
      "decision": true
    },
    {
      "ref": "TOOL-016",
      "category": "Mission Tooling",
      "theme": "Testing",
      "topic": "Performance / Load",
      "codify": "`k6` scripts in `/perf`.",
      "automate": "k6 runs on schedule or PR gates.",
      "intercept": "SLO breach flags PR or blocks merge (configurable).",
      "prove": "k6 summary + trend in artefacts.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Baseline latency and throughput SLIs.",
      "decision": true
    },
    {
      "ref": "TOOL-017",
      "category": "Mission Tooling",
      "theme": "Testing",
      "topic": "Dynamic Security",
      "codify": "ZAP baseline config in `/security/zap.yaml`.",
      "automate": "OWASP ZAP baseline scan in CI against preview URL.",
      "intercept": "High/critical issues block deploy.",
      "prove": "ZAP HTML report archived.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Catch common web vulnerabilities automatically.",
      "decision": true
    },
    {
      "ref": "TOOL-018",
      "category": "Mission Tooling",
      "theme": "Quality",
      "topic": "Static Analysis & Lint",
      "codify": "ESLint/Prettier, Flake8, golangci-lint configs.",
      "automate": "Lint job runs in CI on PRs.",
      "intercept": "Lint errors fail job.",
      "prove": "Lint report uploaded.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Enforce style and detect defects.",
      "decision": true
    },
    {
      "ref": "TOOL-019",
      "category": "Mission Tooling",
      "theme": "Testing",
      "topic": "Coverage",
      "codify": "Coverage config (nyc/Istanbul, coverage.py, JaCoCo).",
      "automate": "Coverage generated in CI; threshold gate optional.",
      "intercept": "Under-threshold blocks merge (if enabled).",
      "prove": "Coverage badge + report artefact.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Track and gate minimum coverage.",
      "decision": true
    },
    {
      "ref": "TOOL-020",
      "category": "Mission Tooling",
      "theme": "Testing",
      "topic": "UI End-to-End",
      "codify": "Playwright config + specs in `/e2e`.",
      "automate": "Playwright runs headless in CI.",
      "intercept": "Failing E2E blocks pipeline.",
      "prove": "Traces/videos uploaded by CI.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Cross-browser E2E tests.",
      "decision": true
    },
    {
      "ref": "TOOL-021",
      "category": "Mission Tooling",
      "theme": "Testing",
      "topic": "Service Virtualisation",
      "codify": "WireMock / MockServer configs in `/mocks`.",
      "automate": "Mock servers spun up in CI pre-test.",
      "intercept": "Mock startup failure fails job.",
      "prove": "Mock logs + mappings archived.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Decouple from unavailable or external dependencies.",
      "decision": true
    },
    {
      "ref": "TOOL-022",
      "category": "Mission Tooling",
      "theme": "Resilience",
      "topic": "Chaos Experiments",
      "codify": "LitmusChaos experiment manifests.",
      "automate": "Periodic chaos runs in non-prod.",
      "intercept": "Failed recovery raises incident.",
      "prove": "Chaos run report stored.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Validate graceful degradation and recovery.",
      "decision": true
    },
    {
      "ref": "TOOL-023",
      "category": "Mission Tooling",
      "theme": "Accessibility",
      "topic": "a11y Checks",
      "codify": "axe-core / pa11y configs and test scripts.",
      "automate": "a11y job runs on PRs.",
      "intercept": "WCAG violations flag PR / block per severity.",
      "prove": "a11y report artefact + trend.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Embed accessibility testing for web UIs.",
      "decision": true
    }
  ]
};

/********************
 * Constants
 ********************/
const SECTIONS = [
  { key: "info", label: "Mission Info" },
  { key: "objectives", label: "Mission Objectives" },
  { key: "principles", label: "Mission Principles" },
  { key: "guardrails", label: "Mission Guardrails" },
  { key: "ground", label: "Mission Tooling" },
  { key: "service", label: "Mission Services" },
  { key: "review", label: "Systems Check" },
];

/********************
 * UI atoms
 ********************/
const DecisionPill = ({ value }) => {
  const label = value === true ? "Accepted" : value === false ? "Later" : "Pending";
  const cls =
    value === true
      ? "bg-[color:var(--ms-teal)] text-white"
      : value === false
      ? "bg-[color:var(--ms-orange)] text-white"
      : "bg-gray-200 text-gray-700";
  return (
    <span className={`px-2 py-1 rounded-full text-xs font-medium ${cls}`}>{label}</span>
  );
};


const TopBar = ({ onImportJSON, progress }) => {
  return (
    <header className="sticky top-0 z-40 w-full border-b bg-white/70 backdrop-blur">
      <div className="mx-auto max-w-7xl px-4">
        <div className="flex h-14 items-center justify-between">
          <div className="flex items-center gap-3">
            <div className="h-7 w-7 rounded-xl" style={{ background: "var(--ms-teal)" }} />
            <h1 className="text-lg font-semibold tracking-tight">MissionSmith</h1>
            <span className="ml-2 hidden text-sm text-gray-500 sm:block">
              Forge your Mission Objectives, Principles, Guardrails & Mission Tooling
            </span>
          </div>
          <div className="flex items-center gap-2">
            <button className="rounded-xl border px-3 py-1.5 text-sm hover:bg-gray-50" onClick={onImportJSON}>Import JSON</button>
          </div>
        </div>
        <div className="mb-3 mt-1 h-1 w-full overflow-hidden rounded-full bg-gray-100">
          <div className="h-full rounded-full" style={{ width: `${Math.round(progress * 100)}%`, background: "var(--ms-blue)" }} />
        </div>
      </div>
    </header>
  );
};

const Sidebar = ({ section, setSection }) => {
  return (
    <aside className="sticky top-14 h-[calc(100dvh-56px)] w-full max-w-[260px] shrink-0 border-r bg-white/60 p-3">
      <nav className="flex flex-col gap-1">
        {SECTIONS.map((s) => (
          <button
            key={s.key}
            onClick={() => setSection(s.key)}
            className={`flex items-center justify-between rounded-xl px-3 py-2 text-left text-sm hover:bg-gray-50 ${section === s.key ? "bg-gray-100" : ""}`}
          >
            <span>{s.label}</span>
            {section === s.key && (
              <span className="h-2 w-2 rounded-full" style={{ background: "var(--ms-teal)" }} />
            )}
          </button>
        ))}
      </nav>
      <div className="mt-4 rounded-xl border p-3 text-xs text-gray-600">
        <p className="font-medium">Tip</p>
        <p>Mission Info first, then review & accept rows section by section (Objectives, Principles, Guardrails, Tooling).</p>
      </div>
    </aside>
  );
};

/********************
 * Feature components
 ********************/
const RowEditor = ({ value, onChange, onClose }) => {
  const [local, setLocal] = useState(value);
  const update = (k, v) => setLocal((p) => ({ ...p, [k]: v }));
  const save = () => onChange(local);
  return (
    <div className="fixed inset-0 z-50 flex items-end justify-center bg-black/40 p-0 sm:items-center sm:p-8">
      <div className="w-full max-w-3xl rounded-2xl bg-white p-4 shadow-2xl sm:p-6">
        <div className="mb-3 flex items-center justify-between">
          <h3 className="text-base font-semibold">Edit: {local.ref} â€” {local.topic}</h3>
          <button className="rounded-lg border px-3 py-1 text-sm" onClick={onClose}>Close</button>
        </div>
        <div className="grid grid-cols-1 gap-3 sm:grid-cols-2">
          {[
            ["ref", "Ref"],
            ["category", "Category"],
            ["theme", "Theme"],
            ["topic", "Topic"],
            ["codify", "Codify"],
            ["automate", "Automate"],
            ["intercept", "Intercept"],
            ["prove", "Prove"],
            ["dependency", "Dependency"],
            ["status", "Status"],
            ["user_notes", "Notes"],
          ].map(([key, label]) => (
            <label key={key} className="flex flex-col text-sm">
              <span className="mb-1 text-gray-600">{label}</span>
              <textarea className="min-h-[42px] rounded-xl border p-2 focus:outline-none focus:ring-2" value={local[key] ?? ""} onChange={(e) => update(key, e.target.value)} />
            </label>
          ))}
        </div>
        <div className="mt-4 flex items-center justify-between">
          <div className="flex items-center gap-3 text-sm">
            <span>Decision:</span>
            <button className={`rounded-xl px-3 py-1 ${local.decision === true ? "text-white" : "border"}`} style={{ background: local.decision === true ? "var(--ms-teal)" : undefined }} onClick={() => update("decision", true)}>Accept</button>
            <button className={`rounded-xl px-3 py-1 ${local.decision === false ? "text-white" : "border"}`} style={{ background: local.decision === false ? "var(--ms-orange)" : undefined }} onClick={() => update("decision", false)}>Later</button>
            <button className="rounded-xl border px-3 py-1" onClick={() => update("decision", null)}>Clear</button>
          </div>
          <div className="flex items-center gap-2">
            <button className="rounded-xl border px-3 py-1" onClick={onClose}>Cancel</button>
            <button className="rounded-xl px-3 py-1 text-white" style={{ background: "var(--ms-teal)" }} onClick={save}>Save</button>
          </div>
        </div>
      </div>
    </div>
  );
};

const SectionTable = ({ title, rows, onRowsChange, allowAdd = false }) => {
  const [query, setQuery] = useState("");
  const [editing, setEditing] = useState(null);

  const filtered = useMemo(() => {
    const q = query.trim().toLowerCase();
    if (!q) return rows;
    return rows.filter((r) => JSON.stringify(r).toLowerCase().includes(q));
  }, [query, rows]);

  const updateRow = (idx, patch) => {
    const next = [...rows];
    next[idx] = { ...rows[idx], ...patch };
    onRowsChange(next);
  };

  const removeRow = (idx) => {
    const next = [...rows];
    next.splice(idx, 1);
    onRowsChange(next);
  };

  const addRow = () => {
    const n = {
      ref: `NEW-${Math.random().toString(36).slice(2, 6).toUpperCase()}`,
      category: title,
      theme: "",
      topic: "",
      codify: "",
      automate: "",
      intercept: "",
      prove: "",
      dependency: "N/A",
      status: "option",
      user_notes: "",
      decision: null,
    };
    onRowsChange([n, ...rows]);
    setEditing({ idx: 0, value: n });
  };

  return (
    <div className="rounded-2xl border bg-white/70 p-3 sm:p-4">
      <div className="mb-3 flex flex-col gap-2 sm:flex-row sm:items-center sm:justify-between">
        <div>
          <h2 className="text-base font-semibold">{title}</h2>
          <p className="text-xs text-gray-600">Search, accept/later, edit, || add.</p>
        </div>
        <div className="flex items-center gap-2">
          <input placeholder="Searchâ€¦" className="w-48 rounded-xl border px-3 py-1.5 text-sm" value={query} onChange={(e) => setQuery(e.target.value)} />
          {allowAdd && (
            <button onClick={addRow} className="rounded-xl px-3 py-1.5 text-sm text-white" style={{ background: "var(--ms-teal)" }}>+ Add</button>
          )}
        </div>
      </div>

      <div className="overflow-x-auto">
        <table className="min-w-full text-sm">
          <thead>
            <tr className="bg-gray-50 text-left text-xs uppercase text-gray-500">
              {["Ref", "Theme", "Topic", "Codify", "Automate", "Intercept", "Prove", "Dependency", "Decision", ""].map((h) => (
                <th key={h} className="whitespace-nowrap px-3 py-2 font-medium">{h}</th>
              ))}
            </tr>
          </thead>
          <tbody>
            {filtered.map((r, i) => (
              <tr key={r.ref} className="border-b hover:bg-gray-50">
                <td className="px-3 py-2 font-mono">{r.ref}</td>
                <td className="px-3 py-2">{r.theme}</td>
                <td className="px-3 py-2">
                  <div className="flex items-center gap-2">
                    <span className="font-medium">{r.topic}</span>
                    <button className="rounded-lg border px-2 py-0.5 text-xs" onClick={() => setEditing({ idx: i, value: r })}>Edit</button>
                  </div>
                </td>
                <td className="px-3 py-2 max-w-[260px] truncate" title={r.codify}>{r.codify}</td>
                <td className="px-3 py-2 max-w-[260px] truncate" title={r.automate}>{r.automate}</td>
                <td className="px-3 py-2 max-w-[260px] truncate" title={r.intercept}>{r.intercept}</td>
                <td className="px-3 py-2 max-w-[260px] truncate" title={r.prove}>{r.prove}</td>
                <td className="px-3 py-2">{r.dependency}</td>
                <td className="px-3 py-2">
                  <div className="flex items-center gap-2">
                    <button className={`rounded-xl px-2 py-1 text-xs ${r.decision === true ? "text-white" : "border"}`} style={{ background: r.decision === true ? "var(--ms-teal)" : undefined }} onClick={() => updateRow(i, { decision: true })}>Accept</button>
                    <button className={`rounded-xl px-2 py-1 text-xs ${r.decision === false ? "text-white" : "border"}`} style={{ background: r.decision === false ? "var(--ms-orange)" : undefined }} onClick={() => updateRow(i, { decision: false })}>Later</button>
                    <button className="rounded-xl border px-2 py-1 text-xs" onClick={() => updateRow(i, { decision: null })}>Clear</button>
                  </div>
                </td>
                <td className="px-3 py-2 text-right">
                  <button className="rounded-lg px-2 py-1 text-xs text-white" style={{ background: "var(--ms-red)" }} onClick={() => removeRow(i)}>Delete</button>
                </td>
              </tr>
            ))}
            {filtered.length === 0 && (
              <tr>
                <td className="px-3 py-6 text-center text-gray-500" colSpan={10}>No rows match your search.</td>
              </tr>
            )}
          </tbody>
        </table>
      </div>

      {editing && (
        <RowEditor
          value={editing.value}
          onClose={() => setEditing(null)}
          onChange={(next) => {
            const updated = [...rows];
            updated[editing.idx] = next;
            onRowsChange(updated);
            setEditing(null);
          }}
        />
      )}
    </div>
  );
};

const Review = ({ data, onResetDecisions }) => {
  const flat = [
    ...data.objectives.map((r) => ({ ...r, section: "Mission Objectives" })),
    ...data.principles.map((r) => ({ ...r, section: "Mission Principles" })),
    ...data.guardrails.map((r) => ({ ...r, section: "Mission Guardrails" })),
    ...data.ground.map((r) => ({ ...r, section: "Mission Tooling" })),
  ];
  const accepted = flat.filter((r) => r.decision === true);
  const later = flat.filter((r) => r.decision === false);
  const pending = flat.filter((r) => r.decision === null);
  return (
    <div className="grid grid-cols-1 gap-4 lg:grid-cols-3">
      {[["Accepted", accepted, "var(--ms-teal)"],["Later", later, "var(--ms-orange)"],["Pending", pending, "var(--ms-blue)"]].map(([label, rows, color]) => (
        <div key={label} className="rounded-2xl border bg-white/70 p-4">
          <div className="mb-2 flex items-center justify-between">
            <h3 className="text-base font-semibold">{label}</h3>
            <span className="rounded-full px-2 py-1 text-xs text-white" style={{ background: color }}>{rows.length}</span>
          </div>
          <ul className="space-y-2">
            {rows.map((r) => (
              <li key={r.ref} className="rounded-xl border p-3 text-sm">
                <div className="mb-1 flex items-center justify-between">
                  <span className="font-medium">{r.ref} â€” {r.topic}</span>
                  <DecisionPill value={r.decision} />
                </div>
                <p className="text-xs text-gray-600">{r.section} â€¢ {r.theme}</p>
              </li>
            ))}
            {rows.length === 0 && (<li className="text-sm text-gray-500">Nothing here yet.</li>)}
          </ul>
        </div>
      ))}
      <div className="lg:col-span-3">
        <button className="rounded-xl px-3 py-2 text-sm text-white" style={{ background: "var(--ms-red)" }} onClick={onResetDecisions}>Reset all decisions</button>
      </div>
    </div>
  );
};


function ServiceConfig({ value, onChange }) {
  const [local, setLocal] = useState(value || {});
  const update = (path, v) => {
    const parts = path.split(".");
    const copy = JSON.parse(JSON.stringify(local || {}));
    let cur = copy;
    for (let i = 0; i < parts.length - 1; i++) {
      const k = parts[i];
      if (!cur[k] || typeof cur[k] !== "object") cur[k] = {};
      cur = cur[k];
    }
    cur[parts[parts.length-1]] = v;
    setLocal(copy);
  };
  const save = () => onChange(local);
  const arr = (a) => Array.isArray(a) ? a.join(", ") : (a || "");

  const opts = {
    backendLang: ["java17","python3.11","node18","go1.21"],
    backendFw:   ["spring-boot","fastapi","express","gin"],
    uiLang:      ["react18","angular16","vue3"],
    uiFw:        ["nextjs","cra","nuxt"],
    database:    ["postgres","mongodb","mysql","dynamodb"],
    migrate:     ["flyway","prisma","alembic","liquibase"],
    deploy:      ["rolling","blue-green","canary","feature-flag-only"],
    policies:    ["no-wildcard-iam","no-plaintext-internal","no-pii-in-logs","schema-compat","secure-dependencies"],
    cigates:     ["typecheck","unit","contract","property","sast","sbom","iac","schema-compat"]
  };

  return (
    <div className="rounded-2xl border bg-white/70 p-4 space-y-6">
      <h2 className="text-base font-semibold">Service Config (Mission-wide Defaults & Guardrails)</h2>
      <div className="space-y-3">
        <h3 className="text-sm font-semibold text-gray-700">Defaults (optional)</h3>
        <div className="grid gap-3 md:grid-cols-2">
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">Default Service Name</span>
            <input className="rounded-xl border px-3 py-2" placeholder="example-service"
              value={local?.default_service_name || ""}
              onChange={e=>update("default_service_name", e.target.value)} />
          </label>
          <div />
        </div>
        <div className="grid gap-3 md:grid-cols-2">
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">Default Backend Language</span>
            <input className="rounded-xl border px-3 py-2" list="opt-backend-lang" placeholder="e.g. java17"
              value={local?.default_backend_language || ""}
              onChange={e=>update("default_backend_language", e.target.value)} />
            <datalist id="opt-backend-lang">{opts.backendLang.map(o => <option key={o} value={o} />)}</datalist>
          </label>
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">Default Backend Framework</span>
            <input className="rounded-xl border px-3 py-2" list="opt-backend-fw" placeholder="e.g. spring-boot"
              value={local?.default_backend_framework || ""}
              onChange={e=>update("default_backend_framework", e.target.value)} />
            <datalist id="opt-backend-fw">{opts.backendFw.map(o => <option key={o} value={o} />)}</datalist>
          </label>
        </div>
        <div className="grid gap-3 md:grid-cols-2">
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">Default UI Language</span>
            <input className="rounded-xl border px-3 py-2" list="opt-ui-lang" placeholder="e.g. react18"
              value={local?.default_ui_language || ""}
              onChange={e=>update("default_ui_language", e.target.value)} />
            <datalist id="opt-ui-lang">{opts.uiLang.map(o => <option key={o} value={o} />)}</datalist>
          </label>
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">Default UI Framework</span>
            <input className="rounded-xl border px-3 py-2" list="opt-ui-fw" placeholder="e.g. nextjs"
              value={local?.default_ui_framework || ""}
              onChange={e=>update("default_ui_framework", e.target.value)} />
            <datalist id="opt-ui-fw">{opts.uiFw.map(o => <option key={o} value={o} />)}</datalist>
          </label>
        </div>
        <div className="grid gap-3 md:grid-cols-3">
          <label className="flex flex-col text-sm md:col-span-1">
            <span className="mb-1 text-gray-600">Default Database</span>
            <input className="rounded-xl border px-3 py-2" list="opt-db" placeholder="e.g. postgres"
              value={local?.default_database || ""}
              onChange={e=>update("default_database", e.target.value)} />
            <datalist id="opt-db">{opts.database.map(o => <option key={o} value={o} />)}</datalist>
          </label>
          <label className="flex flex-col text-sm md:col-span-2">
            <span className="mb-1 text-gray-600">Default Migration Tool</span>
            <input className="rounded-xl border px-3 py-2" list="opt-mig" placeholder="e.g. flyway"
              value={local?.default_migration_tool || ""}
              onChange={e=>update("default_migration_tool", e.target.value)} />
            <datalist id="opt-mig">{opts.migrate.map(o => <option key={o} value={o} />)}</datalist>
          </label>
        </div>
        <label className="flex items-center gap-2 text-sm">
          <input type="checkbox" checked={!!local?.default_outbox_enabled}
            onChange={e=>update("default_outbox_enabled", e.target.checked)} />
          <span>Default Outbox Enabled</span>
        </label>
      </div>

      <div className="space-y-3">
        <h3 className="text-sm font-semibold text-gray-700">Security (guardrails)</h3>
        <div className="grid gap-3 md:grid-cols-3">
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">AuthN</span>
            <input className="rounded-xl border px-3 py-2" placeholder="e.g. jwt"
              value={arr(local?.security?.authn)}
              onChange={e=>update("security.authn", e.target.value.split(",").map(s=>s.trim()).filter(Boolean))} />
          </label>
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">AuthZ</span>
            <input className="rounded-xl border px-3 py-2" placeholder="e.g. opa"
              value={arr(local?.security?.authz)}
              onChange={e=>update("security.authz", e.target.value.split(",").map(s=>s.trim()).filter(Boolean))} />
          </label>
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">CORS Allowlist (comma-separated)</span>
            <input className="rounded-xl border px-3 py-2" placeholder="https://app.example.com"
              value={arr(local?.security?.cors_allowlist)}
              onChange={e=>update("security.cors_allowlist", e.target.value.split(",").map(s=>s.trim()).filter(Boolean))} />
          </label>
        </div>
      </div>

      <div className="space-y-3">
        <h3 className="text-sm font-semibold text-gray-700">Observability (guardrails)</h3>
        <div className="grid gap-3 md:grid-cols-3">
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">Tracing</span>
            <input className="rounded-xl border px-3 py-2" placeholder="otel"
              value={local?.observability?.tracing || ""}
              onChange={e=>update("observability.tracing", e.target.value)} />
          </label>
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">Metrics</span>
            <input className="rounded-xl border px-3 py-2" placeholder="red"
              value={local?.observability?.metrics || ""}
              onChange={e=>update("observability.metrics", e.target.value)} />
          </label>
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">Logs</span>
            <input className="rounded-xl border px-3 py-2" placeholder="json"
              value={local?.observability?.logs || ""}
              onChange={e=>update("observability.logs", e.target.value)} />
          </label>
        </div>
      </div>

      <div className="space-y-3">
        <h3 className="text-sm font-semibold text-gray-700">NFR: SLOs</h3>
        <div className="grid gap-3 md:grid-cols-2">
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">http_p95_ms</span>
            <input className="rounded-xl border px-3 py-2" type="number"
              value={(Number(local?.nfr?.slo?.find(s=>s.name==='http_p95_ms')?.target) || "")}
              onChange={e=>{
                const val = e.target.value === "" ? "" : Number(e.target.value);
                const arr = (local?.nfr?.slo || []).filter(s=>s.name!=="http_p95_ms");
                arr.push({ name: "http_p95_ms", target: val });
                update("nfr.slo", arr);
              }} />
          </label>
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">error_rate</span>
            <input className="rounded-xl border px-3 py-2"
              value={(local?.nfr?.slo?.find(s=>s.name==='error_rate')?.target) ?? ""}
              onChange={e=>{
                const arr = (local?.nfr?.slo || []).filter(s=>s.name!=="error_rate");
                arr.push({ name: "error_rate", target: e.target.value });
                update("nfr.slo", arr);
              }} />
          </label>
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">availability</span>
            <input className="rounded-xl border px-3 py-2"
              value={(local?.nfr?.slo?.find(s=>s.name==='availability')?.target) ?? ""}
              onChange={e=>{
                const arr = (local?.nfr?.slo || []).filter(s=>s.name!=="availability");
                arr.push({ name: "availability", target: e.target.value });
                update("nfr.slo", arr);
              }} />
          </label>
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">throughput_rps (optional)</span>
            <input className="rounded-xl border px-3 py-2"
              value={(local?.nfr?.slo?.find(s=>s.name==='throughput_rps')?.target) ?? ""}
              onChange={e=>{
                const arr = (local?.nfr?.slo || []).filter(s=>s.name!=="throughput_rps");
                arr.push({ name: "throughput_rps", target: e.target.value });
                update("nfr.slo", arr);
              }} />
          </label>
        </div>
      </div>

      <div className="space-y-3">
        <h3 className="text-sm font-semibold text-gray-700">NFR: Resilience</h3>
        <div className="grid gap-3 md:grid-cols-3">
          <label className="flex items-center gap-2 text-sm">
            <input type="checkbox" checked={!!local?.nfr?.resilience?.circuit_breaker}
              onChange={e=>update("nfr.resilience.circuit_breaker", e.target.checked)} />
            <span>Circuit Breaker</span>
          </label>
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">Idempotency Policy</span>
            <select className="rounded-xl border px-3 py-2"
              value={local?.nfr?.resilience?.idempotency_policy || "mutations_required"}
              onChange={e=>update("nfr.resilience.idempotency_policy", e.target.value)}>
              <option value="mutations_required">mutations_required</option>
              <option value="recommended">recommended</option>
              <option value="off">off</option>
            </select>
          </label>
          <div className="grid gap-2">
            <label className="flex flex-col text-sm">
              <span className="mb-1 text-gray-600">Retries (max)</span>
              <input className="rounded-xl border px-3 py-2" type="number"
                value={(local?.nfr?.resilience?.retries?.max) ?? 0}
                onChange={e=>update("nfr.resilience.retries.max", Number(e.target.value))} />
            </label>
            <label className="flex flex-col text-sm">
              <span className="mb-1 text-gray-600">Retries (strategy)</span>
              <input className="rounded-xl border px-3 py-2" placeholder="exponential-jitter"
                value={(local?.nfr?.resilience?.retries?.strategy) ?? ""}
                onChange={e=>update("nfr.resilience.retries.strategy", e.target.value)} />
            </label>
          </div>
        </div>
      </div>

      <div className="space-y-3">
        <h3 className="text-sm font-semibold text-gray-700">Governance, CI/CD & Deploy</h3>
        <div className="grid gap-3 md:grid-cols-2">
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">Governance: Lineage</span>
            <input className="rounded-xl border px-3 py-2" placeholder="required"
              value={local?.governance?.lineage || ""}
              onChange={e=>update("governance.lineage", e.target.value)} />
          </label>
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">Default Deploy Strategy</span>
            <input className="rounded-xl border px-3 py-2" list="opt-deploy" placeholder="e.g. canary"
              value={local?.deploy?.default_strategy || ""}
              onChange={e=>update("deploy.default_strategy", e.target.value)} />
            <datalist id="opt-deploy">{opts.deploy.map(o => <option key={o} value={o} />)}</datalist>
          </label>
        </div>
        <label className="flex items-center gap-2 text-sm">
          <input type="checkbox" checked={!!local?.deploy?.feature_flags}
            onChange={e=>update("deploy.feature_flags", e.target.checked)} />
          <span>Default Feature Flags Enabled</span>
        </label>
        <label className="flex flex-col text-sm">
          <span className="mb-1 text-gray-600">Policy Packs (comma-separated or custom)</span>
          <input className="rounded-xl border px-3 py-2" list="opt-policies" placeholder="no-wildcard-iam, no-pii-in-logs"
            value={arr(local?.governance?.policy_packs)}
            onChange={e=>update("governance.policy_packs", e.target.value.split(",").map(s=>s.trim()).filter(Boolean))} />
          <datalist id="opt-policies">{opts.policies.map(o => <option key={o} value={o} />)}</datalist>
        </label>
        <label className="flex flex-col text-sm">
          <span className="mb-1 text-gray-600">CI Gates (comma-separated or custom)</span>
          <input className="rounded-xl border px-3 py-2" list="opt-cigates" placeholder="typecheck, unit, ..."
            value={arr(local?.ci?.gates)}
            onChange={e=>update("ci.gates", e.target.value.split(",").map(s=>s.trim()).filter(Boolean))} />
          <datalist id="opt-cigates">{opts.cigates.map(o => <option key={o} value={o} />)}</datalist>
        </label>
        <label className="flex flex-col text-sm">
          <span className="mb-1 text-gray-600">Default Owner (optional)</span>
          <input className="rounded-xl border px-3 py-2" placeholder="team-trade"
            value={local?.ownership?.owner || ""}
            onChange={e=>update("ownership.owner", e.target.value)} />
        </label>
      </div>

      <div className="flex gap-2 pt-2">
        <button className="rounded-xl border px-3 py-1" onClick={()=>setLocal(value)}>Reset</button>
        <button className="rounded-xl px-3 py-1 text-white" style={{ background: "var(--ms-teal)" }} onClick={save}>Save</button>
      </div>
    </div>
  );
}


function MissionInfo({ value, onChange }) {
  const update = (k, v) => onChange({ ...value, [k]: v });
  return (
    <div className="rounded-2xl border bg-white/70 p-4 space-y-4">
      <h2 className="text-base font-semibold">Mission Information</h2>
      {[["title","Mission Title"],["sponsor","Sponsor"],["owner","Owner"],["stakeholders","Stakeholders"],["version","Version"],["description","Description"],["date","Date"]].map(([key, label]) => (
        <label key={key} className="flex flex-col text-sm">
          <span className="mb-1 text-gray-600">{label}</span>
          <input
            className="rounded-xl border px-3 py-2 focus:outline-none focus:ring-2 focus:ring-teal-500"
            value={value?.[key] ?? ""}
            onChange={(e) => update(key, e.target.value)}
          />
        </label>
      ))}
    </div>
  );
}

/********************
 * Main App
 ********************/
function MissionSmithApp() {
  const [section, setSection] = useState("info");
  const [data, setData] = useState(initialData);

  
  
  useEffect(() => { window.__ms_data = data; window.__ms_getData = () => data; }, [data]);
useEffect(() => { window.__ms_data = data; window.__ms_getData = () => data; }, [data]);
const progress = useMemo(() => {
    const all = [...data.objectives, ...data.principles, ...data.guardrails, ...data.ground];
    const decided = all.filter((r) => r.decision !== null).length;
    return all.length ? decided / all.length : 0;
  }, [data]);

  const onRowsChange = (key, next) => setData((p) => ({ ...p, [key]: next }));

  const exportJSON = () => {
    const blob = new Blob([JSON.stringify(data, null, 2)], { type: "application/json" });
    const url = URL.createObjectURL(blob);
    const a = document.createElement("a");
    a.href = url;
    a.download = `missionsmith-framework.json`;
    a.click();
    URL.revokeObjectURL(url);
  };

  const exportCSVHandler = () => exportCSV(data);

  
  // CSV Export helpers (flat table across all sections)
  const CSV_HEADERS = ["ref","category","theme","topic","codify","automate","intercept","prove","dependency","status","user_notes","decision"];
  function toCSVRow(obj){
    function esc(v){
      const s = (v === null || v === undefined) ? "" : String(v);
      const needsQuote = /[",\n]/.test(s);
      const out = s.replace(/"/g,'""');
      return needsQuote ? "\"" + out + "\"" : out;
    }
    return CSV_HEADERS.map(h => {
      if (h === "decision") {
        return esc(obj.decision === true ? "Accepted" : obj.decision === false ? "Later" : "Pending");
      }
      return esc(obj[h] ?? "");
    }).join(",");
  }
  function exportCSV(data){
    const flat = [
      ...data.objectives.map(r => ({...r})),
      ...data.principles.map(r => ({...r})),
      ...data.guardrails.map(r => ({...r})),
      ...data.ground.map(r => ({...r})),
    ];
    const header = CSV_HEADERS.join(",");
    const rows = flat.map(toCSVRow);
    const csv = [header, ...rows].join("\n");
    const blob = new Blob([csv], { type: "text/csv;charset=utf-8" });
    const url = URL.createObjectURL(blob);
    const a = document.createElement("a");
    a.href = url;
    a.download = "missionsmith-framework.csv";
    a.click();
    URL.revokeObjectURL(url);
  }
const importJSON = () => {
    const input = document.createElement("input");
    input.type = "file";
    input.accept = ".json,application/json";
    input.onchange = (e) => {
      const file = e.target.files?.[0];
      if (!file) return;
      const reader = new FileReader();
      reader.onload = () => {
        try {
          const parsed = JSON.parse(String(reader.result));
          setData((p) => ({ ...p, ...parsed }));
          alert("Imported JSON successfully.");
        } catch (err) {
          alert("Invalid JSON file.");
        }
      };
      reader.readAsText(file);
    };
    input.click();
  };

  const importCSV = () => {
    const input = document.createElement("input");
    input.type = "file";
    input.accept = ".csv,text/csv";
    input.onchange = (e) => {
      const file = e.target.files?.[0];
      if (!file) return;
      const reader = new FileReader();
      reader.onload = () => {
        const text = String(reader.result);
        const { rows } = parseCSVSimple(text);

        const buckets = { objectives: [], principles: [], guardrails: [], ground: [] };
        for (const r of rows) {
          const item = {
            ref: r.ref || r.Ref || `CSV-${Math.random().toString(36).slice(2, 6).toUpperCase()}`,
            category: r.category || r.Category || "",
            theme: r.theme || r.Theme || "",
            topic: r.topic || r.Topic || "",
            codify: r.codify || r.Codify || "",
            automate: r.automate || r.Automate || "",
            intercept: r.intercept || r.Intercept || "",
            prove: r.prove || r.Prove || "",
            dependency: r.dependency || r.Dependency || "N/A",
            status: r.status || r.Status || "proposed",
            user_notes: r.user_notes || r.Notes || r.UserNotes || "",
            decision: null,
          };
          const cat = (item.category || "").toLowerCase();
          if (cat.includes("objective")) buckets.objectives.push(item);
          else if (cat.includes("principle")) buckets.principles.push(item);
          else if (cat.includes("guardrail")) buckets.guardrails.push(item);
          else if (cat.includes("ground")) buckets.ground.push(item);
        }
        setData((p) => ({
          objectives: buckets.objectives.length ? buckets.objectives : p.objectives,
          principles: buckets.principles.length ? buckets.principles : p.principles,
          guardrails: buckets.guardrails.length ? buckets.guardrails : p.guardrails,
          ground: buckets.ground.length ? buckets.ground : p.ground,
        }));
        alert("Imported CSV rows into the matching sections.");
      };
      reader.readAsText(file);
    };
    input.click();
  };

  const resetDecisions = () => {
    const reset = (arr) => arr.map((r) => ({ ...r, decision: null }));
    setData((p) => ({
      objectives: reset(p.objectives),
      principles: reset(p.principles),
      guardrails: reset(p.guardrails),
      ground: reset(p.ground),
    }));
  };

  return (
    <div className="min-h-dvh bg-gray-50">
      <style>{`
        :root{
          --ms-teal:   rgb(26,153,136);
          --ms-blue:   rgb(106,164,200);
          --ms-orange: rgb(235,86,0);
          --ms-mint:   rgb(162,255,232);
          --ms-red:    rgb(255,0,0);
        }
      `}</style>

      <TopBar onImportJSON={importJSON} progress={progress} />

      <main className="mx-auto grid max-w-7xl grid-cols-1 gap-4 px-4 pb-8 pt-4 sm:grid-cols-[260px_1fr]">
        <Sidebar section={section} setSection={setSection} />

        <div className="space-y-4">
          {section === "info" && (<MissionInfo value={data.missionInfo} onChange={(val) => setData((p) => ({ ...p, missionInfo: val }))} />)}
{section === "service" && (<ServiceConfig value={data.serviceConfig} onChange={(val) => setData((p) => ({ ...p, serviceConfig: val }))} />)}
          {section === "objectives" && (<SectionTable title="Mission Objectives" rows={data.objectives} onRowsChange={(rows) => onRowsChange("objectives", rows)} />)}
          {section === "principles" && (<SectionTable title="Mission Principles" rows={data.principles} onRowsChange={(rows) => onRowsChange("principles", rows)} />)}
          {section === "guardrails" && (<SectionTable title="Mission Guardrails" rows={data.guardrails} onRowsChange={(rows) => onRowsChange("guardrails", rows)} />)}
          {section === "ground" && (<SectionTable title="Mission Tooling" rows={data.ground} onRowsChange={(rows) => onRowsChange("ground", rows)} allowAdd />)}
          {section === "review" && (<Review data={data} onResetDecisions={resetDecisions} />)}
        </div>
      </main>
    </div>
  );
}

    const root = ReactDOM.createRoot(document.getElementById('root'));
    root.render(<MissionSmithApp />);
  </script>

<script>
window.MS_actions = (function(){
  const download = (filename, text, type) => {
    const blob = new Blob([text], {type});
    const a = document.createElement("a");
    a.href = URL.createObjectURL(blob);
    a.download = filename;
    a.click();
    setTimeout(()=>URL.revokeObjectURL(a.href), 200);
  };

  const acceptedOnly = (arr = []) => (arr||[]).filter(x => {
  const d = x && x.decision;
  if (d === true) return true;
  if (typeof d === 'string') {
    const s = d.trim().toLowerCase();
    if (s === 'accepted' || s === 'accept' || s === 'true' || s === 'yes' || s === 'y') return true;
  }
  if (typeof d === 'number' && d === 1) return true;
  const s2 = x && (x.status || x.accepted);
  return (typeof s2 === 'string' && s2.toLowerCase() === 'accepted');
});

  const deriveAccepted = (data = {}) => ({
  objectives: acceptedOnly(data.objectives || []),
  principles: acceptedOnly(data.principles  || []),
  guardrails: acceptedOnly(data.guardrails  || []),
  ground:     acceptedOnly((data.ground || data.tooling || []) )
});

  const mdList = (title, items) =>
    items.length ? `\n## ${title}\n` + items.map(i=>`- **${i.name || i.id || "item"}**${i.description ? ` â€” ${i.description}` : ""}`).join("\n") + "\n" : "";

  const missionTitle = (data) => (data?.missionInfo?.title || "Mission").replace(/[^\w\-]+/g,"_");
  const getData = () => (typeof window.__ms_getData === 'function' ? window.__ms_getData() : (window.__ms_data || window.data || window.initialData || {}));

  const buildAgentsMd = (data) => {
  const acc = deriveAccepted(data);

  const section = (title, rows) => {
    if (!rows || !rows.length) return "";
    const blocks = rows.map(r => {
      const lines = [
        `- **${r.ref || r.id || ""} â€” ${r.topic || r.purpose || ""}** *(Theme: ${r.theme || ""}; Category: ${r.category || ""})*`,
        `  - Codify: ${r.codify || ""}`,
        `  - Automate: ${r.automate || ""}`,
        `  - Intercept: ${r.intercept || ""}`,
        `  - Prove: ${r.prove || ""}`,
        `  - Dependency: ${r.dependency || ""}`,
        `  - Notes: ${r.user_notes || r.notes || ""}`,
      ];
      return lines.join("\n");
    }).join("\n");
    return `\n## ${title}\n${blocks}\n`;
  };

  let md = `# Agents Charter â€” ${data?.missionInfo?.title || "Mission"}\n`;
  md += `\n> Generated from accepted items in Objectives, Principles, Guardrails and Tooling.\n`;
  md += section("Objectives", acc.objectives);
  md += section("Principles", acc.principles);
  md += section("Guardrails", acc.guardrails);
  md += section("Tooling", acc.ground);
  md += `\n---\nGenerated by MissionSmith\n`;
  return md;
};

  const buildPipelineYml = (data) => {
    const acc = deriveAccepted(data);
    const hasCIGuardrail = acc.guardrails.some(g => /ci|pipeline/i.test((g.name||"")+ " " + (g.description||"")));
    const gates = hasCIGuardrail ? (data?.serviceConfig?.ci?.gates || []) : [];
    const steps = gates.map(g => `      - name: ${g}\n        run: echo "Running ${g} gate"\n`).join("");
    return `name: pipeline\non: [push, pull_request]\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n${steps || '      - run: echo "No accepted CI gates configured"'}\n`;
  };

  const buildPolicyBundleTxt = (data) => {
    const acc = deriveAccepted(data);
    const hasPolicy = acc.guardrails.some(g => /policy/i.test((g.name||"")+ " " + (g.description||"")));
    const packs = hasPolicy ? (data?.serviceConfig?.governance?.policy_packs || []) : [];
    return packs.length ? packs.map(p=>`- ${p}`).join("\n") : "No accepted policy packs.";
  };

  const buildDeployPlan = (data) => {
    const acc = deriveAccepted(data);
    const hasDeploy = acc.guardrails.some(g => /deploy|release|rollout/i.test((g.name||"")+ " " + (g.description||"")));
    const sc = data?.serviceConfig?.deploy || {};
    return `strategy: ${hasDeploy ? (sc.default_strategy || "") : "UNSET (no accepted deploy guardrail)"}\nfeature_flags: ${!!sc.feature_flags}\n`;
  };

  const buildDashboards = (data) => {
    const acc = deriveAccepted(data);
    const hasSLO = acc.guardrails.some(g => /slo|observability|latency|error rate|availability/i.test((g.name||"")+ " " + (g.description||"")));
    const slos = hasSLO ? (data?.serviceConfig?.nfr?.slo || []) : [];
    if (!slos.length) return "# No accepted SLOs";
    return "panels:\n" + slos.map(s => `- title: ${s.name}\n  target: ${s.target}`).join("\n");
  };

  const buildLineage = (data) => {
    const acc = deriveAccepted(data);
    const hasLineage = acc.guardrails.some(g => /lineage|audit|governance/i.test((g.name||"")+ " " + (g.description||"")));
    if (!hasLineage) return JSON.stringify({ enabled:false, reason:"No accepted lineage guardrail" }, null, 2);
    const sc = data?.serviceConfig || {};
    return JSON.stringify({
      enabled: true,
      mission: data?.missionInfo?.title || "Mission",
      defaults: {
        backend: [sc.default_backend_language, sc.default_backend_framework].filter(Boolean).join(" + "),
        ui: [sc.default_ui_language, sc.default_ui_framework].filter(Boolean).join(" + "),
        database: sc.default_database || "",
        outbox: !!sc.default_outbox_enabled
      }
    }, null, 2);
  };

  return {
    generateJSON(){ const d=getData(); download(`${missionTitle(d)}.json`, JSON.stringify(d,null,2), "application/json"); },
    generateAgents(){ try{ const md = buildAgentsMd(getData()); if(!md || !md.trim()){ alert("Agents file is empty."); return; } download("agents.md", md, "text/markdown"); } catch(e){ console.error(e); alert("Failed to build agents.md"); } },
    generateScaffold(){
      try {
        const d = getData();
        const sc = d?.serviceConfig || {};
        const backend = [sc.default_backend_language, sc.default_backend_framework].filter(Boolean).join(" + ") || "(unset)";
        const ui      = [sc.default_ui_language, sc.default_ui_framework].filter(Boolean).join(" + ") || "(unset)";
        const dbLine  = `${sc.default_database || "(unset)"}; Migrations: ${sc.default_migration_tool || "(unset)"}; Outbox: ${!!sc.default_outbox_enabled}`;
        const secLine = JSON.stringify(sc.security || {});
        const obsLine = JSON.stringify(sc.observability || {});
        const lines = [
          `# Service Scaffold Plan â€” ${d?.missionInfo?.title || "Mission"}`,
          `Backend default: ${backend}`,
          `UI default: ${ui}`,
          `Database: ${dbLine}`,
          `Security: ${secLine}`,
          `Observability: ${obsLine}`,
          ``,
          `---`,
          `Generated by MissionSmith`
        ];
        download('service-scaffold-plan.md', lines.join('\n'), 'text/markdown');
      } catch (e) {
        console.error('generateScaffold failed', e);
        alert('Failed to build service-scaffold-plan.md');
      }
    },
    generateCICD(){ download("pipeline.yml", buildPipelineYml(getData()), "text/yaml"); },
    generatePolicies(){ download("policy-packs.txt", buildPolicyBundleTxt(getData()), "text/plain"); },
    generateDeploy(){ download("deploy-manifests-plan.yaml", buildDeployPlan(getData()), "text/yaml"); },
    generateDashboards(){ download("dashboards-alerts.yaml", buildDashboards(getData()), "text/yaml"); },
    generateLineage(){ download("lineage.json", buildLineage(getData()), "application/json"); }
  };
})();
</script>


<script>
(function(){
  function show(msg, src, line, col){
    const el = document.createElement('div');
    el.style.position='fixed'; el.style.left=0; el.style.right=0; el.style.bottom=0;
    el.style.background='rgba(220,38,38,0.95)'; el.style.color='#fff'; el.style.fontFamily='ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace';
    el.style.whiteSpace='pre-wrap'; el.style.maxHeight='40vh'; el.style.overflow='auto'; el.style.padding='12px 16px'; el.style.zIndex=99999;
    el.textContent = 'MissionSmith runtime error:\n' + msg + (src ? ('\n@ ' + src + ':' + line + ':' + col) : '');
    document.body.appendChild(el);
  }
  window.addEventListener('error', e => show(e.message, e.filename, e.lineno, e.colno));
  window.addEventListener('unhandledrejection', e => show(String(e.reason || 'Unhandled promise rejection')));
})();
</script>


<script>
(function(){
  function show(msg, src, line, col){
    const el = document.createElement('div');
    el.style.position='fixed'; el.style.left=0; el.style.right=0; el.style.bottom=0;
    el.style.background='rgba(220,38,38,0.95)'; el.style.color='#fff'; el.style.fontFamily='ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace';
    el.style.whiteSpace='pre-wrap'; el.style.maxHeight='40vh'; el.style.overflow='auto'; el.style.padding='12px 16px'; el.style.zIndex=99999;
    el.textContent = 'MissionSmith runtime error:\n' + msg + (src ? ('\n@ ' + src + ':' + line + ':' + col) : '');
    document.body.appendChild(el);
  }
  window.addEventListener('error', e => show(e.message, e.filename, e.lineno, e.colno));
  window.addEventListener('unhandledrejection', e => show(String(e.reason || 'Unhandled promise rejection')));
})();
</script>


<script>
(function(){
  function wireFrameworkButtons(){
    var hdr = document.querySelector('header.sticky.top-0');
    if(!hdr) return;
    var right = hdr.querySelector('.flex.items-center.gap-2');
    if(!right) return;

    // 1) Ensure Import button label
    var importBtn = right.querySelector('button');
    if(importBtn){
      var txt = (importBtn.textContent || '').trim().toLowerCase();
      if(txt.includes('import')){
        importBtn.textContent = 'Import Mission Framework';
      }
      // keep existing onClick handler (importJSON) intact
    }

    // 2) Inject Export button if not present
    if(!right.querySelector('.msx-framework-btn')){
      var exp = document.createElement('button');
      exp.className = 'msx-framework-btn';
      exp.textContent = 'Export Mission Framework';
      exp.addEventListener('click', function(){
        try {
          if (window.exportJSON) { window.exportJSON(); return; }
          if (window.MS_actions && typeof window.MS_actions.generateJSON === 'function') {
            window.MS_actions.generateJSON(); return;
          }
          console.warn('No export function found');
        } catch(e){ console.error(e); }
      });
      right.prepend(exp);
    }
  }
  document.addEventListener('DOMContentLoaded', wireFrameworkButtons);
  // Re-apply if React re-renders
  new MutationObserver(wireFrameworkButtons).observe(document.body, {childList:true, subtree:true});
})();
</script>


<!-- === Integrated CI/CD Generator v1.2 (no new screens) === -->
<script>
(function(){
  // --- Utilities ---
  function str(v){ return (v==null?'':String(v)); }
  function val(obj, path, fallback){
    try{
      return path.split('.').reduce((o,k)=> (o && (k in o) ? o[k] : undefined), obj) ?? fallback;
    }catch(_){ return fallback; }
  }
  function toProfile(sc){
    const lang = (str(sc.default_backend_language)).toLowerCase();
    if (/java/.test(lang)) return "java-maven";
    if (/python/.test(lang)) return "python-pytest";
    if (/node|javascript|ts|typescript/.test(lang)) return "node-npm";
    if (/go/.test(lang)) return "go";
    if (/dotnet|csharp/.test(lang)) return "dotnet";
    return "java-maven"; // default
  }
  function toGates(arr){
    if (Array.isArray(arr) && arr.length) return arr.map(x=>String(x).trim()).filter(Boolean);
    return "lint, unit, contract, integration, sast, sbom, iac, schema-compat, docker-scan, policy, sign"
      .split(',').map(s=>s.trim());
  }
  function registryDefault(sc){
    const r = str(sc.default_registry || "").trim();
    return r || "ghcr.io/OWNER/REPO";
  }

  // --- Generators (from LaunchPad v1.2) ---
  function genBuildTest(profile, gates){
    const has = t => gates.includes(t);
    const isJava = profile==='java-maven';
    const isNode = profile==='node-npm';
    const isPy   = profile==='python-pytest';
    let setup='';
    if(isJava) setup = "\n      - uses: actions/setup-java@v4\n        with:\n          distribution: temurin\n          java-version: '21'\n";
    if(isNode) setup = "\n      - uses: actions/setup-node@v4\n        with:\n          node-version: '20'\n";
    if(isPy)   setup = "\n      - uses: actions/setup-python@v5\n        with:\n          python-version: '3.11'\n";
    let lint='';
    if(has('lint')){
      if(isJava) lint = "      - name: Lint (Maven)\n        run: |\n          mvn -B -ntp -DskipTests=true spotless:check || true\n          mvn -B -ntp -DskipTests=true checkstyle:check || true\n";
      if(isNode) lint = "      - name: Lint (ESLint)\n        run: |\n          npm ci\n          npx eslint . || true\n";
      if(isPy)   lint = "      - name: Lint (flake8)\n        run: |\n          python -m pip install --upgrade pip\n          pip install flake8\n          flake8 . || true\n";
    }
    let tests='';
    if(has('unit') || has('integration')){
      if(isJava) tests = "      - name: Maven test (unit + integration)\n        run: mvn -B -ntp -DskipITs=false test\n";
      if(isNode) tests = "      - name: Node tests\n        run: |\n          npm ci\n          npm test --if-present\n";
      if(isPy)   tests = "      - name: PyTest\n        run: |\n          python -m pip install --upgrade pip\n          pip install -r requirements.txt || true\n          pytest -q --maxfail=1 --disable-warnings --junitxml=test-results/python-junit.xml\n";
    }
    const contract = has('contract')
      ? "      - name: Pact verify (if contracts present)\n        if: ${{ hashFiles('**/contracts/**') != '' }}\n        run: mvn -B -ntp pact:verify || echo \'No contracts\'\n" : "";
    const compat = has('schema-compat')
      ? "      - name: Schema compatibility check (if schemas present)\n        if: ${{ hashFiles('**/schemas/**') != '' }}\n        run: echo \'Implement your Avro/JSON compat check here\'\n" : "";

    return "name: ci-cd\n\non: [push, pull_request]\n\npermissions:\n  contents: read\n  packages: write\n  security-events: write\n\njobs:\n  build-test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4" + setup + lint + tests + contract + compat +
      "      - name: Upload test results\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v4\n        with:\n          name: test-results\n          path: |\n            **/target/surefire-reports/*.xml\n            **/target/failsafe-reports/*.xml\n            test-results/**/*.xml\n          if-no-files-found: ignore\n";
  }

  function genSecurity(gates){
    const has = t => gates.includes(t);
    let y = "name: security\n\non: [push, pull_request]\n\npermissions:\n  contents: read\n  security-events: write\n  packages: write\n\njobs:\n  security:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n";
    if(has('sast')) y += "      - name: Semgrep SAST\n        uses: returntocorp/semgrep-action@v1\n        with:\n          config: p/owasp-top-ten\n          generateSarif: true\n";
    if(has('docker-scan') || has('sbom') || has('sign')) y += "      - name: Set up Buildx\n        uses: docker/setup-buildx-action@v3\n      - name: Build image (no push)\n        uses: docker/build-push-action@v6\n        with:\n          context: .\n          push: false\n          load: true\n          tags: local/app:ci\n          provenance: false\n";
    if(has('docker-scan')) y += "      - name: Trivy image scan\n        uses: aquasecurity/trivy-action@0.28.0\n        with:\n          image-ref: local/app:ci\n          format: table\n          exit-code: '1'\n          ignore-unfixed: true\n";
    if(has('sbom')) y += "      - name: SBOM (Syft)\n        uses: anchore/sbom-action@v0\n        with:\n          image: local/app:ci\n          artifact-name: sbom.spdx.json\n";
    if(has('sign')) y += "      - name: Install Cosign\n        uses: sigstore/cosign-installer@v3.7.0\n      - name: Cosign sign (optional)\n        if: ${{ secrets.COSIGN_KEY != '' }}\n        env:\n          COSIGN_EXPERIMENTAL: '1'\n          COSIGN_PASSWORD: ${{ secrets.COSIGN_PASSWORD }}\n        run: |\n          printf \"%s\" \"${{ secrets.COSIGN_KEY }}\" > cosign.key\n          cosign sign --key cosign.key local/app:ci\n";
    y += "      - name: Upload security artefacts\n        uses: actions/upload-artifact@v4\n        with:\n          name: security\n          path: |\n            semgrep.sarif\n            sbom.spdx.json\n          if-no-files-found: ignore\n";
    return y;
  }

  function genIaC(gates){
    const has = t => gates.includes(t);
    let y = "name: iac-policy\n\non: [push, pull_request]\n\npermissions:\n  contents: read\n\njobs:\n  iac-policy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n";
    if(has('iac')) y += "      - name: Terraform fmt/validate/plan\n        if: ${{ hashFiles('**/*.tf') != '' }}\n        run: |\n          terraform -version || (curl -fsSL https://releases.hashicorp.com/terraform/1.9.5/terraform_1.9.5_linux_amd64.zip -o tf.zip && sudo unzip -o tf.zip -d /usr/local/bin)\n          terraform -chdir=infra fmt -check\n          terraform -chdir=infra init -input=false\n          terraform -chdir=infra validate\n          terraform -chdir=infra plan -input=false -lock=false -out=tfplan\n";
    if(has('policy')) y += "      - name: conftest policy check\n        if: ${{ hashFiles('policy/**.rego') != '' }}\n        uses: instrumenta/conftest-action@v0.3.0\n        with:\n          files: |\n            infra/**/*.tf\n            deploy/**/*.yaml\n";
    return y;
  }

  function genPackagePublish(registry){
    return "name: package-publish\non:\n  push:\n    branches: [ \"main\" ]\n  workflow_dispatch: {}\n\npermissions:\n  contents: read\n  packages: write\n\nenv:\n  REGISTRY: " + registry + "\n  IMAGE_SHA: " + registry + ":${{ github.sha }}\n  IMAGE_MAIN: " + registry + ":main\n\njobs:\n  build-push-sign:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: docker/setup-qemu-action@v3\n      - uses: docker/setup-buildx-action@v3\n      - uses: docker/login-action@v3\n        with:\n          registry: ghcr.io\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n      - name: Build & push (sha)\n        uses: docker/build-push-action@v6\n        with:\n          context: .\n          push: true\n          tags: ${{ env.IMAGE_SHA }}\n          provenance: false\n      - name: Build & push (main)\n        uses: docker/build-push-action@v6\n        with:\n          context: .\n          push: true\n          tags: ${{ env.IMAGE_MAIN }}\n          provenance: false\n      - name: Install Cosign\n        uses: sigstore/cosign-installer@v3.7.0\n      - name: Cosign sign (sha)\n        if: ${{ secrets.COSIGN_KEY != '' }}\n        env:\n          COSIGN_EXPERIMENTAL: \"1\"\n          COSIGN_PASSWORD: ${{ secrets.COSIGN_PASSWORD }}\n        run: |\n          printf \"%s\" \"${{ secrets.COSIGN_KEY }}\" > cosign.key\n          cosign sign --key cosign.key ${{ env.IMAGE_SHA }}\n      - name: Cosign sign (main)\n        if: ${{ secrets.COSIGN_KEY != '' }}\n        env:\n          COSIGN_EXPERIMENTAL: \"1\"\n          COSIGN_PASSWORD: ${{ secrets.COSIGN_PASSWORD }}\n        run: |\n          printf \"%s\" \"${{ secrets.COSIGN_KEY }}\" > cosign.key\n          cosign sign --key cosign.key ${{ env.IMAGE_MAIN }}\n";
  }

  function genPromoteDeploy(){
    return "name: promote-deploy\non:\n  workflow_dispatch:\n    inputs:\n      image:\n        description: \"Image to deploy (e.g., ghcr.io/owner/repo:sha)\"\n        required: false\n      envs:\n        description: \"Comma-separated envs to deploy (dev,staging,prod)\"\n        required: false\n        default: \"dev,staging,prod\"\n  push:\n    branches: [ \"main\" ]\n\npermissions:\n  contents: read\n  packages: read\n\nenv:\n  DEFAULT_IMAGE: ghcr.io/${{ github.repository }}:${{ github.sha }}\n  NAMESPACE: default\n  CANARY_REPLICAS: 1\n  STABLE_PERCENT: 90\n\njobs:\n  matrix-setup:\n    runs-on: ubuntu-latest\n    outputs:\n      envs: ${{ steps.mk.outputs.envs }}\n    steps:\n      - id: mk\n        run: |\n          IN=\"${{ github.event.inputs.envs }}\"\n          if [ -z \"$IN\" ]; then IN=\"dev,staging,prod\"; fi\n          echo \"envs=$(printf '[%s]' \\\"$(echo \\\"$IN\\\" | sed 's/,/","/g' | sed 's/^/\\\"/;s/$/\\\"/')\\\")\" >> $GITHUB_OUTPUT\n\n  deploy:\n    needs: matrix-setup\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        env: ${{ fromJson(needs.matrix-setup.outputs.envs) }}\n    environment: ${{ matrix.env }}\n    steps:\n      - uses: actions/checkout@v4\n      - name: Choose image\n        id: img\n        run: |\n          IMG=\"${{ github.event.inputs.image }}\"\n          if [ -z \"$IMG\" ]; then IMG=\"${{ env.DEFAULT_IMAGE }}\"; fi\n          echo \"image=$IMG\" >> $GITHUB_OUTPUT\n      - name: Install Cosign\n        uses: sigstore/cosign-installer@v3.7.0\n      - name: Verify image signature\n        env:\n          COSIGN_EXPERIMENTAL: \"1\"\n          COSIGN_PUBLIC_KEY: ${{ secrets.COSIGN_PUBLIC_KEY }}\n        run: |\n          if [ -z \"$COSIGN_PUBLIC_KEY\" ]; then\n            echo \"Missing COSIGN_PUBLIC_KEY; refusing to deploy unsigned/unverified image\" >&2\n            exit 1\n          fi\n          printf \"%s\" \"$COSIGN_PUBLIC_KEY\" > cosign.pub\n          cosign verify --key cosign.pub \"${{ steps.img.outputs.image }}\"\n      - name: Set kubeconfig\n        id: kube\n        run: |\n          ENV=\"${{ matrix.env }}\"\n          KC_VAR=\"KUBE_CONFIG_\${ENV^^}\"\n          KCONF=\"${!KC_VAR}\"\n          if [ -z \"$KCONF\" ]; then\n            echo \"Kubeconfig secret $KC_VAR is not set\" >&2\n            exit 1\n          fi\n          if echo \"$KCONF\" | grep -q \"apiVersion: v1\"; then\n            printf \"%s\" \"$KCONF\" > $HOME/.kubeconfig\n          else\n            printf \"%s\" \"$KCONF\" | base64 -d > $HOME/.kubeconfig\n          fi\n          echo \"KUBECONFIG=$HOME/.kubeconfig\" >> $GITHUB_ENV\n        env:\n          KUBE_CONFIG_DEV: ${{ secrets.KUBE_CONFIG_DEV }}\n          KUBE_CONFIG_STAGING: ${{ secrets.KUBE_CONFIG_STAGING }}\n          KUBE_CONFIG_PROD: ${{ secrets.KUBE_CONFIG_PROD }}\n      - name: Install kubectl\n        run: |\n          curl -fsSL https://storage.googleapis.com/kubernetes-release/release/v1.30.5/bin/linux/amd64/kubectl -o kubectl\n          chmod +x kubectl && sudo mv kubectl /usr/local/bin/\n      - name: Templatise manifests with image tag\n        run: |\n          ENV=\"${{ matrix.env }}\"\n          find \"deploy/\${ENV}\" -type f -name \"*.yaml\" -print0 | while IFS= read -r -d '' f; do\n            sed -i \"s#IMAGE_PLACEHOLDER#${{ steps.img.outputs.image }}#g\" \"$f\"\n            sed -i \"s#NAMESPACE_PLACEHOLDER#${{ env.NAMESPACE }}#g\" \"$f\"\n          done\n      - name: Apply canary (if present)\n        run: |\n          ENV=\"${{ matrix.env }}\"\n          if ls \"deploy/\${ENV}/canary/\"/*.yaml >/dev/null 2>&1; then\n            kubectl apply -n \"${{ env.NAMESPACE }}\" -f \"deploy/\${ENV}/canary/\"\n            kubectl rollout status -n \"${{ env.NAMESPACE }}\" deployment -l app.kubernetes.io/part-of=canary --timeout=120s\n          else\n            echo \"No canary overlay found; skipping canary\"\n          fi\n      - name: Bake\n        run: sleep 30\n      - name: Promote to stable\n        run: |\n          ENV=\"${{ matrix.env }}\"\n          kubectl apply -n \"${{ env.NAMESPACE }}\" -f \"deploy/\${ENV}/\"\n          kubectl rollout status -n \"${{ env.NAMESPACE }}\" deployment -l app.kubernetes.io/name=${{ github.event.repository.name }} --timeout=180s\n      - name: Cleanup canary\n        run: |\n          ENV=\"${{ matrix.env }}\"\n          if ls \"deploy/\${ENV}/canary/\"/*.yaml >/dev/null 2>&1; then\n            kubectl delete -n \"${{ env.NAMESPACE }}\" -f \"deploy/\${ENV}/canary/\" --ignore-not-found\n          fi\n";
  }

  function genReportMd(gates, profile){
    const tokenMap = { lint:'Lint', unit:'Unit tests', contract:'Contract tests', integration:'Integration tests', coverage:'Coverage', e2e:'End-to-end',
      sast:'SAST', 'docker-scan':'Container scan', sbom:'SBOM', sign:'Image signing', 'schema-compat':'Schema compatibility', iac:'IaC validate/plan', policy:'Policy check', observability:'Observability', chaos:'Chaos', a11y:'Accessibility', perf:'Performance'};
    const lines = ['# CI/CD Generation Report','',`Profile: **${profile}**`,'Gates:',''];
    gates.forEach(g=>lines.push(`- ${tokenMap[g] ? 'âœ…' : 'âš ï¸'} ${g}${tokenMap[g] ? '' : ' (unknown token)'}`));
    lines.push('\nFiles generated: ci-cd.yml, security.yml, iac-policy.yml, package-publish.yml, promote-deploy.yml');
    lines.push('Notes: Configure COSIGN_* and KUBE_CONFIG_* secrets for signing and deploy.');
    return lines.join('\n');
  }

  // --- Wire into MissionSmith button ---
  if (window.MS_actions) {
    const orig = window.MS_actions;
    orig.generateCICD = function(){
      try{
        const data = (typeof window.__ms_getData === 'function' ? window.__ms_getData() : window.__ms_data) || {};
        const sc = data.serviceConfig || {};
        const profile = toProfile(sc);
        const gates = toGates(val(sc, 'ci.gates', []));
        const registry = registryDefault(sc);

        const files = [
          {path: '.github/workflows/ci-cd.yml', content: genBuildTest(profile, gates)},
          {path: '.github/workflows/security.yml', content: genSecurity(gates)},
          {path: '.github/workflows/iac-policy.yml', content: genIaC(gates)},
          {path: '.github/workflows/package-publish.yml', content: genPackagePublish(registry)},
          {path: '.github/workflows/promote-deploy.yml', content: genPromoteDeploy()},
          {path: 'ci-cd-report.md', content: genReportMd(gates, profile)}
        ];

        // bundle download
        const chunks = ['# --- BEGIN MISSIONSMITH CI/CD BUNDLE ---'];
        for (const f of files) { chunks.push(`\n# FILE: ${f.path}\n\n${f.content}`); }
        const blob = new Blob([chunks.join('\n')], {type:'text/plain'});
        const a = document.createElement('a');
        a.href = URL.createObjectURL(blob);
        a.download = 'mission-cicd-bundle.txt';
        a.click();
        setTimeout(()=>URL.revokeObjectURL(a.href), 200);

        alert('âœ… CI/CD workflows generated. Add COSIGN_* and KUBE_CONFIG_* secrets for signing/deploy.');
      }catch(e){
        console.error('generateCICD failed', e);
        alert('Failed to generate CI/CD workflows.');
      }
    };
    window.MS_actions = orig;
  }
})();
</script>

<!-- === Integrated IaC Generator v1.0 === -->
<script>
(function(){
  // Helpers
  function str(v){ return (v==null?'':String(v)); }
  function val(obj, path, fallback){
    try{ return path.split('.').reduce((o,k)=> (o && (k in o) ? o[k] : undefined), obj) ?? fallback; }catch(_){ return fallback; }
  }
  function appName(sc){
    const n = str(sc.default_service_name || 'app').trim() || 'app';
    return n.replace(/[^a-z0-9-]/ig,'-').toLowerCase();
  }
  function imageDefault(sc){
    const reg = str(sc.default_registry || '').trim() || 'ghcr.io/OWNER/REPO';
    return reg + ':main';
  }
  function sloTarget(sc, name, dflt){ try{ return (sc?.nfr?.slo||[]).find(s=>s.name===name)?.target ?? dflt; }catch(_){ return dflt; } }

  // YAML templates (with placeholders to be replaced by the deploy workflow)
  function baseDeploymentYaml(app){
    return `apiVersion: apps/v1
kind: Deployment
metadata:
  name: ${app}
  namespace: NAMESPACE_PLACEHOLDER
  labels:
    app.kubernetes.io/name: ${app}
    app.kubernetes.io/instance: ${app}
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: ${app}
  template:
    metadata:
      labels:
        app.kubernetes.io/name: ${app}
    spec:
      containers:
      - name: ${app}
        image: IMAGE_PLACEHOLDER
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 8080
        env:
        - name: OTEL_SERVICE_NAME
          value: "${app}"
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 10
        resources:
          requests:
            cpu: "100m"
            memory: "128Mi"
          limits:
            cpu: "500m"
            memory: "512Mi"
`;
  }

  function serviceYaml(app){
    return `apiVersion: v1
kind: Service
metadata:
  name: ${app}
  namespace: NAMESPACE_PLACEHOLDER
spec:
  selector:
    app.kubernetes.io/name: ${app}
  ports:
  - name: http
    port: 80
    targetPort: 8080
  type: ClusterIP
`;
  }

  function namespaceYaml(){
    return `apiVersion: v1
kind: Namespace
metadata:
  name: NAMESPACE_PLACEHOLDER
`;
  }

  function canaryDeploymentYaml(app){
    return `apiVersion: apps/v1
kind: Deployment
metadata:
  name: ${app}-canary
  namespace: NAMESPACE_PLACEHOLDER
  labels:
    app.kubernetes.io/name: ${app}
    app.kubernetes.io/part-of: canary
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: ${app}
      app.kubernetes.io/part-of: canary
  template:
    metadata:
      labels:
        app.kubernetes.io/name: ${app}
        app.kubernetes.io/part-of: canary
    spec:
      containers:
      - name: ${app}
        image: IMAGE_PLACEHOLDER
        ports:
        - containerPort: 8080
`;
  }

  // Terraform (kubernetes provider) skeleton
  function tfProviders(){
    return `terraform {
  required_version = ">= 1.5.0"
  required_providers {
    kubernetes = {
      source  = "hashicorp/kubernetes"
      version = ">= 2.32.0"
    }
  }
}

# Uses KUBECONFIG from the environment (set by CI)
provider "kubernetes" {}
`;
  }
  function tfVariables(app, image){
    return `variable "namespace" { type = string  default = "default" }
variable "app_name"  { type = string  default = "${app}" }
variable "image"     { type = string  default = "${image}" }
`;
  }
  function tfMain(){
    return `resource "kubernetes_namespace" "ns" {
  metadata { name = var.namespace }
}

resource "kubernetes_deployment" "app" {
  metadata {
    name      = var.app_name
    namespace = var.namespace
    labels = {
      "app.kubernetes.io/name" = var.app_name
    }
  }
  spec {
    replicas = 2
    selector {
      match_labels = { "app.kubernetes.io/name" = var.app_name }
    }
    template {
      metadata {
        labels = { "app.kubernetes.io/name" = var.app_name }
      }
      spec {
        container {
          name  = var.app_name
          image = var.image
          port  { container_port = 8080 }
        }
      }
    }
  }
}

resource "kubernetes_service" "svc" {
  metadata {
    name      = var.app_name
    namespace = var.namespace
  }
  spec {
    selector = { "app.kubernetes.io/name" = var.app_name }
    port { port = 80  target_port = 8080 }
    type = "ClusterIP"
  }
}
`;
  }
  function tfOutputs(){
    return `output "service_name" { value = kubernetes_service.svc.metadata[0].name }
output "namespace"    { value = kubernetes_namespace.ns.metadata[0].name }
`;
  }

  function readme(){
    return `# MissionSmith IaC Bundle

This bundle includes:
- Kubernetes deploy manifests under \`deploy/{dev,staging,prod}\` (with \`IMAGE_PLACEHOLDER\` and \`NAMESPACE_PLACEHOLDER\` tokens)
- A Terraform skeleton under \`infra/\` using the Kubernetes provider

## Using with the generated CI/CD
- The \`promote-deploy.yml\` workflow will replace the placeholders and apply the manifests.
- Set the following secrets in your repo for each environment:
  - \`COSIGN_PUBLIC_KEY\` (for verification)
  - \`KUBE_CONFIG_DEV\`, \`KUBE_CONFIG_STAGING\`, \`KUBE_CONFIG_PROD\`

> You can also use \`infra/\` with \`terraform -chdir=infra init && terraform -chdir=infra apply -var namespace=<env> -var image=<image>\`.
`;
  }

  function bundleFiles(data){
    const sc = data?.serviceConfig || {};
    const app = appName(sc);
    const image = imageDefault(sc);

    const envs = ["dev","staging","prod"];
    const files = [];

    // Env-specific k8s manifests
    envs.forEach(env => {
      files.push({ path: `deploy/${env}/namespace.yaml`, content: namespaceYaml() });
      files.push({ path: `deploy/${env}/deployment.yaml`, content: baseDeploymentYaml(app) });
      files.push({ path: `deploy/${env}/service.yaml`, content: serviceYaml(app) });
      files.push({ path: `deploy/${env}/canary/deployment.yaml`, content: canaryDeploymentYaml(app) });
    });

    // Terraform skeleton
    files.push({ path: `infra/providers.tf`, content: tfProviders() });
    files.push({ path: `infra/variables.tf`, content: tfVariables(app, image) });
    files.push({ path: `infra/main.tf`, content: tfMain() });
    files.push({ path: `infra/outputs.tf`, content: tfOutputs() });
    files.push({ path: `README-IAC.md`, content: readme() });

    return files;
  }

  // Override the existing IaC button behaviour
  if (window.MS_actions) {
    const orig = window.MS_actions;
    orig.generateDeploy = function(){
      try{
        const data = (typeof window.__ms_getData === 'function' ? window.__ms_getData() : window.__ms_data) || {};
        const files = bundleFiles(data);

        const chunks = ['# --- BEGIN MISSIONSMITH IAC BUNDLE ---'];
        for (const f of files) { chunks.push(`\n# FILE: ${f.path}\n\n${f.content}`); }
        const blob = new Blob([chunks.join('\n')], {type:'text/plain'});
        const a = document.createElement('a');
        a.href = URL.createObjectURL(blob);
        a.download = 'mission-iac-bundle.txt';
        a.click();
        setTimeout(()=>URL.revokeObjectURL(a.href), 200);

        alert('âœ… IaC bundle generated: deploy/{env}/... + infra/ (Terraform).');
      }catch(e){
        console.error('generateDeploy failed', e);
        alert('Failed to generate IaC bundle.');
      }
    };
    window.MS_actions = orig;
  }
})();
</script>


<!-- === MissionSmith Lineage Generator v1.0 === -->
<script>
(function(){
  function safe(v, d){ return (v===undefined || v===null) ? d : v; }
  function norm(s){ return String(s||'').trim().replace(/[^a-z0-9-_:.]/ig,'_'); }
  function title(s){ return String(s||'').trim(); }

  // Extract a best-effort model from the app's data blob
  function extractModel(data){
    const sc = data?.serviceConfig || {};
    const services = [];
    const datasets = [];
    const policies = [];
    const pipelines = [];
    const objectives = [];

    // Service
    const appName = sc.default_service_name || 'app';
    services.push({id: norm(appName), name: title(appName), kind:'service'});

    // Datasets / APIs (best effort)
    const ds = safe(sc.data_sources, []);
    ds.forEach((d, i)=>{
      const name = d?.name || `dataset_${i+1}`;
      datasets.push({id: norm(name), name: title(name), kind:'dataset'});
    });

    // Pipelines (from CI/CD + build stages if present)
    const pl = safe(data?.pipelines, []);
    pl.forEach((p, i)=>{
      const name = p?.name || `pipeline_${i+1}`;
      pipelines.push({id: norm(name), name: title(name), kind:'pipeline'});
    });

    // Policies / Guardrails
    const pol = safe(data?.policies, []);
    pol.forEach((p, i)=>{
      const name = p?.name || `policy_${i+1}`;
      policies.push({id: norm(name), name: title(name), kind:'policy'});
    });

    // Objectives (Mission Objectives sheet)
    const obj = safe(data?.objectives || data?.missionObjectives, []);
    obj.forEach((o, i)=>{
      const name = o?.reference || o?.name || `objective_${i+1}`;
      objectives.push({id: norm(name), name: title(name), kind:'objective'});
    });

    // Build edges heuristically:
    const edges = [];
    // service uses datasets
    datasets.forEach(d => edges.push({from: d.id, to: norm(appName), relation: 'consumed_by'}));
    // pipelines deploy service
    pipelines.forEach(p => edges.push({from: p.id, to: norm(appName), relation: 'deploys'}));
    // policies govern service and pipelines
    policies.forEach(pol => {
      edges.push({from: pol.id, to: norm(appName), relation:'governs'});
      pipelines.forEach(p => edges.push({from: pol.id, to: p.id, relation:'governs'}));
    });
    // objectives drive pipelines (if any)
    objectives.forEach(o => {
      pipelines.forEach(p => edges.push({from: o.id, to: p.id, relation:'drives'}));
    });

    return {services, datasets, policies, pipelines, objectives, edges};
  }

  function toCSV(model){
    const header = "from,to,relation\n";
    const rows = model.edges.map(e => `${e.from},${e.to},${e.relation}`);
    return header + rows.join("\n") + "\n";
  }

  function toDOT(model){
    const lines = [];
    lines.push('digraph MissionSmithLineage {');
    lines.push('  rankdir=LR;');
    function node(n, shape, color){
      lines.push(`  "${n.id}" [label="${n.name}\\n(${n.kind})", shape=${shape}, style=filled, fillcolor="${color}"];`);
    }
    model.datasets.forEach(n => node(n, 'cylinder', '#E0F7FA'));
    model.services.forEach(n => node(n, 'box', '#E8F5E9'));
    model.pipelines.forEach(n => node(n, 'component', '#EDE7F6'));
    model.policies.forEach(n => node(n, 'octagon', '#FFF3E0'));
    model.objectives.forEach(n => node(n, 'ellipse', '#F3E5F5'));

    model.edges.forEach(e => lines.push(`  "${e.from}" -> "${e.to}" [label="${e.relation}"];`));
    lines.push('}');
    return lines.join("\n");
  }

  // Minimal OpenLineage-style JSON (not full spec; enough for import/visualization tools)
  function toOpenLineage(model){
    const now = new Date().toISOString();
    const events = [];

    // Emit one RUN event per pipeline, pointing to the service dataset outputs
    model.pipelines.forEach(p => {
      const outputs = model.services.map(s => ({namespace:"app", name:s.name}));
      const inputs  = model.datasets.map(d => ({namespace:"data", name:d.name}));
      events.push({
        eventType: "COMPLETE",
        eventTime: now,
        run: { runId: `${p.id}-${now}` },
        job: { namespace: "mission-smith", name: p.name },
        inputs, outputs,
        producer: "missionsmith/lineage-generator"
      });
    });
    return JSON.stringify({version:"0.1", events}, null, 2);
  }

  // Hook up Lineage button if MS_actions present
  if (window.MS_actions){
    const orig = window.MS_actions;
    orig.generateLineage = function(){
      try{
        const data = (typeof window.__ms_getData === 'function' ? window.__ms_getData() : window.__ms_data) || {};
        const model = extractModel(data);

        const files = [
          { path: 'lineage/edges.csv', content: toCSV(model) },
          { path: 'lineage/graph.dot', content: toDOT(model) },
          { path: 'lineage/openlineage.json', content: toOpenLineage(model) },
          { path: 'lineage/README-LINEAGE.md', content:
`# MissionSmith Lineage Bundle

This bundle provides three interoperable artifacts:

1) **edges.csv** â€” simple \`from,to,relation\` edge list (easy to load in Neo4j/NetworkX/Gephi).
2) **graph.dot** â€” Graphviz DOT for quick rendering to SVG/PNG (\`dot -Tsvg graph.dot -o graph.svg\`).
3) **openlineage.json** â€” lightweight OpenLineage-style events that many tools can ingest (e.g. Marquez).

### Relations
- \`consumed_by\`: dataset â†’ service
- \`deploys\`: pipeline â†’ service
- \`governs\`: policy â†’ (service|pipeline)
- \`drives\`: objective â†’ pipeline

> Model is generated bestâ€‘effort from your MissionSmith data. Customize by editing this README or the JSON.
`
          }
        ];

        const chunks = ['# --- BEGIN MISSIONSMITH LINEAGE BUNDLE ---'];
        for (const f of files){ chunks.push(`\n# FILE: ${f.path}\n\n${f.content}`); }
        const blob = new Blob([chunks.join('\n')], {type:'text/plain'});
        const a = document.createElement('a');
        a.href = URL.createObjectURL(blob);
        a.download = 'mission-lineage-bundle.txt';
        a.click();
        setTimeout(()=>URL.revokeObjectURL(a.href), 200);

        alert('âœ… Lineage bundle generated: edges.csv, graph.dot, openlineage.json.');
      }catch(e){
        console.error('generateLineage failed', e);
        alert('Failed to generate lineage bundle.');
      }
    };
    window.MS_actions = orig;
  }
})();
</script>


<!-- === MissionSmith Analytics Generator v1.0 === -->
<script>
(function(){
  function safe(v, d){ return (v===undefined||v===null) ? d : v; }
  function norm(s){ return String(s||'').trim().replace(/[^a-z0-9-_:.]/ig,'_'); }
  function title(s){ return String(s||'').trim(); }

  function extractKPIs(data){
    // Try multiple places: nfr.slo, nfr.kpis, analytics.kpis, objectives.*.kpi
    const sc = data?.serviceConfig || {};
    const slo = safe(sc?.nfr?.slo, []);
    const k1 = slo.map(s => ({key: norm(s.name||s.id||'slo'), name: title(s.name||s.id||'SLO'), target: s.target, window: s.window || '30d', unit: s.unit || '%', source: s.source || 'app_metrics'}));

    const k2 = safe(sc?.nfr?.kpis, []).map(k => ({
      key: norm(k.key||k.name), name: title(k.name||k.key), unit: k.unit||'count', target: k.target, source: k.source||'events'
    }));

    const k3 = safe(data?.analytics?.kpis, []).map(k => ({
      key: norm(k.key||k.name), name: title(k.name||k.key), unit: k.unit||'count', target: k.target, source: k.source||'warehouse'
    }));

    // derive from objectives with "KPI:" prefix
    const objectives = safe(data?.objectives || data?.missionObjectives, []);
    const k4 = objectives
      .filter(o => (o?.kpi || '').toString().length || /kpi[:=]/i.test(String(o?.notes||'')))
      .map((o,i)=>{
        const nm = o?.kpi || String(o?.notes||'').match(/kpi[:=]\s*([^\n]+)/i)?.[1] || `objective_kpi_${i+1}`;
        return {key: norm(nm), name: title(nm), unit: 'count', target: o?.target, source: 'derived'};
      });

    const all = [...k1, ...k2, ...k3, ...k4];
    // de-dup by key
    const seen = new Set(); const uniq=[];
    all.forEach(k => { if(!k.key) return; if(!seen.has(k.key)){ seen.add(k.key); uniq.push(k);} });
    if (uniq.length===0){
      // Provide sensible defaults
      uniq.push({key:'latency_p95_ms', name:'Latency p95', unit:'ms', target: 300, source:'app_metrics'});
      uniq.push({key:'error_rate_pct', name:'Error Rate', unit:'%', target: 1, source:'app_metrics'});
      uniq.push({key:'throughput_rps', name:'Throughput', unit:'rps', target: null, source:'app_metrics'});
    }
    return uniq;
  }

  function toMetricsCatalog(kpis){
    const lines = [];
    lines.push('apiVersion: v1');
    lines.push('kind: MetricsCatalog');
    lines.push('metadata:');
    lines.push('  name: missionsmith-metrics');
    lines.push('spec:');
    lines.push('  kpis:');
    kpis.forEach(k => {
      lines.push(`  - key: ${k.key}`);
      lines.push(`    name: "${k.name}"`);
      if (k.unit!=null) lines.push(`    unit: "${k.unit}"`);
      if (k.target!=null) lines.push(`    target: ${k.target}`);
      lines.push(`    source: "${k.source||'warehouse'}"`);
      lines.push(`    owners:`);
      lines.push(`      - platform`);
    });
    return lines.join('\n') + '\n';
  }

  function toPrometheusRules(kpis, app){
    const hdr = [
      'groups:',
      '- name: missionsmith.rules',
      '  interval: 30s',
      '  rules:'
    ];
    const rules = [];
    kpis.forEach(k => {
      if(/error_rate/.test(k.key)){
        rules.push(
`  - alert: HighErrorRate
    expr: rate(http_requests_total{service="${app}",status=~"5.."}[5m]) / clamp_min(rate(http_requests_total{service="${app}"}[5m]),1) * 100 > ${k.target||1}
    for: 10m
    labels: { severity: "page" }
    annotations:
      summary: "High error rate on ${app}"
      description: "Error rate > ${k.target||1}% for 10m"`);
      }
      if(/latency|p95/.test(k.key)){
        rules.push(
`  - alert: HighLatencyP95
    expr: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{service="${app}"}[5m])) by (le)) * 1000 > ${k.target||300}
    for: 10m
    labels: { severity: "page" }
    annotations:
      summary: "High latency p95 on ${app}"
      description: "Latency p95 > ${k.target||300}ms for 10m"`);
      }
    });
    if (rules.length===0){
      rules.push(
`  - alert: ServiceDown
    expr: up{service="${app}"} == 0
    for: 5m
    labels: { severity: "page" }
    annotations:
      summary: "${app} is down"
      description: "No scrape targets reporting for 5m"`);
    }
    return hdr.concat(rules).join('\n') + '\n';
  }

  function toGrafanaDashboard(kpis, app){
    // Minimal Grafana JSON model (v5+ export-ish, not strict; user can import and tweak).
    const dash = {
      annotations: { list: [{builtIn:1, datasource:'-- Grafana --', enable:true, hide:true, iconColor:'rgba(0, 211, 255, 1)', name:'Annotations & Alerts', type:'dashboard'}]},
      editable: true,
      graphTooltip: 0,
      panels: [],
      schemaVersion: 25,
      style: 'dark',
      tags: ['missionsmith','starter'],
      templating: { list: [{name: 'service', type: 'query', query: `label_values(up, service)`, label: 'Service', current: {text: app, value: app}}]},
      time: { from: 'now-6h', to: 'now' },
      timepicker: {},
      timezone: '',
      title: `${app} | MissionSmith Analytics`,
      version: 1
    };

    let id = 1; let y=0;
    function panelFor(key, title, expr){
      const p = {
        id: id++,
        gridPos: {h:8, w:12, x: (id%2?0:12), y: y + (id%2?0:8)},
        type: 'timeseries',
        title: `${title}`,
        targets: [{expr, refId:'A'}]
      };
      return p;
    }

    // Basic panels
    dash.panels.push(panelFor('rps', 'Throughput (RPS)', `sum(rate(http_requests_total{service="$service"}[1m]))`));
    dash.panels.push(panelFor('latency_p95', 'Latency p95 (ms)', `histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{service="$service"}[5m])) by (le)) * 1000`));
    dash.panels.push(panelFor('error_rate', 'Error Rate (%)', `sum(rate(http_requests_total{service="$service",status=~"5.."}[5m])) / clamp_min(sum(rate(http_requests_total{service="$service"}[5m])),1) * 100`));

    // KPI panels
    kpis.forEach(k => {
      if (/latency|p95/.test(k.key) || /error_rate/.test(k.key) || /throughput|rps/.test(k.key)) return;
      // Put generic counter panels â€” user can edit later
      dash.panels.push(panelFor(k.key, k.name, `sum(missionsmith_${k.key}{service="$service"})`));
    });

    return JSON.stringify(dash, null, 2);
  }

  function toDBTScaffold(app){
    return `# dbt project for MissionSmith
name: 'missionsmith_${app}'
version: '1.0'
config-version: 2

profile: 'default'

models:
  missionsmith_${app}:
    +materialized: view
`;
  }

  function toDBTModelSQL(kpis){
    const lines = [];
    lines.push('-- Example KPI model (replace with your warehouse SQL)');
    lines.push('with events as (');
    lines.push('  select * from source(\'app\', \'events\')');
    lines.push(')');
    lines.push('select');
    kpis.forEach((k,i)=>{
      const comma = (i<kpis.length-1)?',':'';
      lines.push(`  /* ${k.name} */ null as ${k.key}${comma}`);
    });
    lines.push('from events');
    lines.push('limit 1');
    return lines.join('\n') + '\n';
  }

  if (window.MS_actions){
    const orig = window.MS_actions;
    orig.generateAnalytics = function(){
      try{
        const data = (typeof window.__ms_getData === 'function' ? window.__ms_getData() : window.__ms_data) || {};
        const sc = data?.serviceConfig || {};
        const app = (sc.default_service_name || 'app').toString().trim();
        const kpis = extractKPIs(data);

        const files = [
          { path: 'analytics/metrics-catalog.yaml', content: toMetricsCatalog(kpis) },
          { path: 'analytics/prometheus-rules.yaml', content: toPrometheusRules(kpis, app) },
          { path: 'analytics/grafana-dashboard.json', content: toGrafanaDashboard(kpis, app) },
          { path: 'analytics/dbt/project.yml', content: toDBTScaffold(app) },
          { path: 'analytics/dbt/models/kpis.sql', content: toDBTModelSQL(kpis) },
          { path: 'analytics/README-ANALYTICS.md', content:
`# MissionSmith Analytics Bundle

This starter pack gives you:
- **metrics-catalog.yaml** â€” canonical KPI list (keys, units, targets, ownership).
- **prometheus-rules.yaml** â€” alert rules keyed off latency, error rate, and common KPIs.
- **grafana-dashboard.json** â€” importable dashboard with RPS, p95 latency, error %, and KPI panels.
- **dbt/** â€” a minimal scaffold to materialize KPI views in your warehouse.

## Next steps
1. Import \`grafana-dashboard.json\` into Grafana; set Prometheus as the data source.
2. Load \`prometheus-rules.yaml\` into your Prometheus/Alertmanager setup.
3. Store your KPI definitions in \`metrics-catalog.yaml\` and keep them versioned with code.
4. Point \`dbt/models/kpis.sql\` at your real warehouse schema and build with \`dbt build\`.

> KPIs were inferred from your MissionSmith data (nfr.slo / nfr.kpis / analytics.kpis / objectives). Edit this bundle as needed.
`}
        ];

        const chunks = ['# --- BEGIN MISSIONSMITH ANALYTICS BUNDLE ---'];
        files.forEach(f => chunks.push(`\n# FILE: ${f.path}\n\n${f.content}`));
        const blob = new Blob([chunks.join('\n')], {type:'text/plain'});
        const a = document.createElement('a');
        a.href = URL.createObjectURL(blob);
        a.download = 'mission-analytics-bundle.txt';
        a.click();
        setTimeout(()=>URL.revokeObjectURL(a.href), 200);

        alert('âœ… Analytics bundle generated: metrics catalog, Prometheus rules, Grafana dashboard, dbt scaffold.');
      }catch(e){
        console.error('generateAnalytics failed', e);
        alert('Failed to generate analytics bundle.');
      }
    };
    window.MS_actions = orig;
  }
})();
</script>

</body>
</html>


===== FILE: app_backend\models.py =====
from sqlalchemy import Column, Integer, String, Text, UniqueConstraint
from .db import Base


class SourceRecord(Base):
    """
    Raw upstream record from a given system for a given client_id.

    These rows replace the hard-coded _mock_crm_source/_mock_kyc_source
    in ClientProfileService. We load them, decode the JSON payloads,
    and pass them into assemble_base_profile.
    """
    __tablename__ = "source_records"

    id = Column(Integer, primary_key=True, index=True)
    client_id = Column(String, index=True, nullable=False)
    system = Column(String, index=True, nullable=False)  # e.g. "CRM", "KYC"
    payload_json = Column(Text, nullable=False)          # JSON-encoded dict

    __table_args__ = (
        UniqueConstraint("client_id", "system", name="uq_client_system"),
    )


===== FILE: app_backend\requirements.txt =====
fastapi
uvicorn
sqlalchemy
pydantic
requests


===== FILE: app_backend\schemas.py =====
from typing import Any, Dict, Optional
from pydantic import BaseModel


class SourceRecordCreate(BaseModel):
    client_id: str
    system: str                   # "CRM", "KYC", "MDM", etc.
    payload: Dict[str, Any]       # raw record from that system


class SourceRecordRead(BaseModel):
    id: int
    client_id: str
    system: str
    payload: Dict[str, Any]

    class Config:
        orm_mode = True


===== FILE: app_frontend\eslint.config.js =====
import js from '@eslint/js'
import globals from 'globals'
import reactHooks from 'eslint-plugin-react-hooks'
import reactRefresh from 'eslint-plugin-react-refresh'
import { defineConfig, globalIgnores } from 'eslint/config'

export default defineConfig([
  globalIgnores(['dist']),
  {
    files: ['**/*.{js,jsx}'],
    extends: [
      js.configs.recommended,
      reactHooks.configs.flat.recommended,
      reactRefresh.configs.vite,
    ],
    languageOptions: {
      ecmaVersion: 2020,
      globals: globals.browser,
      parserOptions: {
        ecmaVersion: 'latest',
        ecmaFeatures: { jsx: true },
        sourceType: 'module',
      },
    },
    rules: {
      'no-unused-vars': ['error', { varsIgnorePattern: '^[A-Z_]' }],
    },
  },
])


===== FILE: app_frontend\index.html =====
<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <!-- <link rel="icon" type="image/svg+xml" href="/vite.svg" /> -->
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>SCV Frontend</title>

    <!-- MissionHalo fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;500;700&family=Raleway:wght@500;600;700&display=swap"
      rel="stylesheet"
    />

    <!-- Fjalla One for MissionSmith / MissionAtlas / MissionLog -->
    <link
      href="https://fonts.googleapis.com/css2?family=Fjalla+One&display=swap"
      rel="stylesheet"
    />
  </head>

  <body class="bg-gray-100">
    <div id="root"></div>
    <script type="module" src="/src/main.jsx"></script>
  </body>
</html>



===== FILE: app_frontend\package.json =====
{
  "name": "app_frontend",
  "private": true,
  "version": "0.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "lint": "eslint .",
    "preview": "vite preview"
  },
  "dependencies": {
    "react": "^19.2.0",
    "react-dom": "^19.2.0",
    "react-markdown": "^10.1.0",
    "remark-gfm": "^4.0.1"
  },
  "devDependencies": {
    "@eslint/js": "^9.39.1",
    "@tailwindcss/postcss": "^4.1.17",
    "@types/react": "^19.2.5",
    "@types/react-dom": "^19.2.3",
    "@vitejs/plugin-react": "^5.1.1",
    "autoprefixer": "^10.4.22",
    "eslint": "^9.39.1",
    "eslint-plugin-react-hooks": "^7.0.1",
    "eslint-plugin-react-refresh": "^0.4.24",
    "globals": "^16.5.0",
    "postcss": "^8.5.6",
    "tailwindcss": "^4.1.17",
    "vite": "^7.2.4"
  }
}


===== FILE: app_frontend\package-lock.json =====
{
  "name": "app_frontend",
  "version": "0.0.0",
  "lockfileVersion": 3,
  "requires": true,
  "packages": {
    "": {
      "name": "app_frontend",
      "version": "0.0.0",
      "dependencies": {
        "react": "^19.2.0",
        "react-dom": "^19.2.0",
        "react-markdown": "^10.1.0",
        "remark-gfm": "^4.0.1"
      },
      "devDependencies": {
        "@eslint/js": "^9.39.1",
        "@tailwindcss/postcss": "^4.1.17",
        "@types/react": "^19.2.5",
        "@types/react-dom": "^19.2.3",
        "@vitejs/plugin-react": "^5.1.1",
        "autoprefixer": "^10.4.22",
        "eslint": "^9.39.1",
        "eslint-plugin-react-hooks": "^7.0.1",
        "eslint-plugin-react-refresh": "^0.4.24",
        "globals": "^16.5.0",
        "postcss": "^8.5.6",
        "tailwindcss": "^4.1.17",
        "vite": "^7.2.4"
      }
    },
    "node_modules/@alloc/quick-lru": {
      "version": "5.2.0",
      "resolved": "https://registry.npmjs.org/@alloc/quick-lru/-/quick-lru-5.2.0.tgz",
      "integrity": "sha512-UrcABB+4bUrFABwbluTIBErXwvbsU/V7TZWfmbgJfbkwiBuziS9gxdODUyuiecfdGQ85jglMW6juS3+z5TsKLw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/@babel/code-frame": {
      "version": "7.27.1",
      "resolved": "https://registry.npmjs.org/@babel/code-frame/-/code-frame-7.27.1.tgz",
      "integrity": "sha512-cjQ7ZlQ0Mv3b47hABuTevyTuYN4i+loJKGeV9flcCgIK37cCXRh+L1bd3iBHlynerhQ7BhCkn2BPbQUL+rGqFg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-validator-identifier": "^7.27.1",
        "js-tokens": "^4.0.0",
        "picocolors": "^1.1.1"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/compat-data": {
      "version": "7.28.5",
      "resolved": "https://registry.npmjs.org/@babel/compat-data/-/compat-data-7.28.5.tgz",
      "integrity": "sha512-6uFXyCayocRbqhZOB+6XcuZbkMNimwfVGFji8CTZnCzOHVGvDqzvitu1re2AU5LROliz7eQPhB8CpAMvnx9EjA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/core": {
      "version": "7.28.5",
      "resolved": "https://registry.npmjs.org/@babel/core/-/core-7.28.5.tgz",
      "integrity": "sha512-e7jT4DxYvIDLk1ZHmU/m/mB19rex9sv0c2ftBtjSBv+kVM/902eh0fINUzD7UwLLNR+jU585GxUJ8/EBfAM5fw==",
      "dev": true,
      "license": "MIT",
      "peer": true,
      "dependencies": {
        "@babel/code-frame": "^7.27.1",
        "@babel/generator": "^7.28.5",
        "@babel/helper-compilation-targets": "^7.27.2",
        "@babel/helper-module-transforms": "^7.28.3",
        "@babel/helpers": "^7.28.4",
        "@babel/parser": "^7.28.5",
        "@babel/template": "^7.27.2",
        "@babel/traverse": "^7.28.5",
        "@babel/types": "^7.28.5",
        "@jridgewell/remapping": "^2.3.5",
        "convert-source-map": "^2.0.0",
        "debug": "^4.1.0",
        "gensync": "^1.0.0-beta.2",
        "json5": "^2.2.3",
        "semver": "^6.3.1"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/babel"
      }
    },
    "node_modules/@babel/generator": {
      "version": "7.28.5",
      "resolved": "https://registry.npmjs.org/@babel/generator/-/generator-7.28.5.tgz",
      "integrity": "sha512-3EwLFhZ38J4VyIP6WNtt2kUdW9dokXA9Cr4IVIFHuCpZ3H8/YFOl5JjZHisrn1fATPBmKKqXzDFvh9fUwHz6CQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/parser": "^7.28.5",
        "@babel/types": "^7.28.5",
        "@jridgewell/gen-mapping": "^0.3.12",
        "@jridgewell/trace-mapping": "^0.3.28",
        "jsesc": "^3.0.2"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-compilation-targets": {
      "version": "7.27.2",
      "resolved": "https://registry.npmjs.org/@babel/helper-compilation-targets/-/helper-compilation-targets-7.27.2.tgz",
      "integrity": "sha512-2+1thGUUWWjLTYTHZWK1n8Yga0ijBz1XAhUXcKy81rd5g6yh7hGqMp45v7cadSbEHc9G3OTv45SyneRN3ps4DQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/compat-data": "^7.27.2",
        "@babel/helper-validator-option": "^7.27.1",
        "browserslist": "^4.24.0",
        "lru-cache": "^5.1.1",
        "semver": "^6.3.1"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-globals": {
      "version": "7.28.0",
      "resolved": "https://registry.npmjs.org/@babel/helper-globals/-/helper-globals-7.28.0.tgz",
      "integrity": "sha512-+W6cISkXFa1jXsDEdYA8HeevQT/FULhxzR99pxphltZcVaugps53THCeiWA8SguxxpSp3gKPiuYfSWopkLQ4hw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-module-imports": {
      "version": "7.27.1",
      "resolved": "https://registry.npmjs.org/@babel/helper-module-imports/-/helper-module-imports-7.27.1.tgz",
      "integrity": "sha512-0gSFWUPNXNopqtIPQvlD5WgXYI5GY2kP2cCvoT8kczjbfcfuIljTbcWrulD1CIPIX2gt1wghbDy08yE1p+/r3w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/traverse": "^7.27.1",
        "@babel/types": "^7.27.1"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-module-transforms": {
      "version": "7.28.3",
      "resolved": "https://registry.npmjs.org/@babel/helper-module-transforms/-/helper-module-transforms-7.28.3.tgz",
      "integrity": "sha512-gytXUbs8k2sXS9PnQptz5o0QnpLL51SwASIORY6XaBKF88nsOT0Zw9szLqlSGQDP/4TljBAD5y98p2U1fqkdsw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-module-imports": "^7.27.1",
        "@babel/helper-validator-identifier": "^7.27.1",
        "@babel/traverse": "^7.28.3"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0"
      }
    },
    "node_modules/@babel/helper-plugin-utils": {
      "version": "7.27.1",
      "resolved": "https://registry.npmjs.org/@babel/helper-plugin-utils/-/helper-plugin-utils-7.27.1.tgz",
      "integrity": "sha512-1gn1Up5YXka3YYAHGKpbideQ5Yjf1tDa9qYcgysz+cNCXukyLl6DjPXhD3VRwSb8c0J9tA4b2+rHEZtc6R0tlw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-string-parser": {
      "version": "7.27.1",
      "resolved": "https://registry.npmjs.org/@babel/helper-string-parser/-/helper-string-parser-7.27.1.tgz",
      "integrity": "sha512-qMlSxKbpRlAridDExk92nSobyDdpPijUq2DW6oDnUqd0iOGxmQjyqhMIihI9+zv4LPyZdRje2cavWPbCbWm3eA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-validator-identifier": {
      "version": "7.28.5",
      "resolved": "https://registry.npmjs.org/@babel/helper-validator-identifier/-/helper-validator-identifier-7.28.5.tgz",
      "integrity": "sha512-qSs4ifwzKJSV39ucNjsvc6WVHs6b7S03sOh2OcHF9UHfVPqWWALUsNUVzhSBiItjRZoLHx7nIarVjqKVusUZ1Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-validator-option": {
      "version": "7.27.1",
      "resolved": "https://registry.npmjs.org/@babel/helper-validator-option/-/helper-validator-option-7.27.1.tgz",
      "integrity": "sha512-YvjJow9FxbhFFKDSuFnVCe2WxXk1zWc22fFePVNEaWJEu8IrZVlda6N0uHwzZrUM1il7NC9Mlp4MaJYbYd9JSg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helpers": {
      "version": "7.28.4",
      "resolved": "https://registry.npmjs.org/@babel/helpers/-/helpers-7.28.4.tgz",
      "integrity": "sha512-HFN59MmQXGHVyYadKLVumYsA9dBFun/ldYxipEjzA4196jpLZd8UjEEBLkbEkvfYreDqJhZxYAWFPtrfhNpj4w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/template": "^7.27.2",
        "@babel/types": "^7.28.4"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/parser": {
      "version": "7.28.5",
      "resolved": "https://registry.npmjs.org/@babel/parser/-/parser-7.28.5.tgz",
      "integrity": "sha512-KKBU1VGYR7ORr3At5HAtUQ+TV3SzRCXmA/8OdDZiLDBIZxVyzXuztPjfLd3BV1PRAQGCMWWSHYhL0F8d5uHBDQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/types": "^7.28.5"
      },
      "bin": {
        "parser": "bin/babel-parser.js"
      },
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/@babel/plugin-transform-react-jsx-self": {
      "version": "7.27.1",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-react-jsx-self/-/plugin-transform-react-jsx-self-7.27.1.tgz",
      "integrity": "sha512-6UzkCs+ejGdZ5mFFC/OCUrv028ab2fp1znZmCZjAOBKiBK2jXD1O+BPSfX8X2qjJ75fZBMSnQn3Rq2mrBJK2mw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.27.1"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-react-jsx-source": {
      "version": "7.27.1",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-react-jsx-source/-/plugin-transform-react-jsx-source-7.27.1.tgz",
      "integrity": "sha512-zbwoTsBruTeKB9hSq73ha66iFeJHuaFkUbwvqElnygoNbj/jHRsSeokowZFN3CZ64IvEqcmmkVe89OPXc7ldAw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.27.1"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/template": {
      "version": "7.27.2",
      "resolved": "https://registry.npmjs.org/@babel/template/-/template-7.27.2.tgz",
      "integrity": "sha512-LPDZ85aEJyYSd18/DkjNh4/y1ntkE5KwUHWTiqgRxruuZL2F1yuHligVHLvcHY2vMHXttKFpJn6LwfI7cw7ODw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/code-frame": "^7.27.1",
        "@babel/parser": "^7.27.2",
        "@babel/types": "^7.27.1"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/traverse": {
      "version": "7.28.5",
      "resolved": "https://registry.npmjs.org/@babel/traverse/-/traverse-7.28.5.tgz",
      "integrity": "sha512-TCCj4t55U90khlYkVV/0TfkJkAkUg3jZFA3Neb7unZT8CPok7iiRfaX0F+WnqWqt7OxhOn0uBKXCw4lbL8W0aQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/code-frame": "^7.27.1",
        "@babel/generator": "^7.28.5",
        "@babel/helper-globals": "^7.28.0",
        "@babel/parser": "^7.28.5",
        "@babel/template": "^7.27.2",
        "@babel/types": "^7.28.5",
        "debug": "^4.3.1"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/types": {
      "version": "7.28.5",
      "resolved": "https://registry.npmjs.org/@babel/types/-/types-7.28.5.tgz",
      "integrity": "sha512-qQ5m48eI/MFLQ5PxQj4PFaprjyCTLI37ElWMmNs0K8Lk3dVeOdNpB3ks8jc7yM5CDmVC73eMVk/trk3fgmrUpA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-string-parser": "^7.27.1",
        "@babel/helper-validator-identifier": "^7.28.5"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@esbuild/aix-ppc64": {
      "version": "0.25.12",
      "resolved": "https://registry.npmjs.org/@esbuild/aix-ppc64/-/aix-ppc64-0.25.12.tgz",
      "integrity": "sha512-Hhmwd6CInZ3dwpuGTF8fJG6yoWmsToE+vYgD4nytZVxcu1ulHpUQRAB1UJ8+N1Am3Mz4+xOByoQoSZf4D+CpkA==",
      "cpu": [
        "ppc64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "aix"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/android-arm": {
      "version": "0.25.12",
      "resolved": "https://registry.npmjs.org/@esbuild/android-arm/-/android-arm-0.25.12.tgz",
      "integrity": "sha512-VJ+sKvNA/GE7Ccacc9Cha7bpS8nyzVv0jdVgwNDaR4gDMC/2TTRc33Ip8qrNYUcpkOHUT5OZ0bUcNNVZQ9RLlg==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/android-arm64": {
      "version": "0.25.12",
      "resolved": "https://registry.npmjs.org/@esbuild/android-arm64/-/android-arm64-0.25.12.tgz",
      "integrity": "sha512-6AAmLG7zwD1Z159jCKPvAxZd4y/VTO0VkprYy+3N2FtJ8+BQWFXU+OxARIwA46c5tdD9SsKGZ/1ocqBS/gAKHg==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/android-x64": {
      "version": "0.25.12",
      "resolved": "https://registry.npmjs.org/@esbuild/android-x64/-/android-x64-0.25.12.tgz",
      "integrity": "sha512-5jbb+2hhDHx5phYR2By8GTWEzn6I9UqR11Kwf22iKbNpYrsmRB18aX/9ivc5cabcUiAT/wM+YIZ6SG9QO6a8kg==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/darwin-arm64": {
      "version": "0.25.12",
      "resolved": "https://registry.npmjs.org/@esbuild/darwin-arm64/-/darwin-arm64-0.25.12.tgz",
      "integrity": "sha512-N3zl+lxHCifgIlcMUP5016ESkeQjLj/959RxxNYIthIg+CQHInujFuXeWbWMgnTo4cp5XVHqFPmpyu9J65C1Yg==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/darwin-x64": {
      "version": "0.25.12",
      "resolved": "https://registry.npmjs.org/@esbuild/darwin-x64/-/darwin-x64-0.25.12.tgz",
      "integrity": "sha512-HQ9ka4Kx21qHXwtlTUVbKJOAnmG1ipXhdWTmNXiPzPfWKpXqASVcWdnf2bnL73wgjNrFXAa3yYvBSd9pzfEIpA==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/freebsd-arm64": {
      "version": "0.25.12",
      "resolved": "https://registry.npmjs.org/@esbuild/freebsd-arm64/-/freebsd-arm64-0.25.12.tgz",
      "integrity": "sha512-gA0Bx759+7Jve03K1S0vkOu5Lg/85dou3EseOGUes8flVOGxbhDDh/iZaoek11Y8mtyKPGF3vP8XhnkDEAmzeg==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "freebsd"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/freebsd-x64": {
      "version": "0.25.12",
      "resolved": "https://registry.npmjs.org/@esbuild/freebsd-x64/-/freebsd-x64-0.25.12.tgz",
      "integrity": "sha512-TGbO26Yw2xsHzxtbVFGEXBFH0FRAP7gtcPE7P5yP7wGy7cXK2oO7RyOhL5NLiqTlBh47XhmIUXuGciXEqYFfBQ==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "freebsd"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/linux-arm": {
      "version": "0.25.12",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-arm/-/linux-arm-0.25.12.tgz",
      "integrity": "sha512-lPDGyC1JPDou8kGcywY0YILzWlhhnRjdof3UlcoqYmS9El818LLfJJc3PXXgZHrHCAKs/Z2SeZtDJr5MrkxtOw==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/linux-arm64": {
      "version": "0.25.12",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-arm64/-/linux-arm64-0.25.12.tgz",
      "integrity": "sha512-8bwX7a8FghIgrupcxb4aUmYDLp8pX06rGh5HqDT7bB+8Rdells6mHvrFHHW2JAOPZUbnjUpKTLg6ECyzvas2AQ==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/linux-ia32": {
      "version": "0.25.12",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-ia32/-/linux-ia32-0.25.12.tgz",
      "integrity": "sha512-0y9KrdVnbMM2/vG8KfU0byhUN+EFCny9+8g202gYqSSVMonbsCfLjUO+rCci7pM0WBEtz+oK/PIwHkzxkyharA==",
      "cpu": [
        "ia32"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/linux-loong64": {
      "version": "0.25.12",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-loong64/-/linux-loong64-0.25.12.tgz",
      "integrity": "sha512-h///Lr5a9rib/v1GGqXVGzjL4TMvVTv+s1DPoxQdz7l/AYv6LDSxdIwzxkrPW438oUXiDtwM10o9PmwS/6Z0Ng==",
      "cpu": [
        "loong64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/linux-mips64el": {
      "version": "0.25.12",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-mips64el/-/linux-mips64el-0.25.12.tgz",
      "integrity": "sha512-iyRrM1Pzy9GFMDLsXn1iHUm18nhKnNMWscjmp4+hpafcZjrr2WbT//d20xaGljXDBYHqRcl8HnxbX6uaA/eGVw==",
      "cpu": [
        "mips64el"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/linux-ppc64": {
      "version": "0.25.12",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-ppc64/-/linux-ppc64-0.25.12.tgz",
      "integrity": "sha512-9meM/lRXxMi5PSUqEXRCtVjEZBGwB7P/D4yT8UG/mwIdze2aV4Vo6U5gD3+RsoHXKkHCfSxZKzmDssVlRj1QQA==",
      "cpu": [
        "ppc64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/linux-riscv64": {
      "version": "0.25.12",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-riscv64/-/linux-riscv64-0.25.12.tgz",
      "integrity": "sha512-Zr7KR4hgKUpWAwb1f3o5ygT04MzqVrGEGXGLnj15YQDJErYu/BGg+wmFlIDOdJp0PmB0lLvxFIOXZgFRrdjR0w==",
      "cpu": [
        "riscv64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/linux-s390x": {
      "version": "0.25.12",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-s390x/-/linux-s390x-0.25.12.tgz",
      "integrity": "sha512-MsKncOcgTNvdtiISc/jZs/Zf8d0cl/t3gYWX8J9ubBnVOwlk65UIEEvgBORTiljloIWnBzLs4qhzPkJcitIzIg==",
      "cpu": [
        "s390x"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/linux-x64": {
      "version": "0.25.12",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-x64/-/linux-x64-0.25.12.tgz",
      "integrity": "sha512-uqZMTLr/zR/ed4jIGnwSLkaHmPjOjJvnm6TVVitAa08SLS9Z0VM8wIRx7gWbJB5/J54YuIMInDquWyYvQLZkgw==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/netbsd-arm64": {
      "version": "0.25.12",
      "resolved": "https://registry.npmjs.org/@esbuild/netbsd-arm64/-/netbsd-arm64-0.25.12.tgz",
      "integrity": "sha512-xXwcTq4GhRM7J9A8Gv5boanHhRa/Q9KLVmcyXHCTaM4wKfIpWkdXiMog/KsnxzJ0A1+nD+zoecuzqPmCRyBGjg==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "netbsd"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/netbsd-x64": {
      "version": "0.25.12",
      "resolved": "https://registry.npmjs.org/@esbuild/netbsd-x64/-/netbsd-x64-0.25.12.tgz",
      "integrity": "sha512-Ld5pTlzPy3YwGec4OuHh1aCVCRvOXdH8DgRjfDy/oumVovmuSzWfnSJg+VtakB9Cm0gxNO9BzWkj6mtO1FMXkQ==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "netbsd"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/openbsd-arm64": {
      "version": "0.25.12",
      "resolved": "https://registry.npmjs.org/@esbuild/openbsd-arm64/-/openbsd-arm64-0.25.12.tgz",
      "integrity": "sha512-fF96T6KsBo/pkQI950FARU9apGNTSlZGsv1jZBAlcLL1MLjLNIWPBkj5NlSz8aAzYKg+eNqknrUJ24QBybeR5A==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "openbsd"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/openbsd-x64": {
      "version": "0.25.12",
      "resolved": "https://registry.npmjs.org/@esbuild/openbsd-x64/-/openbsd-x64-0.25.12.tgz",
      "integrity": "sha512-MZyXUkZHjQxUvzK7rN8DJ3SRmrVrke8ZyRusHlP+kuwqTcfWLyqMOE3sScPPyeIXN/mDJIfGXvcMqCgYKekoQw==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "openbsd"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/openharmony-arm64": {
      "version": "0.25.12",
      "resolved": "https://registry.npmjs.org/@esbuild/openharmony-arm64/-/openharmony-arm64-0.25.12.tgz",
      "integrity": "sha512-rm0YWsqUSRrjncSXGA7Zv78Nbnw4XL6/dzr20cyrQf7ZmRcsovpcRBdhD43Nuk3y7XIoW2OxMVvwuRvk9XdASg==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "openharmony"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/sunos-x64": {
      "version": "0.25.12",
      "resolved": "https://registry.npmjs.org/@esbuild/sunos-x64/-/sunos-x64-0.25.12.tgz",
      "integrity": "sha512-3wGSCDyuTHQUzt0nV7bocDy72r2lI33QL3gkDNGkod22EsYl04sMf0qLb8luNKTOmgF/eDEDP5BFNwoBKH441w==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "sunos"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/win32-arm64": {
      "version": "0.25.12",
      "resolved": "https://registry.npmjs.org/@esbuild/win32-arm64/-/win32-arm64-0.25.12.tgz",
      "integrity": "sha512-rMmLrur64A7+DKlnSuwqUdRKyd3UE7oPJZmnljqEptesKM8wx9J8gx5u0+9Pq0fQQW8vqeKebwNXdfOyP+8Bsg==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/win32-ia32": {
      "version": "0.25.12",
      "resolved": "https://registry.npmjs.org/@esbuild/win32-ia32/-/win32-ia32-0.25.12.tgz",
      "integrity": "sha512-HkqnmmBoCbCwxUKKNPBixiWDGCpQGVsrQfJoVGYLPT41XWF8lHuE5N6WhVia2n4o5QK5M4tYr21827fNhi4byQ==",
      "cpu": [
        "ia32"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@eslint-community/eslint-utils": {
      "version": "4.9.0",
      "resolved": "https://registry.npmjs.org/@eslint-community/eslint-utils/-/eslint-utils-4.9.0.tgz",
      "integrity": "sha512-ayVFHdtZ+hsq1t2Dy24wCmGXGe4q9Gu3smhLYALJrr473ZH27MsnSL+LKUlimp4BWJqMDMLmPpx/Q9R3OAlL4g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "eslint-visitor-keys": "^3.4.3"
      },
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      },
      "peerDependencies": {
        "eslint": "^6.0.0 || ^7.0.0 || >=8.0.0"
      }
    },
    "node_modules/@eslint-community/eslint-utils/node_modules/eslint-visitor-keys": {
      "version": "3.4.3",
      "resolved": "https://registry.npmjs.org/eslint-visitor-keys/-/eslint-visitor-keys-3.4.3.tgz",
      "integrity": "sha512-wpc+LXeiyiisxPlEkUzU6svyS1frIO3Mgxj1fdy7Pm8Ygzguax2N3Fa/D/ag1WqbOprdI+uY6wMUl8/a2G+iag==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/@eslint-community/regexpp": {
      "version": "4.12.2",
      "resolved": "https://registry.npmjs.org/@eslint-community/regexpp/-/regexpp-4.12.2.tgz",
      "integrity": "sha512-EriSTlt5OC9/7SXkRSCAhfSxxoSUgBm33OH+IkwbdpgoqsSsUg7y3uh+IICI/Qg4BBWr3U2i39RpmycbxMq4ew==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "^12.0.0 || ^14.0.0 || >=16.0.0"
      }
    },
    "node_modules/@eslint/config-array": {
      "version": "0.21.1",
      "resolved": "https://registry.npmjs.org/@eslint/config-array/-/config-array-0.21.1.tgz",
      "integrity": "sha512-aw1gNayWpdI/jSYVgzN5pL0cfzU02GT3NBpeT/DXbx1/1x7ZKxFPd9bwrzygx/qiwIQiJ1sw/zD8qY/kRvlGHA==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "@eslint/object-schema": "^2.1.7",
        "debug": "^4.3.1",
        "minimatch": "^3.1.2"
      },
      "engines": {
        "node": "^18.18.0 || ^20.9.0 || >=21.1.0"
      }
    },
    "node_modules/@eslint/config-helpers": {
      "version": "0.4.2",
      "resolved": "https://registry.npmjs.org/@eslint/config-helpers/-/config-helpers-0.4.2.tgz",
      "integrity": "sha512-gBrxN88gOIf3R7ja5K9slwNayVcZgK6SOUORm2uBzTeIEfeVaIhOpCtTox3P6R7o2jLFwLFTLnC7kU/RGcYEgw==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "@eslint/core": "^0.17.0"
      },
      "engines": {
        "node": "^18.18.0 || ^20.9.0 || >=21.1.0"
      }
    },
    "node_modules/@eslint/core": {
      "version": "0.17.0",
      "resolved": "https://registry.npmjs.org/@eslint/core/-/core-0.17.0.tgz",
      "integrity": "sha512-yL/sLrpmtDaFEiUj1osRP4TI2MDz1AddJL+jZ7KSqvBuliN4xqYY54IfdN8qD8Toa6g1iloph1fxQNkjOxrrpQ==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "@types/json-schema": "^7.0.15"
      },
      "engines": {
        "node": "^18.18.0 || ^20.9.0 || >=21.1.0"
      }
    },
    "node_modules/@eslint/eslintrc": {
      "version": "3.3.3",
      "resolved": "https://registry.npmjs.org/@eslint/eslintrc/-/eslintrc-3.3.3.tgz",
      "integrity": "sha512-Kr+LPIUVKz2qkx1HAMH8q1q6azbqBAsXJUxBl/ODDuVPX45Z9DfwB8tPjTi6nNZ8BuM3nbJxC5zCAg5elnBUTQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ajv": "^6.12.4",
        "debug": "^4.3.2",
        "espree": "^10.0.1",
        "globals": "^14.0.0",
        "ignore": "^5.2.0",
        "import-fresh": "^3.2.1",
        "js-yaml": "^4.1.1",
        "minimatch": "^3.1.2",
        "strip-json-comments": "^3.1.1"
      },
      "engines": {
        "node": "^18.18.0 || ^20.9.0 || >=21.1.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/@eslint/eslintrc/node_modules/globals": {
      "version": "14.0.0",
      "resolved": "https://registry.npmjs.org/globals/-/globals-14.0.0.tgz",
      "integrity": "sha512-oahGvuMGQlPw/ivIYBjVSrWAfWLBeku5tpPE2fOPLi+WHffIWbuh2tCjhyQhTBPMf5E9jDEH4FOmTYgYwbKwtQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=18"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/@eslint/js": {
      "version": "9.39.1",
      "resolved": "https://registry.npmjs.org/@eslint/js/-/js-9.39.1.tgz",
      "integrity": "sha512-S26Stp4zCy88tH94QbBv3XCuzRQiZ9yXofEILmglYTh/Ug/a9/umqvgFtYBAo3Lp0nsI/5/qH1CCrbdK3AP1Tw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "^18.18.0 || ^20.9.0 || >=21.1.0"
      },
      "funding": {
        "url": "https://eslint.org/donate"
      }
    },
    "node_modules/@eslint/object-schema": {
      "version": "2.1.7",
      "resolved": "https://registry.npmjs.org/@eslint/object-schema/-/object-schema-2.1.7.tgz",
      "integrity": "sha512-VtAOaymWVfZcmZbp6E2mympDIHvyjXs/12LqWYjVw6qjrfF+VK+fyG33kChz3nnK+SU5/NeHOqrTEHS8sXO3OA==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": "^18.18.0 || ^20.9.0 || >=21.1.0"
      }
    },
    "node_modules/@eslint/plugin-kit": {
      "version": "0.4.1",
      "resolved": "https://registry.npmjs.org/@eslint/plugin-kit/-/plugin-kit-0.4.1.tgz",
      "integrity": "sha512-43/qtrDUokr7LJqoF2c3+RInu/t4zfrpYdoSDfYyhg52rwLV6TnOvdG4fXm7IkSB3wErkcmJS9iEhjVtOSEjjA==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "@eslint/core": "^0.17.0",
        "levn": "^0.4.1"
      },
      "engines": {
        "node": "^18.18.0 || ^20.9.0 || >=21.1.0"
      }
    },
    "node_modules/@humanfs/core": {
      "version": "0.19.1",
      "resolved": "https://registry.npmjs.org/@humanfs/core/-/core-0.19.1.tgz",
      "integrity": "sha512-5DyQ4+1JEUzejeK1JGICcideyfUbGixgS9jNgex5nqkW+cY7WZhxBigmieN5Qnw9ZosSNVC9KQKyb+GUaGyKUA==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": ">=18.18.0"
      }
    },
    "node_modules/@humanfs/node": {
      "version": "0.16.7",
      "resolved": "https://registry.npmjs.org/@humanfs/node/-/node-0.16.7.tgz",
      "integrity": "sha512-/zUx+yOsIrG4Y43Eh2peDeKCxlRt/gET6aHfaKpuq267qXdYDFViVHfMaLyygZOnl0kGWxFIgsBy8QFuTLUXEQ==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "@humanfs/core": "^0.19.1",
        "@humanwhocodes/retry": "^0.4.0"
      },
      "engines": {
        "node": ">=18.18.0"
      }
    },
    "node_modules/@humanwhocodes/module-importer": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/@humanwhocodes/module-importer/-/module-importer-1.0.1.tgz",
      "integrity": "sha512-bxveV4V8v5Yb4ncFTT3rPSgZBOpCkjfK0y4oVVVJwIuDVBRMDXrPyXRL988i5ap9m9bnyEEjWfm5WkBmtffLfA==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": ">=12.22"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/nzakas"
      }
    },
    "node_modules/@humanwhocodes/retry": {
      "version": "0.4.3",
      "resolved": "https://registry.npmjs.org/@humanwhocodes/retry/-/retry-0.4.3.tgz",
      "integrity": "sha512-bV0Tgo9K4hfPCek+aMAn81RppFKv2ySDQeMoSZuvTASywNTnVJCArCZE2FWqpvIatKu7VMRLWlR1EazvVhDyhQ==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": ">=18.18"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/nzakas"
      }
    },
    "node_modules/@jridgewell/gen-mapping": {
      "version": "0.3.13",
      "resolved": "https://registry.npmjs.org/@jridgewell/gen-mapping/-/gen-mapping-0.3.13.tgz",
      "integrity": "sha512-2kkt/7niJ6MgEPxF0bYdQ6etZaA+fQvDcLKckhy1yIQOzaoKjBBjSj63/aLVjYE3qhRt5dvM+uUyfCg6UKCBbA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jridgewell/sourcemap-codec": "^1.5.0",
        "@jridgewell/trace-mapping": "^0.3.24"
      }
    },
    "node_modules/@jridgewell/remapping": {
      "version": "2.3.5",
      "resolved": "https://registry.npmjs.org/@jridgewell/remapping/-/remapping-2.3.5.tgz",
      "integrity": "sha512-LI9u/+laYG4Ds1TDKSJW2YPrIlcVYOwi2fUC6xB43lueCjgxV4lffOCZCtYFiH6TNOX+tQKXx97T4IKHbhyHEQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jridgewell/gen-mapping": "^0.3.5",
        "@jridgewell/trace-mapping": "^0.3.24"
      }
    },
    "node_modules/@jridgewell/resolve-uri": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/@jridgewell/resolve-uri/-/resolve-uri-3.1.2.tgz",
      "integrity": "sha512-bRISgCIjP20/tbWSPWMEi54QVPRZExkuD9lJL+UIxUKtwVJA8wW1Trb1jMs1RFXo1CBTNZ/5hpC9QvmKWdopKw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/@jridgewell/sourcemap-codec": {
      "version": "1.5.5",
      "resolved": "https://registry.npmjs.org/@jridgewell/sourcemap-codec/-/sourcemap-codec-1.5.5.tgz",
      "integrity": "sha512-cYQ9310grqxueWbl+WuIUIaiUaDcj7WOq5fVhEljNVgRfOUhY9fy2zTvfoqWsnebh8Sl70VScFbICvJnLKB0Og==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@jridgewell/trace-mapping": {
      "version": "0.3.31",
      "resolved": "https://registry.npmjs.org/@jridgewell/trace-mapping/-/trace-mapping-0.3.31.tgz",
      "integrity": "sha512-zzNR+SdQSDJzc8joaeP8QQoCQr8NuYx2dIIytl1QeBEZHJ9uW6hebsrYgbz8hJwUQao3TWCMtmfV8Nu1twOLAw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jridgewell/resolve-uri": "^3.1.0",
        "@jridgewell/sourcemap-codec": "^1.4.14"
      }
    },
    "node_modules/@rolldown/pluginutils": {
      "version": "1.0.0-beta.47",
      "resolved": "https://registry.npmjs.org/@rolldown/pluginutils/-/pluginutils-1.0.0-beta.47.tgz",
      "integrity": "sha512-8QagwMH3kNCuzD8EWL8R2YPW5e4OrHNSAHRFDdmFqEwEaD/KcNKjVoumo+gP2vW5eKB2UPbM6vTYiGZX0ixLnw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@rollup/rollup-android-arm-eabi": {
      "version": "4.53.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-android-arm-eabi/-/rollup-android-arm-eabi-4.53.3.tgz",
      "integrity": "sha512-mRSi+4cBjrRLoaal2PnqH82Wqyb+d3HsPUN/W+WslCXsZsyHa9ZeQQX/pQsZaVIWDkPcpV6jJ+3KLbTbgnwv8w==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ]
    },
    "node_modules/@rollup/rollup-android-arm64": {
      "version": "4.53.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-android-arm64/-/rollup-android-arm64-4.53.3.tgz",
      "integrity": "sha512-CbDGaMpdE9sh7sCmTrTUyllhrg65t6SwhjlMJsLr+J8YjFuPmCEjbBSx4Z/e4SmDyH3aB5hGaJUP2ltV/vcs4w==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ]
    },
    "node_modules/@rollup/rollup-darwin-arm64": {
      "version": "4.53.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-darwin-arm64/-/rollup-darwin-arm64-4.53.3.tgz",
      "integrity": "sha512-Nr7SlQeqIBpOV6BHHGZgYBuSdanCXuw09hon14MGOLGmXAFYjx1wNvquVPmpZnl0tLjg25dEdr4IQ6GgyToCUA==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ]
    },
    "node_modules/@rollup/rollup-darwin-x64": {
      "version": "4.53.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-darwin-x64/-/rollup-darwin-x64-4.53.3.tgz",
      "integrity": "sha512-DZ8N4CSNfl965CmPktJ8oBnfYr3F8dTTNBQkRlffnUarJ2ohudQD17sZBa097J8xhQ26AwhHJ5mvUyQW8ddTsQ==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ]
    },
    "node_modules/@rollup/rollup-freebsd-arm64": {
      "version": "4.53.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-freebsd-arm64/-/rollup-freebsd-arm64-4.53.3.tgz",
      "integrity": "sha512-yMTrCrK92aGyi7GuDNtGn2sNW+Gdb4vErx4t3Gv/Tr+1zRb8ax4z8GWVRfr3Jw8zJWvpGHNpss3vVlbF58DZ4w==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "freebsd"
      ]
    },
    "node_modules/@rollup/rollup-freebsd-x64": {
      "version": "4.53.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-freebsd-x64/-/rollup-freebsd-x64-4.53.3.tgz",
      "integrity": "sha512-lMfF8X7QhdQzseM6XaX0vbno2m3hlyZFhwcndRMw8fbAGUGL3WFMBdK0hbUBIUYcEcMhVLr1SIamDeuLBnXS+Q==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "freebsd"
      ]
    },
    "node_modules/@rollup/rollup-linux-arm-gnueabihf": {
      "version": "4.53.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-arm-gnueabihf/-/rollup-linux-arm-gnueabihf-4.53.3.tgz",
      "integrity": "sha512-k9oD15soC/Ln6d2Wv/JOFPzZXIAIFLp6B+i14KhxAfnq76ajt0EhYc5YPeX6W1xJkAdItcVT+JhKl1QZh44/qw==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-arm-musleabihf": {
      "version": "4.53.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-arm-musleabihf/-/rollup-linux-arm-musleabihf-4.53.3.tgz",
      "integrity": "sha512-vTNlKq+N6CK/8UktsrFuc+/7NlEYVxgaEgRXVUVK258Z5ymho29skzW1sutgYjqNnquGwVUObAaxae8rZ6YMhg==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-arm64-gnu": {
      "version": "4.53.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-arm64-gnu/-/rollup-linux-arm64-gnu-4.53.3.tgz",
      "integrity": "sha512-RGrFLWgMhSxRs/EWJMIFM1O5Mzuz3Xy3/mnxJp/5cVhZ2XoCAxJnmNsEyeMJtpK+wu0FJFWz+QF4mjCA7AUQ3w==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-arm64-musl": {
      "version": "4.53.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-arm64-musl/-/rollup-linux-arm64-musl-4.53.3.tgz",
      "integrity": "sha512-kASyvfBEWYPEwe0Qv4nfu6pNkITLTb32p4yTgzFCocHnJLAHs+9LjUu9ONIhvfT/5lv4YS5muBHyuV84epBo/A==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-loong64-gnu": {
      "version": "4.53.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-loong64-gnu/-/rollup-linux-loong64-gnu-4.53.3.tgz",
      "integrity": "sha512-JiuKcp2teLJwQ7vkJ95EwESWkNRFJD7TQgYmCnrPtlu50b4XvT5MOmurWNrCj3IFdyjBQ5p9vnrX4JM6I8OE7g==",
      "cpu": [
        "loong64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-ppc64-gnu": {
      "version": "4.53.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-ppc64-gnu/-/rollup-linux-ppc64-gnu-4.53.3.tgz",
      "integrity": "sha512-EoGSa8nd6d3T7zLuqdojxC20oBfNT8nexBbB/rkxgKj5T5vhpAQKKnD+h3UkoMuTyXkP5jTjK/ccNRmQrPNDuw==",
      "cpu": [
        "ppc64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-riscv64-gnu": {
      "version": "4.53.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-riscv64-gnu/-/rollup-linux-riscv64-gnu-4.53.3.tgz",
      "integrity": "sha512-4s+Wped2IHXHPnAEbIB0YWBv7SDohqxobiiPA1FIWZpX+w9o2i4LezzH/NkFUl8LRci/8udci6cLq+jJQlh+0g==",
      "cpu": [
        "riscv64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-riscv64-musl": {
      "version": "4.53.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-riscv64-musl/-/rollup-linux-riscv64-musl-4.53.3.tgz",
      "integrity": "sha512-68k2g7+0vs2u9CxDt5ktXTngsxOQkSEV/xBbwlqYcUrAVh6P9EgMZvFsnHy4SEiUl46Xf0IObWVbMvPrr2gw8A==",
      "cpu": [
        "riscv64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-s390x-gnu": {
      "version": "4.53.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-s390x-gnu/-/rollup-linux-s390x-gnu-4.53.3.tgz",
      "integrity": "sha512-VYsFMpULAz87ZW6BVYw3I6sWesGpsP9OPcyKe8ofdg9LHxSbRMd7zrVrr5xi/3kMZtpWL/wC+UIJWJYVX5uTKg==",
      "cpu": [
        "s390x"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-x64-gnu": {
      "version": "4.53.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-x64-gnu/-/rollup-linux-x64-gnu-4.53.3.tgz",
      "integrity": "sha512-3EhFi1FU6YL8HTUJZ51imGJWEX//ajQPfqWLI3BQq4TlvHy4X0MOr5q3D2Zof/ka0d5FNdPwZXm3Yyib/UEd+w==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-x64-musl": {
      "version": "4.53.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-x64-musl/-/rollup-linux-x64-musl-4.53.3.tgz",
      "integrity": "sha512-eoROhjcc6HbZCJr+tvVT8X4fW3/5g/WkGvvmwz/88sDtSJzO7r/blvoBDgISDiCjDRZmHpwud7h+6Q9JxFwq1Q==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-openharmony-arm64": {
      "version": "4.53.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-openharmony-arm64/-/rollup-openharmony-arm64-4.53.3.tgz",
      "integrity": "sha512-OueLAWgrNSPGAdUdIjSWXw+u/02BRTcnfw9PN41D2vq/JSEPnJnVuBgw18VkN8wcd4fjUs+jFHVM4t9+kBSNLw==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "openharmony"
      ]
    },
    "node_modules/@rollup/rollup-win32-arm64-msvc": {
      "version": "4.53.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-win32-arm64-msvc/-/rollup-win32-arm64-msvc-4.53.3.tgz",
      "integrity": "sha512-GOFuKpsxR/whszbF/bzydebLiXIHSgsEUp6M0JI8dWvi+fFa1TD6YQa4aSZHtpmh2/uAlj/Dy+nmby3TJ3pkTw==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ]
    },
    "node_modules/@rollup/rollup-win32-ia32-msvc": {
      "version": "4.53.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-win32-ia32-msvc/-/rollup-win32-ia32-msvc-4.53.3.tgz",
      "integrity": "sha512-iah+THLcBJdpfZ1TstDFbKNznlzoxa8fmnFYK4V67HvmuNYkVdAywJSoteUszvBQ9/HqN2+9AZghbajMsFT+oA==",
      "cpu": [
        "ia32"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ]
    },
    "node_modules/@rollup/rollup-win32-x64-gnu": {
      "version": "4.53.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-win32-x64-gnu/-/rollup-win32-x64-gnu-4.53.3.tgz",
      "integrity": "sha512-J9QDiOIZlZLdcot5NXEepDkstocktoVjkaKUtqzgzpt2yWjGlbYiKyp05rWwk4nypbYUNoFAztEgixoLaSETkg==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ]
    },
    "node_modules/@tailwindcss/node": {
      "version": "4.1.17",
      "resolved": "https://registry.npmjs.org/@tailwindcss/node/-/node-4.1.17.tgz",
      "integrity": "sha512-csIkHIgLb3JisEFQ0vxr2Y57GUNYh447C8xzwj89U/8fdW8LhProdxvnVH6U8M2Y73QKiTIH+LWbK3V2BBZsAg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jridgewell/remapping": "^2.3.4",
        "enhanced-resolve": "^5.18.3",
        "jiti": "^2.6.1",
        "lightningcss": "1.30.2",
        "magic-string": "^0.30.21",
        "source-map-js": "^1.2.1",
        "tailwindcss": "4.1.17"
      }
    },
    "node_modules/@tailwindcss/oxide": {
      "version": "4.1.17",
      "resolved": "https://registry.npmjs.org/@tailwindcss/oxide/-/oxide-4.1.17.tgz",
      "integrity": "sha512-F0F7d01fmkQhsTjXezGBLdrl1KresJTcI3DB8EkScCldyKp3Msz4hub4uyYaVnk88BAS1g5DQjjF6F5qczheLA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 10"
      },
      "optionalDependencies": {
        "@tailwindcss/oxide-android-arm64": "4.1.17",
        "@tailwindcss/oxide-darwin-arm64": "4.1.17",
        "@tailwindcss/oxide-darwin-x64": "4.1.17",
        "@tailwindcss/oxide-freebsd-x64": "4.1.17",
        "@tailwindcss/oxide-linux-arm-gnueabihf": "4.1.17",
        "@tailwindcss/oxide-linux-arm64-gnu": "4.1.17",
        "@tailwindcss/oxide-linux-arm64-musl": "4.1.17",
        "@tailwindcss/oxide-linux-x64-gnu": "4.1.17",
        "@tailwindcss/oxide-linux-x64-musl": "4.1.17",
        "@tailwindcss/oxide-wasm32-wasi": "4.1.17",
        "@tailwindcss/oxide-win32-arm64-msvc": "4.1.17",
        "@tailwindcss/oxide-win32-x64-msvc": "4.1.17"
      }
    },
    "node_modules/@tailwindcss/oxide-android-arm64": {
      "version": "4.1.17",
      "resolved": "https://registry.npmjs.org/@tailwindcss/oxide-android-arm64/-/oxide-android-arm64-4.1.17.tgz",
      "integrity": "sha512-BMqpkJHgOZ5z78qqiGE6ZIRExyaHyuxjgrJ6eBO5+hfrfGkuya0lYfw8fRHG77gdTjWkNWEEm+qeG2cDMxArLQ==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@tailwindcss/oxide-darwin-arm64": {
      "version": "4.1.17",
      "resolved": "https://registry.npmjs.org/@tailwindcss/oxide-darwin-arm64/-/oxide-darwin-arm64-4.1.17.tgz",
      "integrity": "sha512-EquyumkQweUBNk1zGEU/wfZo2qkp/nQKRZM8bUYO0J+Lums5+wl2CcG1f9BgAjn/u9pJzdYddHWBiFXJTcxmOg==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@tailwindcss/oxide-darwin-x64": {
      "version": "4.1.17",
      "resolved": "https://registry.npmjs.org/@tailwindcss/oxide-darwin-x64/-/oxide-darwin-x64-4.1.17.tgz",
      "integrity": "sha512-gdhEPLzke2Pog8s12oADwYu0IAw04Y2tlmgVzIN0+046ytcgx8uZmCzEg4VcQh+AHKiS7xaL8kGo/QTiNEGRog==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@tailwindcss/oxide-freebsd-x64": {
      "version": "4.1.17",
      "resolved": "https://registry.npmjs.org/@tailwindcss/oxide-freebsd-x64/-/oxide-freebsd-x64-4.1.17.tgz",
      "integrity": "sha512-hxGS81KskMxML9DXsaXT1H0DyA+ZBIbyG/sSAjWNe2EDl7TkPOBI42GBV3u38itzGUOmFfCzk1iAjDXds8Oh0g==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "freebsd"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@tailwindcss/oxide-linux-arm-gnueabihf": {
      "version": "4.1.17",
      "resolved": "https://registry.npmjs.org/@tailwindcss/oxide-linux-arm-gnueabihf/-/oxide-linux-arm-gnueabihf-4.1.17.tgz",
      "integrity": "sha512-k7jWk5E3ldAdw0cNglhjSgv501u7yrMf8oeZ0cElhxU6Y2o7f8yqelOp3fhf7evjIS6ujTI3U8pKUXV2I4iXHQ==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@tailwindcss/oxide-linux-arm64-gnu": {
      "version": "4.1.17",
      "resolved": "https://registry.npmjs.org/@tailwindcss/oxide-linux-arm64-gnu/-/oxide-linux-arm64-gnu-4.1.17.tgz",
      "integrity": "sha512-HVDOm/mxK6+TbARwdW17WrgDYEGzmoYayrCgmLEw7FxTPLcp/glBisuyWkFz/jb7ZfiAXAXUACfyItn+nTgsdQ==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@tailwindcss/oxide-linux-arm64-musl": {
      "version": "4.1.17",
      "resolved": "https://registry.npmjs.org/@tailwindcss/oxide-linux-arm64-musl/-/oxide-linux-arm64-musl-4.1.17.tgz",
      "integrity": "sha512-HvZLfGr42i5anKtIeQzxdkw/wPqIbpeZqe7vd3V9vI3RQxe3xU1fLjss0TjyhxWcBaipk7NYwSrwTwK1hJARMg==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@tailwindcss/oxide-linux-x64-gnu": {
      "version": "4.1.17",
      "resolved": "https://registry.npmjs.org/@tailwindcss/oxide-linux-x64-gnu/-/oxide-linux-x64-gnu-4.1.17.tgz",
      "integrity": "sha512-M3XZuORCGB7VPOEDH+nzpJ21XPvK5PyjlkSFkFziNHGLc5d6g3di2McAAblmaSUNl8IOmzYwLx9NsE7bplNkwQ==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@tailwindcss/oxide-linux-x64-musl": {
      "version": "4.1.17",
      "resolved": "https://registry.npmjs.org/@tailwindcss/oxide-linux-x64-musl/-/oxide-linux-x64-musl-4.1.17.tgz",
      "integrity": "sha512-k7f+pf9eXLEey4pBlw+8dgfJHY4PZ5qOUFDyNf7SI6lHjQ9Zt7+NcscjpwdCEbYi6FI5c2KDTDWyf2iHcCSyyQ==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@tailwindcss/oxide-wasm32-wasi": {
      "version": "4.1.17",
      "resolved": "https://registry.npmjs.org/@tailwindcss/oxide-wasm32-wasi/-/oxide-wasm32-wasi-4.1.17.tgz",
      "integrity": "sha512-cEytGqSSoy7zK4JRWiTCx43FsKP/zGr0CsuMawhH67ONlH+T79VteQeJQRO/X7L0juEUA8ZyuYikcRBf0vsxhg==",
      "bundleDependencies": [
        "@napi-rs/wasm-runtime",
        "@emnapi/core",
        "@emnapi/runtime",
        "@tybys/wasm-util",
        "@emnapi/wasi-threads",
        "tslib"
      ],
      "cpu": [
        "wasm32"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "@emnapi/core": "^1.6.0",
        "@emnapi/runtime": "^1.6.0",
        "@emnapi/wasi-threads": "^1.1.0",
        "@napi-rs/wasm-runtime": "^1.0.7",
        "@tybys/wasm-util": "^0.10.1",
        "tslib": "^2.4.0"
      },
      "engines": {
        "node": ">=14.0.0"
      }
    },
    "node_modules/@tailwindcss/oxide-win32-arm64-msvc": {
      "version": "4.1.17",
      "resolved": "https://registry.npmjs.org/@tailwindcss/oxide-win32-arm64-msvc/-/oxide-win32-arm64-msvc-4.1.17.tgz",
      "integrity": "sha512-JU5AHr7gKbZlOGvMdb4722/0aYbU+tN6lv1kONx0JK2cGsh7g148zVWLM0IKR3NeKLv+L90chBVYcJ8uJWbC9A==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@tailwindcss/oxide/node_modules/@tailwindcss/oxide-win32-x64-msvc": {
      "version": "4.1.17",
      "resolved": "https://registry.npmjs.org/@tailwindcss/oxide-win32-x64-msvc/-/oxide-win32-x64-msvc-4.1.17.tgz",
      "integrity": "sha512-SKWM4waLuqx0IH+FMDUw6R66Hu4OuTALFgnleKbqhgGU30DY20NORZMZUKgLRjQXNN2TLzKvh48QXTig4h4bGw==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@tailwindcss/postcss": {
      "version": "4.1.17",
      "resolved": "https://registry.npmjs.org/@tailwindcss/postcss/-/postcss-4.1.17.tgz",
      "integrity": "sha512-+nKl9N9mN5uJ+M7dBOOCzINw94MPstNR/GtIhz1fpZysxL/4a+No64jCBD6CPN+bIHWFx3KWuu8XJRrj/572Dw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@alloc/quick-lru": "^5.2.0",
        "@tailwindcss/node": "4.1.17",
        "@tailwindcss/oxide": "4.1.17",
        "postcss": "^8.4.41",
        "tailwindcss": "4.1.17"
      }
    },
    "node_modules/@types/babel__core": {
      "version": "7.20.5",
      "resolved": "https://registry.npmjs.org/@types/babel__core/-/babel__core-7.20.5.tgz",
      "integrity": "sha512-qoQprZvz5wQFJwMDqeseRXWv3rqMvhgpbXFfVyWhbx9X47POIA6i/+dXefEmZKoAgOaTdaIgNSMqMIU61yRyzA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/parser": "^7.20.7",
        "@babel/types": "^7.20.7",
        "@types/babel__generator": "*",
        "@types/babel__template": "*",
        "@types/babel__traverse": "*"
      }
    },
    "node_modules/@types/babel__generator": {
      "version": "7.27.0",
      "resolved": "https://registry.npmjs.org/@types/babel__generator/-/babel__generator-7.27.0.tgz",
      "integrity": "sha512-ufFd2Xi92OAVPYsy+P4n7/U7e68fex0+Ee8gSG9KX7eo084CWiQ4sdxktvdl0bOPupXtVJPY19zk6EwWqUQ8lg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/types": "^7.0.0"
      }
    },
    "node_modules/@types/babel__template": {
      "version": "7.4.4",
      "resolved": "https://registry.npmjs.org/@types/babel__template/-/babel__template-7.4.4.tgz",
      "integrity": "sha512-h/NUaSyG5EyxBIp8YRxo4RMe2/qQgvyowRwVMzhYhBCONbW8PUsg4lkFMrhgZhUe5z3L3MiLDuvyJ/CaPa2A8A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/parser": "^7.1.0",
        "@babel/types": "^7.0.0"
      }
    },
    "node_modules/@types/babel__traverse": {
      "version": "7.28.0",
      "resolved": "https://registry.npmjs.org/@types/babel__traverse/-/babel__traverse-7.28.0.tgz",
      "integrity": "sha512-8PvcXf70gTDZBgt9ptxJ8elBeBjcLOAcOtoO/mPJjtji1+CdGbHgm77om1GrsPxsiE+uXIpNSK64UYaIwQXd4Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/types": "^7.28.2"
      }
    },
    "node_modules/@types/debug": {
      "version": "4.1.12",
      "resolved": "https://registry.npmjs.org/@types/debug/-/debug-4.1.12.tgz",
      "integrity": "sha512-vIChWdVG3LG1SMxEvI/AK+FWJthlrqlTu7fbrlywTkkaONwk/UAGaULXRlf8vkzFBLVm0zkMdCquhL5aOjhXPQ==",
      "license": "MIT",
      "dependencies": {
        "@types/ms": "*"
      }
    },
    "node_modules/@types/estree": {
      "version": "1.0.8",
      "resolved": "https://registry.npmjs.org/@types/estree/-/estree-1.0.8.tgz",
      "integrity": "sha512-dWHzHa2WqEXI/O1E9OjrocMTKJl2mSrEolh1Iomrv6U+JuNwaHXsXx9bLu5gG7BUWFIN0skIQJQ/L1rIex4X6w==",
      "license": "MIT"
    },
    "node_modules/@types/estree-jsx": {
      "version": "1.0.5",
      "resolved": "https://registry.npmjs.org/@types/estree-jsx/-/estree-jsx-1.0.5.tgz",
      "integrity": "sha512-52CcUVNFyfb1A2ALocQw/Dd1BQFNmSdkuC3BkZ6iqhdMfQz7JWOFRuJFloOzjk+6WijU56m9oKXFAXc7o3Towg==",
      "license": "MIT",
      "dependencies": {
        "@types/estree": "*"
      }
    },
    "node_modules/@types/hast": {
      "version": "3.0.4",
      "resolved": "https://registry.npmjs.org/@types/hast/-/hast-3.0.4.tgz",
      "integrity": "sha512-WPs+bbQw5aCj+x6laNGWLH3wviHtoCv/P3+otBhbOhJgG8qtpdAMlTCxLtsTWA7LH1Oh/bFCHsBn0TPS5m30EQ==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "*"
      }
    },
    "node_modules/@types/json-schema": {
      "version": "7.0.15",
      "resolved": "https://registry.npmjs.org/@types/json-schema/-/json-schema-7.0.15.tgz",
      "integrity": "sha512-5+fP8P8MFNC+AyZCDxrB2pkZFPGzqQWUzpSeuuVLvm8VMcorNYavBqoFcxK8bQz4Qsbn4oUEEem4wDLfcysGHA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@types/mdast": {
      "version": "4.0.4",
      "resolved": "https://registry.npmjs.org/@types/mdast/-/mdast-4.0.4.tgz",
      "integrity": "sha512-kGaNbPh1k7AFzgpud/gMdvIm5xuECykRR+JnWKQno9TAXVa6WIVCGTPvYGekIDL4uwCZQSYbUxNBSb1aUo79oA==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "*"
      }
    },
    "node_modules/@types/ms": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/@types/ms/-/ms-2.1.0.tgz",
      "integrity": "sha512-GsCCIZDE/p3i96vtEqx+7dBUGXrc7zeSK3wwPHIaRThS+9OhWIXRqzs4d6k1SVU8g91DrNRWxWUGhp5KXQb2VA==",
      "license": "MIT"
    },
    "node_modules/@types/react": {
      "version": "19.2.7",
      "resolved": "https://registry.npmjs.org/@types/react/-/react-19.2.7.tgz",
      "integrity": "sha512-MWtvHrGZLFttgeEj28VXHxpmwYbor/ATPYbBfSFZEIRK0ecCFLl2Qo55z52Hss+UV9CRN7trSeq1zbgx7YDWWg==",
      "license": "MIT",
      "peer": true,
      "dependencies": {
        "csstype": "^3.2.2"
      }
    },
    "node_modules/@types/react-dom": {
      "version": "19.2.3",
      "resolved": "https://registry.npmjs.org/@types/react-dom/-/react-dom-19.2.3.tgz",
      "integrity": "sha512-jp2L/eY6fn+KgVVQAOqYItbF0VY/YApe5Mz2F0aykSO8gx31bYCZyvSeYxCHKvzHG5eZjc+zyaS5BrBWya2+kQ==",
      "dev": true,
      "license": "MIT",
      "peerDependencies": {
        "@types/react": "^19.2.0"
      }
    },
    "node_modules/@types/unist": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/@types/unist/-/unist-3.0.3.tgz",
      "integrity": "sha512-ko/gIFJRv177XgZsZcBwnqJN5x/Gien8qNOn0D5bQU/zAzVf9Zt3BlcUiLqhV9y4ARk0GbT3tnUiPNgnTXzc/Q==",
      "license": "MIT"
    },
    "node_modules/@ungap/structured-clone": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/@ungap/structured-clone/-/structured-clone-1.3.0.tgz",
      "integrity": "sha512-WmoN8qaIAo7WTYWbAZuG8PYEhn5fkz7dZrqTBZ7dtt//lL2Gwms1IcnQ5yHqjDfX8Ft5j4YzDM23f87zBfDe9g==",
      "license": "ISC"
    },
    "node_modules/@vitejs/plugin-react": {
      "version": "5.1.1",
      "resolved": "https://registry.npmjs.org/@vitejs/plugin-react/-/plugin-react-5.1.1.tgz",
      "integrity": "sha512-WQfkSw0QbQ5aJ2CHYw23ZGkqnRwqKHD/KYsMeTkZzPT4Jcf0DcBxBtwMJxnu6E7oxw5+JC6ZAiePgh28uJ1HBA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/core": "^7.28.5",
        "@babel/plugin-transform-react-jsx-self": "^7.27.1",
        "@babel/plugin-transform-react-jsx-source": "^7.27.1",
        "@rolldown/pluginutils": "1.0.0-beta.47",
        "@types/babel__core": "^7.20.5",
        "react-refresh": "^0.18.0"
      },
      "engines": {
        "node": "^20.19.0 || >=22.12.0"
      },
      "peerDependencies": {
        "vite": "^4.2.0 || ^5.0.0 || ^6.0.0 || ^7.0.0"
      }
    },
    "node_modules/acorn": {
      "version": "8.15.0",
      "resolved": "https://registry.npmjs.org/acorn/-/acorn-8.15.0.tgz",
      "integrity": "sha512-NZyJarBfL7nWwIq+FDL6Zp/yHEhePMNnnJ0y3qfieCrmNvYct8uvtiV41UvlSe6apAfk0fY1FbWx+NwfmpvtTg==",
      "dev": true,
      "license": "MIT",
      "peer": true,
      "bin": {
        "acorn": "bin/acorn"
      },
      "engines": {
        "node": ">=0.4.0"
      }
    },
    "node_modules/acorn-jsx": {
      "version": "5.3.2",
      "resolved": "https://registry.npmjs.org/acorn-jsx/-/acorn-jsx-5.3.2.tgz",
      "integrity": "sha512-rq9s+JNhf0IChjtDXxllJ7g41oZk5SlXtp0LHwyA5cejwn7vKmKp4pPri6YEePv2PU65sAsegbXtIinmDFDXgQ==",
      "dev": true,
      "license": "MIT",
      "peerDependencies": {
        "acorn": "^6.0.0 || ^7.0.0 || ^8.0.0"
      }
    },
    "node_modules/ajv": {
      "version": "6.12.6",
      "resolved": "https://registry.npmjs.org/ajv/-/ajv-6.12.6.tgz",
      "integrity": "sha512-j3fVLgvTo527anyYyJOGTYJbG+vnnQYvE0m5mmkc1TK+nxAppkCLMIL0aZ4dblVCNoGShhm+kzE4ZUykBoMg4g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "fast-deep-equal": "^3.1.1",
        "fast-json-stable-stringify": "^2.0.0",
        "json-schema-traverse": "^0.4.1",
        "uri-js": "^4.2.2"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/epoberezkin"
      }
    },
    "node_modules/ansi-styles": {
      "version": "4.3.0",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-4.3.0.tgz",
      "integrity": "sha512-zbB9rCJAT1rbjiVDb2hqKFHNYLxgtk8NURxZ3IZwD3F6NtxbXZQCnnSi1Lkx+IDohdPlFp222wVALIheZJQSEg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "color-convert": "^2.0.1"
      },
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/argparse": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/argparse/-/argparse-2.0.1.tgz",
      "integrity": "sha512-8+9WqebbFzpX9OR+Wa6O29asIogeRMzcGtAINdpMHHyAg10f05aSFVBbcEqGf/PXw1EjAZ+q2/bEBg3DvurK3Q==",
      "dev": true,
      "license": "Python-2.0"
    },
    "node_modules/autoprefixer": {
      "version": "10.4.22",
      "resolved": "https://registry.npmjs.org/autoprefixer/-/autoprefixer-10.4.22.tgz",
      "integrity": "sha512-ARe0v/t9gO28Bznv6GgqARmVqcWOV3mfgUPn9becPHMiD3o9BwlRgaeccZnwTpZ7Zwqrm+c1sUSsMxIzQzc8Xg==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/autoprefixer"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "browserslist": "^4.27.0",
        "caniuse-lite": "^1.0.30001754",
        "fraction.js": "^5.3.4",
        "normalize-range": "^0.1.2",
        "picocolors": "^1.1.1",
        "postcss-value-parser": "^4.2.0"
      },
      "bin": {
        "autoprefixer": "bin/autoprefixer"
      },
      "engines": {
        "node": "^10 || ^12 || >=14"
      },
      "peerDependencies": {
        "postcss": "^8.1.0"
      }
    },
    "node_modules/bail": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/bail/-/bail-2.0.2.tgz",
      "integrity": "sha512-0xO6mYd7JB2YesxDKplafRpsiOzPt9V02ddPCLbY1xYGPOX24NTyN50qnUxgCPcSoYMhKpAuBTjQoRZCAkUDRw==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/balanced-match": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/balanced-match/-/balanced-match-1.0.2.tgz",
      "integrity": "sha512-3oSeUO0TMV67hN1AmbXsK4yaqU7tjiHlbxRDZOpH0KW9+CeX4bRAaX0Anxt0tx2MrpRpWwQaPwIlISEJhYU5Pw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/baseline-browser-mapping": {
      "version": "2.8.32",
      "resolved": "https://registry.npmjs.org/baseline-browser-mapping/-/baseline-browser-mapping-2.8.32.tgz",
      "integrity": "sha512-OPz5aBThlyLFgxyhdwf/s2+8ab3OvT7AdTNvKHBwpXomIYeXqpUUuT8LrdtxZSsWJ4R4CU1un4XGh5Ez3nlTpw==",
      "dev": true,
      "license": "Apache-2.0",
      "bin": {
        "baseline-browser-mapping": "dist/cli.js"
      }
    },
    "node_modules/brace-expansion": {
      "version": "1.1.12",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-1.1.12.tgz",
      "integrity": "sha512-9T9UjW3r0UW5c1Q7GTwllptXwhvYmEzFhzMfZ9H7FQWt+uZePjZPjBP/W1ZEyZ1twGWom5/56TF4lPcqjnDHcg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "balanced-match": "^1.0.0",
        "concat-map": "0.0.1"
      }
    },
    "node_modules/browserslist": {
      "version": "4.28.0",
      "resolved": "https://registry.npmjs.org/browserslist/-/browserslist-4.28.0.tgz",
      "integrity": "sha512-tbydkR/CxfMwelN0vwdP/pLkDwyAASZ+VfWm4EOwlB6SWhx1sYnWLqo8N5j0rAzPfzfRaxt0mM/4wPU/Su84RQ==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/browserslist"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/browserslist"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "peer": true,
      "dependencies": {
        "baseline-browser-mapping": "^2.8.25",
        "caniuse-lite": "^1.0.30001754",
        "electron-to-chromium": "^1.5.249",
        "node-releases": "^2.0.27",
        "update-browserslist-db": "^1.1.4"
      },
      "bin": {
        "browserslist": "cli.js"
      },
      "engines": {
        "node": "^6 || ^7 || ^8 || ^9 || ^10 || ^11 || ^12 || >=13.7"
      }
    },
    "node_modules/callsites": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/callsites/-/callsites-3.1.0.tgz",
      "integrity": "sha512-P8BjAsXvZS+VIDUI11hHCQEv74YT67YUi5JJFNWIqL235sBmjX4+qx9Muvls5ivyNENctx46xQLQ3aTuE7ssaQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/caniuse-lite": {
      "version": "1.0.30001757",
      "resolved": "https://registry.npmjs.org/caniuse-lite/-/caniuse-lite-1.0.30001757.tgz",
      "integrity": "sha512-r0nnL/I28Zi/yjk1el6ilj27tKcdjLsNqAOZr0yVjWPrSQyHgKI2INaEWw21bAQSv2LXRt1XuCS/GomNpWOxsQ==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/browserslist"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/caniuse-lite"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "CC-BY-4.0"
    },
    "node_modules/ccount": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/ccount/-/ccount-2.0.1.tgz",
      "integrity": "sha512-eyrF0jiFpY+3drT6383f1qhkbGsLSifNAjA61IUjZjmLCWjItY6LB9ft9YhoDgwfmclB2zhu51Lc7+95b8NRAg==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/chalk": {
      "version": "4.1.2",
      "resolved": "https://registry.npmjs.org/chalk/-/chalk-4.1.2.tgz",
      "integrity": "sha512-oKnbhFyRIXpUuez8iBMmyEa4nbj4IOQyuhc/wy9kY7/WVPcwIO9VA668Pu8RkO7+0G76SLROeyw9CpQ061i4mA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-styles": "^4.1.0",
        "supports-color": "^7.1.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/chalk?sponsor=1"
      }
    },
    "node_modules/character-entities": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/character-entities/-/character-entities-2.0.2.tgz",
      "integrity": "sha512-shx7oQ0Awen/BRIdkjkvz54PnEEI/EjwXDSIZp86/KKdbafHh1Df/RYGBhn4hbe2+uKC9FnT5UCEdyPz3ai9hQ==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/character-entities-html4": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/character-entities-html4/-/character-entities-html4-2.1.0.tgz",
      "integrity": "sha512-1v7fgQRj6hnSwFpq1Eu0ynr/CDEw0rXo2B61qXrLNdHZmPKgb7fqS1a2JwF0rISo9q77jDI8VMEHoApn8qDoZA==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/character-entities-legacy": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/character-entities-legacy/-/character-entities-legacy-3.0.0.tgz",
      "integrity": "sha512-RpPp0asT/6ufRm//AJVwpViZbGM/MkjQFxJccQRHmISF/22NBtsHqAWmL+/pmkPWoIUJdWyeVleTl1wydHATVQ==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/character-reference-invalid": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/character-reference-invalid/-/character-reference-invalid-2.0.1.tgz",
      "integrity": "sha512-iBZ4F4wRbyORVsu0jPV7gXkOsGYjGHPmAyv+HiHG8gi5PtC9KI2j1+v8/tlibRvjoWX027ypmG/n0HtO5t7unw==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/color-convert": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/color-convert/-/color-convert-2.0.1.tgz",
      "integrity": "sha512-RRECPsj7iu/xb5oKYcsFHSppFNnsj/52OVTRKb4zP5onXwVF3zVmmToNcOfGC+CRDpfK/U584fMg38ZHCaElKQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "color-name": "~1.1.4"
      },
      "engines": {
        "node": ">=7.0.0"
      }
    },
    "node_modules/color-name": {
      "version": "1.1.4",
      "resolved": "https://registry.npmjs.org/color-name/-/color-name-1.1.4.tgz",
      "integrity": "sha512-dOy+3AuW3a2wNbZHIuMZpTcgjGuLU/uBL/ubcZF9OXbDo8ff4O8yVp5Bf0efS8uEoYo5q4Fx7dY9OgQGXgAsQA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/comma-separated-tokens": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/comma-separated-tokens/-/comma-separated-tokens-2.0.3.tgz",
      "integrity": "sha512-Fu4hJdvzeylCfQPp9SGWidpzrMs7tTrlu6Vb8XGaRGck8QSNZJJp538Wrb60Lax4fPwR64ViY468OIUTbRlGZg==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/concat-map": {
      "version": "0.0.1",
      "resolved": "https://registry.npmjs.org/concat-map/-/concat-map-0.0.1.tgz",
      "integrity": "sha512-/Srv4dswyQNBfohGpz9o6Yb3Gz3SrUDqBH5rTuhGR7ahtlbYKnVxw2bCFMRljaA7EXHaXZ8wsHdodFvbkhKmqg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/convert-source-map": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/convert-source-map/-/convert-source-map-2.0.0.tgz",
      "integrity": "sha512-Kvp459HrV2FEJ1CAsi1Ku+MY3kasH19TFykTz2xWmMeq6bk2NU3XXvfJ+Q61m0xktWwt+1HSYf3JZsTms3aRJg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/cross-spawn": {
      "version": "7.0.6",
      "resolved": "https://registry.npmjs.org/cross-spawn/-/cross-spawn-7.0.6.tgz",
      "integrity": "sha512-uV2QOWP2nWzsy2aMp8aRibhi9dlzF5Hgh5SHaB9OiTGEyDTiJJyx0uy51QXdyWbtAHNua4XJzUKca3OzKUd3vA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "path-key": "^3.1.0",
        "shebang-command": "^2.0.0",
        "which": "^2.0.1"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/csstype": {
      "version": "3.2.3",
      "resolved": "https://registry.npmjs.org/csstype/-/csstype-3.2.3.tgz",
      "integrity": "sha512-z1HGKcYy2xA8AGQfwrn0PAy+PB7X/GSj3UVJW9qKyn43xWa+gl5nXmU4qqLMRzWVLFC8KusUX8T/0kCiOYpAIQ==",
      "license": "MIT"
    },
    "node_modules/debug": {
      "version": "4.4.3",
      "resolved": "https://registry.npmjs.org/debug/-/debug-4.4.3.tgz",
      "integrity": "sha512-RGwwWnwQvkVfavKVt22FGLw+xYSdzARwm0ru6DhTVA3umU5hZc28V3kO4stgYryrTlLpuvgI9GiijltAjNbcqA==",
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.3"
      },
      "engines": {
        "node": ">=6.0"
      },
      "peerDependenciesMeta": {
        "supports-color": {
          "optional": true
        }
      }
    },
    "node_modules/decode-named-character-reference": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/decode-named-character-reference/-/decode-named-character-reference-1.2.0.tgz",
      "integrity": "sha512-c6fcElNV6ShtZXmsgNgFFV5tVX2PaV4g+MOAkb8eXHvn6sryJBrZa9r0zV6+dtTyoCKxtDy5tyQ5ZwQuidtd+Q==",
      "license": "MIT",
      "dependencies": {
        "character-entities": "^2.0.0"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/deep-is": {
      "version": "0.1.4",
      "resolved": "https://registry.npmjs.org/deep-is/-/deep-is-0.1.4.tgz",
      "integrity": "sha512-oIPzksmTg4/MriiaYGO+okXDT7ztn/w3Eptv/+gSIdMdKsJo0u4CfYNFJPy+4SKMuCqGw2wxnA+URMg3t8a/bQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/dequal": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/dequal/-/dequal-2.0.3.tgz",
      "integrity": "sha512-0je+qPKHEMohvfRTCEo3CrPG6cAzAYgmzKyxRiYSSDkS6eGJdyVJm7WaYA5ECaAD9wLB2T4EEeymA5aFVcYXCA==",
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/detect-libc": {
      "version": "2.1.2",
      "resolved": "https://registry.npmjs.org/detect-libc/-/detect-libc-2.1.2.tgz",
      "integrity": "sha512-Btj2BOOO83o3WyH59e8MgXsxEQVcarkUOpEYrubB0urwnN10yQ364rsiByU11nZlqWYZm05i/of7io4mzihBtQ==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/devlop": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/devlop/-/devlop-1.1.0.tgz",
      "integrity": "sha512-RWmIqhcFf1lRYBvNmr7qTNuyCt/7/ns2jbpp1+PalgE/rDQcBT0fioSMUpJ93irlUhC5hrg4cYqe6U+0ImW0rA==",
      "license": "MIT",
      "dependencies": {
        "dequal": "^2.0.0"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/electron-to-chromium": {
      "version": "1.5.262",
      "resolved": "https://registry.npmjs.org/electron-to-chromium/-/electron-to-chromium-1.5.262.tgz",
      "integrity": "sha512-NlAsMteRHek05jRUxUR0a5jpjYq9ykk6+kO0yRaMi5moe7u0fVIOeQ3Y30A8dIiWFBNUoQGi1ljb1i5VtS9WQQ==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/enhanced-resolve": {
      "version": "5.18.3",
      "resolved": "https://registry.npmjs.org/enhanced-resolve/-/enhanced-resolve-5.18.3.tgz",
      "integrity": "sha512-d4lC8xfavMeBjzGr2vECC3fsGXziXZQyJxD868h2M/mBI3PwAuODxAkLkq5HYuvrPYcUtiLzsTo8U3PgX3Ocww==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "graceful-fs": "^4.2.4",
        "tapable": "^2.2.0"
      },
      "engines": {
        "node": ">=10.13.0"
      }
    },
    "node_modules/esbuild": {
      "version": "0.25.12",
      "resolved": "https://registry.npmjs.org/esbuild/-/esbuild-0.25.12.tgz",
      "integrity": "sha512-bbPBYYrtZbkt6Os6FiTLCTFxvq4tt3JKall1vRwshA3fdVztsLAatFaZobhkBC8/BrPetoa0oksYoKXoG4ryJg==",
      "dev": true,
      "hasInstallScript": true,
      "license": "MIT",
      "bin": {
        "esbuild": "bin/esbuild"
      },
      "engines": {
        "node": ">=18"
      },
      "optionalDependencies": {
        "@esbuild/aix-ppc64": "0.25.12",
        "@esbuild/android-arm": "0.25.12",
        "@esbuild/android-arm64": "0.25.12",
        "@esbuild/android-x64": "0.25.12",
        "@esbuild/darwin-arm64": "0.25.12",
        "@esbuild/darwin-x64": "0.25.12",
        "@esbuild/freebsd-arm64": "0.25.12",
        "@esbuild/freebsd-x64": "0.25.12",
        "@esbuild/linux-arm": "0.25.12",
        "@esbuild/linux-arm64": "0.25.12",
        "@esbuild/linux-ia32": "0.25.12",
        "@esbuild/linux-loong64": "0.25.12",
        "@esbuild/linux-mips64el": "0.25.12",
        "@esbuild/linux-ppc64": "0.25.12",
        "@esbuild/linux-riscv64": "0.25.12",
        "@esbuild/linux-s390x": "0.25.12",
        "@esbuild/linux-x64": "0.25.12",
        "@esbuild/netbsd-arm64": "0.25.12",
        "@esbuild/netbsd-x64": "0.25.12",
        "@esbuild/openbsd-arm64": "0.25.12",
        "@esbuild/openbsd-x64": "0.25.12",
        "@esbuild/openharmony-arm64": "0.25.12",
        "@esbuild/sunos-x64": "0.25.12",
        "@esbuild/win32-arm64": "0.25.12",
        "@esbuild/win32-ia32": "0.25.12",
        "@esbuild/win32-x64": "0.25.12"
      }
    },
    "node_modules/esbuild/node_modules/@esbuild/win32-x64": {
      "version": "0.25.12",
      "resolved": "https://registry.npmjs.org/@esbuild/win32-x64/-/win32-x64-0.25.12.tgz",
      "integrity": "sha512-alJC0uCZpTFrSL0CCDjcgleBXPnCrEAhTBILpeAp7M/OFgoqtAetfBzX0xM00MUsVVPpVjlPuMbREqnZCXaTnA==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/escalade": {
      "version": "3.2.0",
      "resolved": "https://registry.npmjs.org/escalade/-/escalade-3.2.0.tgz",
      "integrity": "sha512-WUj2qlxaQtO4g6Pq5c29GTcWGDyd8itL8zTlipgECz3JesAiiOKotd8JU6otB3PACgG6xkJUyVhboMS+bje/jA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/escape-string-regexp": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/escape-string-regexp/-/escape-string-regexp-4.0.0.tgz",
      "integrity": "sha512-TtpcNJ3XAzx3Gq8sWRzJaVajRs0uVxA2YAkdb1jm2YkPz4G6egUFAyA3n5vtEIZefPk5Wa4UXbKuS5fKkJWdgA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/eslint": {
      "version": "9.39.1",
      "resolved": "https://registry.npmjs.org/eslint/-/eslint-9.39.1.tgz",
      "integrity": "sha512-BhHmn2yNOFA9H9JmmIVKJmd288g9hrVRDkdoIgRCRuSySRUHH7r/DI6aAXW9T1WwUuY3DFgrcaqB+deURBLR5g==",
      "dev": true,
      "license": "MIT",
      "peer": true,
      "dependencies": {
        "@eslint-community/eslint-utils": "^4.8.0",
        "@eslint-community/regexpp": "^4.12.1",
        "@eslint/config-array": "^0.21.1",
        "@eslint/config-helpers": "^0.4.2",
        "@eslint/core": "^0.17.0",
        "@eslint/eslintrc": "^3.3.1",
        "@eslint/js": "9.39.1",
        "@eslint/plugin-kit": "^0.4.1",
        "@humanfs/node": "^0.16.6",
        "@humanwhocodes/module-importer": "^1.0.1",
        "@humanwhocodes/retry": "^0.4.2",
        "@types/estree": "^1.0.6",
        "ajv": "^6.12.4",
        "chalk": "^4.0.0",
        "cross-spawn": "^7.0.6",
        "debug": "^4.3.2",
        "escape-string-regexp": "^4.0.0",
        "eslint-scope": "^8.4.0",
        "eslint-visitor-keys": "^4.2.1",
        "espree": "^10.4.0",
        "esquery": "^1.5.0",
        "esutils": "^2.0.2",
        "fast-deep-equal": "^3.1.3",
        "file-entry-cache": "^8.0.0",
        "find-up": "^5.0.0",
        "glob-parent": "^6.0.2",
        "ignore": "^5.2.0",
        "imurmurhash": "^0.1.4",
        "is-glob": "^4.0.0",
        "json-stable-stringify-without-jsonify": "^1.0.1",
        "lodash.merge": "^4.6.2",
        "minimatch": "^3.1.2",
        "natural-compare": "^1.4.0",
        "optionator": "^0.9.3"
      },
      "bin": {
        "eslint": "bin/eslint.js"
      },
      "engines": {
        "node": "^18.18.0 || ^20.9.0 || >=21.1.0"
      },
      "funding": {
        "url": "https://eslint.org/donate"
      },
      "peerDependencies": {
        "jiti": "*"
      },
      "peerDependenciesMeta": {
        "jiti": {
          "optional": true
        }
      }
    },
    "node_modules/eslint-plugin-react-hooks": {
      "version": "7.0.1",
      "resolved": "https://registry.npmjs.org/eslint-plugin-react-hooks/-/eslint-plugin-react-hooks-7.0.1.tgz",
      "integrity": "sha512-O0d0m04evaNzEPoSW+59Mezf8Qt0InfgGIBJnpC0h3NH/WjUAR7BIKUfysC6todmtiZ/A0oUVS8Gce0WhBrHsA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/core": "^7.24.4",
        "@babel/parser": "^7.24.4",
        "hermes-parser": "^0.25.1",
        "zod": "^3.25.0 || ^4.0.0",
        "zod-validation-error": "^3.5.0 || ^4.0.0"
      },
      "engines": {
        "node": ">=18"
      },
      "peerDependencies": {
        "eslint": "^3.0.0 || ^4.0.0 || ^5.0.0 || ^6.0.0 || ^7.0.0 || ^8.0.0-0 || ^9.0.0"
      }
    },
    "node_modules/eslint-plugin-react-refresh": {
      "version": "0.4.24",
      "resolved": "https://registry.npmjs.org/eslint-plugin-react-refresh/-/eslint-plugin-react-refresh-0.4.24.tgz",
      "integrity": "sha512-nLHIW7TEq3aLrEYWpVaJ1dRgFR+wLDPN8e8FpYAql/bMV2oBEfC37K0gLEGgv9fy66juNShSMV8OkTqzltcG/w==",
      "dev": true,
      "license": "MIT",
      "peerDependencies": {
        "eslint": ">=8.40"
      }
    },
    "node_modules/eslint-scope": {
      "version": "8.4.0",
      "resolved": "https://registry.npmjs.org/eslint-scope/-/eslint-scope-8.4.0.tgz",
      "integrity": "sha512-sNXOfKCn74rt8RICKMvJS7XKV/Xk9kA7DyJr8mJik3S7Cwgy3qlkkmyS2uQB3jiJg6VNdZd/pDBJu0nvG2NlTg==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "esrecurse": "^4.3.0",
        "estraverse": "^5.2.0"
      },
      "engines": {
        "node": "^18.18.0 || ^20.9.0 || >=21.1.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/eslint-visitor-keys": {
      "version": "4.2.1",
      "resolved": "https://registry.npmjs.org/eslint-visitor-keys/-/eslint-visitor-keys-4.2.1.tgz",
      "integrity": "sha512-Uhdk5sfqcee/9H/rCOJikYz67o0a2Tw2hGRPOG2Y1R2dg7brRe1uG0yaNQDHu+TO/uQPF/5eCapvYSmHUjt7JQ==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": "^18.18.0 || ^20.9.0 || >=21.1.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/espree": {
      "version": "10.4.0",
      "resolved": "https://registry.npmjs.org/espree/-/espree-10.4.0.tgz",
      "integrity": "sha512-j6PAQ2uUr79PZhBjP5C5fhl8e39FmRnOjsD5lGnWrFU8i2G776tBK7+nP8KuQUTTyAZUwfQqXAgrVH5MbH9CYQ==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "acorn": "^8.15.0",
        "acorn-jsx": "^5.3.2",
        "eslint-visitor-keys": "^4.2.1"
      },
      "engines": {
        "node": "^18.18.0 || ^20.9.0 || >=21.1.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/esquery": {
      "version": "1.6.0",
      "resolved": "https://registry.npmjs.org/esquery/-/esquery-1.6.0.tgz",
      "integrity": "sha512-ca9pw9fomFcKPvFLXhBKUK90ZvGibiGOvRJNbjljY7s7uq/5YO4BOzcYtJqExdx99rF6aAcnRxHmcUHcz6sQsg==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "estraverse": "^5.1.0"
      },
      "engines": {
        "node": ">=0.10"
      }
    },
    "node_modules/esrecurse": {
      "version": "4.3.0",
      "resolved": "https://registry.npmjs.org/esrecurse/-/esrecurse-4.3.0.tgz",
      "integrity": "sha512-KmfKL3b6G+RXvP8N1vr3Tq1kL/oCFgn2NYXEtqP8/L3pKapUA4G8cFVaoF3SU323CD4XypR/ffioHmkti6/Tag==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "estraverse": "^5.2.0"
      },
      "engines": {
        "node": ">=4.0"
      }
    },
    "node_modules/estraverse": {
      "version": "5.3.0",
      "resolved": "https://registry.npmjs.org/estraverse/-/estraverse-5.3.0.tgz",
      "integrity": "sha512-MMdARuVEQziNTeJD8DgMqmhwR11BRQ/cBP+pLtYdSTnf3MIO8fFeiINEbX36ZdNlfU/7A9f3gUw49B3oQsvwBA==",
      "dev": true,
      "license": "BSD-2-Clause",
      "engines": {
        "node": ">=4.0"
      }
    },
    "node_modules/estree-util-is-identifier-name": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/estree-util-is-identifier-name/-/estree-util-is-identifier-name-3.0.0.tgz",
      "integrity": "sha512-hFtqIDZTIUZ9BXLb8y4pYGyk6+wekIivNVTcmvk8NoOh+VeRn5y6cEHzbURrWbfp1fIqdVipilzj+lfaadNZmg==",
      "license": "MIT",
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/esutils": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/esutils/-/esutils-2.0.3.tgz",
      "integrity": "sha512-kVscqXk4OCp68SZ0dkgEKVi6/8ij300KBWTJq32P/dYeWTSwK41WyTxalN1eRmA5Z9UU/LX9D7FWSmV9SAYx6g==",
      "dev": true,
      "license": "BSD-2-Clause",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/extend": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/extend/-/extend-3.0.2.tgz",
      "integrity": "sha512-fjquC59cD7CyW6urNXK0FBufkZcoiGG80wTuPujX590cB5Ttln20E2UB4S/WARVqhXffZl2LNgS+gQdPIIim/g==",
      "license": "MIT"
    },
    "node_modules/fast-deep-equal": {
      "version": "3.1.3",
      "resolved": "https://registry.npmjs.org/fast-deep-equal/-/fast-deep-equal-3.1.3.tgz",
      "integrity": "sha512-f3qQ9oQy9j2AhBe/H9VC91wLmKBCCU/gDOnKNAYG5hswO7BLKj09Hc5HYNz9cGI++xlpDCIgDaitVs03ATR84Q==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/fast-json-stable-stringify": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/fast-json-stable-stringify/-/fast-json-stable-stringify-2.1.0.tgz",
      "integrity": "sha512-lhd/wF+Lk98HZoTCtlVraHtfh5XYijIjalXck7saUtuanSDyLMxnHhSXEDJqHxD7msR8D0uCmqlkwjCV8xvwHw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/fast-levenshtein": {
      "version": "2.0.6",
      "resolved": "https://registry.npmjs.org/fast-levenshtein/-/fast-levenshtein-2.0.6.tgz",
      "integrity": "sha512-DCXu6Ifhqcks7TZKY3Hxp3y6qphY5SJZmrWMDrKcERSOXWQdMhU9Ig/PYrzyw/ul9jOIyh0N4M0tbC5hodg8dw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/fdir": {
      "version": "6.5.0",
      "resolved": "https://registry.npmjs.org/fdir/-/fdir-6.5.0.tgz",
      "integrity": "sha512-tIbYtZbucOs0BRGqPJkshJUYdL+SDH7dVM8gjy+ERp3WAUjLEFJE+02kanyHtwjWOnwrKYBiwAmM0p4kLJAnXg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=12.0.0"
      },
      "peerDependencies": {
        "picomatch": "^3 || ^4"
      },
      "peerDependenciesMeta": {
        "picomatch": {
          "optional": true
        }
      }
    },
    "node_modules/file-entry-cache": {
      "version": "8.0.0",
      "resolved": "https://registry.npmjs.org/file-entry-cache/-/file-entry-cache-8.0.0.tgz",
      "integrity": "sha512-XXTUwCvisa5oacNGRP9SfNtYBNAMi+RPwBFmblZEF7N7swHYQS6/Zfk7SRwx4D5j3CH211YNRco1DEMNVfZCnQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "flat-cache": "^4.0.0"
      },
      "engines": {
        "node": ">=16.0.0"
      }
    },
    "node_modules/find-up": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/find-up/-/find-up-5.0.0.tgz",
      "integrity": "sha512-78/PXT1wlLLDgTzDs7sjq9hzz0vXD+zn+7wypEe4fXQxCmdmqfGsEPQxmiCSQI3ajFV91bVSsvNtrJRiW6nGng==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "locate-path": "^6.0.0",
        "path-exists": "^4.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/flat-cache": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/flat-cache/-/flat-cache-4.0.1.tgz",
      "integrity": "sha512-f7ccFPK3SXFHpx15UIGyRJ/FJQctuKZ0zVuN3frBo4HnK3cay9VEW0R6yPYFHC0AgqhukPzKjq22t5DmAyqGyw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "flatted": "^3.2.9",
        "keyv": "^4.5.4"
      },
      "engines": {
        "node": ">=16"
      }
    },
    "node_modules/flatted": {
      "version": "3.3.3",
      "resolved": "https://registry.npmjs.org/flatted/-/flatted-3.3.3.tgz",
      "integrity": "sha512-GX+ysw4PBCz0PzosHDepZGANEuFCMLrnRTiEy9McGjmkCQYwRq4A/X786G/fjM/+OjsWSU1ZrY5qyARZmO/uwg==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/fraction.js": {
      "version": "5.3.4",
      "resolved": "https://registry.npmjs.org/fraction.js/-/fraction.js-5.3.4.tgz",
      "integrity": "sha512-1X1NTtiJphryn/uLQz3whtY6jK3fTqoE3ohKs0tT+Ujr1W59oopxmoEh7Lu5p6vBaPbgoM0bzveAW4Qi5RyWDQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "*"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/rawify"
      }
    },
    "node_modules/fsevents": {
      "version": "2.3.3",
      "resolved": "https://registry.npmjs.org/fsevents/-/fsevents-2.3.3.tgz",
      "integrity": "sha512-5xoDfX+fL7faATnagmWPpbFtwh/R77WmMMqqHGS65C3vvB0YHrgF+B1YmZ3441tMj5n63k0212XNoJwzlhffQw==",
      "dev": true,
      "hasInstallScript": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": "^8.16.0 || ^10.6.0 || >=11.0.0"
      }
    },
    "node_modules/gensync": {
      "version": "1.0.0-beta.2",
      "resolved": "https://registry.npmjs.org/gensync/-/gensync-1.0.0-beta.2.tgz",
      "integrity": "sha512-3hN7NaskYvMDLQY55gnW3NQ+mesEAepTqlg+VEbj7zzqEMBVNhzcGYYeqFo/TlYz6eQiFcp1HcsCZO+nGgS8zg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/glob-parent": {
      "version": "6.0.2",
      "resolved": "https://registry.npmjs.org/glob-parent/-/glob-parent-6.0.2.tgz",
      "integrity": "sha512-XxwI8EOhVQgWp6iDL+3b0r86f4d6AX6zSU55HfB4ydCEuXLXc5FcYeOu+nnGftS4TEju/11rt4KJPTMgbfmv4A==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "is-glob": "^4.0.3"
      },
      "engines": {
        "node": ">=10.13.0"
      }
    },
    "node_modules/globals": {
      "version": "16.5.0",
      "resolved": "https://registry.npmjs.org/globals/-/globals-16.5.0.tgz",
      "integrity": "sha512-c/c15i26VrJ4IRt5Z89DnIzCGDn9EcebibhAOjw5ibqEHsE1wLUgkPn9RDmNcUKyU87GeaL633nyJ+pplFR2ZQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=18"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/graceful-fs": {
      "version": "4.2.11",
      "resolved": "https://registry.npmjs.org/graceful-fs/-/graceful-fs-4.2.11.tgz",
      "integrity": "sha512-RbJ5/jmFcNNCcDV5o9eTnBLJ/HszWV0P73bc+Ff4nS/rJj+YaS6IGyiOL0VoBYX+l1Wrl3k63h/KrH+nhJ0XvQ==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/has-flag": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/has-flag/-/has-flag-4.0.0.tgz",
      "integrity": "sha512-EykJT/Q1KjTWctppgIAgfSO0tKVuZUjhgMr17kqTumMl6Afv3EISleU7qZUzoXDFTAHTDC4NOoG/ZxU3EvlMPQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/hast-util-to-jsx-runtime": {
      "version": "2.3.6",
      "resolved": "https://registry.npmjs.org/hast-util-to-jsx-runtime/-/hast-util-to-jsx-runtime-2.3.6.tgz",
      "integrity": "sha512-zl6s8LwNyo1P9uw+XJGvZtdFF1GdAkOg8ujOw+4Pyb76874fLps4ueHXDhXWdk6YHQ6OgUtinliG7RsYvCbbBg==",
      "license": "MIT",
      "dependencies": {
        "@types/estree": "^1.0.0",
        "@types/hast": "^3.0.0",
        "@types/unist": "^3.0.0",
        "comma-separated-tokens": "^2.0.0",
        "devlop": "^1.0.0",
        "estree-util-is-identifier-name": "^3.0.0",
        "hast-util-whitespace": "^3.0.0",
        "mdast-util-mdx-expression": "^2.0.0",
        "mdast-util-mdx-jsx": "^3.0.0",
        "mdast-util-mdxjs-esm": "^2.0.0",
        "property-information": "^7.0.0",
        "space-separated-tokens": "^2.0.0",
        "style-to-js": "^1.0.0",
        "unist-util-position": "^5.0.0",
        "vfile-message": "^4.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/hast-util-whitespace": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/hast-util-whitespace/-/hast-util-whitespace-3.0.0.tgz",
      "integrity": "sha512-88JUN06ipLwsnv+dVn+OIYOvAuvBMy/Qoi6O7mQHxdPXpjy+Cd6xRkWwux7DKO+4sYILtLBRIKgsdpS2gQc7qw==",
      "license": "MIT",
      "dependencies": {
        "@types/hast": "^3.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/hermes-estree": {
      "version": "0.25.1",
      "resolved": "https://registry.npmjs.org/hermes-estree/-/hermes-estree-0.25.1.tgz",
      "integrity": "sha512-0wUoCcLp+5Ev5pDW2OriHC2MJCbwLwuRx+gAqMTOkGKJJiBCLjtrvy4PWUGn6MIVefecRpzoOZ/UV6iGdOr+Cw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/hermes-parser": {
      "version": "0.25.1",
      "resolved": "https://registry.npmjs.org/hermes-parser/-/hermes-parser-0.25.1.tgz",
      "integrity": "sha512-6pEjquH3rqaI6cYAXYPcz9MS4rY6R4ngRgrgfDshRptUZIc3lw0MCIJIGDj9++mfySOuPTHB4nrSW99BCvOPIA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "hermes-estree": "0.25.1"
      }
    },
    "node_modules/html-url-attributes": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/html-url-attributes/-/html-url-attributes-3.0.1.tgz",
      "integrity": "sha512-ol6UPyBWqsrO6EJySPz2O7ZSr856WDrEzM5zMqp+FJJLGMW35cLYmmZnl0vztAZxRUoNZJFTCohfjuIJ8I4QBQ==",
      "license": "MIT",
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/ignore": {
      "version": "5.3.2",
      "resolved": "https://registry.npmjs.org/ignore/-/ignore-5.3.2.tgz",
      "integrity": "sha512-hsBTNUqQTDwkWtcdYI2i06Y/nUBEsNEDJKjWdigLvegy8kDuJAS8uRlpkkcQpyEXL0Z/pjDy5HBmMjRCJ2gq+g==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 4"
      }
    },
    "node_modules/import-fresh": {
      "version": "3.3.1",
      "resolved": "https://registry.npmjs.org/import-fresh/-/import-fresh-3.3.1.tgz",
      "integrity": "sha512-TR3KfrTZTYLPB6jUjfx6MF9WcWrHL9su5TObK4ZkYgBdWKPOFoSoQIdEuTuR82pmtxH2spWG9h6etwfr1pLBqQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "parent-module": "^1.0.0",
        "resolve-from": "^4.0.0"
      },
      "engines": {
        "node": ">=6"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/imurmurhash": {
      "version": "0.1.4",
      "resolved": "https://registry.npmjs.org/imurmurhash/-/imurmurhash-0.1.4.tgz",
      "integrity": "sha512-JmXMZ6wuvDmLiHEml9ykzqO6lwFbof0GG4IkcGaENdCRDDmMVnny7s5HsIgHCbaq0w2MyPhDqkhTUgS2LU2PHA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.8.19"
      }
    },
    "node_modules/inline-style-parser": {
      "version": "0.2.7",
      "resolved": "https://registry.npmjs.org/inline-style-parser/-/inline-style-parser-0.2.7.tgz",
      "integrity": "sha512-Nb2ctOyNR8DqQoR0OwRG95uNWIC0C1lCgf5Naz5H6Ji72KZ8OcFZLz2P5sNgwlyoJ8Yif11oMuYs5pBQa86csA==",
      "license": "MIT"
    },
    "node_modules/is-alphabetical": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/is-alphabetical/-/is-alphabetical-2.0.1.tgz",
      "integrity": "sha512-FWyyY60MeTNyeSRpkM2Iry0G9hpr7/9kD40mD/cGQEuilcZYS4okz8SN2Q6rLCJ8gbCt6fN+rC+6tMGS99LaxQ==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/is-alphanumerical": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/is-alphanumerical/-/is-alphanumerical-2.0.1.tgz",
      "integrity": "sha512-hmbYhX/9MUMF5uh7tOXyK/n0ZvWpad5caBA17GsC6vyuCqaWliRG5K1qS9inmUhEMaOBIW7/whAnSwveW/LtZw==",
      "license": "MIT",
      "dependencies": {
        "is-alphabetical": "^2.0.0",
        "is-decimal": "^2.0.0"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/is-decimal": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/is-decimal/-/is-decimal-2.0.1.tgz",
      "integrity": "sha512-AAB9hiomQs5DXWcRB1rqsxGUstbRroFOPPVAomNk/3XHR5JyEZChOyTWe2oayKnsSsr/kcGqF+z6yuH6HHpN0A==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/is-extglob": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/is-extglob/-/is-extglob-2.1.1.tgz",
      "integrity": "sha512-SbKbANkN603Vi4jEZv49LeVJMn4yGwsbzZworEoyEiutsN3nJYdbO36zfhGJ6QEDpOZIFkDtnq5JRxmvl3jsoQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/is-glob": {
      "version": "4.0.3",
      "resolved": "https://registry.npmjs.org/is-glob/-/is-glob-4.0.3.tgz",
      "integrity": "sha512-xelSayHH36ZgE7ZWhli7pW34hNbNl8Ojv5KVmkJD4hBdD3th8Tfk9vYasLM+mXWOZhFkgZfxhLSnrwRr4elSSg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-extglob": "^2.1.1"
      },
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/is-hexadecimal": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/is-hexadecimal/-/is-hexadecimal-2.0.1.tgz",
      "integrity": "sha512-DgZQp241c8oO6cA1SbTEWiXeoxV42vlcJxgH+B3hi1AiqqKruZR3ZGF8In3fj4+/y/7rHvlOZLZtgJ/4ttYGZg==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/is-plain-obj": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/is-plain-obj/-/is-plain-obj-4.1.0.tgz",
      "integrity": "sha512-+Pgi+vMuUNkJyExiMBt5IlFoMyKnr5zhJ4Uspz58WOhBF5QoIZkFyNHIbBAtHwzVAgk5RtndVNsDRN61/mmDqg==",
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/isexe": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/isexe/-/isexe-2.0.0.tgz",
      "integrity": "sha512-RHxMLp9lnKHGHRng9QFhRCMbYAcVpn69smSGcq3f36xjgVVWThj4qqLbTLlq7Ssj8B+fIQ1EuCEGI2lKsyQeIw==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/jiti": {
      "version": "2.6.1",
      "resolved": "https://registry.npmjs.org/jiti/-/jiti-2.6.1.tgz",
      "integrity": "sha512-ekilCSN1jwRvIbgeg/57YFh8qQDNbwDb9xT/qu2DAHbFFZUicIl4ygVaAvzveMhMVr3LnpSKTNnwt8PoOfmKhQ==",
      "dev": true,
      "license": "MIT",
      "bin": {
        "jiti": "lib/jiti-cli.mjs"
      }
    },
    "node_modules/js-tokens": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/js-tokens/-/js-tokens-4.0.0.tgz",
      "integrity": "sha512-RdJUflcE3cUzKiMqQgsCu06FPu9UdIJO0beYbPhHN4k6apgJtifcoCtT9bcxOpYBtpD2kCM6Sbzg4CausW/PKQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/js-yaml": {
      "version": "4.1.1",
      "resolved": "https://registry.npmjs.org/js-yaml/-/js-yaml-4.1.1.tgz",
      "integrity": "sha512-qQKT4zQxXl8lLwBtHMWwaTcGfFOZviOJet3Oy/xmGk2gZH677CJM9EvtfdSkgWcATZhj/55JZ0rmy3myCT5lsA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "argparse": "^2.0.1"
      },
      "bin": {
        "js-yaml": "bin/js-yaml.js"
      }
    },
    "node_modules/jsesc": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/jsesc/-/jsesc-3.1.0.tgz",
      "integrity": "sha512-/sM3dO2FOzXjKQhJuo0Q173wf2KOo8t4I8vHy6lF9poUp7bKT0/NHE8fPX23PwfhnykfqnC2xRxOnVw5XuGIaA==",
      "dev": true,
      "license": "MIT",
      "bin": {
        "jsesc": "bin/jsesc"
      },
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/json-buffer": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/json-buffer/-/json-buffer-3.0.1.tgz",
      "integrity": "sha512-4bV5BfR2mqfQTJm+V5tPPdf+ZpuhiIvTuAB5g8kcrXOZpTT/QwwVRWBywX1ozr6lEuPdbHxwaJlm9G6mI2sfSQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/json-schema-traverse": {
      "version": "0.4.1",
      "resolved": "https://registry.npmjs.org/json-schema-traverse/-/json-schema-traverse-0.4.1.tgz",
      "integrity": "sha512-xbbCH5dCYU5T8LcEhhuh7HJ88HXuW3qsI3Y0zOZFKfZEHcpWiHU/Jxzk629Brsab/mMiHQti9wMP+845RPe3Vg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/json-stable-stringify-without-jsonify": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/json-stable-stringify-without-jsonify/-/json-stable-stringify-without-jsonify-1.0.1.tgz",
      "integrity": "sha512-Bdboy+l7tA3OGW6FjyFHWkP5LuByj1Tk33Ljyq0axyzdk9//JSi2u3fP1QSmd1KNwq6VOKYGlAu87CisVir6Pw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/json5": {
      "version": "2.2.3",
      "resolved": "https://registry.npmjs.org/json5/-/json5-2.2.3.tgz",
      "integrity": "sha512-XmOWe7eyHYH14cLdVPoyg+GOH3rYX++KpzrylJwSW98t3Nk+U8XOl8FWKOgwtzdb8lXGf6zYwDUzeHMWfxasyg==",
      "dev": true,
      "license": "MIT",
      "bin": {
        "json5": "lib/cli.js"
      },
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/keyv": {
      "version": "4.5.4",
      "resolved": "https://registry.npmjs.org/keyv/-/keyv-4.5.4.tgz",
      "integrity": "sha512-oxVHkHR/EJf2CNXnWxRLW6mg7JyCCUcG0DtEGmL2ctUo1PNTin1PUil+r/+4r5MpVgC/fn1kjsx7mjSujKqIpw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "json-buffer": "3.0.1"
      }
    },
    "node_modules/levn": {
      "version": "0.4.1",
      "resolved": "https://registry.npmjs.org/levn/-/levn-0.4.1.tgz",
      "integrity": "sha512-+bT2uH4E5LGE7h/n3evcS/sQlJXCpIp6ym8OWJ5eV6+67Dsql/LaaT7qJBAt2rzfoa/5QBGBhxDix1dMt2kQKQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "prelude-ls": "^1.2.1",
        "type-check": "~0.4.0"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/lightningcss": {
      "version": "1.30.2",
      "resolved": "https://registry.npmjs.org/lightningcss/-/lightningcss-1.30.2.tgz",
      "integrity": "sha512-utfs7Pr5uJyyvDETitgsaqSyjCb2qNRAtuqUeWIAKztsOYdcACf2KtARYXg2pSvhkt+9NfoaNY7fxjl6nuMjIQ==",
      "dev": true,
      "license": "MPL-2.0",
      "dependencies": {
        "detect-libc": "^2.0.3"
      },
      "engines": {
        "node": ">= 12.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/parcel"
      },
      "optionalDependencies": {
        "lightningcss-android-arm64": "1.30.2",
        "lightningcss-darwin-arm64": "1.30.2",
        "lightningcss-darwin-x64": "1.30.2",
        "lightningcss-freebsd-x64": "1.30.2",
        "lightningcss-linux-arm-gnueabihf": "1.30.2",
        "lightningcss-linux-arm64-gnu": "1.30.2",
        "lightningcss-linux-arm64-musl": "1.30.2",
        "lightningcss-linux-x64-gnu": "1.30.2",
        "lightningcss-linux-x64-musl": "1.30.2",
        "lightningcss-win32-arm64-msvc": "1.30.2",
        "lightningcss-win32-x64-msvc": "1.30.2"
      }
    },
    "node_modules/lightningcss-android-arm64": {
      "version": "1.30.2",
      "resolved": "https://registry.npmjs.org/lightningcss-android-arm64/-/lightningcss-android-arm64-1.30.2.tgz",
      "integrity": "sha512-BH9sEdOCahSgmkVhBLeU7Hc9DWeZ1Eb6wNS6Da8igvUwAe0sqROHddIlvU06q3WyXVEOYDZ6ykBZQnjTbmo4+A==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MPL-2.0",
      "optional": true,
      "os": [
        "android"
      ],
      "engines": {
        "node": ">= 12.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/parcel"
      }
    },
    "node_modules/lightningcss-darwin-arm64": {
      "version": "1.30.2",
      "resolved": "https://registry.npmjs.org/lightningcss-darwin-arm64/-/lightningcss-darwin-arm64-1.30.2.tgz",
      "integrity": "sha512-ylTcDJBN3Hp21TdhRT5zBOIi73P6/W0qwvlFEk22fkdXchtNTOU4Qc37SkzV+EKYxLouZ6M4LG9NfZ1qkhhBWA==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MPL-2.0",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": ">= 12.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/parcel"
      }
    },
    "node_modules/lightningcss-darwin-x64": {
      "version": "1.30.2",
      "resolved": "https://registry.npmjs.org/lightningcss-darwin-x64/-/lightningcss-darwin-x64-1.30.2.tgz",
      "integrity": "sha512-oBZgKchomuDYxr7ilwLcyms6BCyLn0z8J0+ZZmfpjwg9fRVZIR5/GMXd7r9RH94iDhld3UmSjBM6nXWM2TfZTQ==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MPL-2.0",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": ">= 12.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/parcel"
      }
    },
    "node_modules/lightningcss-freebsd-x64": {
      "version": "1.30.2",
      "resolved": "https://registry.npmjs.org/lightningcss-freebsd-x64/-/lightningcss-freebsd-x64-1.30.2.tgz",
      "integrity": "sha512-c2bH6xTrf4BDpK8MoGG4Bd6zAMZDAXS569UxCAGcA7IKbHNMlhGQ89eRmvpIUGfKWNVdbhSbkQaWhEoMGmGslA==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MPL-2.0",
      "optional": true,
      "os": [
        "freebsd"
      ],
      "engines": {
        "node": ">= 12.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/parcel"
      }
    },
    "node_modules/lightningcss-linux-arm-gnueabihf": {
      "version": "1.30.2",
      "resolved": "https://registry.npmjs.org/lightningcss-linux-arm-gnueabihf/-/lightningcss-linux-arm-gnueabihf-1.30.2.tgz",
      "integrity": "sha512-eVdpxh4wYcm0PofJIZVuYuLiqBIakQ9uFZmipf6LF/HRj5Bgm0eb3qL/mr1smyXIS1twwOxNWndd8z0E374hiA==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MPL-2.0",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 12.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/parcel"
      }
    },
    "node_modules/lightningcss-linux-arm64-gnu": {
      "version": "1.30.2",
      "resolved": "https://registry.npmjs.org/lightningcss-linux-arm64-gnu/-/lightningcss-linux-arm64-gnu-1.30.2.tgz",
      "integrity": "sha512-UK65WJAbwIJbiBFXpxrbTNArtfuznvxAJw4Q2ZGlU8kPeDIWEX1dg3rn2veBVUylA2Ezg89ktszWbaQnxD/e3A==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MPL-2.0",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 12.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/parcel"
      }
    },
    "node_modules/lightningcss-linux-arm64-musl": {
      "version": "1.30.2",
      "resolved": "https://registry.npmjs.org/lightningcss-linux-arm64-musl/-/lightningcss-linux-arm64-musl-1.30.2.tgz",
      "integrity": "sha512-5Vh9dGeblpTxWHpOx8iauV02popZDsCYMPIgiuw97OJ5uaDsL86cnqSFs5LZkG3ghHoX5isLgWzMs+eD1YzrnA==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MPL-2.0",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 12.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/parcel"
      }
    },
    "node_modules/lightningcss-linux-x64-gnu": {
      "version": "1.30.2",
      "resolved": "https://registry.npmjs.org/lightningcss-linux-x64-gnu/-/lightningcss-linux-x64-gnu-1.30.2.tgz",
      "integrity": "sha512-Cfd46gdmj1vQ+lR6VRTTadNHu6ALuw2pKR9lYq4FnhvgBc4zWY1EtZcAc6EffShbb1MFrIPfLDXD6Xprbnni4w==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MPL-2.0",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 12.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/parcel"
      }
    },
    "node_modules/lightningcss-linux-x64-musl": {
      "version": "1.30.2",
      "resolved": "https://registry.npmjs.org/lightningcss-linux-x64-musl/-/lightningcss-linux-x64-musl-1.30.2.tgz",
      "integrity": "sha512-XJaLUUFXb6/QG2lGIW6aIk6jKdtjtcffUT0NKvIqhSBY3hh9Ch+1LCeH80dR9q9LBjG3ewbDjnumefsLsP6aiA==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MPL-2.0",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 12.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/parcel"
      }
    },
    "node_modules/lightningcss-win32-arm64-msvc": {
      "version": "1.30.2",
      "resolved": "https://registry.npmjs.org/lightningcss-win32-arm64-msvc/-/lightningcss-win32-arm64-msvc-1.30.2.tgz",
      "integrity": "sha512-FZn+vaj7zLv//D/192WFFVA0RgHawIcHqLX9xuWiQt7P0PtdFEVaxgF9rjM/IRYHQXNnk61/H/gb2Ei+kUQ4xQ==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MPL-2.0",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">= 12.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/parcel"
      }
    },
    "node_modules/lightningcss/node_modules/lightningcss-win32-x64-msvc": {
      "version": "1.30.2",
      "resolved": "https://registry.npmjs.org/lightningcss-win32-x64-msvc/-/lightningcss-win32-x64-msvc-1.30.2.tgz",
      "integrity": "sha512-5g1yc73p+iAkid5phb4oVFMB45417DkRevRbt/El/gKXJk4jid+vPFF/AXbxn05Aky8PapwzZrdJShv5C0avjw==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MPL-2.0",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">= 12.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/parcel"
      }
    },
    "node_modules/locate-path": {
      "version": "6.0.0",
      "resolved": "https://registry.npmjs.org/locate-path/-/locate-path-6.0.0.tgz",
      "integrity": "sha512-iPZK6eYjbxRu3uB4/WZ3EsEIMJFMqAoopl3R+zuq0UjcAm/MO6KCweDgPfP3elTztoKP3KtnVHxTn2NHBSDVUw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "p-locate": "^5.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/lodash.merge": {
      "version": "4.6.2",
      "resolved": "https://registry.npmjs.org/lodash.merge/-/lodash.merge-4.6.2.tgz",
      "integrity": "sha512-0KpjqXRVvrYyCsX1swR/XTK0va6VQkQM6MNo7PqW77ByjAhoARA8EfrP1N4+KlKj8YS0ZUCtRT/YUuhyYDujIQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/longest-streak": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/longest-streak/-/longest-streak-3.1.0.tgz",
      "integrity": "sha512-9Ri+o0JYgehTaVBBDoMqIl8GXtbWg711O3srftcHhZ0dqnETqLaoIK0x17fUw9rFSlK/0NlsKe0Ahhyl5pXE2g==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/lru-cache": {
      "version": "5.1.1",
      "resolved": "https://registry.npmjs.org/lru-cache/-/lru-cache-5.1.1.tgz",
      "integrity": "sha512-KpNARQA3Iwv+jTA0utUVVbrh+Jlrr1Fv0e56GGzAFOXN7dk/FviaDW8LHmK52DlcH4WP2n6gI8vN1aesBFgo9w==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "yallist": "^3.0.2"
      }
    },
    "node_modules/magic-string": {
      "version": "0.30.21",
      "resolved": "https://registry.npmjs.org/magic-string/-/magic-string-0.30.21.tgz",
      "integrity": "sha512-vd2F4YUyEXKGcLHoq+TEyCjxueSeHnFxyyjNp80yg0XV4vUhnDer/lvvlqM/arB5bXQN5K2/3oinyCRyx8T2CQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jridgewell/sourcemap-codec": "^1.5.5"
      }
    },
    "node_modules/markdown-table": {
      "version": "3.0.4",
      "resolved": "https://registry.npmjs.org/markdown-table/-/markdown-table-3.0.4.tgz",
      "integrity": "sha512-wiYz4+JrLyb/DqW2hkFJxP7Vd7JuTDm77fvbM8VfEQdmSMqcImWeeRbHwZjBjIFki/VaMK2BhFi7oUUZeM5bqw==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/mdast-util-find-and-replace": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/mdast-util-find-and-replace/-/mdast-util-find-and-replace-3.0.2.tgz",
      "integrity": "sha512-Tmd1Vg/m3Xz43afeNxDIhWRtFZgM2VLyaf4vSTYwudTyeuTneoL3qtWMA5jeLyz/O1vDJmmV4QuScFCA2tBPwg==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "escape-string-regexp": "^5.0.0",
        "unist-util-is": "^6.0.0",
        "unist-util-visit-parents": "^6.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-find-and-replace/node_modules/escape-string-regexp": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/escape-string-regexp/-/escape-string-regexp-5.0.0.tgz",
      "integrity": "sha512-/veY75JbMK4j1yjvuUxuVsiS/hr/4iHs9FTT6cgTexxdE0Ly/glccBAkloH/DofkjRbZU3bnoj38mOmhkZ0lHw==",
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/mdast-util-from-markdown": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/mdast-util-from-markdown/-/mdast-util-from-markdown-2.0.2.tgz",
      "integrity": "sha512-uZhTV/8NBuw0WHkPTrCqDOl0zVe1BIng5ZtHoDk49ME1qqcjYmmLmOf0gELgcRMxN4w2iuIeVso5/6QymSrgmA==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "@types/unist": "^3.0.0",
        "decode-named-character-reference": "^1.0.0",
        "devlop": "^1.0.0",
        "mdast-util-to-string": "^4.0.0",
        "micromark": "^4.0.0",
        "micromark-util-decode-numeric-character-reference": "^2.0.0",
        "micromark-util-decode-string": "^2.0.0",
        "micromark-util-normalize-identifier": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0",
        "unist-util-stringify-position": "^4.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-gfm": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/mdast-util-gfm/-/mdast-util-gfm-3.1.0.tgz",
      "integrity": "sha512-0ulfdQOM3ysHhCJ1p06l0b0VKlhU0wuQs3thxZQagjcjPrlFRqY215uZGHHJan9GEAXd9MbfPjFJz+qMkVR6zQ==",
      "license": "MIT",
      "dependencies": {
        "mdast-util-from-markdown": "^2.0.0",
        "mdast-util-gfm-autolink-literal": "^2.0.0",
        "mdast-util-gfm-footnote": "^2.0.0",
        "mdast-util-gfm-strikethrough": "^2.0.0",
        "mdast-util-gfm-table": "^2.0.0",
        "mdast-util-gfm-task-list-item": "^2.0.0",
        "mdast-util-to-markdown": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-gfm-autolink-literal": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/mdast-util-gfm-autolink-literal/-/mdast-util-gfm-autolink-literal-2.0.1.tgz",
      "integrity": "sha512-5HVP2MKaP6L+G6YaxPNjuL0BPrq9orG3TsrZ9YXbA3vDw/ACI4MEsnoDpn6ZNm7GnZgtAcONJyPhOP8tNJQavQ==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "ccount": "^2.0.0",
        "devlop": "^1.0.0",
        "mdast-util-find-and-replace": "^3.0.0",
        "micromark-util-character": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-gfm-footnote": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/mdast-util-gfm-footnote/-/mdast-util-gfm-footnote-2.1.0.tgz",
      "integrity": "sha512-sqpDWlsHn7Ac9GNZQMeUzPQSMzR6Wv0WKRNvQRg0KqHh02fpTz69Qc1QSseNX29bhz1ROIyNyxExfawVKTm1GQ==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "devlop": "^1.1.0",
        "mdast-util-from-markdown": "^2.0.0",
        "mdast-util-to-markdown": "^2.0.0",
        "micromark-util-normalize-identifier": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-gfm-strikethrough": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/mdast-util-gfm-strikethrough/-/mdast-util-gfm-strikethrough-2.0.0.tgz",
      "integrity": "sha512-mKKb915TF+OC5ptj5bJ7WFRPdYtuHv0yTRxK2tJvi+BDqbkiG7h7u/9SI89nRAYcmap2xHQL9D+QG/6wSrTtXg==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "mdast-util-from-markdown": "^2.0.0",
        "mdast-util-to-markdown": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-gfm-table": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/mdast-util-gfm-table/-/mdast-util-gfm-table-2.0.0.tgz",
      "integrity": "sha512-78UEvebzz/rJIxLvE7ZtDd/vIQ0RHv+3Mh5DR96p7cS7HsBhYIICDBCu8csTNWNO6tBWfqXPWekRuj2FNOGOZg==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "devlop": "^1.0.0",
        "markdown-table": "^3.0.0",
        "mdast-util-from-markdown": "^2.0.0",
        "mdast-util-to-markdown": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-gfm-task-list-item": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/mdast-util-gfm-task-list-item/-/mdast-util-gfm-task-list-item-2.0.0.tgz",
      "integrity": "sha512-IrtvNvjxC1o06taBAVJznEnkiHxLFTzgonUdy8hzFVeDun0uTjxxrRGVaNFqkU1wJR3RBPEfsxmU6jDWPofrTQ==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "devlop": "^1.0.0",
        "mdast-util-from-markdown": "^2.0.0",
        "mdast-util-to-markdown": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-mdx-expression": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/mdast-util-mdx-expression/-/mdast-util-mdx-expression-2.0.1.tgz",
      "integrity": "sha512-J6f+9hUp+ldTZqKRSg7Vw5V6MqjATc+3E4gf3CFNcuZNWD8XdyI6zQ8GqH7f8169MM6P7hMBRDVGnn7oHB9kXQ==",
      "license": "MIT",
      "dependencies": {
        "@types/estree-jsx": "^1.0.0",
        "@types/hast": "^3.0.0",
        "@types/mdast": "^4.0.0",
        "devlop": "^1.0.0",
        "mdast-util-from-markdown": "^2.0.0",
        "mdast-util-to-markdown": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-mdx-jsx": {
      "version": "3.2.0",
      "resolved": "https://registry.npmjs.org/mdast-util-mdx-jsx/-/mdast-util-mdx-jsx-3.2.0.tgz",
      "integrity": "sha512-lj/z8v0r6ZtsN/cGNNtemmmfoLAFZnjMbNyLzBafjzikOM+glrjNHPlf6lQDOTccj9n5b0PPihEBbhneMyGs1Q==",
      "license": "MIT",
      "dependencies": {
        "@types/estree-jsx": "^1.0.0",
        "@types/hast": "^3.0.0",
        "@types/mdast": "^4.0.0",
        "@types/unist": "^3.0.0",
        "ccount": "^2.0.0",
        "devlop": "^1.1.0",
        "mdast-util-from-markdown": "^2.0.0",
        "mdast-util-to-markdown": "^2.0.0",
        "parse-entities": "^4.0.0",
        "stringify-entities": "^4.0.0",
        "unist-util-stringify-position": "^4.0.0",
        "vfile-message": "^4.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-mdxjs-esm": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/mdast-util-mdxjs-esm/-/mdast-util-mdxjs-esm-2.0.1.tgz",
      "integrity": "sha512-EcmOpxsZ96CvlP03NghtH1EsLtr0n9Tm4lPUJUBccV9RwUOneqSycg19n5HGzCf+10LozMRSObtVr3ee1WoHtg==",
      "license": "MIT",
      "dependencies": {
        "@types/estree-jsx": "^1.0.0",
        "@types/hast": "^3.0.0",
        "@types/mdast": "^4.0.0",
        "devlop": "^1.0.0",
        "mdast-util-from-markdown": "^2.0.0",
        "mdast-util-to-markdown": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-phrasing": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/mdast-util-phrasing/-/mdast-util-phrasing-4.1.0.tgz",
      "integrity": "sha512-TqICwyvJJpBwvGAMZjj4J2n0X8QWp21b9l0o7eXyVJ25YNWYbJDVIyD1bZXE6WtV6RmKJVYmQAKWa0zWOABz2w==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "unist-util-is": "^6.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-to-hast": {
      "version": "13.2.1",
      "resolved": "https://registry.npmjs.org/mdast-util-to-hast/-/mdast-util-to-hast-13.2.1.tgz",
      "integrity": "sha512-cctsq2wp5vTsLIcaymblUriiTcZd0CwWtCbLvrOzYCDZoWyMNV8sZ7krj09FSnsiJi3WVsHLM4k6Dq/yaPyCXA==",
      "license": "MIT",
      "dependencies": {
        "@types/hast": "^3.0.0",
        "@types/mdast": "^4.0.0",
        "@ungap/structured-clone": "^1.0.0",
        "devlop": "^1.0.0",
        "micromark-util-sanitize-uri": "^2.0.0",
        "trim-lines": "^3.0.0",
        "unist-util-position": "^5.0.0",
        "unist-util-visit": "^5.0.0",
        "vfile": "^6.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-to-markdown": {
      "version": "2.1.2",
      "resolved": "https://registry.npmjs.org/mdast-util-to-markdown/-/mdast-util-to-markdown-2.1.2.tgz",
      "integrity": "sha512-xj68wMTvGXVOKonmog6LwyJKrYXZPvlwabaryTjLh9LuvovB/KAH+kvi8Gjj+7rJjsFi23nkUxRQv1KqSroMqA==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "@types/unist": "^3.0.0",
        "longest-streak": "^3.0.0",
        "mdast-util-phrasing": "^4.0.0",
        "mdast-util-to-string": "^4.0.0",
        "micromark-util-classify-character": "^2.0.0",
        "micromark-util-decode-string": "^2.0.0",
        "unist-util-visit": "^5.0.0",
        "zwitch": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-to-string": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/mdast-util-to-string/-/mdast-util-to-string-4.0.0.tgz",
      "integrity": "sha512-0H44vDimn51F0YwvxSJSm0eCDOJTRlmN0R1yBh4HLj9wiV1Dn0QoXGbvFAWj2hSItVTlCmBF1hqKlIyUBVFLPg==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/micromark": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/micromark/-/micromark-4.0.2.tgz",
      "integrity": "sha512-zpe98Q6kvavpCr1NPVSCMebCKfD7CA2NqZ+rykeNhONIJBpc1tFKt9hucLGwha3jNTNI8lHpctWJWoimVF4PfA==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "@types/debug": "^4.0.0",
        "debug": "^4.0.0",
        "decode-named-character-reference": "^1.0.0",
        "devlop": "^1.0.0",
        "micromark-core-commonmark": "^2.0.0",
        "micromark-factory-space": "^2.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-chunked": "^2.0.0",
        "micromark-util-combine-extensions": "^2.0.0",
        "micromark-util-decode-numeric-character-reference": "^2.0.0",
        "micromark-util-encode": "^2.0.0",
        "micromark-util-normalize-identifier": "^2.0.0",
        "micromark-util-resolve-all": "^2.0.0",
        "micromark-util-sanitize-uri": "^2.0.0",
        "micromark-util-subtokenize": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-core-commonmark": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/micromark-core-commonmark/-/micromark-core-commonmark-2.0.3.tgz",
      "integrity": "sha512-RDBrHEMSxVFLg6xvnXmb1Ayr2WzLAWjeSATAoxwKYJV94TeNavgoIdA0a9ytzDSVzBy2YKFK+emCPOEibLeCrg==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "decode-named-character-reference": "^1.0.0",
        "devlop": "^1.0.0",
        "micromark-factory-destination": "^2.0.0",
        "micromark-factory-label": "^2.0.0",
        "micromark-factory-space": "^2.0.0",
        "micromark-factory-title": "^2.0.0",
        "micromark-factory-whitespace": "^2.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-chunked": "^2.0.0",
        "micromark-util-classify-character": "^2.0.0",
        "micromark-util-html-tag-name": "^2.0.0",
        "micromark-util-normalize-identifier": "^2.0.0",
        "micromark-util-resolve-all": "^2.0.0",
        "micromark-util-subtokenize": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-extension-gfm": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/micromark-extension-gfm/-/micromark-extension-gfm-3.0.0.tgz",
      "integrity": "sha512-vsKArQsicm7t0z2GugkCKtZehqUm31oeGBV/KVSorWSy8ZlNAv7ytjFhvaryUiCUJYqs+NoE6AFhpQvBTM6Q4w==",
      "license": "MIT",
      "dependencies": {
        "micromark-extension-gfm-autolink-literal": "^2.0.0",
        "micromark-extension-gfm-footnote": "^2.0.0",
        "micromark-extension-gfm-strikethrough": "^2.0.0",
        "micromark-extension-gfm-table": "^2.0.0",
        "micromark-extension-gfm-tagfilter": "^2.0.0",
        "micromark-extension-gfm-task-list-item": "^2.0.0",
        "micromark-util-combine-extensions": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/micromark-extension-gfm-autolink-literal": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/micromark-extension-gfm-autolink-literal/-/micromark-extension-gfm-autolink-literal-2.1.0.tgz",
      "integrity": "sha512-oOg7knzhicgQ3t4QCjCWgTmfNhvQbDDnJeVu9v81r7NltNCVmhPy1fJRX27pISafdjL+SVc4d3l48Gb6pbRypw==",
      "license": "MIT",
      "dependencies": {
        "micromark-util-character": "^2.0.0",
        "micromark-util-sanitize-uri": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/micromark-extension-gfm-footnote": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/micromark-extension-gfm-footnote/-/micromark-extension-gfm-footnote-2.1.0.tgz",
      "integrity": "sha512-/yPhxI1ntnDNsiHtzLKYnE3vf9JZ6cAisqVDauhp4CEHxlb4uoOTxOCJ+9s51bIB8U1N1FJ1RXOKTIlD5B/gqw==",
      "license": "MIT",
      "dependencies": {
        "devlop": "^1.0.0",
        "micromark-core-commonmark": "^2.0.0",
        "micromark-factory-space": "^2.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-normalize-identifier": "^2.0.0",
        "micromark-util-sanitize-uri": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/micromark-extension-gfm-strikethrough": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/micromark-extension-gfm-strikethrough/-/micromark-extension-gfm-strikethrough-2.1.0.tgz",
      "integrity": "sha512-ADVjpOOkjz1hhkZLlBiYA9cR2Anf8F4HqZUO6e5eDcPQd0Txw5fxLzzxnEkSkfnD0wziSGiv7sYhk/ktvbf1uw==",
      "license": "MIT",
      "dependencies": {
        "devlop": "^1.0.0",
        "micromark-util-chunked": "^2.0.0",
        "micromark-util-classify-character": "^2.0.0",
        "micromark-util-resolve-all": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/micromark-extension-gfm-table": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/micromark-extension-gfm-table/-/micromark-extension-gfm-table-2.1.1.tgz",
      "integrity": "sha512-t2OU/dXXioARrC6yWfJ4hqB7rct14e8f7m0cbI5hUmDyyIlwv5vEtooptH8INkbLzOatzKuVbQmAYcbWoyz6Dg==",
      "license": "MIT",
      "dependencies": {
        "devlop": "^1.0.0",
        "micromark-factory-space": "^2.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/micromark-extension-gfm-tagfilter": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/micromark-extension-gfm-tagfilter/-/micromark-extension-gfm-tagfilter-2.0.0.tgz",
      "integrity": "sha512-xHlTOmuCSotIA8TW1mDIM6X2O1SiX5P9IuDtqGonFhEK0qgRI4yeC6vMxEV2dgyr2TiD+2PQ10o+cOhdVAcwfg==",
      "license": "MIT",
      "dependencies": {
        "micromark-util-types": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/micromark-extension-gfm-task-list-item": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/micromark-extension-gfm-task-list-item/-/micromark-extension-gfm-task-list-item-2.1.0.tgz",
      "integrity": "sha512-qIBZhqxqI6fjLDYFTBIa4eivDMnP+OZqsNwmQ3xNLE4Cxwc+zfQEfbs6tzAo2Hjq+bh6q5F+Z8/cksrLFYWQQw==",
      "license": "MIT",
      "dependencies": {
        "devlop": "^1.0.0",
        "micromark-factory-space": "^2.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/micromark-factory-destination": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-factory-destination/-/micromark-factory-destination-2.0.1.tgz",
      "integrity": "sha512-Xe6rDdJlkmbFRExpTOmRj9N3MaWmbAgdpSrBQvCFqhezUn4AHqJHbaEnfbVYYiexVSs//tqOdY/DxhjdCiJnIA==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-character": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-factory-label": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-factory-label/-/micromark-factory-label-2.0.1.tgz",
      "integrity": "sha512-VFMekyQExqIW7xIChcXn4ok29YE3rnuyveW3wZQWWqF4Nv9Wk5rgJ99KzPvHjkmPXF93FXIbBp6YdW3t71/7Vg==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "devlop": "^1.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-factory-space": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-factory-space/-/micromark-factory-space-2.0.1.tgz",
      "integrity": "sha512-zRkxjtBxxLd2Sc0d+fbnEunsTj46SWXgXciZmHq0kDYGnck/ZSGj9/wULTV95uoeYiK5hRXP2mJ98Uo4cq/LQg==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-character": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-factory-title": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-factory-title/-/micromark-factory-title-2.0.1.tgz",
      "integrity": "sha512-5bZ+3CjhAd9eChYTHsjy6TGxpOFSKgKKJPJxr293jTbfry2KDoWkhBb6TcPVB4NmzaPhMs1Frm9AZH7OD4Cjzw==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-factory-space": "^2.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-factory-whitespace": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-factory-whitespace/-/micromark-factory-whitespace-2.0.1.tgz",
      "integrity": "sha512-Ob0nuZ3PKt/n0hORHyvoD9uZhr+Za8sFoP+OnMcnWK5lngSzALgQYKMr9RJVOWLqQYuyn6ulqGWSXdwf6F80lQ==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-factory-space": "^2.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-util-character": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/micromark-util-character/-/micromark-util-character-2.1.1.tgz",
      "integrity": "sha512-wv8tdUTJ3thSFFFJKtpYKOYiGP2+v96Hvk4Tu8KpCAsTMs6yi+nVmGh1syvSCsaxz45J6Jbw+9DD6g97+NV67Q==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-util-chunked": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-chunked/-/micromark-util-chunked-2.0.1.tgz",
      "integrity": "sha512-QUNFEOPELfmvv+4xiNg2sRYeS/P84pTW0TCgP5zc9FpXetHY0ab7SxKyAQCNCc1eK0459uoLI1y5oO5Vc1dbhA==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-symbol": "^2.0.0"
      }
    },
    "node_modules/micromark-util-classify-character": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-classify-character/-/micromark-util-classify-character-2.0.1.tgz",
      "integrity": "sha512-K0kHzM6afW/MbeWYWLjoHQv1sgg2Q9EccHEDzSkxiP/EaagNzCm7T/WMKZ3rjMbvIpvBiZgwR3dKMygtA4mG1Q==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-character": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-util-combine-extensions": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-combine-extensions/-/micromark-util-combine-extensions-2.0.1.tgz",
      "integrity": "sha512-OnAnH8Ujmy59JcyZw8JSbK9cGpdVY44NKgSM7E9Eh7DiLS2E9RNQf0dONaGDzEG9yjEl5hcqeIsj4hfRkLH/Bg==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-chunked": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-util-decode-numeric-character-reference": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/micromark-util-decode-numeric-character-reference/-/micromark-util-decode-numeric-character-reference-2.0.2.tgz",
      "integrity": "sha512-ccUbYk6CwVdkmCQMyr64dXz42EfHGkPQlBj5p7YVGzq8I7CtjXZJrubAYezf7Rp+bjPseiROqe7G6foFd+lEuw==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-symbol": "^2.0.0"
      }
    },
    "node_modules/micromark-util-decode-string": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-decode-string/-/micromark-util-decode-string-2.0.1.tgz",
      "integrity": "sha512-nDV/77Fj6eH1ynwscYTOsbK7rR//Uj0bZXBwJZRfaLEJ1iGBR6kIfNmlNqaqJf649EP0F3NWNdeJi03elllNUQ==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "decode-named-character-reference": "^1.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-decode-numeric-character-reference": "^2.0.0",
        "micromark-util-symbol": "^2.0.0"
      }
    },
    "node_modules/micromark-util-encode": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-encode/-/micromark-util-encode-2.0.1.tgz",
      "integrity": "sha512-c3cVx2y4KqUnwopcO9b/SCdo2O67LwJJ/UyqGfbigahfegL9myoEFoDYZgkT7f36T0bLrM9hZTAaAyH+PCAXjw==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT"
    },
    "node_modules/micromark-util-html-tag-name": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-html-tag-name/-/micromark-util-html-tag-name-2.0.1.tgz",
      "integrity": "sha512-2cNEiYDhCWKI+Gs9T0Tiysk136SnR13hhO8yW6BGNyhOC4qYFnwF1nKfD3HFAIXA5c45RrIG1ub11GiXeYd1xA==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT"
    },
    "node_modules/micromark-util-normalize-identifier": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-normalize-identifier/-/micromark-util-normalize-identifier-2.0.1.tgz",
      "integrity": "sha512-sxPqmo70LyARJs0w2UclACPUUEqltCkJ6PhKdMIDuJ3gSf/Q+/GIe3WKl0Ijb/GyH9lOpUkRAO2wp0GVkLvS9Q==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-symbol": "^2.0.0"
      }
    },
    "node_modules/micromark-util-resolve-all": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-resolve-all/-/micromark-util-resolve-all-2.0.1.tgz",
      "integrity": "sha512-VdQyxFWFT2/FGJgwQnJYbe1jjQoNTS4RjglmSjTUlpUMa95Htx9NHeYW4rGDJzbjvCsl9eLjMQwGeElsqmzcHg==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-util-sanitize-uri": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-sanitize-uri/-/micromark-util-sanitize-uri-2.0.1.tgz",
      "integrity": "sha512-9N9IomZ/YuGGZZmQec1MbgxtlgougxTodVwDzzEouPKo3qFWvymFHWcnDi2vzV1ff6kas9ucW+o3yzJK9YB1AQ==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-character": "^2.0.0",
        "micromark-util-encode": "^2.0.0",
        "micromark-util-symbol": "^2.0.0"
      }
    },
    "node_modules/micromark-util-subtokenize": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/micromark-util-subtokenize/-/micromark-util-subtokenize-2.1.0.tgz",
      "integrity": "sha512-XQLu552iSctvnEcgXw6+Sx75GflAPNED1qx7eBJ+wydBb2KCbRZe+NwvIEEMM83uml1+2WSXpBAcp9IUCgCYWA==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "devlop": "^1.0.0",
        "micromark-util-chunked": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-util-symbol": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-symbol/-/micromark-util-symbol-2.0.1.tgz",
      "integrity": "sha512-vs5t8Apaud9N28kgCrRUdEed4UJ+wWNvicHLPxCa9ENlYuAY31M0ETy5y1vA33YoNPDFTghEbnh6efaE8h4x0Q==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT"
    },
    "node_modules/micromark-util-types": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/micromark-util-types/-/micromark-util-types-2.0.2.tgz",
      "integrity": "sha512-Yw0ECSpJoViF1qTU4DC6NwtC4aWGt1EkzaQB8KPPyCRR8z9TWeV0HbEFGTO+ZY1wB22zmxnJqhPyTpOVCpeHTA==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT"
    },
    "node_modules/minimatch": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-3.1.2.tgz",
      "integrity": "sha512-J7p63hRiAjw1NDEww1W7i37+ByIrOWO5XQQAzZ3VOcL0PNybwpfmV/N05zFAzwQ9USyEcX6t3UO+K5aqBQOIHw==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "brace-expansion": "^1.1.7"
      },
      "engines": {
        "node": "*"
      }
    },
    "node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==",
      "license": "MIT"
    },
    "node_modules/nanoid": {
      "version": "3.3.11",
      "resolved": "https://registry.npmjs.org/nanoid/-/nanoid-3.3.11.tgz",
      "integrity": "sha512-N8SpfPUnUp1bK+PMYW8qSWdl9U+wwNWI4QKxOYDy9JAro3WMX7p2OeVRF9v+347pnakNevPmiHhNmZ2HbFA76w==",
      "dev": true,
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "bin": {
        "nanoid": "bin/nanoid.cjs"
      },
      "engines": {
        "node": "^10 || ^12 || ^13.7 || ^14 || >=15.0.1"
      }
    },
    "node_modules/natural-compare": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/natural-compare/-/natural-compare-1.4.0.tgz",
      "integrity": "sha512-OWND8ei3VtNC9h7V60qff3SVobHr996CTwgxubgyQYEpg290h9J0buyECNNJexkFm5sOajh5G116RYA1c8ZMSw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/node-releases": {
      "version": "2.0.27",
      "resolved": "https://registry.npmjs.org/node-releases/-/node-releases-2.0.27.tgz",
      "integrity": "sha512-nmh3lCkYZ3grZvqcCH+fjmQ7X+H0OeZgP40OierEaAptX4XofMh5kwNbWh7lBduUzCcV/8kZ+NDLCwm2iorIlA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/normalize-range": {
      "version": "0.1.2",
      "resolved": "https://registry.npmjs.org/normalize-range/-/normalize-range-0.1.2.tgz",
      "integrity": "sha512-bdok/XvKII3nUpklnV6P2hxtMNrCboOjAcyBuQnWEhO665FwrSNRxU+AqpsyvO6LgGYPspN+lu5CLtw4jPRKNA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/optionator": {
      "version": "0.9.4",
      "resolved": "https://registry.npmjs.org/optionator/-/optionator-0.9.4.tgz",
      "integrity": "sha512-6IpQ7mKUxRcZNLIObR0hz7lxsapSSIYNZJwXPGeF0mTVqGKFIXj1DQcMoT22S3ROcLyY/rz0PWaWZ9ayWmad9g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "deep-is": "^0.1.3",
        "fast-levenshtein": "^2.0.6",
        "levn": "^0.4.1",
        "prelude-ls": "^1.2.1",
        "type-check": "^0.4.0",
        "word-wrap": "^1.2.5"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/p-limit": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/p-limit/-/p-limit-3.1.0.tgz",
      "integrity": "sha512-TYOanM3wGwNGsZN2cVTYPArw454xnXj5qmWF1bEoAc4+cU/ol7GVh7odevjp1FNHduHc3KZMcFduxU5Xc6uJRQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "yocto-queue": "^0.1.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/p-locate": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/p-locate/-/p-locate-5.0.0.tgz",
      "integrity": "sha512-LaNjtRWUBY++zB5nE/NwcaoMylSPk+S+ZHNB1TzdbMJMny6dynpAGt7X/tl/QYq3TIeE6nxHppbo2LGymrG5Pw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "p-limit": "^3.0.2"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/parent-module": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/parent-module/-/parent-module-1.0.1.tgz",
      "integrity": "sha512-GQ2EWRpQV8/o+Aw8YqtfZZPfNRWZYkbidE9k5rpl/hC3vtHHBfGm2Ifi6qWV+coDGkrUKZAxE3Lot5kcsRlh+g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "callsites": "^3.0.0"
      },
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/parse-entities": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/parse-entities/-/parse-entities-4.0.2.tgz",
      "integrity": "sha512-GG2AQYWoLgL877gQIKeRPGO1xF9+eG1ujIb5soS5gPvLQ1y2o8FL90w2QWNdf9I361Mpp7726c+lj3U0qK1uGw==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^2.0.0",
        "character-entities-legacy": "^3.0.0",
        "character-reference-invalid": "^2.0.0",
        "decode-named-character-reference": "^1.0.0",
        "is-alphanumerical": "^2.0.0",
        "is-decimal": "^2.0.0",
        "is-hexadecimal": "^2.0.0"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/parse-entities/node_modules/@types/unist": {
      "version": "2.0.11",
      "resolved": "https://registry.npmjs.org/@types/unist/-/unist-2.0.11.tgz",
      "integrity": "sha512-CmBKiL6NNo/OqgmMn95Fk9Whlp2mtvIv+KNpQKN2F4SjvrEesubTRWGYSg+BnWZOnlCaSTU1sMpsBOzgbYhnsA==",
      "license": "MIT"
    },
    "node_modules/path-exists": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/path-exists/-/path-exists-4.0.0.tgz",
      "integrity": "sha512-ak9Qy5Q7jYb2Wwcey5Fpvg2KoAc/ZIhLSLOSBmRmygPsGwkVVt0fZa0qrtMz+m6tJTAHfZQ8FnmB4MG4LWy7/w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/path-key": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/path-key/-/path-key-3.1.1.tgz",
      "integrity": "sha512-ojmeN0qd+y0jszEtoY48r0Peq5dwMEkIlCOu6Q5f41lfkswXuKtYrhgoTpLnyIcHm24Uhqx+5Tqm2InSwLhE6Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/picocolors": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/picocolors/-/picocolors-1.1.1.tgz",
      "integrity": "sha512-xceH2snhtb5M9liqDsmEw56le376mTZkEX/jEb/RxNFyegNul7eNslCXP9FDj/Lcu0X8KEyMceP2ntpaHrDEVA==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/picomatch": {
      "version": "4.0.3",
      "resolved": "https://registry.npmjs.org/picomatch/-/picomatch-4.0.3.tgz",
      "integrity": "sha512-5gTmgEY/sqK6gFXLIsQNH19lWb4ebPDLA4SdLP7dsWkIXHWlG66oPuVvXSGFPppYZz8ZDZq0dYYrbHfBCVUb1Q==",
      "dev": true,
      "license": "MIT",
      "peer": true,
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/sponsors/jonschlinkert"
      }
    },
    "node_modules/postcss": {
      "version": "8.5.6",
      "resolved": "https://registry.npmjs.org/postcss/-/postcss-8.5.6.tgz",
      "integrity": "sha512-3Ybi1tAuwAP9s0r1UQ2J4n5Y0G05bJkpUIO0/bI9MhwmD70S5aTWbXGBwxHrelT+XM1k6dM0pk+SwNkpTRN7Pg==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/postcss"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "peer": true,
      "dependencies": {
        "nanoid": "^3.3.11",
        "picocolors": "^1.1.1",
        "source-map-js": "^1.2.1"
      },
      "engines": {
        "node": "^10 || ^12 || >=14"
      }
    },
    "node_modules/postcss-value-parser": {
      "version": "4.2.0",
      "resolved": "https://registry.npmjs.org/postcss-value-parser/-/postcss-value-parser-4.2.0.tgz",
      "integrity": "sha512-1NNCs6uurfkVbeXG4S8JFT9t19m45ICnif8zWLd5oPSZ50QnwMfK+H3jv408d4jw/7Bttv5axS5IiHoLaVNHeQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/prelude-ls": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/prelude-ls/-/prelude-ls-1.2.1.tgz",
      "integrity": "sha512-vkcDPrRZo1QZLbn5RLGPpg/WmIQ65qoWWhcGKf/b5eplkkarX0m9z8ppCat4mlOqUsWpyNuYgO3VRyrYHSzX5g==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/property-information": {
      "version": "7.1.0",
      "resolved": "https://registry.npmjs.org/property-information/-/property-information-7.1.0.tgz",
      "integrity": "sha512-TwEZ+X+yCJmYfL7TPUOcvBZ4QfoT5YenQiJuX//0th53DE6w0xxLEtfK3iyryQFddXuvkIk51EEgrJQ0WJkOmQ==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/punycode": {
      "version": "2.3.1",
      "resolved": "https://registry.npmjs.org/punycode/-/punycode-2.3.1.tgz",
      "integrity": "sha512-vYt7UD1U9Wg6138shLtLOvdAu+8DsC/ilFtEVHcH+wydcSpNE20AfSOduf6MkRFahL5FY7X1oU7nKVZFtfq8Fg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/react": {
      "version": "19.2.0",
      "resolved": "https://registry.npmjs.org/react/-/react-19.2.0.tgz",
      "integrity": "sha512-tmbWg6W31tQLeB5cdIBOicJDJRR2KzXsV7uSK9iNfLWQ5bIZfxuPEHp7M8wiHyHnn0DD1i7w3Zmin0FtkrwoCQ==",
      "license": "MIT",
      "peer": true,
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/react-dom": {
      "version": "19.2.0",
      "resolved": "https://registry.npmjs.org/react-dom/-/react-dom-19.2.0.tgz",
      "integrity": "sha512-UlbRu4cAiGaIewkPyiRGJk0imDN2T3JjieT6spoL2UeSf5od4n5LB/mQ4ejmxhCFT1tYe8IvaFulzynWovsEFQ==",
      "license": "MIT",
      "dependencies": {
        "scheduler": "^0.27.0"
      },
      "peerDependencies": {
        "react": "^19.2.0"
      }
    },
    "node_modules/react-markdown": {
      "version": "10.1.0",
      "resolved": "https://registry.npmjs.org/react-markdown/-/react-markdown-10.1.0.tgz",
      "integrity": "sha512-qKxVopLT/TyA6BX3Ue5NwabOsAzm0Q7kAPwq6L+wWDwisYs7R8vZ0nRXqq6rkueboxpkjvLGU9fWifiX/ZZFxQ==",
      "license": "MIT",
      "dependencies": {
        "@types/hast": "^3.0.0",
        "@types/mdast": "^4.0.0",
        "devlop": "^1.0.0",
        "hast-util-to-jsx-runtime": "^2.0.0",
        "html-url-attributes": "^3.0.0",
        "mdast-util-to-hast": "^13.0.0",
        "remark-parse": "^11.0.0",
        "remark-rehype": "^11.0.0",
        "unified": "^11.0.0",
        "unist-util-visit": "^5.0.0",
        "vfile": "^6.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      },
      "peerDependencies": {
        "@types/react": ">=18",
        "react": ">=18"
      }
    },
    "node_modules/react-refresh": {
      "version": "0.18.0",
      "resolved": "https://registry.npmjs.org/react-refresh/-/react-refresh-0.18.0.tgz",
      "integrity": "sha512-QgT5//D3jfjJb6Gsjxv0Slpj23ip+HtOpnNgnb2S5zU3CB26G/IDPGoy4RJB42wzFE46DRsstbW6tKHoKbhAxw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/remark-gfm": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/remark-gfm/-/remark-gfm-4.0.1.tgz",
      "integrity": "sha512-1quofZ2RQ9EWdeN34S79+KExV1764+wCUGop5CPL1WGdD0ocPpu91lzPGbwWMECpEpd42kJGQwzRfyov9j4yNg==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "mdast-util-gfm": "^3.0.0",
        "micromark-extension-gfm": "^3.0.0",
        "remark-parse": "^11.0.0",
        "remark-stringify": "^11.0.0",
        "unified": "^11.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/remark-parse": {
      "version": "11.0.0",
      "resolved": "https://registry.npmjs.org/remark-parse/-/remark-parse-11.0.0.tgz",
      "integrity": "sha512-FCxlKLNGknS5ba/1lmpYijMUzX2esxW5xQqjWxw2eHFfS2MSdaHVINFmhjo+qN1WhZhNimq0dZATN9pH0IDrpA==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "mdast-util-from-markdown": "^2.0.0",
        "micromark-util-types": "^2.0.0",
        "unified": "^11.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/remark-rehype": {
      "version": "11.1.2",
      "resolved": "https://registry.npmjs.org/remark-rehype/-/remark-rehype-11.1.2.tgz",
      "integrity": "sha512-Dh7l57ianaEoIpzbp0PC9UKAdCSVklD8E5Rpw7ETfbTl3FqcOOgq5q2LVDhgGCkaBv7p24JXikPdvhhmHvKMsw==",
      "license": "MIT",
      "dependencies": {
        "@types/hast": "^3.0.0",
        "@types/mdast": "^4.0.0",
        "mdast-util-to-hast": "^13.0.0",
        "unified": "^11.0.0",
        "vfile": "^6.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/remark-stringify": {
      "version": "11.0.0",
      "resolved": "https://registry.npmjs.org/remark-stringify/-/remark-stringify-11.0.0.tgz",
      "integrity": "sha512-1OSmLd3awB/t8qdoEOMazZkNsfVTeY4fTsgzcQFdXNq8ToTN4ZGwrMnlda4K6smTFKD+GRV6O48i6Z4iKgPPpw==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "mdast-util-to-markdown": "^2.0.0",
        "unified": "^11.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/resolve-from": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/resolve-from/-/resolve-from-4.0.0.tgz",
      "integrity": "sha512-pb/MYmXstAkysRFx8piNI1tGFNQIFA3vkE3Gq4EuA1dF6gHp/+vgZqsCGJapvy8N3Q+4o7FwvquPJcnZ7RYy4g==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/rollup": {
      "version": "4.53.3",
      "resolved": "https://registry.npmjs.org/rollup/-/rollup-4.53.3.tgz",
      "integrity": "sha512-w8GmOxZfBmKknvdXU1sdM9NHcoQejwF/4mNgj2JuEEdRaHwwF12K7e9eXn1nLZ07ad+du76mkVsyeb2rKGllsA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@types/estree": "1.0.8"
      },
      "bin": {
        "rollup": "dist/bin/rollup"
      },
      "engines": {
        "node": ">=18.0.0",
        "npm": ">=8.0.0"
      },
      "optionalDependencies": {
        "@rollup/rollup-android-arm-eabi": "4.53.3",
        "@rollup/rollup-android-arm64": "4.53.3",
        "@rollup/rollup-darwin-arm64": "4.53.3",
        "@rollup/rollup-darwin-x64": "4.53.3",
        "@rollup/rollup-freebsd-arm64": "4.53.3",
        "@rollup/rollup-freebsd-x64": "4.53.3",
        "@rollup/rollup-linux-arm-gnueabihf": "4.53.3",
        "@rollup/rollup-linux-arm-musleabihf": "4.53.3",
        "@rollup/rollup-linux-arm64-gnu": "4.53.3",
        "@rollup/rollup-linux-arm64-musl": "4.53.3",
        "@rollup/rollup-linux-loong64-gnu": "4.53.3",
        "@rollup/rollup-linux-ppc64-gnu": "4.53.3",
        "@rollup/rollup-linux-riscv64-gnu": "4.53.3",
        "@rollup/rollup-linux-riscv64-musl": "4.53.3",
        "@rollup/rollup-linux-s390x-gnu": "4.53.3",
        "@rollup/rollup-linux-x64-gnu": "4.53.3",
        "@rollup/rollup-linux-x64-musl": "4.53.3",
        "@rollup/rollup-openharmony-arm64": "4.53.3",
        "@rollup/rollup-win32-arm64-msvc": "4.53.3",
        "@rollup/rollup-win32-ia32-msvc": "4.53.3",
        "@rollup/rollup-win32-x64-gnu": "4.53.3",
        "@rollup/rollup-win32-x64-msvc": "4.53.3",
        "fsevents": "~2.3.2"
      }
    },
    "node_modules/rollup/node_modules/@rollup/rollup-win32-x64-msvc": {
      "version": "4.53.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-win32-x64-msvc/-/rollup-win32-x64-msvc-4.53.3.tgz",
      "integrity": "sha512-UhTd8u31dXadv0MopwGgNOBpUVROFKWVQgAg5N1ESyCz8AuBcMqm4AuTjrwgQKGDfoFuz02EuMRHQIw/frmYKQ==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ]
    },
    "node_modules/scheduler": {
      "version": "0.27.0",
      "resolved": "https://registry.npmjs.org/scheduler/-/scheduler-0.27.0.tgz",
      "integrity": "sha512-eNv+WrVbKu1f3vbYJT/xtiF5syA5HPIMtf9IgY/nKg0sWqzAUEvqY/xm7OcZc/qafLx/iO9FgOmeSAp4v5ti/Q==",
      "license": "MIT"
    },
    "node_modules/semver": {
      "version": "6.3.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-6.3.1.tgz",
      "integrity": "sha512-BR7VvDCVHO+q2xBEWskxS6DJE1qRnb7DxzUrogb71CWoSficBxYsiAGd+Kl0mmq/MprG9yArRkyrQxTO6XjMzA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      }
    },
    "node_modules/shebang-command": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/shebang-command/-/shebang-command-2.0.0.tgz",
      "integrity": "sha512-kHxr2zZpYtdmrN1qDjrrX/Z1rR1kG8Dx+gkpK1G4eXmvXswmcE1hTWBWYUzlraYw1/yZp6YuDY77YtvbN0dmDA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "shebang-regex": "^3.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/shebang-regex": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/shebang-regex/-/shebang-regex-3.0.0.tgz",
      "integrity": "sha512-7++dFhtcx3353uBaq8DDR4NuxBetBzC7ZQOhmTQInHEd6bSrXdiEyzCvG07Z44UYdLShWUyXt5M/yhz8ekcb1A==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/source-map-js": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/source-map-js/-/source-map-js-1.2.1.tgz",
      "integrity": "sha512-UXWMKhLOwVKb728IUtQPXxfYU+usdybtUrK/8uGE8CQMvrhOpwvzDBwj0QhSL7MQc7vIsISBG8VQ8+IDQxpfQA==",
      "dev": true,
      "license": "BSD-3-Clause",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/space-separated-tokens": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/space-separated-tokens/-/space-separated-tokens-2.0.2.tgz",
      "integrity": "sha512-PEGlAwrG8yXGXRjW32fGbg66JAlOAwbObuqVoJpv/mRgoWDQfgH1wDPvtzWyUSNAXBGSk8h755YDbbcEy3SH2Q==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/stringify-entities": {
      "version": "4.0.4",
      "resolved": "https://registry.npmjs.org/stringify-entities/-/stringify-entities-4.0.4.tgz",
      "integrity": "sha512-IwfBptatlO+QCJUo19AqvrPNqlVMpW9YEL2LIVY+Rpv2qsjCGxaDLNRgeGsQWJhfItebuJhsGSLjaBbNSQ+ieg==",
      "license": "MIT",
      "dependencies": {
        "character-entities-html4": "^2.0.0",
        "character-entities-legacy": "^3.0.0"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/strip-json-comments": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/strip-json-comments/-/strip-json-comments-3.1.1.tgz",
      "integrity": "sha512-6fPc+R4ihwqP6N/aIv2f1gMH8lOVtWQHoqC4yK6oSDVVocumAsfCqjkXnqiYMhmMwS/mEHLp7Vehlt3ql6lEig==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/style-to-js": {
      "version": "1.1.21",
      "resolved": "https://registry.npmjs.org/style-to-js/-/style-to-js-1.1.21.tgz",
      "integrity": "sha512-RjQetxJrrUJLQPHbLku6U/ocGtzyjbJMP9lCNK7Ag0CNh690nSH8woqWH9u16nMjYBAok+i7JO1NP2pOy8IsPQ==",
      "license": "MIT",
      "dependencies": {
        "style-to-object": "1.0.14"
      }
    },
    "node_modules/style-to-object": {
      "version": "1.0.14",
      "resolved": "https://registry.npmjs.org/style-to-object/-/style-to-object-1.0.14.tgz",
      "integrity": "sha512-LIN7rULI0jBscWQYaSswptyderlarFkjQ+t79nzty8tcIAceVomEVlLzH5VP4Cmsv6MtKhs7qaAiwlcp+Mgaxw==",
      "license": "MIT",
      "dependencies": {
        "inline-style-parser": "0.2.7"
      }
    },
    "node_modules/supports-color": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/supports-color/-/supports-color-7.2.0.tgz",
      "integrity": "sha512-qpCAvRl9stuOHveKsn7HncJRvv501qIacKzQlO/+Lwxc9+0q2wLyv4Dfvt80/DPn2pqOBsJdDiogXGR9+OvwRw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "has-flag": "^4.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/tailwindcss": {
      "version": "4.1.17",
      "resolved": "https://registry.npmjs.org/tailwindcss/-/tailwindcss-4.1.17.tgz",
      "integrity": "sha512-j9Ee2YjuQqYT9bbRTfTZht9W/ytp5H+jJpZKiYdP/bpnXARAuELt9ofP0lPnmHjbga7SNQIxdTAXCmtKVYjN+Q==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/tapable": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/tapable/-/tapable-2.3.0.tgz",
      "integrity": "sha512-g9ljZiwki/LfxmQADO3dEY1CbpmXT5Hm2fJ+QaGKwSXUylMybePR7/67YW7jOrrvjEgL1Fmz5kzyAjWVWLlucg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/webpack"
      }
    },
    "node_modules/tinyglobby": {
      "version": "0.2.15",
      "resolved": "https://registry.npmjs.org/tinyglobby/-/tinyglobby-0.2.15.tgz",
      "integrity": "sha512-j2Zq4NyQYG5XMST4cbs02Ak8iJUdxRM0XI5QyxXuZOzKOINmWurp3smXu3y5wDcJrptwpSjgXHzIQxR0omXljQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "fdir": "^6.5.0",
        "picomatch": "^4.0.3"
      },
      "engines": {
        "node": ">=12.0.0"
      },
      "funding": {
        "url": "https://github.com/sponsors/SuperchupuDev"
      }
    },
    "node_modules/trim-lines": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/trim-lines/-/trim-lines-3.0.1.tgz",
      "integrity": "sha512-kRj8B+YHZCc9kQYdWfJB2/oUl9rA99qbowYYBtr4ui4mZyAQ2JpvVBd/6U2YloATfqBhBTSMhTpgBHtU0Mf3Rg==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/trough": {
      "version": "2.2.0",
      "resolved": "https://registry.npmjs.org/trough/-/trough-2.2.0.tgz",
      "integrity": "sha512-tmMpK00BjZiUyVyvrBK7knerNgmgvcV/KLVyuma/SC+TQN167GrMRciANTz09+k3zW8L8t60jWO1GpfkZdjTaw==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/type-check": {
      "version": "0.4.0",
      "resolved": "https://registry.npmjs.org/type-check/-/type-check-0.4.0.tgz",
      "integrity": "sha512-XleUoc9uwGXqjWwXaUTZAmzMcFZ5858QA2vvx1Ur5xIcixXIP+8LnFDgRplU30us6teqdlskFfu+ae4K79Ooew==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "prelude-ls": "^1.2.1"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/unified": {
      "version": "11.0.5",
      "resolved": "https://registry.npmjs.org/unified/-/unified-11.0.5.tgz",
      "integrity": "sha512-xKvGhPWw3k84Qjh8bI3ZeJjqnyadK+GEFtazSfZv/rKeTkTjOJho6mFqh2SM96iIcZokxiOpg78GazTSg8+KHA==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^3.0.0",
        "bail": "^2.0.0",
        "devlop": "^1.0.0",
        "extend": "^3.0.0",
        "is-plain-obj": "^4.0.0",
        "trough": "^2.0.0",
        "vfile": "^6.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/unist-util-is": {
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/unist-util-is/-/unist-util-is-6.0.1.tgz",
      "integrity": "sha512-LsiILbtBETkDz8I9p1dQ0uyRUWuaQzd/cuEeS1hoRSyW5E5XGmTzlwY1OrNzzakGowI9Dr/I8HVaw4hTtnxy8g==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^3.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/unist-util-position": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/unist-util-position/-/unist-util-position-5.0.0.tgz",
      "integrity": "sha512-fucsC7HjXvkB5R3kTCO7kUjRdrS0BJt3M/FPxmHMBOm8JQi2BsHAHFsy27E0EolP8rp0NzXsJ+jNPyDWvOJZPA==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^3.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/unist-util-stringify-position": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/unist-util-stringify-position/-/unist-util-stringify-position-4.0.0.tgz",
      "integrity": "sha512-0ASV06AAoKCDkS2+xw5RXJywruurpbC4JZSm7nr7MOt1ojAzvyyaO+UxZf18j8FCF6kmzCZKcAgN/yu2gm2XgQ==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^3.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/unist-util-visit": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/unist-util-visit/-/unist-util-visit-5.0.0.tgz",
      "integrity": "sha512-MR04uvD+07cwl/yhVuVWAtw+3GOR/knlL55Nd/wAdblk27GCVt3lqpTivy/tkJcZoNPzTwS1Y+KMojlLDhoTzg==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^3.0.0",
        "unist-util-is": "^6.0.0",
        "unist-util-visit-parents": "^6.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/unist-util-visit-parents": {
      "version": "6.0.2",
      "resolved": "https://registry.npmjs.org/unist-util-visit-parents/-/unist-util-visit-parents-6.0.2.tgz",
      "integrity": "sha512-goh1s1TBrqSqukSc8wrjwWhL0hiJxgA8m4kFxGlQ+8FYQ3C/m11FcTs4YYem7V664AhHVvgoQLk890Ssdsr2IQ==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^3.0.0",
        "unist-util-is": "^6.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/update-browserslist-db": {
      "version": "1.1.4",
      "resolved": "https://registry.npmjs.org/update-browserslist-db/-/update-browserslist-db-1.1.4.tgz",
      "integrity": "sha512-q0SPT4xyU84saUX+tomz1WLkxUbuaJnR1xWt17M7fJtEJigJeWUNGUqrauFXsHnqev9y9JTRGwk13tFBuKby4A==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/browserslist"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/browserslist"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "escalade": "^3.2.0",
        "picocolors": "^1.1.1"
      },
      "bin": {
        "update-browserslist-db": "cli.js"
      },
      "peerDependencies": {
        "browserslist": ">= 4.21.0"
      }
    },
    "node_modules/uri-js": {
      "version": "4.4.1",
      "resolved": "https://registry.npmjs.org/uri-js/-/uri-js-4.4.1.tgz",
      "integrity": "sha512-7rKUyy33Q1yc98pQ1DAmLtwX109F7TIfWlW1Ydo8Wl1ii1SeHieeh0HHfPeL2fMXK6z0s8ecKs9frCuLJvndBg==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "punycode": "^2.1.0"
      }
    },
    "node_modules/vfile": {
      "version": "6.0.3",
      "resolved": "https://registry.npmjs.org/vfile/-/vfile-6.0.3.tgz",
      "integrity": "sha512-KzIbH/9tXat2u30jf+smMwFCsno4wHVdNmzFyL+T/L3UGqqk6JKfVqOFOZEpZSHADH1k40ab6NUIXZq422ov3Q==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^3.0.0",
        "vfile-message": "^4.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/vfile-message": {
      "version": "4.0.3",
      "resolved": "https://registry.npmjs.org/vfile-message/-/vfile-message-4.0.3.tgz",
      "integrity": "sha512-QTHzsGd1EhbZs4AsQ20JX1rC3cOlt/IWJruk893DfLRr57lcnOeMaWG4K0JrRta4mIJZKth2Au3mM3u03/JWKw==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^3.0.0",
        "unist-util-stringify-position": "^4.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/vite": {
      "version": "7.2.4",
      "resolved": "https://registry.npmjs.org/vite/-/vite-7.2.4.tgz",
      "integrity": "sha512-NL8jTlbo0Tn4dUEXEsUg8KeyG/Lkmc4Fnzb8JXN/Ykm9G4HNImjtABMJgkQoVjOBN/j2WAwDTRytdqJbZsah7w==",
      "dev": true,
      "license": "MIT",
      "peer": true,
      "dependencies": {
        "esbuild": "^0.25.0",
        "fdir": "^6.5.0",
        "picomatch": "^4.0.3",
        "postcss": "^8.5.6",
        "rollup": "^4.43.0",
        "tinyglobby": "^0.2.15"
      },
      "bin": {
        "vite": "bin/vite.js"
      },
      "engines": {
        "node": "^20.19.0 || >=22.12.0"
      },
      "funding": {
        "url": "https://github.com/vitejs/vite?sponsor=1"
      },
      "optionalDependencies": {
        "fsevents": "~2.3.3"
      },
      "peerDependencies": {
        "@types/node": "^20.19.0 || >=22.12.0",
        "jiti": ">=1.21.0",
        "less": "^4.0.0",
        "lightningcss": "^1.21.0",
        "sass": "^1.70.0",
        "sass-embedded": "^1.70.0",
        "stylus": ">=0.54.8",
        "sugarss": "^5.0.0",
        "terser": "^5.16.0",
        "tsx": "^4.8.1",
        "yaml": "^2.4.2"
      },
      "peerDependenciesMeta": {
        "@types/node": {
          "optional": true
        },
        "jiti": {
          "optional": true
        },
        "less": {
          "optional": true
        },
        "lightningcss": {
          "optional": true
        },
        "sass": {
          "optional": true
        },
        "sass-embedded": {
          "optional": true
        },
        "stylus": {
          "optional": true
        },
        "sugarss": {
          "optional": true
        },
        "terser": {
          "optional": true
        },
        "tsx": {
          "optional": true
        },
        "yaml": {
          "optional": true
        }
      }
    },
    "node_modules/which": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/which/-/which-2.0.2.tgz",
      "integrity": "sha512-BLI3Tl1TW3Pvl70l3yq3Y64i+awpwXqsGBYWkkqMtnbXgrMD+yj7rhW0kuEDxzJaYXGjEW5ogapKNMEKNMjibA==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "isexe": "^2.0.0"
      },
      "bin": {
        "node-which": "bin/node-which"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/word-wrap": {
      "version": "1.2.5",
      "resolved": "https://registry.npmjs.org/word-wrap/-/word-wrap-1.2.5.tgz",
      "integrity": "sha512-BN22B5eaMMI9UMtjrGd5g5eCYPpCPDUy0FJXbYsaT5zYxjFOckS53SQDE3pWkVoWpHXVb3BrYcEN4Twa55B5cA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/yallist": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/yallist/-/yallist-3.1.1.tgz",
      "integrity": "sha512-a4UGQaWPH59mOXUYnAG2ewncQS4i4F43Tv3JoAM+s2VDAmS9NsK8GpDMLrCHPksFT7h3K6TOoUNn2pb7RoXx4g==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/yocto-queue": {
      "version": "0.1.0",
      "resolved": "https://registry.npmjs.org/yocto-queue/-/yocto-queue-0.1.0.tgz",
      "integrity": "sha512-rVksvsnNCdJ/ohGc6xgPwyN8eheCxsiLM8mxuE/t/mOVqJewPuO1miLpTHQiRgTKCLexL4MeAFVagts7HmNZ2Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/zod": {
      "version": "4.1.13",
      "resolved": "https://registry.npmjs.org/zod/-/zod-4.1.13.tgz",
      "integrity": "sha512-AvvthqfqrAhNH9dnfmrfKzX5upOdjUVJYFqNSlkmGf64gRaTzlPwz99IHYnVs28qYAybvAlBV+H7pn0saFY4Ig==",
      "dev": true,
      "license": "MIT",
      "peer": true,
      "funding": {
        "url": "https://github.com/sponsors/colinhacks"
      }
    },
    "node_modules/zod-validation-error": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/zod-validation-error/-/zod-validation-error-4.0.2.tgz",
      "integrity": "sha512-Q6/nZLe6jxuU80qb/4uJ4t5v2VEZ44lzQjPDhYJNztRQ4wyWc6VF3D3Kb/fAuPetZQnhS3hnajCf9CsWesghLQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=18.0.0"
      },
      "peerDependencies": {
        "zod": "^3.25.0 || ^4.0.0"
      }
    },
    "node_modules/zwitch": {
      "version": "2.0.4",
      "resolved": "https://registry.npmjs.org/zwitch/-/zwitch-2.0.4.tgz",
      "integrity": "sha512-bXE4cR/kVZhKZX/RjPEflHaKVhUVl85noU3v6b8apfQEc1x4A+zBxjZ4lN8LqGd6WZ3dl98pY4o717VFmoPp+A==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    }
  }
}


===== FILE: app_frontend\postcss.config.js =====
// app_frontend/postcss.config.js
export default {
  plugins: {
    "@tailwindcss/postcss": {},
  },
};






===== FILE: app_frontend\public\demo_ingestion_enabled.json =====
{
  "enabled": true
}

===== FILE: app_frontend\public\missionlog\demo_capabilities.json =====
{ "demo_ingestion_enabled": true }


===== FILE: app_frontend\public\missionlog\status_snapshot.json =====
{
  "generated_at": "2025-12-31T21:49:32Z",
  "epics": [
    {
      "epic_id": "E00",
      "name": "Backend Foundation",
      "overall_status": "Complete",
      "features": [
        {
          "feature_id": "FT-00-BE",
          "name": "Backend Foundation",
          "epic_id": "E00",
          "overall_status": "Complete",
          "stories": [
            {
              "story_id": "ST-00",
              "name": "Backend Foundation",
              "feature_id": "FT-00-BE",
              "overall_status": "Complete",
              "testing_status": "pass",
              "halo_adherence": "pass",
              "guardrail_adherence": "pass",
              "code_quality_adherence": "pass",
              "security_policy_adherence": "pass"
            }
          ]
        }
      ]
    },
    {
      "epic_id": "E00-UI",
      "name": "User Interface Foundation",
      "overall_status": "Complete",
      "features": [
        {
          "feature_id": "FT-00-UI",
          "name": "User Interface Foundation",
          "epic_id": "E00-UI",
          "overall_status": "Complete",
          "stories": [
            {
              "story_id": "ST-00-FRONTEND-UI-SHELL",
              "name": "User Interface Foundation",
              "feature_id": "FT-00-UI",
              "overall_status": "Complete",
              "testing_status": "pass",
              "halo_adherence": "pass",
              "guardrail_adherence": "pass",
              "code_quality_adherence": "pass",
              "security_policy_adherence": "pass"
            }
          ]
        }
      ]
    },
    {
      "epic_id": "EP-01",
      "name": "Client Ingestion & Normalisation",
      "overall_status": "Planned",
      "features": [
        {
          "feature_id": "FT-01",
          "name": "Source System Configuration",
          "epic_id": "EP-01",
          "overall_status": "Planned",
          "stories": [
            {
              "story_id": "ST-01",
              "name": "Register CRM source",
              "feature_id": "FT-01",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            },
            {
              "story_id": "ST-02",
              "name": "Register KYC source",
              "feature_id": "FT-01",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            }
          ]
        },
        {
          "feature_id": "FT-02",
          "name": "Schema Mapping to Canonical Model",
          "epic_id": "EP-01",
          "overall_status": "Planned",
          "stories": [
            {
              "story_id": "ST-03",
              "name": "Map identity fields",
              "feature_id": "FT-02",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            },
            {
              "story_id": "ST-04",
              "name": "Map identifiers",
              "feature_id": "FT-02",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            }
          ]
        },
        {
          "feature_id": "FT-03",
          "name": "Data Ingestion",
          "epic_id": "EP-01",
          "overall_status": "Planned",
          "stories": [
            {
              "story_id": "ST-05",
              "name": "Ingest CRM Data",
              "feature_id": "FT-03",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            },
            {
              "story_id": "ST-06",
              "name": "Ingest KYC Data",
              "feature_id": "FT-03",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            }
          ]
        },
        {
          "feature_id": "FT-04",
          "name": "Incremental Ingestion & Change Detection",
          "epic_id": "EP-01",
          "overall_status": "Planned",
          "stories": [
            {
              "story_id": "ST-07",
              "name": "Detect upstream deltas",
              "feature_id": "FT-04",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            },
            {
              "story_id": "ST-08",
              "name": "Apply deltas",
              "feature_id": "FT-04",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            }
          ]
        }
      ]
    },
    {
      "epic_id": "EP-02",
      "name": "Client Matching & Golden Record",
      "overall_status": "Planned",
      "features": [
        {
          "feature_id": "FT-05",
          "name": "Exact Match Rules",
          "epic_id": "EP-02",
          "overall_status": "Planned",
          "stories": [
            {
              "story_id": "ST-09",
              "name": "Match by tax ID",
              "feature_id": "FT-05",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            },
            {
              "story_id": "ST-10",
              "name": "Match by registration number",
              "feature_id": "FT-05",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            }
          ]
        },
        {
          "feature_id": "FT-06",
          "name": "Fuzzy & Probabilistic Matching",
          "epic_id": "EP-02",
          "overall_status": "Planned",
          "stories": [
            {
              "story_id": "ST-11",
              "name": "Fuzzy name match",
              "feature_id": "FT-06",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            },
            {
              "story_id": "ST-12",
              "name": "Attribute confidence",
              "feature_id": "FT-06",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            }
          ]
        },
        {
          "feature_id": "FT-07",
          "name": "Golden Record Construction",
          "epic_id": "EP-02",
          "overall_status": "Planned",
          "stories": [
            {
              "story_id": "ST-13",
              "name": "Merge identity",
              "feature_id": "FT-07",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            },
            {
              "story_id": "ST-14",
              "name": "Merge addresses",
              "feature_id": "FT-07",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            },
            {
              "story_id": "ST-15",
              "name": "Record lineage",
              "feature_id": "FT-07",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            }
          ]
        }
      ]
    },
    {
      "epic_id": "EP-03",
      "name": "Client Search",
      "overall_status": "Planned",
      "features": [
        {
          "feature_id": "FT-08",
          "name": "Search Index & Normalisation",
          "epic_id": "EP-03",
          "overall_status": "Planned",
          "stories": [
            {
              "story_id": "ST-16",
              "name": "Build index",
              "feature_id": "FT-08",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            },
            {
              "story_id": "ST-17",
              "name": "Normalise search fields",
              "feature_id": "FT-08",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            }
          ]
        },
        {
          "feature_id": "FT-09",
          "name": "Fuzzy Search & Ranking",
          "epic_id": "EP-03",
          "overall_status": "Planned",
          "stories": [
            {
              "story_id": "ST-18",
              "name": "Fuzzy search queries",
              "feature_id": "FT-09",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            },
            {
              "story_id": "ST-19",
              "name": "Search ranking",
              "feature_id": "FT-09",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            }
          ]
        }
      ]
    },
    {
      "epic_id": "EP-04",
      "name": "Client Profile Assembly",
      "overall_status": "In Progress",
      "features": [
        {
          "feature_id": "FT-10",
          "name": "Assemble Canonical Profile",
          "epic_id": "EP-04",
          "overall_status": "In Progress",
          "stories": [
            {
              "story_id": "ST-20",
              "name": "Assemble base profile",
              "feature_id": "FT-10",
              "overall_status": "Complete",
              "testing_status": "pass",
              "halo_adherence": "pass",
              "guardrail_adherence": "pass",
              "code_quality_adherence": "pass",
              "security_policy_adherence": "pass"
            },
            {
              "story_id": "ST-21",
              "name": "Assemble metadata",
              "feature_id": "FT-10",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            }
          ]
        },
        {
          "feature_id": "FT-11",
          "name": "Lineage Exposure",
          "epic_id": "EP-04",
          "overall_status": "Planned",
          "stories": [
            {
              "story_id": "ST-22",
              "name": "Expose lineage",
              "feature_id": "FT-11",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            },
            {
              "story_id": "ST-23",
              "name": "Drill-down lineage",
              "feature_id": "FT-11",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            }
          ]
        },
        {
          "feature_id": "FT-12",
          "name": "Conflict Presentation",
          "epic_id": "EP-04",
          "overall_status": "Planned",
          "stories": [
            {
              "story_id": "ST-24",
              "name": "Flag conflicts",
              "feature_id": "FT-12",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            },
            {
              "story_id": "ST-25",
              "name": "Show merge logic",
              "feature_id": "FT-12",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            }
          ]
        }
      ]
    },
    {
      "epic_id": "EP-05",
      "name": "Data Quality & Lineage",
      "overall_status": "Planned",
      "features": [
        {
          "feature_id": "FT-13",
          "name": "Lineage Tracking",
          "epic_id": "EP-05",
          "overall_status": "Planned",
          "stories": [
            {
              "story_id": "ST-26",
              "name": "Store lineage history",
              "feature_id": "FT-13",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            },
            {
              "story_id": "ST-27",
              "name": "Timestamp lineage",
              "feature_id": "FT-13",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            }
          ]
        },
        {
          "feature_id": "FT-14",
          "name": "Data Quality Scoring",
          "epic_id": "EP-05",
          "overall_status": "Planned",
          "stories": [
            {
              "story_id": "ST-28",
              "name": "Compute freshness",
              "feature_id": "FT-14",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            },
            {
              "story_id": "ST-29",
              "name": "Compute completeness",
              "feature_id": "FT-14",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            }
          ]
        },
        {
          "feature_id": "FT-15",
          "name": "Auditability & Evidence",
          "epic_id": "EP-05",
          "overall_status": "Planned",
          "stories": [
            {
              "story_id": "ST-30",
              "name": "Audit ingestion",
              "feature_id": "FT-15",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            },
            {
              "story_id": "ST-31",
              "name": "Audit merge",
              "feature_id": "FT-15",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            }
          ]
        }
      ]
    },
    {
      "epic_id": "EP-06",
      "name": "Integration & API Exposure",
      "overall_status": "Planned",
      "features": [
        {
          "feature_id": "FT-16",
          "name": "Search API",
          "epic_id": "EP-06",
          "overall_status": "Planned",
          "stories": [
            {
              "story_id": "ST-32",
              "name": "Search API basic",
              "feature_id": "FT-16",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            },
            {
              "story_id": "ST-33",
              "name": "Search API ranking",
              "feature_id": "FT-16",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            }
          ]
        },
        {
          "feature_id": "FT-17",
          "name": "Client Profile API",
          "epic_id": "EP-06",
          "overall_status": "Planned",
          "stories": [
            {
              "story_id": "ST-34",
              "name": "Profile API basic",
              "feature_id": "FT-17",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            },
            {
              "story_id": "ST-35",
              "name": "Profile API lineage",
              "feature_id": "FT-17",
              "overall_status": "Planned",
              "testing_status": "not_run",
              "halo_adherence": "not_run",
              "guardrail_adherence": "not_run",
              "code_quality_adherence": "not_run",
              "security_policy_adherence": "not_run"
            }
          ]
        }
      ]
    }
  ]
}

===== FILE: app_frontend\public\missionlog\story_defs\ST-00.json =====
{
  "story_id": "ST-00",
  "slug": "ST-00-backend-api-availability",
  "source_path": "docs/mission_destination/stories/ST-00-backend-api-availability.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-00",
    "slug": "st-00-backend-api-availability",
    "name": "Provide Basic Backend API Availability",
    "epic": "E00",
    "feature": "FT-00-BE",
    "testing_status": "pass",
    "halo_adherence": "pass",
    "guardrail_adherence": "pass",
    "code_quality_adherence": "fail",
    "security_policy_adherence": "pass",
    "overall_status": "In Progress",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "2025-12-21T16:19:34+00:00"
  },
  "body_markdown": "# Provide Basic Backend API Availability\n\n## Statement\nAs a platform owner, I want a basic backend API to be available so that the system can support the incremental delivery of client data capabilities in a controlled and extensible way.\n\n## Description\nThis story establishes the foundational backend capability on which the entire platform depends. It confirms that the backend application is not merely runnable, but correctly structured to support enterprise-grade delivery across ingestion, processing, audit, and exposure use cases.\n\nThe backend will be implemented using a modern service architecture, with clear separation between routing, service logic, persistence, and configuration. Core infrastructure concerns such as application startup, dependency wiring, configuration loading, and error handling are to be validated.\n\nThe backend exposes initial API endpoints to demonstrate:\n- request handling and routing\n- structured request/response models\n- consistent error behaviour\n- environment-driven configuration\n- health and readiness signalling\n\nPersistence wired using the real database layer, ensuring that subsequent stories operate against a genuine persistence mechanism rather than mocks or stubs. This confirms that the backend is capable of supporting real data flows, controlled schema evolution, and transactional behaviour.\n\nThis story also validates that the backend can be:\n- started locally in a development environment\n- exercised via automated tests\n- extended incrementally by subsequent stories without rework\n\nAll subsequent backend stories assume this capability as a prerequisite.\n\n## Acceptance Criteria\n- **Given** the backend application is started locally or in a deployed environment  \n  **When** a basic API endpoint is invoked  \n  **Then** the backend responds successfully with a structured response\n\n- **Given** the backend application is running  \n  **When** a health or readiness endpoint is accessed  \n  **Then** the application reports itself as available and correctly initialised\n\n- **Given** the backend configuration is invalid or incomplete  \n  **When** the application starts  \n  **Then** failures are surfaced clearly and prevent ambiguous or silent failure\n\n- **Given** automated tests are executed  \n  **When** backend functionality is exercised  \n  **Then** the application behaves consistently across environments"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-00-FRONTEND-UI-SHELL.json =====
{
  "story_id": "ST-00-FRONTEND-UI-SHELL",
  "slug": "ST-00-frontend-ui-shell",
  "source_path": "docs/mission_destination/stories/ST-00-frontend-ui-shell.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-00-FRONTEND-UI-SHELL",
    "slug": "st-00-frontend-ui-shell",
    "name": "Provide Frontend UI Shell Availability",
    "epic": "E00-UI",
    "feature": "FT-00-UI",
    "testing_status": "pass",
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "fail",
    "security_policy_adherence": "not_run",
    "overall_status": "In Progress",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "2025-12-21T16:51:47+00:00"
  },
  "body_markdown": "# Provide Frontend UI Shell\n\n## Statement\nAs a platform owner, I want a frontend UI shell to be available so that delivered business functionality can be surfaced consistently and credibly as the platform evolves.\n\n## Description\nThis story establishes the foundational frontend capability required to present platform functionality to users in a coherent and extensible way. It confirms that the frontend is not merely a static page, but a properly structured application capable of supporting complex, data-driven user journeys.\n\nThe frontend UI shell has been implemented using a modern component-based framework, with:\n- a running application build and dev workflow\n- a consistent layout and visual structure\n- routing and navigation foundations\n- reusable UI components and styling conventions\n\nThe UI shell provides defined integration points for backend services and has been wired to consume real data where appropriate, rather than relying on mock or placeholder responses. This ensures that the frontend is validated against real backend behaviour from the outset.\n\nCore concerns such as:\n- application startup\n- dependency loading\n- error handling\n- environment configuration\n- visual consistency\n\nhave been exercised and proven.\n\nThis story also establishes the structural container into which future stories will be rendered, including MissionLog, evidence panels, lineage views, and client profile screens. As such, it acts as the visual and interaction baseline for all subsequent frontend work.\n\nAll subsequent frontend stories assume the existence of this shell.\n\n## Acceptance Criteria\n- **Given** the frontend application is started  \n  **When** a user accesses the application  \n  **Then** the UI shell loads successfully without errors\n\n- **Given** the UI shell is loaded  \n  **When** navigation and layout elements are displayed  \n  **Then** they provide a consistent structure for future feature integration\n\n- **Given** the frontend build or configuration is invalid  \n  **When** the application is started  \n  **Then** errors are surfaced clearly and prevent ambiguous failure\n\n- **Given** the frontend is connected to backend services  \n  **When** real data is requested  \n  **Then** responses are handled and rendered correctly"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-01.json =====
{
  "story_id": "ST-01",
  "slug": "ST-01_register_crm_source",
  "source_path": "docs/mission_destination/stories/ST-01_register_crm_source.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-01",
    "feature": "FT-01",
    "name": "Register CRM source",
    "description": "Register CRM system as ingestible source.\n",
    "acceptance_criteria": [
      "Connection succeeds",
      "Schema retrieved"
    ],
    "overall_status": "Planned",
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "<auto>"
  },
  "body_markdown": "# Register CRM Source System\n\n## Statement\nAs a data operations user, I want to register a CRM source system so that client data ingested from that system can be correctly identified, governed, and traced throughout the platform.\n\n## Description\nThe platform must allow a CRM source system to be registered as an approved upstream data provider.  \nRegistering a CRM source system establishes it as a recognised origin for client data and enables downstream ingestion, mapping, matching, and lineage tracking.\n\nThe registration process captures the minimum information required to uniquely identify the CRM system and treat it as a governed source within the platform. Once registered, the CRM source system can be referenced consistently by ingestion and processing workflows.\n\n## Acceptance Criteria\n- **Given** a CRM source system has not previously been registered  \n  **When** a data operations user registers the CRM source system  \n  **Then** the system is stored as a recognised and active source\n\n- **Given** a CRM source system is registered  \n  **When** downstream processes reference the source  \n  **Then** the system is identifiable as the origin of ingested client data\n\n- **Given** an attempt is made to register a CRM source system with missing or invalid identifying information  \n  **When** the registration is submitted  \n  **Then** the registration is rejected with a clear validation error"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-02.json =====
{
  "story_id": "ST-02",
  "slug": "ST-02_register_kyc_source",
  "source_path": "docs/mission_destination/stories/ST-02_register_kyc_source.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-02",
    "feature": "FT-01",
    "name": "Register KYC source",
    "description": "Register KYC system.\n",
    "acceptance_criteria": [
      "Connection ok",
      "Schema ok"
    ],
    "overall_status": "Planned",
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "<auto>"
  },
  "body_markdown": "# Register KYC Source System\n\n## Statement\nAs a compliance operations user, I want to register a KYC source system so that client due-diligence data can be ingested and governed with clear provenance.\n\n## Description\nThe platform must support the registration of KYC source systems as approved providers of compliance and due-diligence data.  \nRegistering a KYC source system ensures that KYC data entering the platform can be traced back to its originating system and treated according to governance and compliance requirements.\n\nOnce registered, the KYC source system can be referenced by ingestion, enrichment, and profile assembly processes.\n\n## Acceptance Criteria\n- **Given** a KYC source system has not previously been registered  \n  **When** a compliance operations user registers the KYC source system  \n  **Then** the system is stored as a recognised and active KYC data source\n\n- **Given** a KYC source system is registered  \n  **When** KYC data is ingested  \n  **Then** the data is associated with the registered source system\n\n- **Given** invalid or incomplete registration details are provided  \n  **When** the registration is attempted  \n  **Then** the registration is rejected with a clear error message"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-03.json =====
{
  "story_id": "ST-03",
  "slug": "ST-03_map_identity_fields",
  "source_path": "docs/mission_destination/stories/ST-03_map_identity_fields.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-03",
    "feature": "FT-02",
    "name": "Map identity fields",
    "description": "Map core identity fields.\n",
    "acceptance_criteria": [
      "Fields mapped",
      "Types correct"
    ],
    "overall_status": "In Progress",
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "fail",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "2025-12-21T16:19:34+00:00"
  },
  "body_markdown": "# Map Identity Fields\n\n## Statement\nAs a data operations user, I want to map identity fields so that equivalent client attributes from different source systems can be normalised and compared consistently.\n\n## Description\nClient identity data may be provided by multiple source systems using different field names and structures.  \nThe platform must support mapping source-specific identity fields to a canonical representation so that identity information can be processed consistently across the platform.\n\nMapped identity fields form the basis for downstream matching, profile assembly, and lineage reporting.\n\n## Acceptance Criteria\n- **Given** identity fields exist in a source system  \n  **When** identity field mappings are defined  \n  **Then** the fields are mapped to the platformâ€™s canonical identity model\n\n- **Given** identity mappings are defined  \n  **When** client data is ingested  \n  **Then** identity values are normalised according to the mappings\n\n- **Given** a required identity field is unmapped  \n  **When** identity processing is attempted  \n  **Then** the issue is reported clearly"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-04.json =====
{
  "story_id": "ST-04",
  "slug": "ST-04_map_identifiers",
  "source_path": "docs/mission_destination/stories/ST-04_map_identifiers.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-04",
    "feature": "FT-02",
    "name": "Map identifiers",
    "description": "Map identifiers.\n",
    "acceptance_criteria": [
      "ID mapping valid"
    ],
    "overall_status": "In Progress",
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "fail",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "2025-12-21T16:19:34+00:00"
  },
  "body_markdown": "# Map Identifiers\n\n## Statement\nAs a data operations user, I want to map client identifiers so that records referring to the same real-world entity can be reliably linked across systems.\n\n## Description\nDifferent source systems may represent client identifiers using different formats or naming conventions.  \nThe platform must support mapping these identifiers to a canonical identifier model so that they can be compared and used reliably for matching and consolidation.\n\nCorrect identifier mapping is essential for accurate client matching and profile assembly.\n\n## Acceptance Criteria\n- **Given** identifier fields exist in a source system  \n  **When** identifier mappings are defined  \n  **Then** identifiers are mapped to the canonical identifier model\n\n- **Given** identifier mappings are in place  \n  **When** client records are processed  \n  **Then** identifiers are available for matching logic\n\n- **Given** an identifier required for matching is missing or unmapped  \n  **When** matching is attempted  \n  **Then** the issue is surfaced clearly for investigation"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-05.json =====
{
  "story_id": "ST-05",
  "slug": "ST-05_bulk_load_crm",
  "source_path": "docs/mission_destination/stories/ST-05_bulk_load_crm.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-05",
    "feature": "FT-03",
    "name": "Bulk load CRM",
    "description": "Initial CRM load.\n",
    "acceptance_criteria": [
      "Records loaded"
    ],
    "overall_status": "Complete",
    "testing_status": "pass",
    "halo_adherence": "pass",
    "guardrail_adherence": "pass",
    "code_quality_adherence": "pass",
    "security_policy_adherence": "pass",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "2025-12-22T19:26:52+00:00"
  },
  "body_markdown": "# Ingest CRM Data\n\n## Statement\nAs a data operations user, I want to bulk load CRM data so that existing client records can be ingested into the platform efficiently and consistently.\n\n## Description\nThe platform must support bulk ingestion of client data from a registered CRM source system.  \nThis capability enables an initial or repeat load of CRM records into the platform using a controlled and repeatable process.\n\nBulk loading creates persisted client records that can subsequently be mapped, matched, and assembled into client profiles. The same ingestion logic must be usable for automated testing and operational execution.\n\n## Acceptance Criteria\n- **Given** a CRM source system is registered  \n  **When** a bulk load of CRM data is executed  \n  **Then** client records are ingested and persisted successfully\n\n- **Given** a bulk load is executed  \n  **When** individual records fail validation  \n  **Then** valid records are persisted and invalid records are reported clearly\n\n- **Given** the bulk load process completes  \n  **When** downstream processes run  \n  **Then** the ingested CRM records are available for mapping and matching"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-06.json =====
{
  "story_id": "ST-06",
  "slug": "ST-06_bulk_load_kyc",
  "source_path": "docs/mission_destination/stories/ST-06_bulk_load_kyc.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-06",
    "feature": "FT-03",
    "name": "Bulk load KYC",
    "description": "Initial KYC load.\n",
    "acceptance_criteria": [
      "Records loaded"
    ],
    "overall_status": "Planned",
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "<auto>"
  },
  "body_markdown": "# Ingest KYC Data\n\n## Statement\nAs a compliance operations user, I want KYC data to be ingested from approved source systems so that client due-diligence information is available for review and downstream processing.\n\n## Description\nThe platform must support ingestion of KYC data from registered KYC source systems.  \nIngested KYC data should be persisted in a controlled manner and associated with the originating source system to ensure provenance and auditability.\n\nOnce ingested, KYC data can be used for client enrichment, profile assembly, and compliance review processes.\n\n## Acceptance Criteria\n- **Given** a KYC source system is registered  \n  **When** KYC data is ingested  \n  **Then** the data is persisted successfully and linked to the source system\n\n- **Given** ingested KYC data  \n  **When** downstream processing is performed  \n  **Then** the data is available for enrichment and profile assembly\n\n- **Given** invalid KYC records are encountered  \n  **When** ingestion is attempted  \n  **Then** valid records are stored and invalid records are reported clearly"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-07.json =====
{
  "story_id": "ST-07",
  "slug": "ST-07_detect_upstream_deltas",
  "source_path": "docs/mission_destination/stories/ST-07_detect_upstream_deltas.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-07",
    "feature": "FT-04",
    "name": "Detect upstream deltas",
    "description": "Detect deltas.\n",
    "acceptance_criteria": [
      "Changes detected"
    ],
    "overall_status": "Planned",
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "<auto>"
  },
  "body_markdown": "# Detect Upstream Deltas\n\n## Statement\nAs a data operations user, I want the platform to detect upstream data changes so that only new or modified client records are processed incrementally.\n\n## Description\nUpstream source systems may deliver repeated data extracts containing a mixture of unchanged, new, updated, or removed records.  \nThe platform must be able to compare incoming data against previously ingested data to detect meaningful deltas.\n\nDetecting upstream deltas enables efficient incremental processing and prevents unnecessary reprocessing of unchanged client records.\n\n## Acceptance Criteria\n- **Given** a previous ingestion has occurred  \n  **When** new data is received from the same source system  \n  **Then** the platform identifies new, changed, and unchanged records\n\n- **Given** upstream records have not changed  \n  **When** delta detection runs  \n  **Then** those records are marked as unchanged\n\n- **Given** records are new or updated  \n  **When** delta detection completes  \n  **Then** they are flagged for downstream processing"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-08.json =====
{
  "story_id": "ST-08",
  "slug": "ST-08_apply_deltas",
  "source_path": "docs/mission_destination/stories/ST-08_apply_deltas.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-08",
    "feature": "FT-04",
    "name": "Apply deltas",
    "description": "Apply detected deltas.\n",
    "acceptance_criteria": [
      "Deltas applied"
    ],
    "overall_status": "Planned",
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "<auto>"
  },
  "body_markdown": "# Apply Upstream Deltas\n\n## Statement\nAs a data operations user, I want detected upstream deltas to be applied so that the platform state remains aligned with source system changes.\n\n## Description\nOnce upstream deltas have been identified, the platform must apply those changes to its internal representation of client data.  \nApplying deltas ensures that new records are added, updated records are amended, and removed records are handled appropriately.\n\nThis process keeps the platformâ€™s client data synchronised with upstream systems without requiring full reloads.\n\n## Acceptance Criteria\n- **Given** upstream deltas have been detected  \n  **When** delta application is executed  \n  **Then** new and updated records are applied to the platform state\n\n- **Given** records are marked as removed  \n  **When** deltas are applied  \n  **Then** the platform state reflects the removal according to defined rules\n\n- **Given** no deltas are detected  \n  **When** delta application runs  \n  **Then** no changes are applied"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-09.json =====
{
  "story_id": "ST-09",
  "slug": "ST-09_match_by_tax_id",
  "source_path": "docs/mission_destination/stories/ST-09_match_by_tax_id.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-09",
    "feature": "FT-05",
    "name": "Match by tax ID",
    "description": "Exact match by tax ID.\n",
    "acceptance_criteria": [
      "Matches correct"
    ],
    "overall_status": "Planned",
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "<auto>"
  },
  "body_markdown": "# Match Clients by Tax Identifier\n\n## Statement\nAs a compliance operations user, I want clients to be matched by tax identifier so that duplicate or related client records can be identified accurately.\n\n## Description\nClients may appear in multiple source systems with different representations.  \nThe platform must support matching client records using tax identifiers as a strong matching attribute.\n\nSuccessful matching enables consolidation of records that refer to the same real-world entity and reduces duplication in client profiles.\n\n## Acceptance Criteria\n- **Given** multiple client records exist  \n  **When** matching by tax identifier is performed  \n  **Then** records with the same tax identifier are identified as potential matches\n\n- **Given** a tax identifier match is identified  \n  **When** client profiles are assembled  \n  **Then** matched records are treated as referring to the same client\n\n- **Given** a tax identifier is missing or invalid  \n  **When** matching is attempted  \n  **Then** the limitation is reported clearly"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-10.json =====
{
  "story_id": "ST-10",
  "slug": "ST-10_match_by_registration_number",
  "source_path": "docs/mission_destination/stories/ST-10_match_by_registration_number.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-10",
    "feature": "FT-05",
    "name": "Match by registration number",
    "description": "Exact match.\n",
    "acceptance_criteria": [
      "Matches correct"
    ],
    "overall_status": "Planned",
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "<auto>"
  },
  "body_markdown": "# Match Clients by Registration Number\n\n## Statement\nAs a compliance operations user, I want clients to be matched by registration number so that records referring to the same legal entity can be identified reliably.\n\n## Description\nClient records originating from different systems may refer to the same legal entity using a common registration number.  \nThe platform must support matching client records based on registration number as a strong identifier.\n\nMatching by registration number complements other matching strategies and improves the accuracy of client consolidation.\n\n## Acceptance Criteria\n- **Given** multiple client records exist  \n  **When** matching by registration number is performed  \n  **Then** records with the same registration number are identified as potential matches\n\n- **Given** registration number matches are identified  \n  **When** downstream processing occurs  \n  **Then** those records are treated as referring to the same entity\n\n- **Given** a registration number is missing or invalid  \n  **When** matching is attempted  \n  **Then** the limitation is reported clearly"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-11.json =====
{
  "story_id": "ST-11",
  "slug": "ST-11_fuzzy_name_match",
  "source_path": "docs/mission_destination/stories/ST-11_fuzzy_name_match.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-11",
    "feature": "FT-06",
    "name": "Fuzzy name match",
    "description": "Implement fuzzy name.\n",
    "acceptance_criteria": [
      "Similarity score valid"
    ],
    "overall_status": "Planned",
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "<auto>"
  },
  "body_markdown": "# Drill Down Lineage\n\n## Statement\nAs a compliance or audit user, I want to drill down into lineage details so that I can inspect how specific data elements were produced.\n\n## Description\nHigh-level lineage views may not provide sufficient detail for investigation or audit purposes.  \nThe platform must support drilling down into lineage information, allowing users or systems to navigate from high-level lineage to detailed events and attributes.\n\nDrill-down capability enables deeper understanding of data provenance and processing history.\n\n## Acceptance Criteria\n- **Given** lineage information is available  \n  **When** a drill-down is requested  \n  **Then** more detailed lineage information is returned\n\n- **Given** detailed lineage is displayed  \n  **When** it is inspected  \n  **Then** it clearly shows contributing sources and transformations\n\n- **Given** no further detail exists  \n  **When** a drill-down is attempted  \n  **Then** this is communicated clearly"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-12.json =====
{
  "story_id": "ST-12",
  "slug": "ST-12_attribute_confidence",
  "source_path": "docs/mission_destination/stories/ST-12_attribute_confidence.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-12",
    "feature": "FT-06",
    "name": "Attribute confidence",
    "description": "Compute confidence.\n",
    "acceptance_criteria": [
      "Confidence computed"
    ],
    "overall_status": "Planned",
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "<auto>"
  },
  "body_markdown": "# Fuzzy Name Match\n\n## Statement\nAs a compliance operations user, I want client records to be matched using fuzzy name matching so that potential duplicates can be identified even when names are not identical.\n\n## Description\nClient names may be represented inconsistently across source systems due to spelling variations, abbreviations, or formatting differences.  \nThe platform must support fuzzy name matching to identify potential matches where exact matching is insufficient.\n\nFuzzy name matching complements deterministic matching strategies and supports improved identification of related client records.\n\n## Acceptance Criteria\n- **Given** multiple client records exist with similar names  \n  **When** fuzzy name matching is performed  \n  **Then** records with similar names are identified as potential matches\n\n- **Given** fuzzy name matches are identified  \n  **When** downstream processing occurs  \n  **Then** the records are flagged for consolidation or further review\n\n- **Given** names are dissimilar beyond acceptable thresholds  \n  **When** fuzzy matching is attempted  \n  **Then** no match is identified"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-13.json =====
{
  "story_id": "ST-13",
  "slug": "ST-13_merge_identity",
  "source_path": "docs/mission_destination/stories/ST-13_merge_identity.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-13",
    "feature": "FT-07",
    "name": "Merge identity",
    "description": "Merge identity attributes.\n",
    "acceptance_criteria": [
      "Conflicts resolved"
    ],
    "overall_status": "Planned",
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "<auto>"
  },
  "body_markdown": "# Merge Identity\n\n## Statement\nAs a compliance operations user, I want identity information to be merged so that client profiles reflect a single, coherent representation of the client.\n\n## Description\nWhen client records are identified as referring to the same real-world entity, identity attributes from those records must be merged.  \nThe platform must combine identity information in a controlled manner, resolving conflicts according to defined rules.\n\nMerging identity information enables accurate and consistent client profiles.\n\n## Acceptance Criteria\n- **Given** client records are identified as matches  \n  **When** identity merge is performed  \n  **Then** identity attributes are combined into a single representation\n\n- **Given** conflicting identity attributes exist  \n  **When** a merge occurs  \n  **Then** conflicts are resolved according to defined rules\n\n- **Given** identity merge cannot be completed  \n  **When** the process runs  \n  **Then** the issue is reported clearly"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-14.json =====
{
  "story_id": "ST-14",
  "slug": "ST-14_merge_addresses",
  "source_path": "docs/mission_destination/stories/ST-14_merge_addresses.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-14",
    "feature": "FT-07",
    "name": "Merge addresses",
    "description": "Merge address attributes.\n",
    "acceptance_criteria": [
      "Address selected"
    ],
    "overall_status": "Planned",
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "<auto>"
  },
  "body_markdown": "# Merge Addresses\n\n## Statement\nAs a compliance or operations user, I want client address information to be merged so that address data is consistent and complete within the client profile.\n\n## Description\nClients may have multiple address records originating from different source systems.  \nThe platform must merge address information when records are matched, ensuring that valid and relevant addresses are retained.\n\nAddress merging supports accurate client profiling and downstream operational use.\n\n## Acceptance Criteria\n- **Given** matched client records contain address information  \n  **When** address merging is performed  \n  **Then** addresses are combined into a unified set\n\n- **Given** duplicate or conflicting addresses exist  \n  **When** merging occurs  \n  **Then** duplicates are handled and conflicts resolved appropriately\n\n- **Given** address data is incomplete  \n  **When** merging is attempted  \n  **Then** available address information is retained"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-15.json =====
{
  "story_id": "ST-15",
  "slug": "ST-15_record_lineage",
  "source_path": "docs/mission_destination/stories/ST-15_record_lineage.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-15",
    "feature": "FT-07",
    "name": "Record lineage",
    "description": "Lineage for merges.\n",
    "acceptance_criteria": [
      "Lineage stored"
    ],
    "overall_status": "Planned",
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "<auto>"
  },
  "body_markdown": "# Record Lineage\n\n## Statement\nAs a compliance or audit user, I want lineage to be recorded so that the origin and transformation of client data can be traced over time.\n\n## Description\nAs client data is ingested, matched, merged, and assembled, the platform must record lineage information describing how the data was produced.  \nRecorded lineage provides the foundation for auditability, transparency, and trust in client profiles.\n\nLineage records must be associated with the relevant data and processing events.\n\n## Acceptance Criteria\n- **Given** client data is processed  \n  **When** processing occurs  \n  **Then** lineage information is recorded for the relevant events\n\n- **Given** lineage has been recorded  \n  **When** it is queried  \n  **Then** it accurately reflects data origins and transformations\n\n- **Given** lineage recording fails  \n  **When** processing continues  \n  **Then** the failure is reported clearly"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-16.json =====
{
  "story_id": "ST-16",
  "slug": "ST-16_build_index",
  "source_path": "docs/mission_destination/stories/ST-16_build_index.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-16",
    "feature": "FT-08",
    "name": "Build index",
    "description": "Build search index.\n",
    "acceptance_criteria": [
      "Index built"
    ],
    "overall_status": "Planned",
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "<auto>"
  },
  "body_markdown": "# Build Index\n\n## Statement\nAs an operations user, I want client data to be indexed so that client information can be searched and retrieved efficiently.\n\n## Description\nTo support fast and reliable search, the platform must build and maintain indexes over relevant client data.  \nIndexes are derived from ingested and assembled client information and are optimised for common search and retrieval patterns.\n\nIndexing enables responsive search and supports downstream operational use of the platform.\n\n## Acceptance Criteria\n- **Given** client data exists  \n  **When** index building is executed  \n  **Then** search indexes are created successfully\n\n- **Given** client data changes  \n  **When** indexes are rebuilt or updated  \n  **Then** indexes reflect the latest data state\n\n- **Given** indexing fails  \n  **When** index construction is attempted  \n  **Then** the failure is reported clearly"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-17.json =====
{
  "story_id": "ST-17",
  "slug": "ST-17_normalise_search_fields",
  "source_path": "docs/mission_destination/stories/ST-17_normalise_search_fields.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-17",
    "feature": "FT-08",
    "name": "Normalise search fields",
    "description": "Normalise fields.\n",
    "acceptance_criteria": [
      "Fields normalised"
    ],
    "overall_status": "Planned",
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "<auto>"
  },
  "body_markdown": "# Normalise Search Fields\n\n## Statement\nAs an operations user, I want search fields to be normalised so that client data can be searched consistently regardless of source formatting.\n\n## Description\nClient data may be represented differently across source systems, including variations in casing, formatting, and structure.  \nThe platform must normalise search-relevant fields into a consistent representation suitable for indexing and querying.\n\nNormalised search fields improve search accuracy and user experience.\n\n## Acceptance Criteria\n- **Given** client data contains searchable attributes  \n  **When** normalisation is performed  \n  **Then** search fields are transformed into a consistent format\n\n- **Given** normalised search fields  \n  **When** indexing occurs  \n  **Then** the normalised values are used\n\n- **Given** a field cannot be normalised  \n  **When** processing occurs  \n  **Then** the limitation is reported clearly"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-18.json =====
{
  "story_id": "ST-18",
  "slug": "ST-18_fuzzy_search_queries",
  "source_path": "docs/mission_destination/stories/ST-18_fuzzy_search_queries.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-18",
    "feature": "FT-09",
    "name": "Fuzzy search queries",
    "description": "Fuzzy queries.\n",
    "acceptance_criteria": [
      "Ranked results"
    ],
    "overall_status": "Planned",
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "<auto>"
  },
  "body_markdown": "# Fuzzy Search Queries\n\n## Statement\nAs an operations or compliance user, I want to perform fuzzy search queries so that I can find clients even when search terms are approximate or incomplete.\n\n## Description\nExact search queries may not always return relevant results due to spelling variations or incomplete information.  \nThe platform must support fuzzy search queries that tolerate minor differences between search input and indexed data.\n\nFuzzy search improves usability and helps users locate client profiles more effectively.\n\n## Acceptance Criteria\n- **Given** indexed client data exists  \n  **When** a fuzzy search query is performed  \n  **Then** relevant approximate matches are returned\n\n- **Given** multiple potential matches exist  \n  **When** fuzzy search is executed  \n  **Then** all relevant results are included\n\n- **Given** no close matches exist  \n  **When** a fuzzy search is performed  \n  **Then** no results are returned clearly"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-19.json =====
{
  "story_id": "ST-19",
  "slug": "ST-19_search_ranking",
  "source_path": "docs/mission_destination/stories/ST-19_search_ranking.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-19",
    "feature": "FT-09",
    "name": "Search ranking",
    "description": "Ranking logic.\n",
    "acceptance_criteria": [
      "Correct ordering"
    ],
    "overall_status": "Planned",
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "<auto>"
  },
  "body_markdown": "# Search Ranking\n\n## Statement\nAs an operations user, I want search results to be ranked so that the most relevant client profiles appear first.\n\n## Description\nWhen multiple client profiles match a search query, the platform must rank results based on relevance.  \nRanking may consider factors such as match strength, attribute confidence, and data completeness.\n\nSearch ranking ensures that users can quickly identify the most likely relevant clients.\n\n## Acceptance Criteria\n- **Given** multiple search results are returned  \n  **When** ranking is applied  \n  **Then** results are ordered by relevance\n\n- **Given** ranking criteria change  \n  **When** search is performed  \n  **Then** result ordering reflects the updated criteria\n\n- **Given** ranking cannot be applied  \n  **When** search is executed  \n  **Then** results are returned without ranking and the issue is reported"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-20.json =====
{
  "story_id": "ST-20",
  "slug": "ST-20_assemble_base_profile",
  "source_path": "docs/mission_destination/stories/ST-20_assemble_base_profile.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-20",
    "feature": "FT-10",
    "name": "Assemble base profile",
    "overall_status": "Complete",
    "testing_status": "pass",
    "halo_adherence": "pass",
    "guardrail_adherence": "pass",
    "code_quality_adherence": "pass",
    "security_policy_adherence": "pass",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "description": "Assemble a canonical client base profile by reading existing client data\nfrom the persistent database and returning it in the shape defined by the\nInitial Logical Data Model.\n\nThis story covers read-only assembly of core client attributes only.\nNo matching, merging, enrichment, lineage computation, or quality scoring\nis performed as part of this story.\n",
    "acceptance_criteria": [
      "A client profile can be retrieved using an existing internal client identifier",
      "The returned profile conforms to the ClientProfile structure defined in the Initial Logical Data Model",
      "Core profile fields (e.g. name, email, country, identifiers, addresses) are populated from persisted data where available",
      "The profile assembly is deterministic and repeatable for the same input",
      "No matching, merging, enrichment, lineage, or quality logic is applied"
    ],
    "guardrails": {
      "G03": {
        "ldm_contract": "ldm://client_profile/1.0.0",
        "artifact": "client_profile",
        "mode": "strict"
      }
    },
    "last_updated": "2025-12-21T21:26:23+00:00"
  },
  "body_markdown": ""
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-21.json =====
{
  "story_id": "ST-21",
  "slug": "ST-21_assemble_metadata",
  "source_path": "docs/mission_destination/stories/ST-21_assemble_metadata.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-21",
    "feature": "FT-10",
    "name": "Assemble metadata",
    "description": "Assemble metadata.\n",
    "acceptance_criteria": [
      "Metadata added"
    ],
    "overall_status": "Planned",
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "<auto>"
  },
  "body_markdown": "# Assemble Profile Metadata\n\n## Statement\nAs a compliance or operations user, I want profile metadata to be assembled so that I can assess the quality and state of a client profile.\n\n## Description\nIn addition to core client data, the platform must derive and assemble metadata about each client profile.  \nProfile metadata may include indicators such as completeness, freshness, confidence, and references to lineage or evidence.\n\nThis metadata supports informed decision-making and operational oversight of client profiles.\n\n## Acceptance Criteria\n- **Given** a client profile exists  \n  **When** metadata assembly is performed  \n  **Then** profile metadata is calculated and associated with the profile\n\n- **Given** underlying client data changes  \n  **When** metadata is reassembled  \n  **Then** metadata reflects the updated profile state\n\n- **Given** metadata cannot be fully derived  \n  **When** assembly is attempted  \n  **Then** partial metadata is recorded with clear indicators"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-22.json =====
{
  "story_id": "ST-22",
  "slug": "ST-22_expose_lineage",
  "source_path": "docs/mission_destination/stories/ST-22_expose_lineage.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-22",
    "feature": "FT-11",
    "name": "Expose lineage",
    "description": "Lineage display.\n",
    "acceptance_criteria": [
      "Lineage visible"
    ],
    "overall_status": "Planned",
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "<auto>"
  },
  "body_markdown": "# Expose Lineage\n\n## Statement\nAs a compliance or audit user, I want lineage information to be exposed so that downstream systems and users can understand how client data was derived.\n\n## Description\nThe platform must make data lineage information available through a controlled interface.  \nExposed lineage describes the origin of data, the transformations applied, and the processes involved in producing client profiles.\n\nExposing lineage enables transparency, auditability, and integration with downstream tools.\n\n## Acceptance Criteria\n- **Given** lineage information exists  \n  **When** lineage is requested  \n  **Then** the information is returned successfully\n\n- **Given** lineage is exposed  \n  **When** it is consumed  \n  **Then** it accurately reflects source systems and transformations\n\n- **Given** lineage is unavailable for a request  \n  **When** exposure is attempted  \n  **Then** this is indicated clearly"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-23.json =====
{
  "story_id": "ST-23",
  "slug": "ST-23_drill-down_lineage",
  "source_path": "docs/mission_destination/stories/ST-23_drill-down_lineage.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-23",
    "feature": "FT-11",
    "name": "Drill-down lineage",
    "description": "Drill-down.\n",
    "acceptance_criteria": [
      "Source-level detail"
    ],
    "overall_status": "Planned",
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "<auto>"
  },
  "body_markdown": "# Drill Down Lineage\n\n## Statement\nAs a compliance or audit user, I want to drill down into lineage details so that I can inspect how specific data elements were produced.\n\n## Description\nHigh-level lineage views may not provide sufficient detail for investigation or audit purposes.  \nThe platform must support drilling down into lineage information, allowing users or systems to navigate from high-level lineage to detailed events and attributes.\n\nDrill-down capability enables deeper understanding of data provenance and processing history.\n\n## Acceptance Criteria\n- **Given** lineage information is available  \n  **When** a drill-down is requested  \n  **Then** more detailed lineage information is returned\n\n- **Given** detailed lineage is displayed  \n  **When** it is inspected  \n  **Then** it clearly shows contributing sources and transformations\n\n- **Given** no further detail exists  \n  **When** a drill-down is attempted  \n  **Then** this is communicated clearly"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-24.json =====
{
  "story_id": "ST-24",
  "slug": "ST-24_flag_conflicts",
  "source_path": "docs/mission_destination/stories/ST-24_flag_conflicts.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-24",
    "feature": "FT-12",
    "name": "Flag conflicts",
    "description": "Conflict flags.\n",
    "acceptance_criteria": [
      "Flags correct"
    ],
    "overall_status": "Planned",
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "<auto>"
  },
  "body_markdown": "# Flag Conflicts\n\n## Statement\nAs a compliance or operations user, I want data conflicts to be flagged so that inconsistencies in client information can be identified and addressed.\n\n## Description\nWhen client data from multiple sources is merged or assembled, conflicts may arise between attributes such as identifiers, names, or addresses.  \nThe platform must detect and flag these conflicts so that they are visible for review and resolution.\n\nFlagging conflicts supports data quality management and prevents silent inconsistencies in client profiles.\n\n## Acceptance Criteria\n- **Given** conflicting client attributes are detected  \n  **When** profile processing occurs  \n  **Then** the conflicts are flagged clearly\n\n- **Given** flagged conflicts exist  \n  **When** a client profile is reviewed  \n  **Then** the conflicts are visible to the user\n\n- **Given** no conflicts are present  \n  **When** processing occurs  \n  **Then** no conflict flags are created"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-25.json =====
{
  "story_id": "ST-25",
  "slug": "ST-25_show_merge_logic",
  "source_path": "docs/mission_destination/stories/ST-25_show_merge_logic.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-25",
    "feature": "FT-12",
    "name": "Show merge logic",
    "description": "Show logic.\n",
    "acceptance_criteria": [
      "Logic displayed"
    ],
    "overall_status": "Planned",
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "<auto>"
  },
  "body_markdown": "# Show Merge Logic\n\n## Statement\nAs a compliance or audit user, I want to understand how merge decisions were made so that client data consolidation is transparent.\n\n## Description\nWhen client data is merged, the platform applies rules and logic to determine which values are retained.  \nThe platform must expose the merge logic applied to client attributes so that users can understand why specific values were chosen.\n\nShowing merge logic supports auditability, trust, and investigation of client profile outcomes.\n\n## Acceptance Criteria\n- **Given** client attributes have been merged  \n  **When** merge logic is requested  \n  **Then** the applied rules and outcomes are displayed clearly\n\n- **Given** merge logic is displayed  \n  **When** it is reviewed  \n  **Then** it explains why specific values were retained\n\n- **Given** merge logic cannot be determined  \n  **When** it is requested  \n  **Then** this is indicated clearly"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-26.json =====
{
  "story_id": "ST-26",
  "slug": "ST-26_store_lineage_history",
  "source_path": "docs/mission_destination/stories/ST-26_store_lineage_history.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-26",
    "feature": "FT-13",
    "name": "Store lineage history",
    "description": "Store history.\n",
    "acceptance_criteria": [
      "History stored"
    ],
    "overall_status": "Planned",
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "<auto>"
  },
  "body_markdown": "# Store Lineage History\n\n## Statement\nAs a compliance or audit user, I want lineage history to be stored so that changes to client data can be traced over time.\n\n## Description\nClient data and profiles evolve as new data is ingested and processed.  \nThe platform must store lineage history so that past states and transformations of client data can be reviewed retrospectively.\n\nStoring lineage history enables audit, investigation, and historical analysis.\n\n## Acceptance Criteria\n- **Given** client data is processed  \n  **When** lineage events occur  \n  **Then** lineage history is stored persistently\n\n- **Given** lineage history exists  \n  **When** it is requested  \n  **Then** historical lineage events can be retrieved\n\n- **Given** lineage history storage fails  \n  **When** processing continues  \n  **Then** the failure is reported clearly"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-27.json =====
{
  "story_id": "ST-27",
  "slug": "ST-27_timestamp_lineage",
  "source_path": "docs/mission_destination/stories/ST-27_timestamp_lineage.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-27",
    "feature": "FT-13",
    "name": "Timestamp lineage",
    "description": "Timestamp entries.\n",
    "acceptance_criteria": [
      "Timestamps correct"
    ],
    "overall_status": "Planned",
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "<auto>"
  },
  "body_markdown": "# Timestamp Lineage\n\n## Statement\nAs a compliance or audit user, I want lineage events to be timestamped so that I can understand when client data changes occurred.\n\n## Description\nTo support accurate audit and investigation, lineage events must include timing information.  \nThe platform must record timestamps for lineage events, enabling users to understand the sequence and timing of data changes.\n\nTimestamped lineage supports chronological analysis of client data evolution.\n\n## Acceptance Criteria\n- **Given** lineage events are recorded  \n  **When** they are stored  \n  **Then** each event includes an accurate timestamp\n\n- **Given** timestamped lineage exists  \n  **When** it is reviewed  \n  **Then** events can be ordered chronologically\n\n- **Given** a timestamp cannot be recorded  \n  **When** an event occurs  \n  **Then** the issue is reported clearly"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-28.json =====
{
  "story_id": "ST-28",
  "slug": "ST-28_compute_freshness",
  "source_path": "docs/mission_destination/stories/ST-28_compute_freshness.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-28",
    "feature": "FT-14",
    "name": "Compute freshness",
    "description": "Freshness score.\n",
    "acceptance_criteria": [
      "Score correct"
    ],
    "overall_status": "Planned",
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "<auto>"
  },
  "body_markdown": "# Compute Freshness\n\n## Statement\nAs a compliance or operations user, I want data freshness to be computed so that I can assess how up to date client information is.\n\n## Description\nClient data may become stale as time passes without updates from source systems.  \nThe platform must compute freshness indicators for client data based on timestamps, update frequency, or source characteristics.\n\nFreshness indicators support informed decision-making and data quality assessment.\n\n## Acceptance Criteria\n- **Given** client data exists  \n  **When** freshness computation is performed  \n  **Then** freshness indicators are calculated for relevant data\n\n- **Given** underlying data is updated  \n  **When** freshness is recomputed  \n  **Then** indicators reflect the latest state\n\n- **Given** freshness cannot be determined  \n  **When** computation is attempted  \n  **Then** this is indicated clearly"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-29.json =====
{
  "story_id": "ST-29",
  "slug": "ST-29_compute_completeness",
  "source_path": "docs/mission_destination/stories/ST-29_compute_completeness.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-29",
    "feature": "FT-14",
    "name": "Compute completeness",
    "description": "Completeness.\n",
    "acceptance_criteria": [
      "Completeness correct"
    ],
    "overall_status": "Planned",
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "<auto>"
  },
  "body_markdown": "# Compute Completeness\n\n## Statement\nAs a compliance or operations user, I want data completeness to be computed so that I can assess whether client profiles contain sufficient information.\n\n## Description\nClient profiles may be partially populated depending on available source data.  \nThe platform must compute completeness indicators that describe how fully populated a client profile is relative to expected attributes.\n\nCompleteness indicators support data quality monitoring and informed operational decision-making.\n\n## Acceptance Criteria\n- **Given** a client profile exists  \n  **When** completeness is computed  \n  **Then** completeness indicators are calculated for the profile\n\n- **Given** underlying client data changes  \n  **When** completeness is recomputed  \n  **Then** indicators reflect the updated profile state\n\n- **Given** completeness cannot be fully determined  \n  **When** computation is attempted  \n  **Then** partial completeness is recorded with clear indicators"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-30.json =====
{
  "story_id": "ST-30",
  "slug": "ST-30_audit_ingestion",
  "source_path": "docs/mission_destination/stories/ST-30_audit_ingestion.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-30",
    "feature": "FT-15",
    "name": "Audit ingestion",
    "description": "Audit ingestion.\n",
    "acceptance_criteria": [
      "Audit entries"
    ],
    "overall_status": "Planned",
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "<auto>"
  },
  "body_markdown": "# Audit Ingestion\n\n## Statement\nAs a compliance or audit user, I want ingestion activity to be audited so that I can verify what data was ingested and when.\n\n## Description\nThe platform must record audit information for data ingestion activities.  \nAudit records should capture relevant details such as source system, timing, and outcomes of ingestion processes.\n\nAuditing ingestion supports regulatory compliance, investigation, and operational oversight.\n\n## Acceptance Criteria\n- **Given** data ingestion occurs  \n  **When** the process completes  \n  **Then** an audit record is created for the ingestion activity\n\n- **Given** ingestion audit records exist  \n  **When** they are requested  \n  **Then** they can be retrieved and reviewed\n\n- **Given** ingestion auditing fails  \n  **When** ingestion proceeds  \n  **Then** the failure is reported clearly"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-31.json =====
{
  "story_id": "ST-31",
  "slug": "ST-31_audit_merge",
  "source_path": "docs/mission_destination/stories/ST-31_audit_merge.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-31",
    "feature": "FT-15",
    "name": "Audit merge",
    "description": "Audit merge.\n",
    "acceptance_criteria": [
      "Audit recorded"
    ],
    "overall_status": "Planned",
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "<auto>"
  },
  "body_markdown": "# Audit Merge\n\n## Statement\nAs a compliance or audit user, I want merge activity to be audited so that I can understand how client records were consolidated.\n\n## Description\nWhen client records are merged, the platform must record audit information describing the merge activity.  \nAudit records should capture which records were merged, when the merge occurred, and the outcome.\n\nAuditing merge activity supports transparency, investigation, and regulatory compliance.\n\n## Acceptance Criteria\n- **Given** client records are merged  \n  **When** the merge completes  \n  **Then** an audit record is created for the merge activity\n\n- **Given** merge audit records exist  \n  **When** they are requested  \n  **Then** they can be retrieved and reviewed\n\n- **Given** merge auditing fails  \n  **When** merging proceeds  \n  **Then** the failure is reported clearly"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-32.json =====
{
  "story_id": "ST-32",
  "slug": "ST-32_search_api_basic",
  "source_path": "docs/mission_destination/stories/ST-32_search_api_basic.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-32",
    "feature": "FT-16",
    "name": "Search API basic",
    "description": "Search endpoint.\n",
    "acceptance_criteria": [
      "JSON response"
    ],
    "overall_status": "Planned",
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "<auto>"
  },
  "body_markdown": "# Search API (Basic)\n\n## Statement\nAs an application or operations user, I want a basic search API so that client profiles can be retrieved programmatically.\n\n## Description\nThe platform must expose a basic search API that allows clients to be searched using common criteria.  \nThe API provides programmatic access to search capabilities and supports integration with downstream applications and user interfaces.\n\nThe basic search API focuses on core search functionality without advanced ranking or tuning.\n\n## Acceptance Criteria\n- **Given** client profiles exist  \n  **When** the basic search API is called with valid criteria  \n  **Then** matching client profiles are returned\n\n- **Given** no profiles match the criteria  \n  **When** the API is called  \n  **Then** an empty result set is returned\n\n- **Given** invalid search parameters are provided  \n  **When** the API is called  \n  **Then** a clear error response is returned"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-33.json =====
{
  "story_id": "ST-33",
  "slug": "ST-33_search_api_ranking",
  "source_path": "docs/mission_destination/stories/ST-33_search_api_ranking.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-33",
    "feature": "FT-16",
    "name": "Search API ranking",
    "description": "Ranking via API.\n",
    "acceptance_criteria": [
      "Ranked results"
    ],
    "overall_status": "Planned",
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "<auto>"
  },
  "body_markdown": "# Search API (Ranking)\n\n## Statement\nAs an application or operations user, I want the search API to return ranked results so that the most relevant client profiles are prioritised.\n\n## Description\nBuilding on the basic search API, the platform must support ranked search results.  \nRanking logic orders results based on relevance criteria such as match strength, confidence, or completeness.\n\nRanked search improves usability and effectiveness for both users and integrated systems.\n\n## Acceptance Criteria\n- **Given** multiple search results are returned  \n  **When** ranked search is performed  \n  **Then** results are ordered by relevance\n\n- **Given** ranking criteria are applied  \n  **When** the search API is called  \n  **Then** results reflect the ranking logic\n\n- **Given** ranking cannot be applied  \n  **When** the API is called  \n  **Then** results are returned without ranking and the limitation is reported"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-34.json =====
{
  "story_id": "ST-34",
  "slug": "ST-34_profile_api_basic",
  "source_path": "docs/mission_destination/stories/ST-34_profile_api_basic.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-34",
    "feature": "FT-17",
    "name": "Profile API basic",
    "description": "Profile endpoint.\n",
    "acceptance_criteria": [
      "Profile returned"
    ],
    "overall_status": "Planned",
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "<auto>"
  },
  "body_markdown": "# Profile API (Basic)\n\n## Statement\nAs an application or operations user, I want a basic profile API so that consolidated client profiles can be retrieved programmatically.\n\n## Description\nThe platform must expose a basic profile API that allows authorised consumers to retrieve assembled client profiles.  \nThe API provides programmatic access to the platformâ€™s consolidated view of a client and supports integration with downstream systems and user interfaces.\n\nThe basic profile API focuses on core profile retrieval without advanced metadata or lineage detail.\n\n## Acceptance Criteria\n- **Given** a client profile exists  \n  **When** the basic profile API is called with a valid identifier  \n  **Then** the client profile is returned successfully\n\n- **Given** a requested profile does not exist  \n  **When** the API is called  \n  **Then** a clear â€œnot foundâ€ response is returned\n\n- **Given** invalid request parameters are provided  \n  **When** the API is called  \n  **Then** a clear error response is returned"
}


===== FILE: app_frontend\public\missionlog\story_defs\ST-35.json =====
{
  "story_id": "ST-35",
  "slug": "ST-35_profile_api_lineage",
  "source_path": "docs/mission_destination/stories/ST-35_profile_api_lineage.md",
  "exported_at_utc": "2025-12-27T20:51:45Z",
  "front_matter": {
    "story_id": "ST-35",
    "feature": "FT-17",
    "name": "Profile API lineage",
    "description": "Lineage in API.\n",
    "acceptance_criteria": [
      "Lineage included"
    ],
    "overall_status": "Planned",
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
    "last_updated": "<auto>"
  },
  "body_markdown": "# Profile API (Lineage)\n\n## Statement\nAs a compliance or audit user, I want the profile API to expose lineage information so that I can understand how client profile data was derived.\n\n## Description\nIn addition to basic profile retrieval, the platform must support exposing lineage information through the profile API.  \nThis allows consumers to retrieve not only the client profile but also the associated lineage describing data origins and transformations.\n\nExposing lineage through the API supports transparency, auditability, and integration with governance tooling.\n\n## Acceptance Criteria\n- **Given** a client profile with recorded lineage exists  \n  **When** the profile API is called with lineage enabled  \n  **Then** the profile and associated lineage are returned\n\n- **Given** lineage information is requested  \n  **When** it is retrieved  \n  **Then** it accurately reflects data sources and processing steps\n\n- **Given** lineage is unavailable  \n  **When** the API is called  \n  **Then** this is indicated clearly in the response"
}


===== FILE: app_frontend\public\MissionSmith-M7-SingleClientView.html =====
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>MissionSmith</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <script crossorigin src="https://unpkg.com/react@18/umd/react.development.js"></script>
  <script crossorigin src="https://unpkg.com/react-dom@18/umd/react-dom.development.js"></script>
  <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>

  <style>
    :root{ --lp-border:#d9e2ea; --lp-text:#243745; }
    #launchpad .lp-actions > .lp-pill{
      appearance:none;display:inline-flex;align-items:center;justify-content:center;
      height:34px;padding:0 12px;width:132px;border-radius:999px;border:1px solid var(--lp-border);
      background:#f5f9fb;color:var(--lp-text);font-weight:600;font-size:13.5px;white-space:nowrap;
      transition:transform .06s ease,background .15s ease,border-color .15s ease;cursor:pointer;
    }
    #launchpad .lp-actions > .lp-pill:hover{ transform:translateY(-1px); background:#eef5f8; border-color:#c9d6e1; }
  </style>


  <style>
    :root{ --lp-border:#d9e2ea; --lp-text:#243745; }
    header.sticky.top-0 { background: rgba(255,255,255,.70); backdrop-filter: blur(4px); border-bottom:1px solid #e5e7eb; }
    header.sticky.top-0 > .mx-auto { max-width: 80rem; padding-left: 1rem; padding-right: 1rem; }
    header.sticky.top-0 .flex.items-center.gap-2 > button,
    header.sticky.top-0 .msx-framework-btn{
      appearance:none; display:inline-flex; align-items:center; justify-content:center;
      height:34px; padding:0 14px; min-width:220px;
      border-radius:999px; border:1px solid var(--lp-border);
      background:#f5f9fb; color:var(--lp-text); font-weight:600; font-size:13.5px; white-space:nowrap;
      transition:transform .06s ease, border-color .15s ease, background .15s ease; cursor:pointer;
    }
    header.sticky.top-0 .flex.items-center.gap-2 > button:hover,
    header.sticky.top-0 .msx-framework-btn:hover { transform:translateY(-1px); border-color:#c9d6e1; background:#eef5f8; }
    /* Teal badge gloss (if present) */
    header.sticky.top-0 .flex.items-center.gap-3 .h-7.w-7.rounded-xl{
      border-radius:9999px !important;
      background: radial-gradient(ellipse at 65% 35%, rgba(255,255,255,.22), rgba(255,255,255,0) 40%), #1ba39c !important;
      box-shadow: inset 0 0 0 1px rgba(0,0,0,.05), 0 1px 2px rgba(0,0,0,.06);
    }
  </style>

</head>
<body class="min-h-screen bg-gray-50">
  
<!-- ms-actions removed by request -->
</div>


<!-- ===== LaunchPad (functional shortcuts) ===== -->
<div id="launchpad" style="position:sticky;top:0;z-index:60;background:#fff;border-bottom:1px solid #d9e2ea;backdrop-filter:blur(4px);">
  <div class="inner" style="max-width:80rem;margin:0 auto;padding:0 1rem;">
    <div class="bar" style="display:flex;align-items:center;gap:8px;padding:10px 0;">
      <div class="lp-title" style="font-weight:700;color:#5e6b77;">LaunchPad</div>
      <div style="flex:1 1 auto;"></div>
      <div class="lp-actions" style="display:inline-flex;gap:8px;align-items:center;">
        <button onclick="try{MS_actions.generateAgents&&MS_actions.generateAgents()}catch(e){console.error(e)}" class="lp-pill">Agents</button>
        <button onclick="try{MS_actions.generateScaffold&&MS_actions.generateScaffold()}catch(e){console.error(e)}" class="lp-pill">Microservices</button>
        <button onclick="try{MS_actions.generateCICD&&MS_actions.generateCICD()}catch(e){console.error(e)}" class="lp-pill">CI/CD</button>
        <button onclick="try{MS_actions.generateDeploy&&MS_actions.generateDeploy()}catch(e){console.error(e)}" class="lp-pill">IaC</button>
        <button onclick="try{MS_actions.generatePolicies&&MS_actions.generatePolicies()}catch(e){console.error(e)}" class="lp-pill">Policies</button>
        <button onclick="try{MS_actions.generateLineage&&MS_actions.generateLineage()}catch(e){console.error(e)}" class="lp-pill">Lineage</button>
        <button onclick="(window.MS_actions&&MS_actions.generateAnalytics)?MS_actions.generateAnalytics():console.warn('Analytics handler missing')" class="lp-pill">Analytics</button>
      </div>
    </div>
  </div>
</div>

<div id="root"></div>
  <script type="text/babel" data-presets="env,react">

const { useMemo, useState, useEffect } = React;

/********************
 * CSV helpers + tests
 ********************/
const LB_RE = new RegExp("\\r\\n?|\\r", "g");
function splitLines(raw) {
  // Normalize CRLF || CR to LF, then split
  return raw.replace(LB_RE, "\n").split("\n");
}

function parseCSVSimple(text) {
  const lines = splitLines(text).filter(Boolean);
  if (lines.length < 2) return { headers: [], rows: [] };
  const headers = lines[0].split(",").map((h) => h.trim());
  const rows = lines.slice(1).map((line) => {
    const cells = line.split(",");
    const obj = {};
    headers.forEach((h, i) => (obj[h] = cells[i] ?? ""));
    return obj;
  });
  return { headers, rows };
}

// Self-tests (console)
(function runSelfTests() {
  const inputs = [
    { label: "LF", text: "a,b\\n1,2\\n3,4" },
    { label: "CRLF", text: "a,b\\r\\n1,2\\r\\n3,4" },
    { label: "CR", text: "a,b\\r1,2\\r3,4" },
  ];
  inputs.forEach(({ label, text }) => {
    const real = text
      .split("\\r\\n").join("\\r\\n")
      .split("\\n").join("\\n")
      .split("\\r").join("\\r");
    const { headers, rows } = parseCSVSimple(real
      .replace(/\\r\\n/g, "\r\n")
      .replace(/\\n/g, "\n")
      .replace(/\\r/g, "\r"));
    const ok = headers.length === 2 && rows.length === 2;
    // eslint-disable-next-line no-console
    console.log("CSV " + label + " split test: " + (ok ? "pass" : "fail"));
  });
})();

/********************
 * Initial data
 ********************/
const today = new Date().toISOString().split("T")[0];

const initialData = {
  "missionInfo": {
    "title": "M7 Single Client View",
    "sponsor": "Leon Orr",
    "owner": "Leon Orr",
    "stakeholders": "Leon Orr",
    "version": "v0.1",
    "description": "M7 Single Client View",
    "date": "2025-10-04"
  },
  "serviceConfig": {
    "default_service_name": "example-service",
    "default_backend_language": "java",
    "default_backend_framework": "spring-boot",
    "default_ui_language": "react18",
    "default_ui_framework": "nextjs",
    "default_database": "postgres",
    "default_migration_tool": "flyway",
    "default_outbox_enabled": true,
    "observability": {
      "tracing": "otel",
      "metrics": "red",
      "logs": "json",
      "otel_sampler": "parentbased_traceidratio",
      "otel_sampler_arg": 0.1
    },
    "security": {
      "authn": [
        "jwt"
      ],
      "authz": [
        "opa"
      ],
      "cors_allowlist": [
        "http://localhost:3000",
        "http://localhost:5173"
      ],
      "secrets_management": "vault",
      "image_signing": "cosign",
      "base_image_registry": "ghcr.io"
    },
    "nfr": {
      "slo": [
        {
          "name": "http_p95_ms",
          "target": 150
        },
        {
          "name": "error_rate",
          "target": "0.5%"
        },
        {
          "name": "availability",
          "target": "99.9%"
        },
        {
          "name": "throughput_rps",
          "target": ">=50"
        }
      ],
      "resilience": {
        "circuit_breaker": true,
        "retries": {
          "max": 3,
          "strategy": "exponential-jitter"
        },
        "idempotency_policy": "mutations_required",
        "graceful_shutdown_timeout_s": 20
      }
    },
    "governance": {
      "lineage": "required",
      "policy_packs": [
        "no-wildcard-iam",
        "no-plaintext-internal",
        "no-pii-in-logs",
        "signed-images-only",
        "mission-labels-required"
      ],
      "adr_required": true
    },
    "ci": {
      "gates": [
        "typecheck",
        "unit",
        "contract",
        "integration",
        "property",
        "sast",
        "sbom",
        "iac",
        "schema-compat",
        "docker-scan",
        "policy"
      ],
      "coverage_min": 0.8,
      "lint_required": true,
      "evidence_artifacts": [
        "junit.xml",
        "coverage.json",
        "conftest.json",
        "sbom.spdx.json",
        "lineage.json"
      ]
    },
    "deploy": {
      "default_strategy": "canary",
      "feature_flags": true,
      "namespace": "mission",
      "require_labels": {
        "mission/reference": true,
        "mission/theme": true,
        "mission/topic": true
      },
      "admission_policies": [
        "sigstore-verify",
        "mission-labels",
        "health-endpoints"
      ],
      "rollback": {
        "enabled": true,
        "validate_quarterly": true
      }
    },
    "ownership": {
      "owner": ""
    },
    "api": {
      "require_openapi": true,
      "contract_path": "openapi.yaml",
      "health_endpoints": [
        "/health",
        "/ready",
        "/version"
      ]
    },
    "data": {
      "golden_source_required": true,
      "openapi_tag": "x-golden-source",
      "allowed_topics": [
        "pricing",
        "counterparty",
        "orders",
        "trades"
      ]
    },
    "images": {
      "signed_only": true,
      "max_image_size_mb": 500,
      "approved_bases": [
        "ghcr.io/distroless",
        "gcr.io/distroless",
        "alpine:3"
      ]
    }
  },
  "objectives": [
    {
      "ref": "OBJ-001",
      "category": "Mission Objectives",
      "theme": "Data Integrity",
      "topic": "Golden Source",
      "codify": "API contract registry; OpenAPI refs include `x-golden-source=true`.",
      "automate": "OPA rule validates data-source tags during build.",
      "intercept": "CI fails if endpoint lacks `x-golden-source` tag.",
      "prove": "Build report confirming \u201cAll data sources validated as golden.\u201d",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Ensure all services consume and publish data only via golden-source APIs or message topics.",
      "decision": true
    },
    {
      "ref": "OBJ-002",
      "category": "Mission Objectives",
      "theme": "Automation & Delivery",
      "topic": "CI/CD Coverage",
      "codify": "`ci.yml` template required in every repo.",
      "automate": "GitHub Action executes on push and publishes artefact hash.",
      "intercept": "Pipeline missing \u2192 auto-raise issue or block merge.",
      "prove": "Successful workflow badge and artefact hash stored.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Every deployable unit must have a complete CI/CD pipeline that builds, tests, and produces a signed image.",
      "decision": true
    },
    {
      "ref": "OBJ-003",
      "category": "Mission Objectives",
      "theme": "Observability",
      "topic": "Telemetry",
      "codify": "Shared `otel-config.yaml` schema with standard field names.",
      "automate": "Build injects OpenTelemetry library and exporters.",
      "intercept": "Missing OTEL fields trigger alert in CI.",
      "prove": "Grafana dashboard shows active traces and metrics per service.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Standardise and auto-collect logs, metrics, and traces via OpenTelemetry.",
      "decision": true
    },
    {
      "ref": "OBJ-004",
      "category": "Mission Objectives",
      "theme": "Lineage & Traceability",
      "topic": "Artefact Discoverability",
      "codify": "`lineage.json` template emitted by pipeline.",
      "automate": "CI publishes lineage metadata to registry.",
      "intercept": "Missing lineage \u2192 build blocked or flagged.",
      "prove": "Lineage entry visible in OpenLineage UI.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Every artefact must be registered in the lineage registry with declared inputs and outputs.",
      "decision": true
    },
    {
      "ref": "OBJ-005",
      "category": "Mission Objectives",
      "theme": "Infrastructure as Code",
      "topic": "Declarative Systems",
      "codify": "Terraform, Rego, and Helm templates committed in repo.",
      "automate": "Terraform plan/apply and policy lint run in CI.",
      "intercept": "Missing IaC directory \u2192 CI warning.",
      "prove": "Verified `.tf` or `.rego` artefacts committed and validated.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "All infrastructure and policy must be declarative and stored as code.",
      "decision": true
    },
    {
      "ref": "OBJ-006",
      "category": "Mission Objectives",
      "theme": "Reliability",
      "topic": "Health Endpoints",
      "codify": "OpenAPI annotations define standard health contracts.",
      "automate": "CI test job queries these endpoints on every build.",
      "intercept": "Non-200 status blocks deploy.",
      "prove": "Automated test report shows uptime and response success.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Each service must expose `/health`, `/ready`, and `/version` endpoints.",
      "decision": true
    },
    {
      "ref": "OBJ-007",
      "category": "Mission Objectives",
      "theme": "Change Control",
      "topic": "Auditability",
      "codify": "Git commit metadata and versioned deployment manifests.",
      "automate": "CI annotates releases with actor and change reason.",
      "intercept": "Missing rollback metadata triggers warning.",
      "prove": "Version history and audit log linked to commit.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "All changes must be observable, reversible, and logged with human and agent attribution.",
      "decision": true
    }
  ],
  "principles": [
    {
      "ref": "PRI-001",
      "category": "Mission Principles",
      "theme": "Delivery Discipline",
      "topic": "Trunk-Based Development",
      "codify": "Branch protection rules; PR merge policy in GitHub.",
      "automate": "CI enforces merge checks and tests before commit to trunk.",
      "intercept": "Attempt to merge failing branch \u2192 PR blocked.",
      "prove": "Commit history shows <24h branch lifespan and green pipeline.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Maintain a single mainline branch; minimise long-lived feature branches.",
      "decision": true
    },
    {
      "ref": "PRI-002",
      "category": "Mission Principles",
      "theme": "Quality Assurance",
      "topic": "Evidence Before Release",
      "codify": "Release workflow requires `evidence.json` or build artefacts with test results.",
      "automate": "CI release job checks for evidence hash or signature.",
      "intercept": "Missing evidence file halts release job.",
      "prove": "Evidence artefact stored with release tag.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Deploy only when verifiable proof of readiness exists.",
      "decision": true
    },
    {
      "ref": "PRI-003",
      "category": "Mission Principles",
      "theme": "Design Integrity",
      "topic": "Everything as Code",
      "codify": "Repo structure includes `/infra`, `/policy`, `/docs` folders.",
      "automate": "Linter checks required directories and file patterns.",
      "intercept": "Missing directory \u2192 build warning or failure.",
      "prove": "Manifest of artefact types generated at build time.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "All infrastructure, policy, lineage, and documentation must be expressed as code.",
      "decision": true
    },
    {
      "ref": "PRI-004",
      "category": "Mission Principles",
      "theme": "Governance",
      "topic": "Guardrails Over Gates",
      "codify": "Rego/OPA rules define policy severity levels (`warn` vs `deny`).",
      "automate": "CI runs policy checks on each commit.",
      "intercept": "Exceeded threshold triggers issue but doesn\u2019t block build unless critical.",
      "prove": "Policy status log showing zero critical violations.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Automate compliance and quality controls without manual approval steps.",
      "decision": true
    },
    {
      "ref": "PRI-005",
      "category": "Mission Principles",
      "theme": "Automation",
      "topic": "Automate Where Evidence Exists",
      "codify": "Define measurable metrics in `mission-metrics.yaml`.",
      "automate": "CI executes tests or validations tied to those metrics.",
      "intercept": "Manual step found without automation tag \u2192 flag warning.",
      "prove": "Automated test coverage and metric dashboard.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Any measurable or testable requirement must be automated.",
      "decision": true
    },
    {
      "ref": "PRI-006",
      "category": "Mission Principles",
      "theme": "Observability",
      "topic": "Built-In Telemetry",
      "codify": "Shared instrumentation library (`otel-lib`).",
      "automate": "Static analysis ensures import of `otel-lib` or env var presence.",
      "intercept": "Missing instrumentation triggers build warning.",
      "prove": "Grafana dashboard populated automatically.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Embed observability hooks (logs, traces, metrics) in every template.",
      "decision": true
    },
    {
      "ref": "PRI-007",
      "category": "Mission Principles",
      "theme": "Stability & Reversibility",
      "topic": "Reproducible and Reversible Change",
      "codify": "Version manifests, Docker image digests, Terraform state snapshots.",
      "automate": "CI captures and archives state at build time.",
      "intercept": "Missing snapshot blocks promotion.",
      "prove": "Redeploy previous version reproduces same artefact hash.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Every artefact and deployment must be rebuildable and rollback-capable.",
      "decision": true
    }
  ],
  "guardrails": [
    {
      "ref": "GR-001",
      "category": "Mission Guardrails",
      "theme": "Logging Standards",
      "topic": "Structured JSON Logging",
      "codify": "Central `logging.jsonschema` published for all services.",
      "automate": "Linter or static analysis ensures schema compliance in CI.",
      "intercept": "CI fails if logs deviate from schema.",
      "prove": "Log sample validated against schema and included in evidence pack.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "All application logs must be structured JSON including request ID, user, and service context.",
      "decision": true
    },
    {
      "ref": "GR-002",
      "category": "Mission Guardrails",
      "theme": "Secrets Management",
      "topic": "No Hard-Coded Secrets",
      "codify": "`.secretlint.yml` or regex/entropy patterns in repo root.",
      "automate": "Secret scanner runs pre-commit and in CI.",
      "intercept": "Match found \u2192 merge blocked and issue created.",
      "prove": "CI artefact confirms \u201c0 secrets found.\u201d",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Repositories must not contain plaintext secrets or credentials.",
      "decision": true
    },
    {
      "ref": "GR-003",
      "category": "Mission Guardrails",
      "theme": "Testing Standards",
      "topic": "Automated Test Coverage",
      "codify": "Required `tests/` folder; test framework config present.",
      "automate": "CI runs test suite and reports coverage.",
      "intercept": "Test failures or missing coverage block pipeline.",
      "prove": "Test report attached to build artefacts.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Each repository must include automated unit and integration tests.",
      "decision": true
    },
    {
      "ref": "GR-004",
      "category": "Mission Guardrails",
      "theme": "API Governance",
      "topic": "Machine-Readable Contracts",
      "codify": "Presence of `openapi.yaml` or `schema.graphql`.",
      "automate": "Linter verifies schema syntax and completeness.",
      "intercept": "Missing or invalid schema \u2192 CI fails.",
      "prove": "Spec validated and linked in artefact manifest.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "All APIs must expose OpenAPI or GraphQL schema in repo root.",
      "decision": true
    },
    {
      "ref": "GR-005",
      "category": "Mission Guardrails",
      "theme": "Supply Chain Security",
      "topic": "Signed Base Images",
      "codify": "`Dockerfile` FROM statement restricted to whitelisted registries.",
      "automate": "CI verifies signature with Cosign/Sigstore.",
      "intercept": "Unsigned or unverified image blocks deployment.",
      "prove": "Signature verification log stored with image tag.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "All containers must originate from signed, approved base images.",
      "decision": true
    },
    {
      "ref": "GR-006",
      "category": "Mission Guardrails",
      "theme": "Data Lineage",
      "topic": "Source and Destination Tracking",
      "codify": "`lineage.json` or metadata annotations in code.",
      "automate": "CI publishes lineage metadata to OpenLineage registry.",
      "intercept": "Missing lineage entry triggers policy violation.",
      "prove": "Lineage visible in registry dashboard.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Every data pipeline or transformation must declare its source and destination.",
      "decision": true
    },
    {
      "ref": "GR-007",
      "category": "Mission Guardrails",
      "theme": "Operational Safety",
      "topic": "Rollback Readiness",
      "codify": "Rollback scripts or Helm history retained per environment.",
      "automate": "CI executes rollback dry-run quarterly.",
      "intercept": "Failed rollback test triggers alert.",
      "prove": "Report showing rollback simulation success.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "All deployments must have a defined and tested rollback mechanism.",
      "decision": true
    }
  ],
  "ground": [
    {
      "ref": "TOOL-001",
      "category": "Mission Tooling",
      "theme": "Source Control & Flow",
      "topic": "GitHub",
      "codify": "Repo initialised with `.github` config and branch protection rules.",
      "automate": "Enforce branch protection, required reviews, and signed commits.",
      "intercept": "PR fails if checks or reviews missing.",
      "prove": "Audit log of merges and signed commits.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Manage version control with branch protection and PR checks.",
      "decision": true
    },
    {
      "ref": "TOOL-002",
      "category": "Mission Tooling",
      "theme": "CI/CD",
      "topic": "GitHub Actions",
      "codify": "Standard `.github/workflows/ci.yml` templates.",
      "automate": "Actions triggered on push and pull requests.",
      "intercept": "Workflow failure blocks merge.",
      "prove": "CI badges and artefact hashes attached to releases.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Automate build, test, and deployment workflows.",
      "decision": true
    },
    {
      "ref": "TOOL-003",
      "category": "Mission Tooling",
      "theme": "IaC / Config",
      "topic": "Terraform",
      "codify": "`main.tf` defines environments and resources.",
      "automate": "Terraform plan/apply in pipeline.",
      "intercept": "Drift detection alerts in CI.",
      "prove": "Terraform plan output archived with build.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Provision cloud and infrastructure declaratively.",
      "decision": true
    },
    {
      "ref": "TOOL-004",
      "category": "Mission Tooling",
      "theme": "Policy Enforcement",
      "topic": "OPA / Conftest",
      "codify": "Policy packs in `/policy` folder.",
      "automate": "Conftest executes Rego policies in CI.",
      "intercept": "Violations flagged with severity.",
      "prove": "Conftest JSON output stored in build artefacts.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Enforce Mission Principles and Guardrails programmatically.",
      "decision": true
    },
    {
      "ref": "TOOL-005",
      "category": "Mission Tooling",
      "theme": "Observability",
      "topic": "OpenTelemetry + Grafana",
      "codify": "Shared `otel-config.yaml`; Grafana dashboards.",
      "automate": "Collector agents deployed automatically.",
      "intercept": "Missing OTEL data triggers alert.",
      "prove": "Dashboards display live telemetry.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Centralise logs, metrics, and traces across services.",
      "decision": true
    },
    {
      "ref": "TOOL-006",
      "category": "Mission Tooling",
      "theme": "Security / Secrets",
      "topic": "Trivy + Sigstore + Vault",
      "codify": "`trivy.yml` and Cosign key config.",
      "automate": "Trivy scan and Cosign signature in CI.",
      "intercept": "Vulnerabilities or unsigned images block deploy.",
      "prove": "Signed image logs + scan report stored.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Scan containers, sign images, and manage secrets.",
      "decision": true
    },
    {
      "ref": "TOOL-007",
      "category": "Mission Tooling",
      "theme": "Lineage & Metadata",
      "topic": "OpenLineage + Marquez",
      "codify": "`lineage.json` generated per pipeline.",
      "automate": "Pipeline publishes lineage metadata to registry.",
      "intercept": "Missing lineage raises CI warning.",
      "prove": "Lineage entries visible in Marquez UI.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Capture and visualise data lineage and build provenance.",
      "decision": true
    },
    {
      "ref": "TOOL-008",
      "category": "Mission Tooling",
      "theme": "Documentation",
      "topic": "MkDocs + Markdown ADRs",
      "codify": "`/docs` folder with Markdown and `mkdocs.yml`.",
      "automate": "Docs auto-built on merge to main.",
      "intercept": "Missing or broken link triggers warning.",
      "prove": "Published site and changelog per release.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Generate human-readable mission documentation.",
      "decision": true
    },
    {
      "ref": "TOOL-009",
      "category": "Mission Tooling",
      "theme": "AI Assist",
      "topic": "Copilot / ChatGPT / Gemini",
      "codify": "`.copilot` config and access policy.",
      "automate": "Inline AI suggestions enabled for approved repos.",
      "intercept": "None (advisory only).",
      "prove": "Generated docs and code reviews logged.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Support developers with contextual AI code and doc generation.",
      "decision": true
    },
    {
      "ref": "TOOL-010",
      "category": "Mission Tooling",
      "theme": "Containerisation",
      "topic": "Docker / Podman",
      "codify": "`Dockerfile` in each repo with approved base image.",
      "automate": "CI builds container images on every push.",
      "intercept": "Linting ensures image size and layer limits.",
      "prove": "Image digest and metadata captured in release.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Ensure consistent build artefacts and portable environments.",
      "decision": true
    },
    {
      "ref": "TOOL-011",
      "category": "Mission Tooling",
      "theme": "Deployment",
      "topic": "Kubernetes / Render / Cloud Run",
      "codify": "Helm charts or deployment manifests in `/deploy`.",
      "automate": "GitOps or CD workflow applies manifests.",
      "intercept": "Admission controller denies non-compliant deploys.",
      "prove": "Successful rollout recorded and observable.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Deploy applications in reproducible environments.",
      "decision": true
    },
    {
      "ref": "TOOL-012",
      "category": "Mission Tooling",
      "theme": "Testing",
      "topic": "Unit Tests",
      "codify": "`testing.md` lists per-lang defaults (Jest/Vitest, Pytest, JUnit, Go test).",
      "automate": "CI step runs `npm test` / `pytest` / `mvn test` / `go test`.",
      "intercept": "Non-zero exit blocks merge.",
      "prove": "JUnit/JSON test report uploaded.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Standardise on free unit-test frameworks per language.",
      "decision": true
    },
    {
      "ref": "TOOL-013",
      "category": "Mission Tooling",
      "theme": "Testing",
      "topic": "Contract Tests",
      "codify": "Pact files in `/contracts`; OpenAPI as source of truth.",
      "automate": "Pact tests run in CI; broker verification (OSS).",
      "intercept": "Failed verification blocks release.",
      "prove": "Pact verification report stored.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Enforce producer/consumer API contracts.",
      "decision": true
    },
    {
      "ref": "TOOL-014",
      "category": "Mission Tooling",
      "theme": "Testing",
      "topic": "API Tests",
      "codify": "Postman collections or `.http` specs in repo.",
      "automate": "Newman runs collections in CI.",
      "intercept": "Failing requests block pipeline.",
      "prove": "Newman HTML/JSON report artefact.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Automate API regression via collections.",
      "decision": true
    },
    {
      "ref": "TOOL-015",
      "category": "Mission Tooling",
      "theme": "Testing",
      "topic": "Integration (Containers)",
      "codify": "Testcontainers in test code; docker-compose for local.",
      "automate": "CI launches ephemeral containers for suites.",
      "intercept": "Startup/health failure fails job.",
      "prove": "Logs + container list archived.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Spin up real dependencies in tests.",
      "decision": true
    },
    {
      "ref": "TOOL-016",
      "category": "Mission Tooling",
      "theme": "Testing",
      "topic": "Performance / Load",
      "codify": "`k6` scripts in `/perf`.",
      "automate": "k6 runs on schedule or PR gates.",
      "intercept": "SLO breach flags PR or blocks merge (configurable).",
      "prove": "k6 summary + trend in artefacts.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Baseline latency and throughput SLIs.",
      "decision": true
    },
    {
      "ref": "TOOL-017",
      "category": "Mission Tooling",
      "theme": "Testing",
      "topic": "Dynamic Security",
      "codify": "ZAP baseline config in `/security/zap.yaml`.",
      "automate": "OWASP ZAP baseline scan in CI against preview URL.",
      "intercept": "High/critical issues block deploy.",
      "prove": "ZAP HTML report archived.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Catch common web vulnerabilities automatically.",
      "decision": true
    },
    {
      "ref": "TOOL-018",
      "category": "Mission Tooling",
      "theme": "Quality",
      "topic": "Static Analysis & Lint",
      "codify": "ESLint/Prettier, Flake8, golangci-lint configs.",
      "automate": "Lint job runs in CI on PRs.",
      "intercept": "Lint errors fail job.",
      "prove": "Lint report uploaded.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Enforce style and detect defects.",
      "decision": true
    },
    {
      "ref": "TOOL-019",
      "category": "Mission Tooling",
      "theme": "Testing",
      "topic": "Coverage",
      "codify": "Coverage config (nyc/Istanbul, coverage.py, JaCoCo).",
      "automate": "Coverage generated in CI; threshold gate optional.",
      "intercept": "Under-threshold blocks merge (if enabled).",
      "prove": "Coverage badge + report artefact.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Track and gate minimum coverage.",
      "decision": true
    },
    {
      "ref": "TOOL-020",
      "category": "Mission Tooling",
      "theme": "Testing",
      "topic": "UI End-to-End",
      "codify": "Playwright config + specs in `/e2e`.",
      "automate": "Playwright runs headless in CI.",
      "intercept": "Failing E2E blocks pipeline.",
      "prove": "Traces/videos uploaded by CI.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Cross-browser E2E tests.",
      "decision": true
    },
    {
      "ref": "TOOL-021",
      "category": "Mission Tooling",
      "theme": "Testing",
      "topic": "Service Virtualisation",
      "codify": "WireMock / MockServer configs in `/mocks`.",
      "automate": "Mock servers spun up in CI pre-test.",
      "intercept": "Mock startup failure fails job.",
      "prove": "Mock logs + mappings archived.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Decouple from unavailable or external dependencies.",
      "decision": true
    },
    {
      "ref": "TOOL-022",
      "category": "Mission Tooling",
      "theme": "Resilience",
      "topic": "Chaos Experiments",
      "codify": "LitmusChaos experiment manifests.",
      "automate": "Periodic chaos runs in non-prod.",
      "intercept": "Failed recovery raises incident.",
      "prove": "Chaos run report stored.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Validate graceful degradation and recovery.",
      "decision": true
    },
    {
      "ref": "TOOL-023",
      "category": "Mission Tooling",
      "theme": "Accessibility",
      "topic": "a11y Checks",
      "codify": "axe-core / pa11y configs and test scripts.",
      "automate": "a11y job runs on PRs.",
      "intercept": "WCAG violations flag PR / block per severity.",
      "prove": "a11y report artefact + trend.",
      "dependency": "None",
      "status": "proposed",
      "user_notes": "Embed accessibility testing for web UIs.",
      "decision": true
    }
  ]
};

/********************
 * Constants
 ********************/
const SECTIONS = [
  { key: "info", label: "Mission Info" },
  { key: "objectives", label: "Mission Objectives" },
  { key: "principles", label: "Mission Principles" },
  { key: "guardrails", label: "Mission Guardrails" },
  { key: "ground", label: "Mission Tooling" },
  { key: "service", label: "Mission Services" },
  { key: "review", label: "Systems Check" },
];

/********************
 * UI atoms
 ********************/
const DecisionPill = ({ value }) => {
  const label = value === true ? "Accepted" : value === false ? "Later" : "Pending";
  const cls =
    value === true
      ? "bg-[color:var(--ms-teal)] text-white"
      : value === false
      ? "bg-[color:var(--ms-orange)] text-white"
      : "bg-gray-200 text-gray-700";
  return (
    <span className={`px-2 py-1 rounded-full text-xs font-medium ${cls}`}>{label}</span>
  );
};


const TopBar = ({ onImportJSON, progress }) => {
  return (
    <header className="sticky top-0 z-40 w-full border-b bg-white/70 backdrop-blur">
      <div className="mx-auto max-w-7xl px-4">
        <div className="flex h-14 items-center justify-between">
          <div className="flex items-center gap-3">
            <div className="h-7 w-7 rounded-xl" style={{ background: "var(--ms-teal)" }} />
            <h1 className="text-lg font-semibold tracking-tight">MissionSmith</h1>
            <span className="ml-2 hidden text-sm text-gray-500 sm:block">
              Forge your Mission Objectives, Principles, Guardrails & Mission Tooling
            </span>
          </div>
          <div className="flex items-center gap-2">
            <button className="rounded-xl border px-3 py-1.5 text-sm hover:bg-gray-50" onClick={onImportJSON}>Import JSON</button>
          </div>
        </div>
        <div className="mb-3 mt-1 h-1 w-full overflow-hidden rounded-full bg-gray-100">
          <div className="h-full rounded-full" style={{ width: `${Math.round(progress * 100)}%`, background: "var(--ms-blue)" }} />
        </div>
      </div>
    </header>
  );
};

const Sidebar = ({ section, setSection }) => {
  return (
    <aside className="sticky top-14 h-[calc(100dvh-56px)] w-full max-w-[260px] shrink-0 border-r bg-white/60 p-3">
      <nav className="flex flex-col gap-1">
        {SECTIONS.map((s) => (
          <button
            key={s.key}
            onClick={() => setSection(s.key)}
            className={`flex items-center justify-between rounded-xl px-3 py-2 text-left text-sm hover:bg-gray-50 ${section === s.key ? "bg-gray-100" : ""}`}
          >
            <span>{s.label}</span>
            {section === s.key && (
              <span className="h-2 w-2 rounded-full" style={{ background: "var(--ms-teal)" }} />
            )}
          </button>
        ))}
      </nav>
      <div className="mt-4 rounded-xl border p-3 text-xs text-gray-600">
        <p className="font-medium">Tip</p>
        <p>Mission Info first, then review & accept rows section by section (Objectives, Principles, Guardrails, Tooling).</p>
      </div>
    </aside>
  );
};

/********************
 * Feature components
 ********************/
const RowEditor = ({ value, onChange, onClose }) => {
  const [local, setLocal] = useState(value);
  const update = (k, v) => setLocal((p) => ({ ...p, [k]: v }));
  const save = () => onChange(local);
  return (
    <div className="fixed inset-0 z-50 flex items-end justify-center bg-black/40 p-0 sm:items-center sm:p-8">
      <div className="w-full max-w-3xl rounded-2xl bg-white p-4 shadow-2xl sm:p-6">
        <div className="mb-3 flex items-center justify-between">
          <h3 className="text-base font-semibold">Edit: {local.ref} â€” {local.topic}</h3>
          <button className="rounded-lg border px-3 py-1 text-sm" onClick={onClose}>Close</button>
        </div>
        <div className="grid grid-cols-1 gap-3 sm:grid-cols-2">
          {[
            ["ref", "Ref"],
            ["category", "Category"],
            ["theme", "Theme"],
            ["topic", "Topic"],
            ["codify", "Codify"],
            ["automate", "Automate"],
            ["intercept", "Intercept"],
            ["prove", "Prove"],
            ["dependency", "Dependency"],
            ["status", "Status"],
            ["user_notes", "Notes"],
          ].map(([key, label]) => (
            <label key={key} className="flex flex-col text-sm">
              <span className="mb-1 text-gray-600">{label}</span>
              <textarea className="min-h-[42px] rounded-xl border p-2 focus:outline-none focus:ring-2" value={local[key] ?? ""} onChange={(e) => update(key, e.target.value)} />
            </label>
          ))}
        </div>
        <div className="mt-4 flex items-center justify-between">
          <div className="flex items-center gap-3 text-sm">
            <span>Decision:</span>
            <button className={`rounded-xl px-3 py-1 ${local.decision === true ? "text-white" : "border"}`} style={{ background: local.decision === true ? "var(--ms-teal)" : undefined }} onClick={() => update("decision", true)}>Accept</button>
            <button className={`rounded-xl px-3 py-1 ${local.decision === false ? "text-white" : "border"}`} style={{ background: local.decision === false ? "var(--ms-orange)" : undefined }} onClick={() => update("decision", false)}>Later</button>
            <button className="rounded-xl border px-3 py-1" onClick={() => update("decision", null)}>Clear</button>
          </div>
          <div className="flex items-center gap-2">
            <button className="rounded-xl border px-3 py-1" onClick={onClose}>Cancel</button>
            <button className="rounded-xl px-3 py-1 text-white" style={{ background: "var(--ms-teal)" }} onClick={save}>Save</button>
          </div>
        </div>
      </div>
    </div>
  );
};

const SectionTable = ({ title, rows, onRowsChange, allowAdd = false }) => {
  const [query, setQuery] = useState("");
  const [editing, setEditing] = useState(null);

  const filtered = useMemo(() => {
    const q = query.trim().toLowerCase();
    if (!q) return rows;
    return rows.filter((r) => JSON.stringify(r).toLowerCase().includes(q));
  }, [query, rows]);

  const updateRow = (idx, patch) => {
    const next = [...rows];
    next[idx] = { ...rows[idx], ...patch };
    onRowsChange(next);
  };

  const removeRow = (idx) => {
    const next = [...rows];
    next.splice(idx, 1);
    onRowsChange(next);
  };

  const addRow = () => {
    const n = {
      ref: `NEW-${Math.random().toString(36).slice(2, 6).toUpperCase()}`,
      category: title,
      theme: "",
      topic: "",
      codify: "",
      automate: "",
      intercept: "",
      prove: "",
      dependency: "N/A",
      status: "option",
      user_notes: "",
      decision: null,
    };
    onRowsChange([n, ...rows]);
    setEditing({ idx: 0, value: n });
  };

  return (
    <div className="rounded-2xl border bg-white/70 p-3 sm:p-4">
      <div className="mb-3 flex flex-col gap-2 sm:flex-row sm:items-center sm:justify-between">
        <div>
          <h2 className="text-base font-semibold">{title}</h2>
          <p className="text-xs text-gray-600">Search, accept/later, edit, || add.</p>
        </div>
        <div className="flex items-center gap-2">
          <input placeholder="Searchâ€¦" className="w-48 rounded-xl border px-3 py-1.5 text-sm" value={query} onChange={(e) => setQuery(e.target.value)} />
          {allowAdd && (
            <button onClick={addRow} className="rounded-xl px-3 py-1.5 text-sm text-white" style={{ background: "var(--ms-teal)" }}>+ Add</button>
          )}
        </div>
      </div>

      <div className="overflow-x-auto">
        <table className="min-w-full text-sm">
          <thead>
            <tr className="bg-gray-50 text-left text-xs uppercase text-gray-500">
              {["Ref", "Theme", "Topic", "Codify", "Automate", "Intercept", "Prove", "Dependency", "Decision", ""].map((h) => (
                <th key={h} className="whitespace-nowrap px-3 py-2 font-medium">{h}</th>
              ))}
            </tr>
          </thead>
          <tbody>
            {filtered.map((r, i) => (
              <tr key={r.ref} className="border-b hover:bg-gray-50">
                <td className="px-3 py-2 font-mono">{r.ref}</td>
                <td className="px-3 py-2">{r.theme}</td>
                <td className="px-3 py-2">
                  <div className="flex items-center gap-2">
                    <span className="font-medium">{r.topic}</span>
                    <button className="rounded-lg border px-2 py-0.5 text-xs" onClick={() => setEditing({ idx: i, value: r })}>Edit</button>
                  </div>
                </td>
                <td className="px-3 py-2 max-w-[260px] truncate" title={r.codify}>{r.codify}</td>
                <td className="px-3 py-2 max-w-[260px] truncate" title={r.automate}>{r.automate}</td>
                <td className="px-3 py-2 max-w-[260px] truncate" title={r.intercept}>{r.intercept}</td>
                <td className="px-3 py-2 max-w-[260px] truncate" title={r.prove}>{r.prove}</td>
                <td className="px-3 py-2">{r.dependency}</td>
                <td className="px-3 py-2">
                  <div className="flex items-center gap-2">
                    <button className={`rounded-xl px-2 py-1 text-xs ${r.decision === true ? "text-white" : "border"}`} style={{ background: r.decision === true ? "var(--ms-teal)" : undefined }} onClick={() => updateRow(i, { decision: true })}>Accept</button>
                    <button className={`rounded-xl px-2 py-1 text-xs ${r.decision === false ? "text-white" : "border"}`} style={{ background: r.decision === false ? "var(--ms-orange)" : undefined }} onClick={() => updateRow(i, { decision: false })}>Later</button>
                    <button className="rounded-xl border px-2 py-1 text-xs" onClick={() => updateRow(i, { decision: null })}>Clear</button>
                  </div>
                </td>
                <td className="px-3 py-2 text-right">
                  <button className="rounded-lg px-2 py-1 text-xs text-white" style={{ background: "var(--ms-red)" }} onClick={() => removeRow(i)}>Delete</button>
                </td>
              </tr>
            ))}
            {filtered.length === 0 && (
              <tr>
                <td className="px-3 py-6 text-center text-gray-500" colSpan={10}>No rows match your search.</td>
              </tr>
            )}
          </tbody>
        </table>
      </div>

      {editing && (
        <RowEditor
          value={editing.value}
          onClose={() => setEditing(null)}
          onChange={(next) => {
            const updated = [...rows];
            updated[editing.idx] = next;
            onRowsChange(updated);
            setEditing(null);
          }}
        />
      )}
    </div>
  );
};

const Review = ({ data, onResetDecisions }) => {
  const flat = [
    ...data.objectives.map((r) => ({ ...r, section: "Mission Objectives" })),
    ...data.principles.map((r) => ({ ...r, section: "Mission Principles" })),
    ...data.guardrails.map((r) => ({ ...r, section: "Mission Guardrails" })),
    ...data.ground.map((r) => ({ ...r, section: "Mission Tooling" })),
  ];
  const accepted = flat.filter((r) => r.decision === true);
  const later = flat.filter((r) => r.decision === false);
  const pending = flat.filter((r) => r.decision === null);
  return (
    <div className="grid grid-cols-1 gap-4 lg:grid-cols-3">
      {[["Accepted", accepted, "var(--ms-teal)"],["Later", later, "var(--ms-orange)"],["Pending", pending, "var(--ms-blue)"]].map(([label, rows, color]) => (
        <div key={label} className="rounded-2xl border bg-white/70 p-4">
          <div className="mb-2 flex items-center justify-between">
            <h3 className="text-base font-semibold">{label}</h3>
            <span className="rounded-full px-2 py-1 text-xs text-white" style={{ background: color }}>{rows.length}</span>
          </div>
          <ul className="space-y-2">
            {rows.map((r) => (
              <li key={r.ref} className="rounded-xl border p-3 text-sm">
                <div className="mb-1 flex items-center justify-between">
                  <span className="font-medium">{r.ref} â€” {r.topic}</span>
                  <DecisionPill value={r.decision} />
                </div>
                <p className="text-xs text-gray-600">{r.section} â€¢ {r.theme}</p>
              </li>
            ))}
            {rows.length === 0 && (<li className="text-sm text-gray-500">Nothing here yet.</li>)}
          </ul>
        </div>
      ))}
      <div className="lg:col-span-3">
        <button className="rounded-xl px-3 py-2 text-sm text-white" style={{ background: "var(--ms-red)" }} onClick={onResetDecisions}>Reset all decisions</button>
      </div>
    </div>
  );
};


function ServiceConfig({ value, onChange }) {
  const [local, setLocal] = useState(value || {});
  const update = (path, v) => {
    const parts = path.split(".");
    const copy = JSON.parse(JSON.stringify(local || {}));
    let cur = copy;
    for (let i = 0; i < parts.length - 1; i++) {
      const k = parts[i];
      if (!cur[k] || typeof cur[k] !== "object") cur[k] = {};
      cur = cur[k];
    }
    cur[parts[parts.length-1]] = v;
    setLocal(copy);
  };
  const save = () => onChange(local);
  const arr = (a) => Array.isArray(a) ? a.join(", ") : (a || "");

  const opts = {
    backendLang: ["java17","python3.11","node18","go1.21"],
    backendFw:   ["spring-boot","fastapi","express","gin"],
    uiLang:      ["react18","angular16","vue3"],
    uiFw:        ["nextjs","cra","nuxt"],
    database:    ["postgres","mongodb","mysql","dynamodb"],
    migrate:     ["flyway","prisma","alembic","liquibase"],
    deploy:      ["rolling","blue-green","canary","feature-flag-only"],
    policies:    ["no-wildcard-iam","no-plaintext-internal","no-pii-in-logs","schema-compat","secure-dependencies"],
    cigates:     ["typecheck","unit","contract","property","sast","sbom","iac","schema-compat"]
  };

  return (
    <div className="rounded-2xl border bg-white/70 p-4 space-y-6">
      <h2 className="text-base font-semibold">Service Config (Mission-wide Defaults & Guardrails)</h2>
      <div className="space-y-3">
        <h3 className="text-sm font-semibold text-gray-700">Defaults (optional)</h3>
        <div className="grid gap-3 md:grid-cols-2">
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">Default Service Name</span>
            <input className="rounded-xl border px-3 py-2" placeholder="example-service"
              value={local?.default_service_name || ""}
              onChange={e=>update("default_service_name", e.target.value)} />
          </label>
          <div />
        </div>
        <div className="grid gap-3 md:grid-cols-2">
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">Default Backend Language</span>
            <input className="rounded-xl border px-3 py-2" list="opt-backend-lang" placeholder="e.g. java17"
              value={local?.default_backend_language || ""}
              onChange={e=>update("default_backend_language", e.target.value)} />
            <datalist id="opt-backend-lang">{opts.backendLang.map(o => <option key={o} value={o} />)}</datalist>
          </label>
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">Default Backend Framework</span>
            <input className="rounded-xl border px-3 py-2" list="opt-backend-fw" placeholder="e.g. spring-boot"
              value={local?.default_backend_framework || ""}
              onChange={e=>update("default_backend_framework", e.target.value)} />
            <datalist id="opt-backend-fw">{opts.backendFw.map(o => <option key={o} value={o} />)}</datalist>
          </label>
        </div>
        <div className="grid gap-3 md:grid-cols-2">
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">Default UI Language</span>
            <input className="rounded-xl border px-3 py-2" list="opt-ui-lang" placeholder="e.g. react18"
              value={local?.default_ui_language || ""}
              onChange={e=>update("default_ui_language", e.target.value)} />
            <datalist id="opt-ui-lang">{opts.uiLang.map(o => <option key={o} value={o} />)}</datalist>
          </label>
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">Default UI Framework</span>
            <input className="rounded-xl border px-3 py-2" list="opt-ui-fw" placeholder="e.g. nextjs"
              value={local?.default_ui_framework || ""}
              onChange={e=>update("default_ui_framework", e.target.value)} />
            <datalist id="opt-ui-fw">{opts.uiFw.map(o => <option key={o} value={o} />)}</datalist>
          </label>
        </div>
        <div className="grid gap-3 md:grid-cols-3">
          <label className="flex flex-col text-sm md:col-span-1">
            <span className="mb-1 text-gray-600">Default Database</span>
            <input className="rounded-xl border px-3 py-2" list="opt-db" placeholder="e.g. postgres"
              value={local?.default_database || ""}
              onChange={e=>update("default_database", e.target.value)} />
            <datalist id="opt-db">{opts.database.map(o => <option key={o} value={o} />)}</datalist>
          </label>
          <label className="flex flex-col text-sm md:col-span-2">
            <span className="mb-1 text-gray-600">Default Migration Tool</span>
            <input className="rounded-xl border px-3 py-2" list="opt-mig" placeholder="e.g. flyway"
              value={local?.default_migration_tool || ""}
              onChange={e=>update("default_migration_tool", e.target.value)} />
            <datalist id="opt-mig">{opts.migrate.map(o => <option key={o} value={o} />)}</datalist>
          </label>
        </div>
        <label className="flex items-center gap-2 text-sm">
          <input type="checkbox" checked={!!local?.default_outbox_enabled}
            onChange={e=>update("default_outbox_enabled", e.target.checked)} />
          <span>Default Outbox Enabled</span>
        </label>
      </div>

      <div className="space-y-3">
        <h3 className="text-sm font-semibold text-gray-700">Security (guardrails)</h3>
        <div className="grid gap-3 md:grid-cols-3">
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">AuthN</span>
            <input className="rounded-xl border px-3 py-2" placeholder="e.g. jwt"
              value={arr(local?.security?.authn)}
              onChange={e=>update("security.authn", e.target.value.split(",").map(s=>s.trim()).filter(Boolean))} />
          </label>
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">AuthZ</span>
            <input className="rounded-xl border px-3 py-2" placeholder="e.g. opa"
              value={arr(local?.security?.authz)}
              onChange={e=>update("security.authz", e.target.value.split(",").map(s=>s.trim()).filter(Boolean))} />
          </label>
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">CORS Allowlist (comma-separated)</span>
            <input className="rounded-xl border px-3 py-2" placeholder="https://app.example.com"
              value={arr(local?.security?.cors_allowlist)}
              onChange={e=>update("security.cors_allowlist", e.target.value.split(",").map(s=>s.trim()).filter(Boolean))} />
          </label>
        </div>
      </div>

      <div className="space-y-3">
        <h3 className="text-sm font-semibold text-gray-700">Observability (guardrails)</h3>
        <div className="grid gap-3 md:grid-cols-3">
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">Tracing</span>
            <input className="rounded-xl border px-3 py-2" placeholder="otel"
              value={local?.observability?.tracing || ""}
              onChange={e=>update("observability.tracing", e.target.value)} />
          </label>
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">Metrics</span>
            <input className="rounded-xl border px-3 py-2" placeholder="red"
              value={local?.observability?.metrics || ""}
              onChange={e=>update("observability.metrics", e.target.value)} />
          </label>
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">Logs</span>
            <input className="rounded-xl border px-3 py-2" placeholder="json"
              value={local?.observability?.logs || ""}
              onChange={e=>update("observability.logs", e.target.value)} />
          </label>
        </div>
      </div>

      <div className="space-y-3">
        <h3 className="text-sm font-semibold text-gray-700">NFR: SLOs</h3>
        <div className="grid gap-3 md:grid-cols-2">
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">http_p95_ms</span>
            <input className="rounded-xl border px-3 py-2" type="number"
              value={(Number(local?.nfr?.slo?.find(s=>s.name==='http_p95_ms')?.target) || "")}
              onChange={e=>{
                const val = e.target.value === "" ? "" : Number(e.target.value);
                const arr = (local?.nfr?.slo || []).filter(s=>s.name!=="http_p95_ms");
                arr.push({ name: "http_p95_ms", target: val });
                update("nfr.slo", arr);
              }} />
          </label>
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">error_rate</span>
            <input className="rounded-xl border px-3 py-2"
              value={(local?.nfr?.slo?.find(s=>s.name==='error_rate')?.target) ?? ""}
              onChange={e=>{
                const arr = (local?.nfr?.slo || []).filter(s=>s.name!=="error_rate");
                arr.push({ name: "error_rate", target: e.target.value });
                update("nfr.slo", arr);
              }} />
          </label>
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">availability</span>
            <input className="rounded-xl border px-3 py-2"
              value={(local?.nfr?.slo?.find(s=>s.name==='availability')?.target) ?? ""}
              onChange={e=>{
                const arr = (local?.nfr?.slo || []).filter(s=>s.name!=="availability");
                arr.push({ name: "availability", target: e.target.value });
                update("nfr.slo", arr);
              }} />
          </label>
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">throughput_rps (optional)</span>
            <input className="rounded-xl border px-3 py-2"
              value={(local?.nfr?.slo?.find(s=>s.name==='throughput_rps')?.target) ?? ""}
              onChange={e=>{
                const arr = (local?.nfr?.slo || []).filter(s=>s.name!=="throughput_rps");
                arr.push({ name: "throughput_rps", target: e.target.value });
                update("nfr.slo", arr);
              }} />
          </label>
        </div>
      </div>

      <div className="space-y-3">
        <h3 className="text-sm font-semibold text-gray-700">NFR: Resilience</h3>
        <div className="grid gap-3 md:grid-cols-3">
          <label className="flex items-center gap-2 text-sm">
            <input type="checkbox" checked={!!local?.nfr?.resilience?.circuit_breaker}
              onChange={e=>update("nfr.resilience.circuit_breaker", e.target.checked)} />
            <span>Circuit Breaker</span>
          </label>
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">Idempotency Policy</span>
            <select className="rounded-xl border px-3 py-2"
              value={local?.nfr?.resilience?.idempotency_policy || "mutations_required"}
              onChange={e=>update("nfr.resilience.idempotency_policy", e.target.value)}>
              <option value="mutations_required">mutations_required</option>
              <option value="recommended">recommended</option>
              <option value="off">off</option>
            </select>
          </label>
          <div className="grid gap-2">
            <label className="flex flex-col text-sm">
              <span className="mb-1 text-gray-600">Retries (max)</span>
              <input className="rounded-xl border px-3 py-2" type="number"
                value={(local?.nfr?.resilience?.retries?.max) ?? 0}
                onChange={e=>update("nfr.resilience.retries.max", Number(e.target.value))} />
            </label>
            <label className="flex flex-col text-sm">
              <span className="mb-1 text-gray-600">Retries (strategy)</span>
              <input className="rounded-xl border px-3 py-2" placeholder="exponential-jitter"
                value={(local?.nfr?.resilience?.retries?.strategy) ?? ""}
                onChange={e=>update("nfr.resilience.retries.strategy", e.target.value)} />
            </label>
          </div>
        </div>
      </div>

      <div className="space-y-3">
        <h3 className="text-sm font-semibold text-gray-700">Governance, CI/CD & Deploy</h3>
        <div className="grid gap-3 md:grid-cols-2">
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">Governance: Lineage</span>
            <input className="rounded-xl border px-3 py-2" placeholder="required"
              value={local?.governance?.lineage || ""}
              onChange={e=>update("governance.lineage", e.target.value)} />
          </label>
          <label className="flex flex-col text-sm">
            <span className="mb-1 text-gray-600">Default Deploy Strategy</span>
            <input className="rounded-xl border px-3 py-2" list="opt-deploy" placeholder="e.g. canary"
              value={local?.deploy?.default_strategy || ""}
              onChange={e=>update("deploy.default_strategy", e.target.value)} />
            <datalist id="opt-deploy">{opts.deploy.map(o => <option key={o} value={o} />)}</datalist>
          </label>
        </div>
        <label className="flex items-center gap-2 text-sm">
          <input type="checkbox" checked={!!local?.deploy?.feature_flags}
            onChange={e=>update("deploy.feature_flags", e.target.checked)} />
          <span>Default Feature Flags Enabled</span>
        </label>
        <label className="flex flex-col text-sm">
          <span className="mb-1 text-gray-600">Policy Packs (comma-separated or custom)</span>
          <input className="rounded-xl border px-3 py-2" list="opt-policies" placeholder="no-wildcard-iam, no-pii-in-logs"
            value={arr(local?.governance?.policy_packs)}
            onChange={e=>update("governance.policy_packs", e.target.value.split(",").map(s=>s.trim()).filter(Boolean))} />
          <datalist id="opt-policies">{opts.policies.map(o => <option key={o} value={o} />)}</datalist>
        </label>
        <label className="flex flex-col text-sm">
          <span className="mb-1 text-gray-600">CI Gates (comma-separated or custom)</span>
          <input className="rounded-xl border px-3 py-2" list="opt-cigates" placeholder="typecheck, unit, ..."
            value={arr(local?.ci?.gates)}
            onChange={e=>update("ci.gates", e.target.value.split(",").map(s=>s.trim()).filter(Boolean))} />
          <datalist id="opt-cigates">{opts.cigates.map(o => <option key={o} value={o} />)}</datalist>
        </label>
        <label className="flex flex-col text-sm">
          <span className="mb-1 text-gray-600">Default Owner (optional)</span>
          <input className="rounded-xl border px-3 py-2" placeholder="team-trade"
            value={local?.ownership?.owner || ""}
            onChange={e=>update("ownership.owner", e.target.value)} />
        </label>
      </div>

      <div className="flex gap-2 pt-2">
        <button className="rounded-xl border px-3 py-1" onClick={()=>setLocal(value)}>Reset</button>
        <button className="rounded-xl px-3 py-1 text-white" style={{ background: "var(--ms-teal)" }} onClick={save}>Save</button>
      </div>
    </div>
  );
}


function MissionInfo({ value, onChange }) {
  const update = (k, v) => onChange({ ...value, [k]: v });
  return (
    <div className="rounded-2xl border bg-white/70 p-4 space-y-4">
      <h2 className="text-base font-semibold">Mission Information</h2>
      {[["title","Mission Title"],["sponsor","Sponsor"],["owner","Owner"],["stakeholders","Stakeholders"],["version","Version"],["description","Description"],["date","Date"]].map(([key, label]) => (
        <label key={key} className="flex flex-col text-sm">
          <span className="mb-1 text-gray-600">{label}</span>
          <input
            className="rounded-xl border px-3 py-2 focus:outline-none focus:ring-2 focus:ring-teal-500"
            value={value?.[key] ?? ""}
            onChange={(e) => update(key, e.target.value)}
          />
        </label>
      ))}
    </div>
  );
}

/********************
 * Main App
 ********************/
function MissionSmithApp() {
  const [section, setSection] = useState("info");
  const [data, setData] = useState(initialData);

  
  
  useEffect(() => { window.__ms_data = data; window.__ms_getData = () => data; }, [data]);
useEffect(() => { window.__ms_data = data; window.__ms_getData = () => data; }, [data]);
const progress = useMemo(() => {
    const all = [...data.objectives, ...data.principles, ...data.guardrails, ...data.ground];
    const decided = all.filter((r) => r.decision !== null).length;
    return all.length ? decided / all.length : 0;
  }, [data]);

  const onRowsChange = (key, next) => setData((p) => ({ ...p, [key]: next }));

  const exportJSON = () => {
    const blob = new Blob([JSON.stringify(data, null, 2)], { type: "application/json" });
    const url = URL.createObjectURL(blob);
    const a = document.createElement("a");
    a.href = url;
    a.download = `missionsmith-framework.json`;
    a.click();
    URL.revokeObjectURL(url);
  };

  const exportCSVHandler = () => exportCSV(data);

  
  // CSV Export helpers (flat table across all sections)
  const CSV_HEADERS = ["ref","category","theme","topic","codify","automate","intercept","prove","dependency","status","user_notes","decision"];
  function toCSVRow(obj){
    function esc(v){
      const s = (v === null || v === undefined) ? "" : String(v);
      const needsQuote = /[",\n]/.test(s);
      const out = s.replace(/"/g,'""');
      return needsQuote ? "\"" + out + "\"" : out;
    }
    return CSV_HEADERS.map(h => {
      if (h === "decision") {
        return esc(obj.decision === true ? "Accepted" : obj.decision === false ? "Later" : "Pending");
      }
      return esc(obj[h] ?? "");
    }).join(",");
  }
  function exportCSV(data){
    const flat = [
      ...data.objectives.map(r => ({...r})),
      ...data.principles.map(r => ({...r})),
      ...data.guardrails.map(r => ({...r})),
      ...data.ground.map(r => ({...r})),
    ];
    const header = CSV_HEADERS.join(",");
    const rows = flat.map(toCSVRow);
    const csv = [header, ...rows].join("\n");
    const blob = new Blob([csv], { type: "text/csv;charset=utf-8" });
    const url = URL.createObjectURL(blob);
    const a = document.createElement("a");
    a.href = url;
    a.download = "missionsmith-framework.csv";
    a.click();
    URL.revokeObjectURL(url);
  }
const importJSON = () => {
    const input = document.createElement("input");
    input.type = "file";
    input.accept = ".json,application/json";
    input.onchange = (e) => {
      const file = e.target.files?.[0];
      if (!file) return;
      const reader = new FileReader();
      reader.onload = () => {
        try {
          const parsed = JSON.parse(String(reader.result));
          setData((p) => ({ ...p, ...parsed }));
          alert("Imported JSON successfully.");
        } catch (err) {
          alert("Invalid JSON file.");
        }
      };
      reader.readAsText(file);
    };
    input.click();
  };

  const importCSV = () => {
    const input = document.createElement("input");
    input.type = "file";
    input.accept = ".csv,text/csv";
    input.onchange = (e) => {
      const file = e.target.files?.[0];
      if (!file) return;
      const reader = new FileReader();
      reader.onload = () => {
        const text = String(reader.result);
        const { rows } = parseCSVSimple(text);

        const buckets = { objectives: [], principles: [], guardrails: [], ground: [] };
        for (const r of rows) {
          const item = {
            ref: r.ref || r.Ref || `CSV-${Math.random().toString(36).slice(2, 6).toUpperCase()}`,
            category: r.category || r.Category || "",
            theme: r.theme || r.Theme || "",
            topic: r.topic || r.Topic || "",
            codify: r.codify || r.Codify || "",
            automate: r.automate || r.Automate || "",
            intercept: r.intercept || r.Intercept || "",
            prove: r.prove || r.Prove || "",
            dependency: r.dependency || r.Dependency || "N/A",
            status: r.status || r.Status || "proposed",
            user_notes: r.user_notes || r.Notes || r.UserNotes || "",
            decision: null,
          };
          const cat = (item.category || "").toLowerCase();
          if (cat.includes("objective")) buckets.objectives.push(item);
          else if (cat.includes("principle")) buckets.principles.push(item);
          else if (cat.includes("guardrail")) buckets.guardrails.push(item);
          else if (cat.includes("ground")) buckets.ground.push(item);
        }
        setData((p) => ({
          objectives: buckets.objectives.length ? buckets.objectives : p.objectives,
          principles: buckets.principles.length ? buckets.principles : p.principles,
          guardrails: buckets.guardrails.length ? buckets.guardrails : p.guardrails,
          ground: buckets.ground.length ? buckets.ground : p.ground,
        }));
        alert("Imported CSV rows into the matching sections.");
      };
      reader.readAsText(file);
    };
    input.click();
  };

  const resetDecisions = () => {
    const reset = (arr) => arr.map((r) => ({ ...r, decision: null }));
    setData((p) => ({
      objectives: reset(p.objectives),
      principles: reset(p.principles),
      guardrails: reset(p.guardrails),
      ground: reset(p.ground),
    }));
  };

  return (
    <div className="min-h-dvh bg-gray-50">
      <style>{`
        :root{
          --ms-teal:   rgb(26,153,136);
          --ms-blue:   rgb(106,164,200);
          --ms-orange: rgb(235,86,0);
          --ms-mint:   rgb(162,255,232);
          --ms-red:    rgb(255,0,0);
        }
      `}</style>

      <TopBar onImportJSON={importJSON} progress={progress} />

      <main className="mx-auto grid max-w-7xl grid-cols-1 gap-4 px-4 pb-8 pt-4 sm:grid-cols-[260px_1fr]">
        <Sidebar section={section} setSection={setSection} />

        <div className="space-y-4">
          {section === "info" && (<MissionInfo value={data.missionInfo} onChange={(val) => setData((p) => ({ ...p, missionInfo: val }))} />)}
{section === "service" && (<ServiceConfig value={data.serviceConfig} onChange={(val) => setData((p) => ({ ...p, serviceConfig: val }))} />)}
          {section === "objectives" && (<SectionTable title="Mission Objectives" rows={data.objectives} onRowsChange={(rows) => onRowsChange("objectives", rows)} />)}
          {section === "principles" && (<SectionTable title="Mission Principles" rows={data.principles} onRowsChange={(rows) => onRowsChange("principles", rows)} />)}
          {section === "guardrails" && (<SectionTable title="Mission Guardrails" rows={data.guardrails} onRowsChange={(rows) => onRowsChange("guardrails", rows)} />)}
          {section === "ground" && (<SectionTable title="Mission Tooling" rows={data.ground} onRowsChange={(rows) => onRowsChange("ground", rows)} allowAdd />)}
          {section === "review" && (<Review data={data} onResetDecisions={resetDecisions} />)}
        </div>
      </main>
    </div>
  );
}

    const root = ReactDOM.createRoot(document.getElementById('root'));
    root.render(<MissionSmithApp />);
  </script>

<script>
window.MS_actions = (function(){
  const download = (filename, text, type) => {
    const blob = new Blob([text], {type});
    const a = document.createElement("a");
    a.href = URL.createObjectURL(blob);
    a.download = filename;
    a.click();
    setTimeout(()=>URL.revokeObjectURL(a.href), 200);
  };

  const acceptedOnly = (arr = []) => (arr||[]).filter(x => {
  const d = x && x.decision;
  if (d === true) return true;
  if (typeof d === 'string') {
    const s = d.trim().toLowerCase();
    if (s === 'accepted' || s === 'accept' || s === 'true' || s === 'yes' || s === 'y') return true;
  }
  if (typeof d === 'number' && d === 1) return true;
  const s2 = x && (x.status || x.accepted);
  return (typeof s2 === 'string' && s2.toLowerCase() === 'accepted');
});

  const deriveAccepted = (data = {}) => ({
  objectives: acceptedOnly(data.objectives || []),
  principles: acceptedOnly(data.principles  || []),
  guardrails: acceptedOnly(data.guardrails  || []),
  ground:     acceptedOnly((data.ground || data.tooling || []) )
});

  const mdList = (title, items) =>
    items.length ? `\n## ${title}\n` + items.map(i=>`- **${i.name || i.id || "item"}**${i.description ? ` â€” ${i.description}` : ""}`).join("\n") + "\n" : "";

  const missionTitle = (data) => (data?.missionInfo?.title || "Mission").replace(/[^\w\-]+/g,"_");
  const getData = () => (typeof window.__ms_getData === 'function' ? window.__ms_getData() : (window.__ms_data || window.data || window.initialData || {}));

  const buildAgentsMd = (data) => {
  const acc = deriveAccepted(data);

  const section = (title, rows) => {
    if (!rows || !rows.length) return "";
    const blocks = rows.map(r => {
      const lines = [
        `- **${r.ref || r.id || ""} â€” ${r.topic || r.purpose || ""}** *(Theme: ${r.theme || ""}; Category: ${r.category || ""})*`,
        `  - Codify: ${r.codify || ""}`,
        `  - Automate: ${r.automate || ""}`,
        `  - Intercept: ${r.intercept || ""}`,
        `  - Prove: ${r.prove || ""}`,
        `  - Dependency: ${r.dependency || ""}`,
        `  - Notes: ${r.user_notes || r.notes || ""}`,
      ];
      return lines.join("\n");
    }).join("\n");
    return `\n## ${title}\n${blocks}\n`;
  };

  let md = `# Agents Charter â€” ${data?.missionInfo?.title || "Mission"}\n`;
  md += `\n> Generated from accepted items in Objectives, Principles, Guardrails and Tooling.\n`;
  md += section("Objectives", acc.objectives);
  md += section("Principles", acc.principles);
  md += section("Guardrails", acc.guardrails);
  md += section("Tooling", acc.ground);
  md += `\n---\nGenerated by MissionSmith\n`;
  return md;
};

  const buildPipelineYml = (data) => {
    const acc = deriveAccepted(data);
    const hasCIGuardrail = acc.guardrails.some(g => /ci|pipeline/i.test((g.name||"")+ " " + (g.description||"")));
    const gates = hasCIGuardrail ? (data?.serviceConfig?.ci?.gates || []) : [];
    const steps = gates.map(g => `      - name: ${g}\n        run: echo "Running ${g} gate"\n`).join("");
    return `name: pipeline\non: [push, pull_request]\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n${steps || '      - run: echo "No accepted CI gates configured"'}\n`;
  };

  const buildPolicyBundleTxt = (data) => {
    const acc = deriveAccepted(data);
    const hasPolicy = acc.guardrails.some(g => /policy/i.test((g.name||"")+ " " + (g.description||"")));
    const packs = hasPolicy ? (data?.serviceConfig?.governance?.policy_packs || []) : [];
    return packs.length ? packs.map(p=>`- ${p}`).join("\n") : "No accepted policy packs.";
  };

  const buildDeployPlan = (data) => {
    const acc = deriveAccepted(data);
    const hasDeploy = acc.guardrails.some(g => /deploy|release|rollout/i.test((g.name||"")+ " " + (g.description||"")));
    const sc = data?.serviceConfig?.deploy || {};
    return `strategy: ${hasDeploy ? (sc.default_strategy || "") : "UNSET (no accepted deploy guardrail)"}\nfeature_flags: ${!!sc.feature_flags}\n`;
  };

  const buildDashboards = (data) => {
    const acc = deriveAccepted(data);
    const hasSLO = acc.guardrails.some(g => /slo|observability|latency|error rate|availability/i.test((g.name||"")+ " " + (g.description||"")));
    const slos = hasSLO ? (data?.serviceConfig?.nfr?.slo || []) : [];
    if (!slos.length) return "# No accepted SLOs";
    return "panels:\n" + slos.map(s => `- title: ${s.name}\n  target: ${s.target}`).join("\n");
  };

  const buildLineage = (data) => {
    const acc = deriveAccepted(data);
    const hasLineage = acc.guardrails.some(g => /lineage|audit|governance/i.test((g.name||"")+ " " + (g.description||"")));
    if (!hasLineage) return JSON.stringify({ enabled:false, reason:"No accepted lineage guardrail" }, null, 2);
    const sc = data?.serviceConfig || {};
    return JSON.stringify({
      enabled: true,
      mission: data?.missionInfo?.title || "Mission",
      defaults: {
        backend: [sc.default_backend_language, sc.default_backend_framework].filter(Boolean).join(" + "),
        ui: [sc.default_ui_language, sc.default_ui_framework].filter(Boolean).join(" + "),
        database: sc.default_database || "",
        outbox: !!sc.default_outbox_enabled
      }
    }, null, 2);
  };

  return {
    generateJSON(){ const d=getData(); download(`${missionTitle(d)}.json`, JSON.stringify(d,null,2), "application/json"); },
    generateAgents(){ try{ const md = buildAgentsMd(getData()); if(!md || !md.trim()){ alert("Agents file is empty."); return; } download("agents.md", md, "text/markdown"); } catch(e){ console.error(e); alert("Failed to build agents.md"); } },
    generateScaffold(){
      try {
        const d = getData();
        const sc = d?.serviceConfig || {};
        const backend = [sc.default_backend_language, sc.default_backend_framework].filter(Boolean).join(" + ") || "(unset)";
        const ui      = [sc.default_ui_language, sc.default_ui_framework].filter(Boolean).join(" + ") || "(unset)";
        const dbLine  = `${sc.default_database || "(unset)"}; Migrations: ${sc.default_migration_tool || "(unset)"}; Outbox: ${!!sc.default_outbox_enabled}`;
        const secLine = JSON.stringify(sc.security || {});
        const obsLine = JSON.stringify(sc.observability || {});
        const lines = [
          `# Service Scaffold Plan â€” ${d?.missionInfo?.title || "Mission"}`,
          `Backend default: ${backend}`,
          `UI default: ${ui}`,
          `Database: ${dbLine}`,
          `Security: ${secLine}`,
          `Observability: ${obsLine}`,
          ``,
          `---`,
          `Generated by MissionSmith`
        ];
        download('service-scaffold-plan.md', lines.join('\n'), 'text/markdown');
      } catch (e) {
        console.error('generateScaffold failed', e);
        alert('Failed to build service-scaffold-plan.md');
      }
    },
    generateCICD(){ download("pipeline.yml", buildPipelineYml(getData()), "text/yaml"); },
    generatePolicies(){ download("policy-packs.txt", buildPolicyBundleTxt(getData()), "text/plain"); },
    generateDeploy(){ download("deploy-manifests-plan.yaml", buildDeployPlan(getData()), "text/yaml"); },
    generateDashboards(){ download("dashboards-alerts.yaml", buildDashboards(getData()), "text/yaml"); },
    generateLineage(){ download("lineage.json", buildLineage(getData()), "application/json"); }
  };
})();
</script>


<script>
(function(){
  function show(msg, src, line, col){
    const el = document.createElement('div');
    el.style.position='fixed'; el.style.left=0; el.style.right=0; el.style.bottom=0;
    el.style.background='rgba(220,38,38,0.95)'; el.style.color='#fff'; el.style.fontFamily='ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace';
    el.style.whiteSpace='pre-wrap'; el.style.maxHeight='40vh'; el.style.overflow='auto'; el.style.padding='12px 16px'; el.style.zIndex=99999;
    el.textContent = 'MissionSmith runtime error:\n' + msg + (src ? ('\n@ ' + src + ':' + line + ':' + col) : '');
    document.body.appendChild(el);
  }
  window.addEventListener('error', e => show(e.message, e.filename, e.lineno, e.colno));
  window.addEventListener('unhandledrejection', e => show(String(e.reason || 'Unhandled promise rejection')));
})();
</script>


<script>
(function(){
  function show(msg, src, line, col){
    const el = document.createElement('div');
    el.style.position='fixed'; el.style.left=0; el.style.right=0; el.style.bottom=0;
    el.style.background='rgba(220,38,38,0.95)'; el.style.color='#fff'; el.style.fontFamily='ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace';
    el.style.whiteSpace='pre-wrap'; el.style.maxHeight='40vh'; el.style.overflow='auto'; el.style.padding='12px 16px'; el.style.zIndex=99999;
    el.textContent = 'MissionSmith runtime error:\n' + msg + (src ? ('\n@ ' + src + ':' + line + ':' + col) : '');
    document.body.appendChild(el);
  }
  window.addEventListener('error', e => show(e.message, e.filename, e.lineno, e.colno));
  window.addEventListener('unhandledrejection', e => show(String(e.reason || 'Unhandled promise rejection')));
})();
</script>


<script>
(function(){
  function wireFrameworkButtons(){
    var hdr = document.querySelector('header.sticky.top-0');
    if(!hdr) return;
    var right = hdr.querySelector('.flex.items-center.gap-2');
    if(!right) return;

    // 1) Ensure Import button label
    var importBtn = right.querySelector('button');
    if(importBtn){
      var txt = (importBtn.textContent || '').trim().toLowerCase();
      if(txt.includes('import')){
        importBtn.textContent = 'Import Mission Framework';
      }
      // keep existing onClick handler (importJSON) intact
    }

    // 2) Inject Export button if not present
    if(!right.querySelector('.msx-framework-btn')){
      var exp = document.createElement('button');
      exp.className = 'msx-framework-btn';
      exp.textContent = 'Export Mission Framework';
      exp.addEventListener('click', function(){
        try {
          if (window.exportJSON) { window.exportJSON(); return; }
          if (window.MS_actions && typeof window.MS_actions.generateJSON === 'function') {
            window.MS_actions.generateJSON(); return;
          }
          console.warn('No export function found');
        } catch(e){ console.error(e); }
      });
      right.prepend(exp);
    }
  }
  document.addEventListener('DOMContentLoaded', wireFrameworkButtons);
  // Re-apply if React re-renders
  new MutationObserver(wireFrameworkButtons).observe(document.body, {childList:true, subtree:true});
})();
</script>


<!-- === Integrated CI/CD Generator v1.2 (no new screens) === -->
<script>
(function(){
  // --- Utilities ---
  function str(v){ return (v==null?'':String(v)); }
  function val(obj, path, fallback){
    try{
      return path.split('.').reduce((o,k)=> (o && (k in o) ? o[k] : undefined), obj) ?? fallback;
    }catch(_){ return fallback; }
  }
  function toProfile(sc){
    const lang = (str(sc.default_backend_language)).toLowerCase();
    if (/java/.test(lang)) return "java-maven";
    if (/python/.test(lang)) return "python-pytest";
    if (/node|javascript|ts|typescript/.test(lang)) return "node-npm";
    if (/go/.test(lang)) return "go";
    if (/dotnet|csharp/.test(lang)) return "dotnet";
    return "java-maven"; // default
  }
  function toGates(arr){
    if (Array.isArray(arr) && arr.length) return arr.map(x=>String(x).trim()).filter(Boolean);
    return "lint, unit, contract, integration, sast, sbom, iac, schema-compat, docker-scan, policy, sign"
      .split(',').map(s=>s.trim());
  }
  function registryDefault(sc){
    const r = str(sc.default_registry || "").trim();
    return r || "ghcr.io/OWNER/REPO";
  }

  // --- Generators (from LaunchPad v1.2) ---
  function genBuildTest(profile, gates){
    const has = t => gates.includes(t);
    const isJava = profile==='java-maven';
    const isNode = profile==='node-npm';
    const isPy   = profile==='python-pytest';
    let setup='';
    if(isJava) setup = "\n      - uses: actions/setup-java@v4\n        with:\n          distribution: temurin\n          java-version: '21'\n";
    if(isNode) setup = "\n      - uses: actions/setup-node@v4\n        with:\n          node-version: '20'\n";
    if(isPy)   setup = "\n      - uses: actions/setup-python@v5\n        with:\n          python-version: '3.11'\n";
    let lint='';
    if(has('lint')){
      if(isJava) lint = "      - name: Lint (Maven)\n        run: |\n          mvn -B -ntp -DskipTests=true spotless:check || true\n          mvn -B -ntp -DskipTests=true checkstyle:check || true\n";
      if(isNode) lint = "      - name: Lint (ESLint)\n        run: |\n          npm ci\n          npx eslint . || true\n";
      if(isPy)   lint = "      - name: Lint (flake8)\n        run: |\n          python -m pip install --upgrade pip\n          pip install flake8\n          flake8 . || true\n";
    }
    let tests='';
    if(has('unit') || has('integration')){
      if(isJava) tests = "      - name: Maven test (unit + integration)\n        run: mvn -B -ntp -DskipITs=false test\n";
      if(isNode) tests = "      - name: Node tests\n        run: |\n          npm ci\n          npm test --if-present\n";
      if(isPy)   tests = "      - name: PyTest\n        run: |\n          python -m pip install --upgrade pip\n          pip install -r requirements.txt || true\n          pytest -q --maxfail=1 --disable-warnings --junitxml=test-results/python-junit.xml\n";
    }
    const contract = has('contract')
      ? "      - name: Pact verify (if contracts present)\n        if: ${{ hashFiles('**/contracts/**') != '' }}\n        run: mvn -B -ntp pact:verify || echo \'No contracts\'\n" : "";
    const compat = has('schema-compat')
      ? "      - name: Schema compatibility check (if schemas present)\n        if: ${{ hashFiles('**/schemas/**') != '' }}\n        run: echo \'Implement your Avro/JSON compat check here\'\n" : "";

    return "name: ci-cd\n\non: [push, pull_request]\n\npermissions:\n  contents: read\n  packages: write\n  security-events: write\n\njobs:\n  build-test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4" + setup + lint + tests + contract + compat +
      "      - name: Upload test results\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v4\n        with:\n          name: test-results\n          path: |\n            **/target/surefire-reports/*.xml\n            **/target/failsafe-reports/*.xml\n            test-results/**/*.xml\n          if-no-files-found: ignore\n";
  }

  function genSecurity(gates){
    const has = t => gates.includes(t);
    let y = "name: security\n\non: [push, pull_request]\n\npermissions:\n  contents: read\n  security-events: write\n  packages: write\n\njobs:\n  security:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n";
    if(has('sast')) y += "      - name: Semgrep SAST\n        uses: returntocorp/semgrep-action@v1\n        with:\n          config: p/owasp-top-ten\n          generateSarif: true\n";
    if(has('docker-scan') || has('sbom') || has('sign')) y += "      - name: Set up Buildx\n        uses: docker/setup-buildx-action@v3\n      - name: Build image (no push)\n        uses: docker/build-push-action@v6\n        with:\n          context: .\n          push: false\n          load: true\n          tags: local/app:ci\n          provenance: false\n";
    if(has('docker-scan')) y += "      - name: Trivy image scan\n        uses: aquasecurity/trivy-action@0.28.0\n        with:\n          image-ref: local/app:ci\n          format: table\n          exit-code: '1'\n          ignore-unfixed: true\n";
    if(has('sbom')) y += "      - name: SBOM (Syft)\n        uses: anchore/sbom-action@v0\n        with:\n          image: local/app:ci\n          artifact-name: sbom.spdx.json\n";
    if(has('sign')) y += "      - name: Install Cosign\n        uses: sigstore/cosign-installer@v3.7.0\n      - name: Cosign sign (optional)\n        if: ${{ secrets.COSIGN_KEY != '' }}\n        env:\n          COSIGN_EXPERIMENTAL: '1'\n          COSIGN_PASSWORD: ${{ secrets.COSIGN_PASSWORD }}\n        run: |\n          printf \"%s\" \"${{ secrets.COSIGN_KEY }}\" > cosign.key\n          cosign sign --key cosign.key local/app:ci\n";
    y += "      - name: Upload security artefacts\n        uses: actions/upload-artifact@v4\n        with:\n          name: security\n          path: |\n            semgrep.sarif\n            sbom.spdx.json\n          if-no-files-found: ignore\n";
    return y;
  }

  function genIaC(gates){
    const has = t => gates.includes(t);
    let y = "name: iac-policy\n\non: [push, pull_request]\n\npermissions:\n  contents: read\n\njobs:\n  iac-policy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n";
    if(has('iac')) y += "      - name: Terraform fmt/validate/plan\n        if: ${{ hashFiles('**/*.tf') != '' }}\n        run: |\n          terraform -version || (curl -fsSL https://releases.hashicorp.com/terraform/1.9.5/terraform_1.9.5_linux_amd64.zip -o tf.zip && sudo unzip -o tf.zip -d /usr/local/bin)\n          terraform -chdir=infra fmt -check\n          terraform -chdir=infra init -input=false\n          terraform -chdir=infra validate\n          terraform -chdir=infra plan -input=false -lock=false -out=tfplan\n";
    if(has('policy')) y += "      - name: conftest policy check\n        if: ${{ hashFiles('policy/**.rego') != '' }}\n        uses: instrumenta/conftest-action@v0.3.0\n        with:\n          files: |\n            infra/**/*.tf\n            deploy/**/*.yaml\n";
    return y;
  }

  function genPackagePublish(registry){
    return "name: package-publish\non:\n  push:\n    branches: [ \"main\" ]\n  workflow_dispatch: {}\n\npermissions:\n  contents: read\n  packages: write\n\nenv:\n  REGISTRY: " + registry + "\n  IMAGE_SHA: " + registry + ":${{ github.sha }}\n  IMAGE_MAIN: " + registry + ":main\n\njobs:\n  build-push-sign:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: docker/setup-qemu-action@v3\n      - uses: docker/setup-buildx-action@v3\n      - uses: docker/login-action@v3\n        with:\n          registry: ghcr.io\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n      - name: Build & push (sha)\n        uses: docker/build-push-action@v6\n        with:\n          context: .\n          push: true\n          tags: ${{ env.IMAGE_SHA }}\n          provenance: false\n      - name: Build & push (main)\n        uses: docker/build-push-action@v6\n        with:\n          context: .\n          push: true\n          tags: ${{ env.IMAGE_MAIN }}\n          provenance: false\n      - name: Install Cosign\n        uses: sigstore/cosign-installer@v3.7.0\n      - name: Cosign sign (sha)\n        if: ${{ secrets.COSIGN_KEY != '' }}\n        env:\n          COSIGN_EXPERIMENTAL: \"1\"\n          COSIGN_PASSWORD: ${{ secrets.COSIGN_PASSWORD }}\n        run: |\n          printf \"%s\" \"${{ secrets.COSIGN_KEY }}\" > cosign.key\n          cosign sign --key cosign.key ${{ env.IMAGE_SHA }}\n      - name: Cosign sign (main)\n        if: ${{ secrets.COSIGN_KEY != '' }}\n        env:\n          COSIGN_EXPERIMENTAL: \"1\"\n          COSIGN_PASSWORD: ${{ secrets.COSIGN_PASSWORD }}\n        run: |\n          printf \"%s\" \"${{ secrets.COSIGN_KEY }}\" > cosign.key\n          cosign sign --key cosign.key ${{ env.IMAGE_MAIN }}\n";
  }

  function genPromoteDeploy(){
    return "name: promote-deploy\non:\n  workflow_dispatch:\n    inputs:\n      image:\n        description: \"Image to deploy (e.g., ghcr.io/owner/repo:sha)\"\n        required: false\n      envs:\n        description: \"Comma-separated envs to deploy (dev,staging,prod)\"\n        required: false\n        default: \"dev,staging,prod\"\n  push:\n    branches: [ \"main\" ]\n\npermissions:\n  contents: read\n  packages: read\n\nenv:\n  DEFAULT_IMAGE: ghcr.io/${{ github.repository }}:${{ github.sha }}\n  NAMESPACE: default\n  CANARY_REPLICAS: 1\n  STABLE_PERCENT: 90\n\njobs:\n  matrix-setup:\n    runs-on: ubuntu-latest\n    outputs:\n      envs: ${{ steps.mk.outputs.envs }}\n    steps:\n      - id: mk\n        run: |\n          IN=\"${{ github.event.inputs.envs }}\"\n          if [ -z \"$IN\" ]; then IN=\"dev,staging,prod\"; fi\n          echo \"envs=$(printf '[%s]' \\\"$(echo \\\"$IN\\\" | sed 's/,/","/g' | sed 's/^/\\\"/;s/$/\\\"/')\\\")\" >> $GITHUB_OUTPUT\n\n  deploy:\n    needs: matrix-setup\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        env: ${{ fromJson(needs.matrix-setup.outputs.envs) }}\n    environment: ${{ matrix.env }}\n    steps:\n      - uses: actions/checkout@v4\n      - name: Choose image\n        id: img\n        run: |\n          IMG=\"${{ github.event.inputs.image }}\"\n          if [ -z \"$IMG\" ]; then IMG=\"${{ env.DEFAULT_IMAGE }}\"; fi\n          echo \"image=$IMG\" >> $GITHUB_OUTPUT\n      - name: Install Cosign\n        uses: sigstore/cosign-installer@v3.7.0\n      - name: Verify image signature\n        env:\n          COSIGN_EXPERIMENTAL: \"1\"\n          COSIGN_PUBLIC_KEY: ${{ secrets.COSIGN_PUBLIC_KEY }}\n        run: |\n          if [ -z \"$COSIGN_PUBLIC_KEY\" ]; then\n            echo \"Missing COSIGN_PUBLIC_KEY; refusing to deploy unsigned/unverified image\" >&2\n            exit 1\n          fi\n          printf \"%s\" \"$COSIGN_PUBLIC_KEY\" > cosign.pub\n          cosign verify --key cosign.pub \"${{ steps.img.outputs.image }}\"\n      - name: Set kubeconfig\n        id: kube\n        run: |\n          ENV=\"${{ matrix.env }}\"\n          KC_VAR=\"KUBE_CONFIG_\${ENV^^}\"\n          KCONF=\"${!KC_VAR}\"\n          if [ -z \"$KCONF\" ]; then\n            echo \"Kubeconfig secret $KC_VAR is not set\" >&2\n            exit 1\n          fi\n          if echo \"$KCONF\" | grep -q \"apiVersion: v1\"; then\n            printf \"%s\" \"$KCONF\" > $HOME/.kubeconfig\n          else\n            printf \"%s\" \"$KCONF\" | base64 -d > $HOME/.kubeconfig\n          fi\n          echo \"KUBECONFIG=$HOME/.kubeconfig\" >> $GITHUB_ENV\n        env:\n          KUBE_CONFIG_DEV: ${{ secrets.KUBE_CONFIG_DEV }}\n          KUBE_CONFIG_STAGING: ${{ secrets.KUBE_CONFIG_STAGING }}\n          KUBE_CONFIG_PROD: ${{ secrets.KUBE_CONFIG_PROD }}\n      - name: Install kubectl\n        run: |\n          curl -fsSL https://storage.googleapis.com/kubernetes-release/release/v1.30.5/bin/linux/amd64/kubectl -o kubectl\n          chmod +x kubectl && sudo mv kubectl /usr/local/bin/\n      - name: Templatise manifests with image tag\n        run: |\n          ENV=\"${{ matrix.env }}\"\n          find \"deploy/\${ENV}\" -type f -name \"*.yaml\" -print0 | while IFS= read -r -d '' f; do\n            sed -i \"s#IMAGE_PLACEHOLDER#${{ steps.img.outputs.image }}#g\" \"$f\"\n            sed -i \"s#NAMESPACE_PLACEHOLDER#${{ env.NAMESPACE }}#g\" \"$f\"\n          done\n      - name: Apply canary (if present)\n        run: |\n          ENV=\"${{ matrix.env }}\"\n          if ls \"deploy/\${ENV}/canary/\"/*.yaml >/dev/null 2>&1; then\n            kubectl apply -n \"${{ env.NAMESPACE }}\" -f \"deploy/\${ENV}/canary/\"\n            kubectl rollout status -n \"${{ env.NAMESPACE }}\" deployment -l app.kubernetes.io/part-of=canary --timeout=120s\n          else\n            echo \"No canary overlay found; skipping canary\"\n          fi\n      - name: Bake\n        run: sleep 30\n      - name: Promote to stable\n        run: |\n          ENV=\"${{ matrix.env }}\"\n          kubectl apply -n \"${{ env.NAMESPACE }}\" -f \"deploy/\${ENV}/\"\n          kubectl rollout status -n \"${{ env.NAMESPACE }}\" deployment -l app.kubernetes.io/name=${{ github.event.repository.name }} --timeout=180s\n      - name: Cleanup canary\n        run: |\n          ENV=\"${{ matrix.env }}\"\n          if ls \"deploy/\${ENV}/canary/\"/*.yaml >/dev/null 2>&1; then\n            kubectl delete -n \"${{ env.NAMESPACE }}\" -f \"deploy/\${ENV}/canary/\" --ignore-not-found\n          fi\n";
  }

  function genReportMd(gates, profile){
    const tokenMap = { lint:'Lint', unit:'Unit tests', contract:'Contract tests', integration:'Integration tests', coverage:'Coverage', e2e:'End-to-end',
      sast:'SAST', 'docker-scan':'Container scan', sbom:'SBOM', sign:'Image signing', 'schema-compat':'Schema compatibility', iac:'IaC validate/plan', policy:'Policy check', observability:'Observability', chaos:'Chaos', a11y:'Accessibility', perf:'Performance'};
    const lines = ['# CI/CD Generation Report','',`Profile: **${profile}**`,'Gates:',''];
    gates.forEach(g=>lines.push(`- ${tokenMap[g] ? 'âœ…' : 'âš ï¸'} ${g}${tokenMap[g] ? '' : ' (unknown token)'}`));
    lines.push('\nFiles generated: ci-cd.yml, security.yml, iac-policy.yml, package-publish.yml, promote-deploy.yml');
    lines.push('Notes: Configure COSIGN_* and KUBE_CONFIG_* secrets for signing and deploy.');
    return lines.join('\n');
  }

  // --- Wire into MissionSmith button ---
  if (window.MS_actions) {
    const orig = window.MS_actions;
    orig.generateCICD = function(){
      try{
        const data = (typeof window.__ms_getData === 'function' ? window.__ms_getData() : window.__ms_data) || {};
        const sc = data.serviceConfig || {};
        const profile = toProfile(sc);
        const gates = toGates(val(sc, 'ci.gates', []));
        const registry = registryDefault(sc);

        const files = [
          {path: '.github/workflows/ci-cd.yml', content: genBuildTest(profile, gates)},
          {path: '.github/workflows/security.yml', content: genSecurity(gates)},
          {path: '.github/workflows/iac-policy.yml', content: genIaC(gates)},
          {path: '.github/workflows/package-publish.yml', content: genPackagePublish(registry)},
          {path: '.github/workflows/promote-deploy.yml', content: genPromoteDeploy()},
          {path: 'ci-cd-report.md', content: genReportMd(gates, profile)}
        ];

        // bundle download
        const chunks = ['# --- BEGIN MISSIONSMITH CI/CD BUNDLE ---'];
        for (const f of files) { chunks.push(`\n# FILE: ${f.path}\n\n${f.content}`); }
        const blob = new Blob([chunks.join('\n')], {type:'text/plain'});
        const a = document.createElement('a');
        a.href = URL.createObjectURL(blob);
        a.download = 'mission-cicd-bundle.txt';
        a.click();
        setTimeout(()=>URL.revokeObjectURL(a.href), 200);

        alert('âœ… CI/CD workflows generated. Add COSIGN_* and KUBE_CONFIG_* secrets for signing/deploy.');
      }catch(e){
        console.error('generateCICD failed', e);
        alert('Failed to generate CI/CD workflows.');
      }
    };
    window.MS_actions = orig;
  }
})();
</script>

<!-- === Integrated IaC Generator v1.0 === -->
<script>
(function(){
  // Helpers
  function str(v){ return (v==null?'':String(v)); }
  function val(obj, path, fallback){
    try{ return path.split('.').reduce((o,k)=> (o && (k in o) ? o[k] : undefined), obj) ?? fallback; }catch(_){ return fallback; }
  }
  function appName(sc){
    const n = str(sc.default_service_name || 'app').trim() || 'app';
    return n.replace(/[^a-z0-9-]/ig,'-').toLowerCase();
  }
  function imageDefault(sc){
    const reg = str(sc.default_registry || '').trim() || 'ghcr.io/OWNER/REPO';
    return reg + ':main';
  }
  function sloTarget(sc, name, dflt){ try{ return (sc?.nfr?.slo||[]).find(s=>s.name===name)?.target ?? dflt; }catch(_){ return dflt; } }

  // YAML templates (with placeholders to be replaced by the deploy workflow)
  function baseDeploymentYaml(app){
    return `apiVersion: apps/v1
kind: Deployment
metadata:
  name: ${app}
  namespace: NAMESPACE_PLACEHOLDER
  labels:
    app.kubernetes.io/name: ${app}
    app.kubernetes.io/instance: ${app}
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: ${app}
  template:
    metadata:
      labels:
        app.kubernetes.io/name: ${app}
    spec:
      containers:
      - name: ${app}
        image: IMAGE_PLACEHOLDER
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 8080
        env:
        - name: OTEL_SERVICE_NAME
          value: "${app}"
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 10
        resources:
          requests:
            cpu: "100m"
            memory: "128Mi"
          limits:
            cpu: "500m"
            memory: "512Mi"
`;
  }

  function serviceYaml(app){
    return `apiVersion: v1
kind: Service
metadata:
  name: ${app}
  namespace: NAMESPACE_PLACEHOLDER
spec:
  selector:
    app.kubernetes.io/name: ${app}
  ports:
  - name: http
    port: 80
    targetPort: 8080
  type: ClusterIP
`;
  }

  function namespaceYaml(){
    return `apiVersion: v1
kind: Namespace
metadata:
  name: NAMESPACE_PLACEHOLDER
`;
  }

  function canaryDeploymentYaml(app){
    return `apiVersion: apps/v1
kind: Deployment
metadata:
  name: ${app}-canary
  namespace: NAMESPACE_PLACEHOLDER
  labels:
    app.kubernetes.io/name: ${app}
    app.kubernetes.io/part-of: canary
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: ${app}
      app.kubernetes.io/part-of: canary
  template:
    metadata:
      labels:
        app.kubernetes.io/name: ${app}
        app.kubernetes.io/part-of: canary
    spec:
      containers:
      - name: ${app}
        image: IMAGE_PLACEHOLDER
        ports:
        - containerPort: 8080
`;
  }

  // Terraform (kubernetes provider) skeleton
  function tfProviders(){
    return `terraform {
  required_version = ">= 1.5.0"
  required_providers {
    kubernetes = {
      source  = "hashicorp/kubernetes"
      version = ">= 2.32.0"
    }
  }
}

# Uses KUBECONFIG from the environment (set by CI)
provider "kubernetes" {}
`;
  }
  function tfVariables(app, image){
    return `variable "namespace" { type = string  default = "default" }
variable "app_name"  { type = string  default = "${app}" }
variable "image"     { type = string  default = "${image}" }
`;
  }
  function tfMain(){
    return `resource "kubernetes_namespace" "ns" {
  metadata { name = var.namespace }
}

resource "kubernetes_deployment" "app" {
  metadata {
    name      = var.app_name
    namespace = var.namespace
    labels = {
      "app.kubernetes.io/name" = var.app_name
    }
  }
  spec {
    replicas = 2
    selector {
      match_labels = { "app.kubernetes.io/name" = var.app_name }
    }
    template {
      metadata {
        labels = { "app.kubernetes.io/name" = var.app_name }
      }
      spec {
        container {
          name  = var.app_name
          image = var.image
          port  { container_port = 8080 }
        }
      }
    }
  }
}

resource "kubernetes_service" "svc" {
  metadata {
    name      = var.app_name
    namespace = var.namespace
  }
  spec {
    selector = { "app.kubernetes.io/name" = var.app_name }
    port { port = 80  target_port = 8080 }
    type = "ClusterIP"
  }
}
`;
  }
  function tfOutputs(){
    return `output "service_name" { value = kubernetes_service.svc.metadata[0].name }
output "namespace"    { value = kubernetes_namespace.ns.metadata[0].name }
`;
  }

  function readme(){
    return `# MissionSmith IaC Bundle

This bundle includes:
- Kubernetes deploy manifests under \`deploy/{dev,staging,prod}\` (with \`IMAGE_PLACEHOLDER\` and \`NAMESPACE_PLACEHOLDER\` tokens)
- A Terraform skeleton under \`infra/\` using the Kubernetes provider

## Using with the generated CI/CD
- The \`promote-deploy.yml\` workflow will replace the placeholders and apply the manifests.
- Set the following secrets in your repo for each environment:
  - \`COSIGN_PUBLIC_KEY\` (for verification)
  - \`KUBE_CONFIG_DEV\`, \`KUBE_CONFIG_STAGING\`, \`KUBE_CONFIG_PROD\`

> You can also use \`infra/\` with \`terraform -chdir=infra init && terraform -chdir=infra apply -var namespace=<env> -var image=<image>\`.
`;
  }

  function bundleFiles(data){
    const sc = data?.serviceConfig || {};
    const app = appName(sc);
    const image = imageDefault(sc);

    const envs = ["dev","staging","prod"];
    const files = [];

    // Env-specific k8s manifests
    envs.forEach(env => {
      files.push({ path: `deploy/${env}/namespace.yaml`, content: namespaceYaml() });
      files.push({ path: `deploy/${env}/deployment.yaml`, content: baseDeploymentYaml(app) });
      files.push({ path: `deploy/${env}/service.yaml`, content: serviceYaml(app) });
      files.push({ path: `deploy/${env}/canary/deployment.yaml`, content: canaryDeploymentYaml(app) });
    });

    // Terraform skeleton
    files.push({ path: `infra/providers.tf`, content: tfProviders() });
    files.push({ path: `infra/variables.tf`, content: tfVariables(app, image) });
    files.push({ path: `infra/main.tf`, content: tfMain() });
    files.push({ path: `infra/outputs.tf`, content: tfOutputs() });
    files.push({ path: `README-IAC.md`, content: readme() });

    return files;
  }

  // Override the existing IaC button behaviour
  if (window.MS_actions) {
    const orig = window.MS_actions;
    orig.generateDeploy = function(){
      try{
        const data = (typeof window.__ms_getData === 'function' ? window.__ms_getData() : window.__ms_data) || {};
        const files = bundleFiles(data);

        const chunks = ['# --- BEGIN MISSIONSMITH IAC BUNDLE ---'];
        for (const f of files) { chunks.push(`\n# FILE: ${f.path}\n\n${f.content}`); }
        const blob = new Blob([chunks.join('\n')], {type:'text/plain'});
        const a = document.createElement('a');
        a.href = URL.createObjectURL(blob);
        a.download = 'mission-iac-bundle.txt';
        a.click();
        setTimeout(()=>URL.revokeObjectURL(a.href), 200);

        alert('âœ… IaC bundle generated: deploy/{env}/... + infra/ (Terraform).');
      }catch(e){
        console.error('generateDeploy failed', e);
        alert('Failed to generate IaC bundle.');
      }
    };
    window.MS_actions = orig;
  }
})();
</script>


<!-- === MissionSmith Lineage Generator v1.0 === -->
<script>
(function(){
  function safe(v, d){ return (v===undefined || v===null) ? d : v; }
  function norm(s){ return String(s||'').trim().replace(/[^a-z0-9-_:.]/ig,'_'); }
  function title(s){ return String(s||'').trim(); }

  // Extract a best-effort model from the app's data blob
  function extractModel(data){
    const sc = data?.serviceConfig || {};
    const services = [];
    const datasets = [];
    const policies = [];
    const pipelines = [];
    const objectives = [];

    // Service
    const appName = sc.default_service_name || 'app';
    services.push({id: norm(appName), name: title(appName), kind:'service'});

    // Datasets / APIs (best effort)
    const ds = safe(sc.data_sources, []);
    ds.forEach((d, i)=>{
      const name = d?.name || `dataset_${i+1}`;
      datasets.push({id: norm(name), name: title(name), kind:'dataset'});
    });

    // Pipelines (from CI/CD + build stages if present)
    const pl = safe(data?.pipelines, []);
    pl.forEach((p, i)=>{
      const name = p?.name || `pipeline_${i+1}`;
      pipelines.push({id: norm(name), name: title(name), kind:'pipeline'});
    });

    // Policies / Guardrails
    const pol = safe(data?.policies, []);
    pol.forEach((p, i)=>{
      const name = p?.name || `policy_${i+1}`;
      policies.push({id: norm(name), name: title(name), kind:'policy'});
    });

    // Objectives (Mission Objectives sheet)
    const obj = safe(data?.objectives || data?.missionObjectives, []);
    obj.forEach((o, i)=>{
      const name = o?.reference || o?.name || `objective_${i+1}`;
      objectives.push({id: norm(name), name: title(name), kind:'objective'});
    });

    // Build edges heuristically:
    const edges = [];
    // service uses datasets
    datasets.forEach(d => edges.push({from: d.id, to: norm(appName), relation: 'consumed_by'}));
    // pipelines deploy service
    pipelines.forEach(p => edges.push({from: p.id, to: norm(appName), relation: 'deploys'}));
    // policies govern service and pipelines
    policies.forEach(pol => {
      edges.push({from: pol.id, to: norm(appName), relation:'governs'});
      pipelines.forEach(p => edges.push({from: pol.id, to: p.id, relation:'governs'}));
    });
    // objectives drive pipelines (if any)
    objectives.forEach(o => {
      pipelines.forEach(p => edges.push({from: o.id, to: p.id, relation:'drives'}));
    });

    return {services, datasets, policies, pipelines, objectives, edges};
  }

  function toCSV(model){
    const header = "from,to,relation\n";
    const rows = model.edges.map(e => `${e.from},${e.to},${e.relation}`);
    return header + rows.join("\n") + "\n";
  }

  function toDOT(model){
    const lines = [];
    lines.push('digraph MissionSmithLineage {');
    lines.push('  rankdir=LR;');
    function node(n, shape, color){
      lines.push(`  "${n.id}" [label="${n.name}\\n(${n.kind})", shape=${shape}, style=filled, fillcolor="${color}"];`);
    }
    model.datasets.forEach(n => node(n, 'cylinder', '#E0F7FA'));
    model.services.forEach(n => node(n, 'box', '#E8F5E9'));
    model.pipelines.forEach(n => node(n, 'component', '#EDE7F6'));
    model.policies.forEach(n => node(n, 'octagon', '#FFF3E0'));
    model.objectives.forEach(n => node(n, 'ellipse', '#F3E5F5'));

    model.edges.forEach(e => lines.push(`  "${e.from}" -> "${e.to}" [label="${e.relation}"];`));
    lines.push('}');
    return lines.join("\n");
  }

  // Minimal OpenLineage-style JSON (not full spec; enough for import/visualization tools)
  function toOpenLineage(model){
    const now = new Date().toISOString();
    const events = [];

    // Emit one RUN event per pipeline, pointing to the service dataset outputs
    model.pipelines.forEach(p => {
      const outputs = model.services.map(s => ({namespace:"app", name:s.name}));
      const inputs  = model.datasets.map(d => ({namespace:"data", name:d.name}));
      events.push({
        eventType: "COMPLETE",
        eventTime: now,
        run: { runId: `${p.id}-${now}` },
        job: { namespace: "mission-smith", name: p.name },
        inputs, outputs,
        producer: "missionsmith/lineage-generator"
      });
    });
    return JSON.stringify({version:"0.1", events}, null, 2);
  }

  // Hook up Lineage button if MS_actions present
  if (window.MS_actions){
    const orig = window.MS_actions;
    orig.generateLineage = function(){
      try{
        const data = (typeof window.__ms_getData === 'function' ? window.__ms_getData() : window.__ms_data) || {};
        const model = extractModel(data);

        const files = [
          { path: 'lineage/edges.csv', content: toCSV(model) },
          { path: 'lineage/graph.dot', content: toDOT(model) },
          { path: 'lineage/openlineage.json', content: toOpenLineage(model) },
          { path: 'lineage/README-LINEAGE.md', content:
`# MissionSmith Lineage Bundle

This bundle provides three interoperable artifacts:

1) **edges.csv** â€” simple \`from,to,relation\` edge list (easy to load in Neo4j/NetworkX/Gephi).
2) **graph.dot** â€” Graphviz DOT for quick rendering to SVG/PNG (\`dot -Tsvg graph.dot -o graph.svg\`).
3) **openlineage.json** â€” lightweight OpenLineage-style events that many tools can ingest (e.g. Marquez).

### Relations
- \`consumed_by\`: dataset â†’ service
- \`deploys\`: pipeline â†’ service
- \`governs\`: policy â†’ (service|pipeline)
- \`drives\`: objective â†’ pipeline

> Model is generated bestâ€‘effort from your MissionSmith data. Customize by editing this README or the JSON.
`
          }
        ];

        const chunks = ['# --- BEGIN MISSIONSMITH LINEAGE BUNDLE ---'];
        for (const f of files){ chunks.push(`\n# FILE: ${f.path}\n\n${f.content}`); }
        const blob = new Blob([chunks.join('\n')], {type:'text/plain'});
        const a = document.createElement('a');
        a.href = URL.createObjectURL(blob);
        a.download = 'mission-lineage-bundle.txt';
        a.click();
        setTimeout(()=>URL.revokeObjectURL(a.href), 200);

        alert('âœ… Lineage bundle generated: edges.csv, graph.dot, openlineage.json.');
      }catch(e){
        console.error('generateLineage failed', e);
        alert('Failed to generate lineage bundle.');
      }
    };
    window.MS_actions = orig;
  }
})();
</script>


<!-- === MissionSmith Analytics Generator v1.0 === -->
<script>
(function(){
  function safe(v, d){ return (v===undefined||v===null) ? d : v; }
  function norm(s){ return String(s||'').trim().replace(/[^a-z0-9-_:.]/ig,'_'); }
  function title(s){ return String(s||'').trim(); }

  function extractKPIs(data){
    // Try multiple places: nfr.slo, nfr.kpis, analytics.kpis, objectives.*.kpi
    const sc = data?.serviceConfig || {};
    const slo = safe(sc?.nfr?.slo, []);
    const k1 = slo.map(s => ({key: norm(s.name||s.id||'slo'), name: title(s.name||s.id||'SLO'), target: s.target, window: s.window || '30d', unit: s.unit || '%', source: s.source || 'app_metrics'}));

    const k2 = safe(sc?.nfr?.kpis, []).map(k => ({
      key: norm(k.key||k.name), name: title(k.name||k.key), unit: k.unit||'count', target: k.target, source: k.source||'events'
    }));

    const k3 = safe(data?.analytics?.kpis, []).map(k => ({
      key: norm(k.key||k.name), name: title(k.name||k.key), unit: k.unit||'count', target: k.target, source: k.source||'warehouse'
    }));

    // derive from objectives with "KPI:" prefix
    const objectives = safe(data?.objectives || data?.missionObjectives, []);
    const k4 = objectives
      .filter(o => (o?.kpi || '').toString().length || /kpi[:=]/i.test(String(o?.notes||'')))
      .map((o,i)=>{
        const nm = o?.kpi || String(o?.notes||'').match(/kpi[:=]\s*([^\n]+)/i)?.[1] || `objective_kpi_${i+1}`;
        return {key: norm(nm), name: title(nm), unit: 'count', target: o?.target, source: 'derived'};
      });

    const all = [...k1, ...k2, ...k3, ...k4];
    // de-dup by key
    const seen = new Set(); const uniq=[];
    all.forEach(k => { if(!k.key) return; if(!seen.has(k.key)){ seen.add(k.key); uniq.push(k);} });
    if (uniq.length===0){
      // Provide sensible defaults
      uniq.push({key:'latency_p95_ms', name:'Latency p95', unit:'ms', target: 300, source:'app_metrics'});
      uniq.push({key:'error_rate_pct', name:'Error Rate', unit:'%', target: 1, source:'app_metrics'});
      uniq.push({key:'throughput_rps', name:'Throughput', unit:'rps', target: null, source:'app_metrics'});
    }
    return uniq;
  }

  function toMetricsCatalog(kpis){
    const lines = [];
    lines.push('apiVersion: v1');
    lines.push('kind: MetricsCatalog');
    lines.push('metadata:');
    lines.push('  name: missionsmith-metrics');
    lines.push('spec:');
    lines.push('  kpis:');
    kpis.forEach(k => {
      lines.push(`  - key: ${k.key}`);
      lines.push(`    name: "${k.name}"`);
      if (k.unit!=null) lines.push(`    unit: "${k.unit}"`);
      if (k.target!=null) lines.push(`    target: ${k.target}`);
      lines.push(`    source: "${k.source||'warehouse'}"`);
      lines.push(`    owners:`);
      lines.push(`      - platform`);
    });
    return lines.join('\n') + '\n';
  }

  function toPrometheusRules(kpis, app){
    const hdr = [
      'groups:',
      '- name: missionsmith.rules',
      '  interval: 30s',
      '  rules:'
    ];
    const rules = [];
    kpis.forEach(k => {
      if(/error_rate/.test(k.key)){
        rules.push(
`  - alert: HighErrorRate
    expr: rate(http_requests_total{service="${app}",status=~"5.."}[5m]) / clamp_min(rate(http_requests_total{service="${app}"}[5m]),1) * 100 > ${k.target||1}
    for: 10m
    labels: { severity: "page" }
    annotations:
      summary: "High error rate on ${app}"
      description: "Error rate > ${k.target||1}% for 10m"`);
      }
      if(/latency|p95/.test(k.key)){
        rules.push(
`  - alert: HighLatencyP95
    expr: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{service="${app}"}[5m])) by (le)) * 1000 > ${k.target||300}
    for: 10m
    labels: { severity: "page" }
    annotations:
      summary: "High latency p95 on ${app}"
      description: "Latency p95 > ${k.target||300}ms for 10m"`);
      }
    });
    if (rules.length===0){
      rules.push(
`  - alert: ServiceDown
    expr: up{service="${app}"} == 0
    for: 5m
    labels: { severity: "page" }
    annotations:
      summary: "${app} is down"
      description: "No scrape targets reporting for 5m"`);
    }
    return hdr.concat(rules).join('\n') + '\n';
  }

  function toGrafanaDashboard(kpis, app){
    // Minimal Grafana JSON model (v5+ export-ish, not strict; user can import and tweak).
    const dash = {
      annotations: { list: [{builtIn:1, datasource:'-- Grafana --', enable:true, hide:true, iconColor:'rgba(0, 211, 255, 1)', name:'Annotations & Alerts', type:'dashboard'}]},
      editable: true,
      graphTooltip: 0,
      panels: [],
      schemaVersion: 25,
      style: 'dark',
      tags: ['missionsmith','starter'],
      templating: { list: [{name: 'service', type: 'query', query: `label_values(up, service)`, label: 'Service', current: {text: app, value: app}}]},
      time: { from: 'now-6h', to: 'now' },
      timepicker: {},
      timezone: '',
      title: `${app} | MissionSmith Analytics`,
      version: 1
    };

    let id = 1; let y=0;
    function panelFor(key, title, expr){
      const p = {
        id: id++,
        gridPos: {h:8, w:12, x: (id%2?0:12), y: y + (id%2?0:8)},
        type: 'timeseries',
        title: `${title}`,
        targets: [{expr, refId:'A'}]
      };
      return p;
    }

    // Basic panels
    dash.panels.push(panelFor('rps', 'Throughput (RPS)', `sum(rate(http_requests_total{service="$service"}[1m]))`));
    dash.panels.push(panelFor('latency_p95', 'Latency p95 (ms)', `histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{service="$service"}[5m])) by (le)) * 1000`));
    dash.panels.push(panelFor('error_rate', 'Error Rate (%)', `sum(rate(http_requests_total{service="$service",status=~"5.."}[5m])) / clamp_min(sum(rate(http_requests_total{service="$service"}[5m])),1) * 100`));

    // KPI panels
    kpis.forEach(k => {
      if (/latency|p95/.test(k.key) || /error_rate/.test(k.key) || /throughput|rps/.test(k.key)) return;
      // Put generic counter panels â€” user can edit later
      dash.panels.push(panelFor(k.key, k.name, `sum(missionsmith_${k.key}{service="$service"})`));
    });

    return JSON.stringify(dash, null, 2);
  }

  function toDBTScaffold(app){
    return `# dbt project for MissionSmith
name: 'missionsmith_${app}'
version: '1.0'
config-version: 2

profile: 'default'

models:
  missionsmith_${app}:
    +materialized: view
`;
  }

  function toDBTModelSQL(kpis){
    const lines = [];
    lines.push('-- Example KPI model (replace with your warehouse SQL)');
    lines.push('with events as (');
    lines.push('  select * from source(\'app\', \'events\')');
    lines.push(')');
    lines.push('select');
    kpis.forEach((k,i)=>{
      const comma = (i<kpis.length-1)?',':'';
      lines.push(`  /* ${k.name} */ null as ${k.key}${comma}`);
    });
    lines.push('from events');
    lines.push('limit 1');
    return lines.join('\n') + '\n';
  }

  if (window.MS_actions){
    const orig = window.MS_actions;
    orig.generateAnalytics = function(){
      try{
        const data = (typeof window.__ms_getData === 'function' ? window.__ms_getData() : window.__ms_data) || {};
        const sc = data?.serviceConfig || {};
        const app = (sc.default_service_name || 'app').toString().trim();
        const kpis = extractKPIs(data);

        const files = [
          { path: 'analytics/metrics-catalog.yaml', content: toMetricsCatalog(kpis) },
          { path: 'analytics/prometheus-rules.yaml', content: toPrometheusRules(kpis, app) },
          { path: 'analytics/grafana-dashboard.json', content: toGrafanaDashboard(kpis, app) },
          { path: 'analytics/dbt/project.yml', content: toDBTScaffold(app) },
          { path: 'analytics/dbt/models/kpis.sql', content: toDBTModelSQL(kpis) },
          { path: 'analytics/README-ANALYTICS.md', content:
`# MissionSmith Analytics Bundle

This starter pack gives you:
- **metrics-catalog.yaml** â€” canonical KPI list (keys, units, targets, ownership).
- **prometheus-rules.yaml** â€” alert rules keyed off latency, error rate, and common KPIs.
- **grafana-dashboard.json** â€” importable dashboard with RPS, p95 latency, error %, and KPI panels.
- **dbt/** â€” a minimal scaffold to materialize KPI views in your warehouse.

## Next steps
1. Import \`grafana-dashboard.json\` into Grafana; set Prometheus as the data source.
2. Load \`prometheus-rules.yaml\` into your Prometheus/Alertmanager setup.
3. Store your KPI definitions in \`metrics-catalog.yaml\` and keep them versioned with code.
4. Point \`dbt/models/kpis.sql\` at your real warehouse schema and build with \`dbt build\`.

> KPIs were inferred from your MissionSmith data (nfr.slo / nfr.kpis / analytics.kpis / objectives). Edit this bundle as needed.
`}
        ];

        const chunks = ['# --- BEGIN MISSIONSMITH ANALYTICS BUNDLE ---'];
        files.forEach(f => chunks.push(`\n# FILE: ${f.path}\n\n${f.content}`));
        const blob = new Blob([chunks.join('\n')], {type:'text/plain'});
        const a = document.createElement('a');
        a.href = URL.createObjectURL(blob);
        a.download = 'mission-analytics-bundle.txt';
        a.click();
        setTimeout(()=>URL.revokeObjectURL(a.href), 200);

        alert('âœ… Analytics bundle generated: metrics catalog, Prometheus rules, Grafana dashboard, dbt scaffold.');
      }catch(e){
        console.error('generateAnalytics failed', e);
        alert('Failed to generate analytics bundle.');
      }
    };
    window.MS_actions = orig;
  }
})();
</script>

</body>
</html>


===== FILE: app_frontend\README.md =====
# React + Vite

This template provides a minimal setup to get React working in Vite with HMR and some ESLint rules.

Currently, two official plugins are available:

- [@vitejs/plugin-react](https://github.com/vitejs/vite-plugin-react/blob/main/packages/plugin-react) uses [Babel](https://babeljs.io/) (or [oxc](https://oxc.rs) when used in [rolldown-vite](https://vite.dev/guide/rolldown)) for Fast Refresh
- [@vitejs/plugin-react-swc](https://github.com/vitejs/vite-plugin-react/blob/main/packages/plugin-react-swc) uses [SWC](https://swc.rs/) for Fast Refresh

## React Compiler

The React Compiler is not enabled on this template because of its impact on dev & build performances. To add it, see [this documentation](https://react.dev/learn/react-compiler/installation).

## Expanding the ESLint configuration

If you are developing a production application, we recommend using TypeScript with type-aware lint rules enabled. Check out the [TS template](https://github.com/vitejs/vite/tree/main/packages/create-vite/template-react-ts) for information on how to integrate TypeScript and [`typescript-eslint`](https://typescript-eslint.io) in your project.


===== FILE: app_frontend\src\App.css =====
#root {
  max-width: 1280px;
  margin: 0 auto;
  padding: 2rem;
  text-align: center;
}

.logo {
  height: 6em;
  padding: 1.5em;
  will-change: filter;
  transition: filter 300ms;
}
.logo:hover {
  filter: drop-shadow(0 0 2em #646cffaa);
}
.logo.react:hover {
  filter: drop-shadow(0 0 2em #61dafbaa);
}

@keyframes logo-spin {
  from {
    transform: rotate(0deg);
  }
  to {
    transform: rotate(360deg);
  }
}

@media (prefers-reduced-motion: no-preference) {
  a:nth-of-type(2) .logo {
    animation: logo-spin infinite 20s linear;
  }
}

.card {
  padding: 2em;
}

.read-the-docs {
  color: #888;
}


===== FILE: app_frontend\src\App.jsx =====
import React, { useEffect, useMemo, useState } from "react";
import MissionLogPanel from "./MissionLogPanel";
import MissionAtlasPanel from "./MissionAtlasPanel";
import DetailedClientProfilePanel from "./DetailedClientProfilePanel";
import logo from "./assets/m7_single_client_view.png";

const BACKEND_BASE_URL = "http://127.0.0.1:8000";

function App() {
  const [clientId, setClientId] = useState("");
  const [loading, setLoading] = useState(false);
  const [profile, setProfile] = useState(null);
  const [sources, setSources] = useState([]);
  const [error, setError] = useState("");

  // NEW: toggle detailed panel (no routing, no landing regression)
  const [showDetailedProfile, setShowDetailedProfile] = useState(false);

  // Client index (landing screen list)
  const [clientIndex, setClientIndex] = useState([]); // [{client_id,name,risk_rating,status,segment}]
  const [clients, setClients] = useState([]); // datalist IDs
  const [clientsLoading, setClientsLoading] = useState(false);
  const [clientIndexError, setClientIndexError] = useState("");

  // Landing screen search & filters
  const [clientSearch, setClientSearch] = useState("");
  const [riskFilter, setRiskFilter] = useState("All");
  const [statusFilter, setStatusFilter] = useState("All");

  // 'scv' | 'missionLog' | 'missionAtlas'
  const [activeView, setActiveView] = useState("scv");

  // NEW: Pre-Matched Records (ST-05 demo ingestion)
  const [preMatchedRecords, setPreMatchedRecords] = useState([]);
  const [preMatchedLoading, setPreMatchedLoading] = useState(false);
  const [preMatchedError, setPreMatchedError] = useState("");
  const [preMatchedNotice, setPreMatchedNotice] = useState(""); // NEW: neutral demo message

  const isDemoIngestionEnabled = async () => {
    try {
      const res = await fetch("/demo_ingestion_enabled.json", { cache: "no-store" });
      if (!res.ok) return false;

      const data = await res.json();
      return data?.enabled === true;
    } catch {
      return false;
    }
  };

  const fetchPreMatched = async (opts = { silent: false }) => {
    const silent = Boolean(opts?.silent);

    setPreMatchedLoading(true);
    setPreMatchedError("");
    if (!silent) setPreMatchedNotice("");

    try {
      const enabled = await isDemoIngestionEnabled();
      if (!enabled) {
        setPreMatchedRecords([]);
        setPreMatchedError("");
        if (!silent) setPreMatchedNotice("Not enabled yet");
        return;
      }

      const res = await fetch(
        `${BACKEND_BASE_URL}/ingestion/crm/contacts?source_system=DEMO_CRM`
      );
      if (!res.ok) {
        const detail = await res.json().catch(() => ({}));
        throw new Error(
          detail.detail || `Failed to fetch pre-matched records (${res.status}).`
        );
      }

      const data = await res.json();
      const records = Array.isArray(data?.records) ? data.records : [];
      setPreMatchedRecords(records);
      setPreMatchedNotice("");
    } catch (err) {
      setPreMatchedRecords([]);
      setPreMatchedNotice("");
      setPreMatchedError(err?.message || "Failed to fetch pre-matched records.");
    } finally {
      setPreMatchedLoading(false);
    }
  };

  // Fetch client index (best-effort; UI degrades gracefully if endpoint not available)
  useEffect(() => {
    let cancelled = false;

    const normaliseRow = (x) => {
      if (typeof x === "string") {
        return {
          client_id: x,
          name: "",
          risk_rating: "",
          status: "",
          segment: "",
        };
      }

      const client_id = x?.client_id ?? x?.clientId ?? x?.id ?? "";
      const name =
        x?.name ??
        x?.full_name ??
        x?.fullName ??
        x?.client_name ??
        x?.clientName ??
        "";
      const risk_rating = x?.risk_rating ?? x?.riskRating ?? x?.risk ?? "";
      const status =
        x?.status ?? x?.current_status ?? x?.currentStatus ?? x?.state ?? "";
      const segment = x?.segment ?? x?.client_segment ?? x?.clientSegment ?? "";

      return {
        client_id: String(client_id || "").trim(),
        name: String(name || "").trim(),
        risk_rating: String(risk_rating || "").trim(),
        status: String(status || "").trim(),
        segment: String(segment || "").trim(),
      };
    };

    const fetchClientIndex = async () => {
      setClientsLoading(true);
      setClientIndexError("");

      try {
        const res = await fetch(`${BACKEND_BASE_URL}/clients/`);
        if (!res.ok) {
          throw new Error(`Client list not available (${res.status}).`);
        }

        const data = await res.json();
        if (cancelled) return;

        const raw = Array.isArray(data) ? data : data?.clients || [];
        const rows = raw
          .map(normaliseRow)
          .filter((r) => r.client_id && r.client_id.length > 0);

        const ids = rows.map((r) => r.client_id);

        setClientIndex(rows);
        setClients(ids);
      } catch (err) {
        console.warn(err);
        if (!cancelled) {
          setClientIndex([]);
          setClients([]);
          setClientIndexError(err?.message || "Client list not available.");
        }
      } finally {
        if (!cancelled) setClientsLoading(false);
      }
    };

    fetchClientIndex();

    // NEW: fetch pre-matched records on landing load (silent: no "Not enabled yet" banner)
    fetchPreMatched({ silent: true });

    return () => {
      cancelled = true;
    };
  }, []);

  const filteredClientIndex = useMemo(() => {
    const q = clientSearch.trim().toLowerCase();

    return clientIndex.filter((c) => {
      const matchesSearch =
        !q ||
        c.client_id.toLowerCase().includes(q) ||
        (c.name || "").toLowerCase().includes(q) ||
        (c.segment || "").toLowerCase().includes(q) ||
        (c.status || "").toLowerCase().includes(q) ||
        (c.risk_rating || "").toLowerCase().includes(q);

      const matchesRisk =
        riskFilter === "All" ||
        (c.risk_rating || "").toLowerCase() === riskFilter.toLowerCase();

      const matchesStatus =
        statusFilter === "All" ||
        (c.status || "").toLowerCase() === statusFilter.toLowerCase();

      return matchesSearch && matchesRisk && matchesStatus;
    });
  }, [clientIndex, clientSearch, riskFilter, statusFilter]);

  const distinctRiskRatings = useMemo(() => {
    const set = new Set(
      clientIndex
        .map((c) => (c.risk_rating || "").trim())
        .filter((v) => v.length > 0)
    );
    return Array.from(set).sort((a, b) => a.localeCompare(b));
  }, [clientIndex]);

  const distinctStatuses = useMemo(() => {
    const set = new Set(
      clientIndex
        .map((c) => (c.status || "").trim())
        .filter((v) => v.length > 0)
    );
    return Array.from(set).sort((a, b) => a.localeCompare(b));
  }, [clientIndex]);

  const handleSubmit = async (e) => {
    e.preventDefault();
    if (!clientId.trim()) {
      setError("Please enter a Client ID.");
      return;
    }

    setError("");
    setLoading(true);
    setProfile(null);
    setSources([]);
    setShowDetailedProfile(false); // NEW: reset panel on new fetch

    try {
      const encodedId = encodeURIComponent(clientId.trim());

      const profileRes = await fetch(
        `${BACKEND_BASE_URL}/clients/${encodedId}/profile`
      );
      if (!profileRes.ok) {
        const detail = await profileRes.json().catch(() => ({}));
        throw new Error(detail.detail || "Failed to fetch profile.");
      }
      const profileJson = await profileRes.json();

      // Keep existing logging
      console.log("Profile Response:", profileJson);

      setProfile(profileJson);

      // âœ… CHANGE 1: scroll to the profile section after loading
      setTimeout(() => {
        const el = document.getElementById("scv-profile");
        if (el) el.scrollIntoView({ behavior: "smooth", block: "start" });
      }, 50);

      const sourcesRes = await fetch(
        `${BACKEND_BASE_URL}/clients/${encodedId}/sources`
      );
      const sourcesJson = sourcesRes.ok ? await sourcesRes.json() : [];

      setSources(sourcesJson);
    } catch (err) {
      console.error(err);
      setError(err.message || "Something went wrong.");
    } finally {
      setLoading(false);
    }
  };

  const isMissionLog = activeView === "missionLog";
  const isMissionAtlas = activeView === "missionAtlas";

  const viewDetailsDisabled = !profile;

  return (
    <div className="min-h-screen bg-gray-100">
      {/* Header with MissionHalo logo */}
      <header className="bg-white shadow-sm">
        <div className="max-w-6xl mx-auto px-4 py-4">
          <img
            src={logo}
            alt="M7 single client view"
            className="h-16 w-auto md:h-20"
          />
        </div>

        {/* Mission buttons bar */}
        <div className="bg-gray-100 border-t border-gray-200">
          <div className="max-w-6xl mx-auto px-4 py-3 flex justify-end gap-4">
            <button
              type="button"
              style={{ fontFamily: "Fjalla One" }}
              className="inline-flex items-center justify-center px-8 py-2.5 rounded-md text-base text-gray-900 bg-[rgb(176,192,159)] shadow-sm transition-all duration-150 hover:-translate-y-0.5 hover:shadow-md active:translate-y-0 active:shadow-sm"
              onClick={() =>
                window.open(
                  `${window.location.origin}/MissionSmith-M7-SingleClientView.html`,
                  "_blank",
                  "noopener,noreferrer"
                )
              }
            >
              MissionSmith
            </button>

            <button
              type="button"
              style={{ fontFamily: "Fjalla One" }}
              className="inline-flex items-center justify-center px-8 py-2.5 rounded-md text-base text-gray-900 bg-[rgb(205,226,235)] shadow-sm transition-all duration-150 hover:-translate-y-0.5 hover:shadow-md active:translate-y-0 active:shadow-sm"
              onClick={() => setActiveView("missionAtlas")}
            >
              MissionAtlas
            </button>

            <button
              type="button"
              style={{ fontFamily: "Fjalla One" }}
              className="inline-flex items-center justify-center px-8 py-2.5 rounded-md text-base text-gray-900 bg-[rgb(241,205,86)] shadow-sm transition-all duration-150 hover:-translate-y-0.5 hover:shadow-md active:translate-y-0 active:shadow-sm"
              onClick={() => setActiveView("missionLog")}
            >
              MissionLog
            </button>
          </div>
        </div>
      </header>

      <main className="max-w-6xl mx-auto px-4 py-6">
        {isMissionLog ? (
          <MissionLogPanel setActiveView={setActiveView} />
        ) : isMissionAtlas ? (
          <MissionAtlasPanel />
        ) : (
          <>
            {/* Find client profile (always shown in SCV view) */}
            <section className="bg-white rounded-halo shadow-sm border border-gray-200 p-6 mb-6">
              <h2 className="font-heading text-lg text-gray-800 mb-4">
                Find client profile
              </h2>

              <form
                onSubmit={handleSubmit}
                className="flex flex-col md:flex-row gap-4 items-stretch md:items-end"
              >
                <div className="flex-1">
                  <label
                    htmlFor="clientId"
                    className="block text-sm font-body text-gray-700 mb-1"
                  >
                    Client ID
                  </label>
                  <input
                    id="clientId"
                    type="text"
                    value={clientId}
                    onChange={(e) => setClientId(e.target.value)}
                    className="block w-full rounded-md border border-gray-300 px-3 py-2 text-sm font-body text-gray-900 shadow-sm focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-[#1A9988]"
                    placeholder="e.g. client-001"
                    list="clientIdOptions"
                  />
                  <datalist id="clientIdOptions">
                    {clients.map((id) => (
                      <option key={id} value={id} />
                    ))}
                  </datalist>

                  {clientsLoading && (
                    <p className="mt-2 text-xs font-body text-gray-500">
                      Loading client IDsâ€¦
                    </p>
                  )}
                </div>

                <div className="flex flex-row gap-3">
                  <button
                    type="submit"
                    disabled={loading}
                    className={`
                      inline-flex items-center justify-center
                      px-4 py-2 rounded-md
                      bg-[#1A9988] text-white
                      font-body text-sm font-medium
                      shadow-sm
                      transition-colors transition-transform duration-150
                      hover:bg-[#178c7d] hover:-translate-y-0.5 hover:shadow-md
                      active:bg-[#147c6f] active:translate-y-0
                      ${loading ? "opacity-60 cursor-not-allowed" : ""}
                    `}
                  >
                    {loading ? "Loading..." : "Get profile"}
                  </button>

                  {/* NOW WIRED: Detailed Profile button */}
                  <button
                    type="button"
                    disabled={viewDetailsDisabled}
                    className={`
                      inline-flex items-center justify-center
                      px-4 py-2 rounded-md
                      font-body text-sm font-medium
                      shadow-sm
                      transition-colors transition-transform duration-150
                      ${
                        viewDetailsDisabled
                          ? "bg-gray-200 text-gray-500 cursor-not-allowed"
                          : "bg-[rgb(176,192,159)] text-gray-900 hover:-translate-y-0.5 hover:shadow-md active:translate-y-0"
                      }
                    `}
                    onClick={() => {
                      if (!profile) return;
                      setShowDetailedProfile(true);
                      // small UX: nudge scroll to panel on click
                      setTimeout(() => {
                        const el = document.getElementById("scv-detailed-profile");
                        if (el) el.scrollIntoView({ behavior: "smooth", block: "start" });
                      }, 50);
                    }}
                    title={
                      viewDetailsDisabled ? "Load a profile first" : "View detailed profile"
                    }
                  >
                    View detailed profile
                  </button>
                </div>
              </form>

              {error && (
                <p className="mt-3 text-sm font-body text-red-600">{error}</p>
              )}
            </section>

            {/* Initial landing screen (only when no profile): Client Overview + Pre-Matched */}
            {!profile && (
              <>
                {/* Client overview */}
                <section className="bg-white rounded-halo shadow-sm border border-gray-200 p-6 mb-6">
                  {/* ... unchanged ... */}
                  <div className="flex flex-col md:flex-row md:items-end md:justify-between gap-4">
                    <div>
                      <h2 className="font-heading text-lg text-gray-800">
                        Client overview
                      </h2>
                      <p className="mt-1 text-sm font-body text-gray-600">
                        Search and filter clients, then navigate to the detailed profile.
                      </p>
                    </div>

                    <div className="flex flex-col sm:flex-row gap-3 w-full md:w-auto">
                      <div className="flex-1 sm:w-64">
                        <label className="block text-sm font-body text-gray-700 mb-1">
                          Search
                        </label>
                        <input
                          type="text"
                          value={clientSearch}
                          onChange={(e) => setClientSearch(e.target.value)}
                          className="block w-full rounded-md border border-gray-300 px-3 py-2 text-sm font-body text-gray-900 shadow-sm focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-[#1A9988]"
                          placeholder="Name, ID, segmentâ€¦"
                        />
                      </div>

                      <div className="sm:w-44">
                        <label className="block text-sm font-body text-gray-700 mb-1">
                          Risk rating
                        </label>
                        <select
                          value={riskFilter}
                          onChange={(e) => setRiskFilter(e.target.value)}
                          className="block w-full rounded-md border border-gray-300 px-3 py-2 text-sm font-body text-gray-900 shadow-sm focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-[#1A9988]"
                        >
                          <option value="All">All</option>
                          {distinctRiskRatings.map((r) => (
                            <option key={r} value={r}>
                              {r}
                            </option>
                          ))}
                        </select>
                      </div>

                      <div className="sm:w-44">
                        <label className="block text-sm font-body text-gray-700 mb-1">
                          Status
                        </label>
                        <select
                          value={statusFilter}
                          onChange={(e) => setStatusFilter(e.target.value)}
                          className="block w-full rounded-md border border-gray-300 px-3 py-2 text-sm font-body text-gray-900 shadow-sm focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-[#1A9988]"
                        >
                          <option value="All">All</option>
                          {distinctStatuses.map((s) => (
                            <option key={s} value={s}>
                              {s}
                            </option>
                          ))}
                        </select>
                      </div>
                    </div>
                  </div>

                  <div className="mt-5">
                    {clientsLoading ? (
                      <p className="text-sm font-body text-gray-500">
                        Loading client listâ€¦
                      </p>
                    ) : clientIndexError ? (
                      <p className="text-sm font-body text-gray-500">
                        {clientIndexError}
                      </p>
                    ) : filteredClientIndex.length === 0 ? (
                      <p className="text-sm font-body text-gray-500">
                        No clients match your search/filters.
                      </p>
                    ) : (
                      <div className="overflow-auto border border-gray-200 rounded-md">
                        <table className="min-w-full text-sm font-body">
                          <thead className="bg-gray-50 text-gray-700">
                            <tr>
                              <th className="text-left px-4 py-3 font-medium">
                                Client ID
                              </th>
                              <th className="text-left px-4 py-3 font-medium">
                                Name
                              </th>
                              <th className="text-left px-4 py-3 font-medium">
                                Risk
                              </th>
                              <th className="text-left px-4 py-3 font-medium">
                                Status
                              </th>
                              <th className="text-left px-4 py-3 font-medium">
                                Segment
                              </th>
                              <th className="text-left px-4 py-3 font-medium">
                                Action
                              </th>
                            </tr>
                          </thead>
                          <tbody className="divide-y divide-gray-200">
                            {filteredClientIndex.map((c) => (
                              <tr key={c.client_id} className="bg-white">
                                <td className="px-4 py-3 font-mono text-gray-900">
                                  {c.client_id}
                                </td>
                                <td className="px-4 py-3 text-gray-900">
                                  {c.name || "â€”"}
                                </td>
                                <td className="px-4 py-3 text-gray-900">
                                  {c.risk_rating || "â€”"}
                                </td>
                                <td className="px-4 py-3 text-gray-900">
                                  {c.status || "â€”"}
                                </td>
                                <td className="px-4 py-3 text-gray-900">
                                  {c.segment || "â€”"}
                                </td>
                                <td className="px-4 py-3">
                                  <button
                                    type="button"
                                    className="inline-flex items-center justify-center px-3 py-1.5 rounded-md text-sm text-gray-900 bg-[rgb(205,226,235)] shadow-sm transition-all duration-150 hover:-translate-y-0.5 hover:shadow-md active:translate-y-0 active:shadow-sm"
                                    onClick={() => setClientId(c.client_id)}
                                    title="Populate Client ID"
                                  >
                                    Select
                                  </button>
                                </td>
                              </tr>
                            ))}
                          </tbody>
                        </table>
                      </div>
                    )}
                  </div>
                </section>

                {/* Pre-Matched Records */}
                <section className="bg-white rounded-halo shadow-sm border border-gray-200 p-6 mb-6">
                  <div className="flex items-center justify-between mb-4">
                    <h2 className="font-heading text-lg text-gray-800">
                      Pre-Matched Records
                    </h2>

                    <button
                      type="button"
                      style={{ fontFamily: "Fjalla One" }}
                      className="inline-flex items-center justify-center px-5 py-2 rounded-md text-sm text-gray-900 bg-[rgb(205,226,235)] shadow-sm transition-all duration-150 hover:-translate-y-0.5 hover:shadow-md active:translate-y-0 active:shadow-sm"
                      onClick={() => fetchPreMatched({ silent: false })}
                      disabled={preMatchedLoading}
                      title="Refresh pre-matched records"
                    >
                      {preMatchedLoading ? "Refreshingâ€¦" : "Refresh"}
                    </button>
                  </div>

                  {preMatchedNotice && (
                    <p className="text-sm font-body text-gray-600">{preMatchedNotice}</p>
                  )}

                  {preMatchedError && (
                    <p className="text-sm font-body text-red-600">{preMatchedError}</p>
                  )}

                  {!preMatchedError &&
                  !preMatchedNotice &&
                  preMatchedRecords.length === 0 ? (
                    <p className="text-sm font-body text-gray-500">
                      No pre-matched records.
                    </p>
                  ) : (
                    preMatchedRecords.length > 0 && (
                      <div className="overflow-auto border border-gray-200 rounded-md">
                        <table className="min-w-full text-sm font-body">
                          <thead className="bg-gray-50 text-gray-700">
                            <tr>
                              <th className="text-left px-4 py-3 font-medium">
                                Source
                              </th>
                              <th className="text-left px-4 py-3 font-medium">
                                Record ID
                              </th>
                              <th className="text-left px-4 py-3 font-medium">
                                Name
                              </th>
                              <th className="text-left px-4 py-3 font-medium">
                                Email
                              </th>
                              <th className="text-left px-4 py-3 font-medium">
                                Ingested
                              </th>
                            </tr>
                          </thead>
                          <tbody className="divide-y divide-gray-200">
                            {preMatchedRecords.map((r) => {
                              const name = `${r.first_name || ""} ${r.last_name || ""}`.trim();
                              const ingested = new Date().toISOString().slice(0, 10);


                              return (
                                <tr key={r.id} className="bg-white">
                                  <td className="px-4 py-3 text-gray-900">
                                    {r.source_system || "â€”"}
                                  </td>
                                  <td className="px-4 py-3 font-mono text-gray-900">
                                    {r.source_record_id || "â€”"}
                                  </td>
                                  <td className="px-4 py-3 text-gray-900">
                                    {name || "â€”"}
                                  </td>
                                  <td className="px-4 py-3 text-gray-900">
                                    {r.email || "â€”"}
                                  </td>
                                  <td className="px-4 py-3 text-gray-900">
                                    {ingested}
                                  </td>
                                </tr>
                              );
                            })}
                          </tbody>
                        </table>
                      </div>
                    )
                  )}
                </section>
              </>
            )}

            {/* SCV layout grid (only when profile loaded) */}
            {profile && (
              <section
                id="scv-profile"
                className="grid grid-cols-1 lg:grid-cols-2 gap-6 mt-4"
              >
                {/* 1. Client Summary */}
                <div className="bg-white rounded-halo shadow-sm border border-gray-200 p-6">
                  <h3 className="font-heading text-base text-gray-800 mb-4">
                    Client summary
                  </h3>

                  <div className="grid grid-cols-1 sm:grid-cols-2 gap-4">
                    <div>
                      <div className="text-xs font-body text-gray-500">Client ID</div>
                      <div className="text-sm font-mono text-gray-900">
                        {profile?.client_id ?? "â€”"}
                      </div>
                    </div>

                    <div>
                      <div className="text-xs font-body text-gray-500">Name</div>
                      <div className="text-sm font-body text-gray-900">
                        {profile?.name ?? "â€”"}
                      </div>
                    </div>

                    <div>
                      <div className="text-xs font-body text-gray-500">Email</div>
                      <div className="text-sm font-body text-gray-900">
                        {profile?.email ?? "â€”"}
                      </div>
                    </div>

                    <div>
                      <div className="text-xs font-body text-gray-500">Country</div>
                      <div className="text-sm font-body text-gray-900">
                        {profile?.country ?? "â€”"}
                      </div>
                    </div>

                    <div>
                      <div className="text-xs font-body text-gray-500">Risk rating</div>
                      <div className="text-sm font-body text-gray-900">
                        {profile?.risk_rating ?? "â€”"}
                      </div>
                    </div>

                    <div>
                      <div className="text-xs font-body text-gray-500">Status</div>
                      <div className="text-sm font-body text-gray-900">
                        {profile?.operational_state?.status ?? "â€”"}
                      </div>
                    </div>
                  </div>
                </div>

                {/* 2. Accounts */}
                <div className="bg-white rounded-halo shadow-sm border border-gray-200 p-6">
                  <h3 className="font-heading text-base text-gray-800 mb-4">
                    Accounts
                  </h3>

                  {Array.isArray(profile?.accounts) && profile.accounts.length > 0 ? (
                    <div className="overflow-auto border border-gray-200 rounded-md">
                      <table className="min-w-full text-sm font-body">
                        <thead className="bg-gray-50 text-gray-700">
                          <tr>
                            <th className="text-left px-4 py-3 font-medium">Account #</th>
                            <th className="text-left px-4 py-3 font-medium">Type</th>
                            <th className="text-left px-4 py-3 font-medium">CCY</th>
                            <th className="text-left px-4 py-3 font-medium">Status</th>
                          </tr>
                        </thead>
                        <tbody className="divide-y divide-gray-200 bg-white">
                          {profile.accounts.map((a, idx) => (
                            <tr key={a.id ?? a.account_number ?? idx}>
                              <td className="px-4 py-3 font-mono text-gray-900">
                                {a.account_number ?? "â€”"}
                              </td>
                              <td className="px-4 py-3 text-gray-900">
                                {a.account_type ?? "â€”"}
                              </td>
                              <td className="px-4 py-3 text-gray-900">
                                {a.currency ?? "â€”"}
                              </td>
                              <td className="px-4 py-3 text-gray-900">
                                {a.status ?? "â€”"}
                              </td>
                            </tr>
                          ))}
                        </tbody>
                      </table>
                    </div>
                  ) : (
                    <p className="text-sm font-body text-gray-500">No accounts available.</p>
                  )}
                </div>

                {/* 3. Client Information */}
                <div className="bg-white rounded-halo shadow-sm border border-gray-200 p-6">
                  <h3 className="font-heading text-base text-gray-800 mb-4">
                    Client information
                  </h3>

                  <dl className="space-y-2 text-sm font-body text-gray-800">
                    <div className="flex items-start justify-between gap-6">
                      <dt className="text-gray-500">Client ID</dt>
                      <dd className="text-gray-900 font-mono text-xs text-right">
                        {profile?.client_id ?? "â€”"}
                      </dd>
                    </div>

                    <div className="flex items-start justify-between gap-6">
                      <dt className="text-gray-500">Full name</dt>
                      <dd className="text-gray-900 text-right">{profile?.name ?? "â€”"}</dd>
                    </div>

                    <div className="flex items-start justify-between gap-6">
                      <dt className="text-gray-500">Primary email</dt>
                      <dd className="text-gray-900 text-right">{profile?.email ?? "â€”"}</dd>
                    </div>

                    <div className="flex items-start justify-between gap-6">
                      <dt className="text-gray-500">Primary phone</dt>
                      <dd className="text-gray-900 text-right">{profile?.phone ?? "â€”"}</dd>
                    </div>

                    <div className="flex items-start justify-between gap-6">
                      <dt className="text-gray-500">Country</dt>
                      <dd className="text-gray-900 text-right">{profile?.country ?? "â€”"}</dd>
                    </div>

                    <div className="flex items-start justify-between gap-6">
                      <dt className="text-gray-500">Primary address</dt>
                      <dd className="text-gray-900 text-right">
                        {profile?.primary_address ?? "â€”"}
                      </dd>
                    </div>

                    <div className="flex items-start justify-between gap-6">
                      <dt className="text-gray-500">Segment</dt>
                      <dd className="text-gray-900 text-right">{profile?.segment ?? "â€”"}</dd>
                    </div>

                    <div className="flex items-start justify-between gap-6">
                      <dt className="text-gray-500">Risk rating</dt>
                      <dd className="text-gray-900 text-right">
                        {profile?.risk_rating ?? "â€”"}
                      </dd>
                    </div>
                  </dl>
                </div>

                {/* 4. Raw Sources */}
                <div className="bg-white rounded-halo shadow-sm border border-gray-200 p-6">
                  <h3 className="font-heading text-base text-gray-800 mb-4">
                    Raw sources
                  </h3>

                  {Array.isArray(sources) && sources.length > 0 ? (
                    <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
                      {sources.map((s, idx) => (
                        <div
                          key={s.id ?? `src-${idx}`}
                          className="border border-gray-200 rounded-md p-4 bg-gray-50"
                        >
                          <div className="flex items-start justify-between gap-4">
                            <div>
                              <div className="text-xs font-body text-gray-600">System</div>
                              <div className="text-sm font-body text-gray-900">
                                {s.system ?? "â€”"}
                              </div>
                            </div>
                            <div className="text-[11px] font-mono text-gray-500 bg-white border border-gray-200 rounded-md px-2 py-1">
                              {s.id ?? "â€”"}
                            </div>
                          </div>

                          <pre className="mt-3 whitespace-pre-wrap text-[11px] font-mono text-gray-800 bg-white border border-gray-200 rounded-md p-3">
                            {JSON.stringify(s.payload ?? {}, null, 2)}
                          </pre>
                        </div>
                      ))}
                    </div>
                  ) : (
                    <p className="text-sm font-body text-gray-500">No sources available.</p>
                  )}
                </div>
              </section>
            )}

            {/* Detailed Profile panel (below existing SCV grid, no regression) */}
            {profile && showDetailedProfile && (
              <div id="scv-detailed-profile">
                <DetailedClientProfilePanel
                  profile={profile}
                  onClose={() => setShowDetailedProfile(false)}
                />
              </div>
            )}
          </>
        )}
      </main>
    </div>
  );
}

export default App;






























===== FILE: app_frontend\src\BusinessDataLineagePanel.jsx =====
// app_frontend/src/BusinessDataLineagePanel.jsx
import React, { useEffect, useMemo, useState } from "react";

const BACKEND_BASE_URL = "http://127.0.0.1:8000";

const CRITICAL_DATA_ELEMENTS = [
  {
    group: "Identity",
    items: [
      {
        conceptId: "client.legal_name",
        displayName: "Client Legal Name",
        status: "tracked",
        note: "Authoritative CRM source",
      },
      {
        conceptId: "client.trade_name",
        displayName: "Trading / Known-As Name",
        status: "planned",
      },
      {
        conceptId: "client.external_id",
        displayName: "External Client Identifier",
        status: "planned",
      },
      {
        conceptId: "client.primary_address",
        displayName: "Primary Registered Address",
        status: "planned",
      },
    ],
  },
  {
    group: "Jurisdiction & Regulatory",
    items: [
      {
        conceptId: "client.country",
        displayName: "Country of Incorporation",
        status: "planned",
      },
      {
        conceptId: "client.tax_id",
        displayName: "Tax Identifier",
        status: "planned",
        note: "Sensitive / masked",
      },
      {
        conceptId: "client.lei",
        displayName: "Legal Entity Identifier (LEI)",
        status: "planned",
      },
    ],
  },
  {
    group: "Risk & Classification",
    items: [
      {
        conceptId: "client.segment",
        displayName: "Client Segment",
        status: "planned",
      },
      {
        conceptId: "client.risk_rating",
        displayName: "Risk Rating",
        status: "planned",
        note: "Policy-derived",
      },
    ],
  },
  {
    group: "Lifecycle & Governance",
    items: [
      {
        conceptId: "client.onboarding_date",
        displayName: "Onboarding Date",
        status: "planned",
      },
      {
        conceptId: "client.status",
        displayName: "Client Status",
        status: "planned",
      },
      {
        conceptId: "client.last_reviewed_at",
        displayName: "Last KYC Review Date",
        status: "planned",
      },
      {
        conceptId: "client.source_system",
        displayName: "Source System of Record",
        status: "planned",
      },
    ],
  },
];

function Pill({ children, tone = "neutral" }) {
  const toneClass =
    tone === "ok"
      ? "bg-green-100 text-green-800 border-green-200"
      : tone === "error"
      ? "bg-red-100 text-red-800 border-red-200"
      : tone === "warn"
      ? "bg-yellow-100 text-yellow-900 border-yellow-200"
      : "bg-gray-100 text-gray-800 border-gray-200";

  return (
    <span
      className={`inline-flex items-center px-2.5 py-0.5 rounded-full text-xs font-body border ${toneClass}`}
    >
      {children}
    </span>
  );
}

function formatUtc(ts) {
  if (!ts) return "â€”";
  const d = new Date(ts);
  if (Number.isNaN(d.getTime())) return String(ts);
  return d.toLocaleString();
}

export default function BusinessDataLineagePanel({
  defaultClientId = 1,
  defaultConceptId = "client.legal_name",
  onBack,
}) {
  const [clientId, setClientId] = useState(String(defaultClientId));
  const [conceptId, setConceptId] = useState(String(defaultConceptId));

  // Three-step flow:
  // 1) CDE list
  // 2) Client list (for selected CDE)
  // 3) Detail view
  const [view, setView] = useState("cdeList"); // "cdeList" | "clientList" | "detail"

  const [loading, setLoading] = useState(false);
  const [payload, setPayload] = useState(null);
  const [error, setError] = useState("");

  // Client list state
  const [clientsLoading, setClientsLoading] = useState(false);
  const [clients, setClients] = useState([]);
  const [clientsError, setClientsError] = useState("");

  const lineageEndpoint = useMemo(() => {
    const cid = encodeURIComponent(String(clientId).trim());
    const cc = encodeURIComponent(String(conceptId).trim());
    return `${BACKEND_BASE_URL}/atlas/lineage/client/${cid}/concept/${cc}`;
  }, [clientId, conceptId]);

  const fetchLineage = async () => {
    setError("");
    setLoading(true);
    setPayload(null);

    try {
      const res = await fetch(lineageEndpoint);
      if (!res.ok) {
        const detail = await res.json().catch(() => ({}));
        throw new Error(detail?.detail || `HTTP ${res.status}`);
      }
      const json = await res.json();
      setPayload(json);
    } catch (e) {
      setError(e?.message || "Failed to load lineage.");
    } finally {
      setLoading(false);
    }
  };

  const fetchClients = async () => {
    setClientsError("");
    setClientsLoading(true);
    setClients([]);

    try {
      const res = await fetch(`${BACKEND_BASE_URL}/clients/`);
      if (!res.ok) throw new Error(`HTTP ${res.status}`);
      const json = await res.json();
      if (!Array.isArray(json)) throw new Error("Unexpected clients payload");
      setClients(json);
    } catch (e) {
      setClientsError(e?.message || "Failed to load clients.");
    } finally {
      setClientsLoading(false);
    }
  };

  useEffect(() => {
    if (view === "clientList") {
      fetchClients();
    }
    if (view === "detail") {
      fetchLineage();
    }
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [view]);

  const artifact = payload?.artifact || null;
  const resolvedValue = payload?.resolved_value;
  const resolution = payload?.resolution;

  const statusTone =
    resolution?.status === "ok"
      ? "ok"
      : resolution?.status === "not_found"
      ? "warn"
      : resolution?.status === "error"
      ? "error"
      : "neutral";

  const trackedConcepts = new Set(["client.legal_name"]);

  const goToClientList = (nextConceptId) => {
    setConceptId(String(nextConceptId));
    setView("clientList");
  };

  const goToDetail = (nextClientId) => {
    setClientId(String(nextClientId));
    setView("detail");
  };

  const selectedCdeMeta = useMemo(() => {
    for (const g of CRITICAL_DATA_ELEMENTS) {
      const found = g.items.find((x) => x.conceptId === conceptId);
      if (found) return found;
    }
    return null;
  }, [conceptId]);

  // =========================
  // VIEW 1: CDE LIST
  // =========================
  if (view === "cdeList") {
    return (
      <div className="space-y-4">
        <div className="flex items-center justify-between gap-3">
          <div>
            <h3 className="font-fjalla text-base text-gray-900 tracking-wide">
              Business Data Lineage
            </h3>
            <p className="text-xs font-body text-gray-600">
              Critical Data Elements tracked by the platform
            </p>
          </div>

          <div className="flex items-center gap-2">
            {onBack && (
              <button
                type="button"
                onClick={onBack}
                className="px-3 py-2 rounded-md text-sm font-body border border-gray-200 bg-white hover:bg-gray-50"
              >
                Back
              </button>
            )}
          </div>
        </div>

        <div className="bg-white border border-gray-200 rounded-halo p-4">
          <div className="flex items-center justify-between mb-3">
            <h4 className="font-heading text-sm text-gray-900">
              Critical Data Elements
            </h4>
            <span className="text-[11px] font-mono text-gray-500">
              tracked: {Array.from(trackedConcepts).length} â€¢ planned:{" "}
              {CRITICAL_DATA_ELEMENTS.reduce(
                (acc, g) =>
                  acc + g.items.filter((i) => i.status === "planned").length,
                0
              )}
            </span>
          </div>

          <div className="space-y-6">
            {CRITICAL_DATA_ELEMENTS.map((section) => (
              <div key={section.group}>
                <div className="flex items-center justify-between mb-2">
                  <h5 className="font-heading text-sm text-gray-800">
                    {section.group}
                  </h5>
                </div>

                <div className="space-y-2">
                  {section.items.map((item) => {
                    const isTracked = item.status === "tracked";
                    const isClickable = isTracked && trackedConcepts.has(item.conceptId);

                    return (
                      <div
                        key={item.conceptId}
                        className={`flex items-center justify-between p-3 rounded-md border ${
                          isClickable
                            ? "bg-white border-halo-primary cursor-pointer hover:bg-teal-50"
                            : "bg-gray-50 border-gray-200 opacity-70"
                        }`}
                        onClick={() => {
                          if (isClickable) goToClientList(item.conceptId);
                        }}
                      >
                        <div>
                          <div className="font-body text-sm text-gray-900">
                            {item.displayName}
                          </div>
                          <div className="text-xs font-mono text-gray-500">
                            {item.conceptId}
                          </div>
                          {item.note && (
                            <div className="text-xs text-gray-500 mt-1">
                              {item.note}
                            </div>
                          )}
                        </div>

                        <div className="text-xs font-body">
                          {isClickable ? (
                            <span className="px-2 py-1 rounded-full bg-green-100 text-green-800 border border-green-200">
                              Tracked
                            </span>
                          ) : (
                            <span className="px-2 py-1 rounded-full bg-gray-100 text-gray-600 border border-gray-200">
                              Planned
                            </span>
                          )}
                        </div>
                      </div>
                    );
                  })}
                </div>
              </div>
            ))}
          </div>

          <div className="mt-4 text-xs font-body text-gray-600">
            Tip: click a tracked element (e.g.{" "}
            <span className="font-mono">client.legal_name</span>) to choose a
            client and drill into live lineage.
          </div>
        </div>
      </div>
    );
  }

  // =========================
  // VIEW 2: CLIENT LIST (for selected CDE)
  // =========================
  if (view === "clientList") {
    const isTracked = trackedConcepts.has(conceptId);

    return (
      <div className="space-y-4">
        <div className="flex items-center justify-between gap-3">
          <div>
            <h3 className="font-fjalla text-base text-gray-900 tracking-wide">
              Business Data Lineage
            </h3>
            <p className="text-xs font-body text-gray-600">
              Select a client to evaluate{" "}
              <span className="font-mono">{conceptId}</span>
            </p>
          </div>

          <div className="flex items-center gap-2">
            <button
              type="button"
              onClick={() => setView("cdeList")}
              className="px-3 py-2 rounded-md text-sm font-body border border-gray-200 bg-white hover:bg-gray-50"
            >
              Critical Data Elements
            </button>

            {onBack && (
              <button
                type="button"
                onClick={onBack}
                className="px-3 py-2 rounded-md text-sm font-body border border-gray-200 bg-white hover:bg-gray-50"
              >
                Back
              </button>
            )}

            <button
              type="button"
              onClick={fetchClients}
              className="px-3 py-2 rounded-md text-sm font-body text-white bg-halo-primary hover:opacity-90"
            >
              Refresh
            </button>
          </div>
        </div>

        <div className="bg-white border border-gray-200 rounded-halo p-4">
          <div className="flex flex-col md:flex-row md:items-start md:justify-between gap-3">
            <div className="space-y-1">
              <div className="text-xs font-heading text-gray-500">
                Selected CDE
              </div>
              <div className="text-sm font-body text-gray-900">
                {selectedCdeMeta?.displayName || "â€”"}
                <span className="text-xs text-gray-500">
                  {" "}
                  ({conceptId})
                </span>
              </div>
              {selectedCdeMeta?.note && (
                <div className="text-xs font-body text-gray-600">
                  {selectedCdeMeta.note}
                </div>
              )}
            </div>

            <div className="space-y-1">
              <div className="text-xs font-heading text-gray-500">Status</div>
              <div className="text-sm font-body text-gray-900">
                {isTracked ? (
                  <span className="px-2 py-1 rounded-full bg-green-100 text-green-800 border border-green-200">
                    Tracked
                  </span>
                ) : (
                  <span className="px-2 py-1 rounded-full bg-gray-100 text-gray-600 border border-gray-200">
                    Planned
                  </span>
                )}
              </div>
            </div>
          </div>

          <div className="mt-4">
            {clientsLoading && (
              <div className="text-sm font-body text-gray-600">Loadingâ€¦</div>
            )}

            {clientsError && <Pill tone="error">{clientsError}</Pill>}

            {!clientsLoading && !clientsError && (
              <div className="border border-gray-200 rounded-md overflow-hidden">
                <div className="grid grid-cols-12 bg-gray-50 border-b border-gray-200 px-3 py-2">
                  <div className="col-span-2 text-xs font-heading text-gray-600">
                    ID
                  </div>
                  <div className="col-span-7 text-xs font-heading text-gray-600">
                    Client
                  </div>
                  <div className="col-span-3 text-xs font-heading text-gray-600 text-right">
                    Action
                  </div>
                </div>

                {clients.map((c) => (
                  <div
                    key={c.id}
                    className="grid grid-cols-12 px-3 py-2 border-b border-gray-100 hover:bg-gray-50"
                  >
                    <div className="col-span-2 text-sm font-mono text-gray-800">
                      {c.id}
                    </div>
                    <div className="col-span-7 text-sm font-body text-gray-900">
                      {c.full_name || c.display_name || "â€”"}
                      <div className="text-xs text-gray-500 font-mono">
                        {c.external_id || ""}
                      </div>
                    </div>
                    <div className="col-span-3 flex justify-end">
                      <button
                        type="button"
                        onClick={() => goToDetail(c.id)}
                        className="px-3 py-2 rounded-md text-sm font-body text-white bg-halo-primary hover:opacity-90 disabled:opacity-50"
                        disabled={!isTracked}
                        title={!isTracked ? "Planned CDE" : "Explain lineage"}
                      >
                        Explain
                      </button>
                    </div>
                  </div>
                ))}

                {!clients.length && (
                  <div className="px-3 py-3 text-sm font-body text-gray-600">
                    No clients found.
                  </div>
                )}
              </div>
            )}
          </div>
        </div>
      </div>
    );
  }

  // =========================
  // VIEW 3: DETAIL (existing look & feel preserved)
  // =========================
  return (
    <div className="space-y-4">
      <div className="flex items-center justify-between gap-3">
        <div>
          <h3 className="font-fjalla text-base text-gray-900 tracking-wide">
            Business Data Lineage
          </h3>
          <p className="text-xs font-body text-gray-600">
            Attribute-level lineage with live value resolution
          </p>
        </div>

        <div className="flex items-center gap-2">
          <button
            type="button"
            onClick={() => setView("clientList")}
            className="px-3 py-2 rounded-md text-sm font-body border border-gray-200 bg-white hover:bg-gray-50"
          >
            Clients
          </button>

          <button
            type="button"
            onClick={() => setView("cdeList")}
            className="px-3 py-2 rounded-md text-sm font-body border border-gray-200 bg-white hover:bg-gray-50"
          >
            Critical Data Elements
          </button>

          {onBack && (
            <button
              type="button"
              onClick={onBack}
              className="px-3 py-2 rounded-md text-sm font-body border border-gray-200 bg-white hover:bg-gray-50"
            >
              Back
            </button>
          )}

          <button
            type="button"
            onClick={fetchLineage}
            className="px-3 py-2 rounded-md text-sm font-body text-white bg-halo-primary hover:opacity-90"
          >
            Refresh
          </button>
        </div>
      </div>

      <div className="grid grid-cols-1 md:grid-cols-3 gap-3">
        <div className="bg-gray-50 border border-gray-200 rounded-md p-3">
          <label className="block text-xs font-heading text-gray-700 mb-1">
            Client ID
          </label>
          <input
            value={clientId}
            onChange={(e) => setClientId(e.target.value)}
            className="w-full px-3 py-2 rounded-md border border-gray-200 bg-white text-sm font-body"
            placeholder="1"
          />
        </div>

        <div className="md:col-span-2 bg-gray-50 border border-gray-200 rounded-md p-3">
          <label className="block text-xs font-heading text-gray-700 mb-1">
            Concept ID
          </label>
          <input
            value={conceptId}
            onChange={(e) => setConceptId(e.target.value)}
            className="w-full px-3 py-2 rounded-md border border-gray-200 bg-white text-sm font-body"
            placeholder="client.legal_name"
          />
        </div>
      </div>

      <div className="flex items-center gap-3">
        <button
          type="button"
          onClick={fetchLineage}
          className="px-4 py-2 rounded-md text-sm font-body text-white bg-halo-primary hover:opacity-90 disabled:opacity-50"
          disabled={loading}
        >
          {loading ? "Loadingâ€¦" : "Resolve lineage + value"}
        </button>

        {resolution?.status && (
          <Pill tone={statusTone}>
            Resolution: {String(resolution.status).toUpperCase()}
          </Pill>
        )}

        {error && <Pill tone="error">{error}</Pill>}
      </div>

      <div className="bg-white border border-gray-200 rounded-halo p-4">
        <div className="flex flex-col md:flex-row md:items-start md:justify-between gap-3">
          <div className="space-y-1">
            <div className="text-xs font-heading text-gray-500">Subject</div>
            <div className="text-sm font-body text-gray-900">
              {artifact?.subject?.display_name || "â€”"}
              <span className="text-xs text-gray-500">
                {" "}
                (client_id: {artifact?.subject?.entity_id || clientId || "â€”"})
              </span>
            </div>
          </div>

          <div className="space-y-1">
            <div className="text-xs font-heading text-gray-500">Concept</div>
            <div className="text-sm font-body text-gray-900">
              {artifact?.concept?.display_name || "â€”"}
              <span className="text-xs text-gray-500">
                {" "}
                ({artifact?.concept?.concept_id || conceptId || "â€”"})
              </span>
            </div>
          </div>

          <div className="space-y-1">
            <div className="text-xs font-heading text-gray-500">
              Resolved value
            </div>
            <div className="text-sm font-body text-gray-900">
              {resolvedValue == null ? "â€”" : String(resolvedValue)}
            </div>
          </div>
        </div>

        <div className="mt-3 grid grid-cols-1 md:grid-cols-2 gap-3">
          <div className="text-xs font-body text-gray-600">
            <span className="font-heading text-gray-500">Captured at:</span>{" "}
            {formatUtc(artifact?.captured_at)}
          </div>
          <div className="text-xs font-body text-gray-600">
            <span className="font-heading text-gray-500">Evaluated at:</span>{" "}
            {formatUtc(resolution?.evaluated_at)}
          </div>
        </div>

        {resolution?.details && (
          <div className="mt-3 text-xs font-body text-gray-600">
            {resolution.details}
          </div>
        )}
      </div>

      <div className="bg-white border border-gray-200 rounded-halo p-4">
        <div className="flex items-center justify-between mb-3">
          <h4 className="font-heading text-sm text-gray-900">Lineage path</h4>
          <span className="text-[11px] font-mono text-gray-500">
            artefact: {artifact?.artifact_type || "â€”"} v
            {artifact?.artifact_version || "â€”"}
          </span>
        </div>

        {!artifact?.lineage?.length ? (
          <div className="text-sm font-body text-gray-600">
            No lineage stages found in the artefact.
          </div>
        ) : (
          <div className="space-y-2">
            {artifact.lineage.map((step, idx) => (
              <div
                key={`${step.stage || "stage"}-${idx}`}
                className="border border-gray-200 rounded-md p-3 bg-gray-50"
              >
                <div className="flex items-center justify-between gap-3">
                  <div className="font-heading text-sm text-gray-900">
                    {String(step.stage || "stage").toUpperCase()}
                  </div>
                  <div className="text-[11px] font-mono text-gray-600">
                    {step.system ? `system=${step.system}` : ""}
                    {step.rule ? ` rule=${step.rule}` : ""}
                    {step.surface ? ` surface=${step.surface}` : ""}
                  </div>
                </div>

                {step.assertion && (
                  <div className="mt-2 text-sm font-body text-gray-700">
                    {step.assertion}
                  </div>
                )}

                {(step.component || step.field_label) && (
                  <div className="mt-2 text-xs font-body text-gray-600">
                    {step.component ? `Component: ${step.component}` : ""}
                    {step.component && step.field_label ? " â€¢ " : ""}
                    {step.field_label ? `Field: ${step.field_label}` : ""}
                  </div>
                )}
              </div>
            ))}
          </div>
        )}
      </div>

      <div className="bg-white border border-gray-200 rounded-halo p-4">
        <h4 className="font-heading text-sm text-gray-900 mb-2">
          Raw response payload
        </h4>
        <pre className="whitespace-pre-wrap text-[11px] font-mono text-gray-800 bg-gray-50 border border-gray-200 rounded-md p-3 max-h-[260px] overflow-auto">
          {payload ? JSON.stringify(payload, null, 2) : "â€”"}
        </pre>
      </div>
    </div>
  );
}




===== FILE: app_frontend\src\data\initial_logical_data_model.json =====
{
  "artifact_type": "logical_data_model",
  "artifact_version": "1.0",
  "model_name": "Initial Logical Data Model (LDM)",
  "mission": "Single Client View (SCV)",
  "source": {
    "authority": "MissionDestination",
    "derived_from": "docs/mission_destination/initial_logical_data_model.md"
  },
  "entities": [
    {
      "entity": "ClientProfile",
      "description": "Represents the unified, deduplicated profile of a client.",
      "fields": [
        { "name": "client_id", "type": "str", "description": "Internal SCV identifier" },
        { "name": "name", "type": "str", "description": "Canonical client name" },
        { "name": "email", "type": "Optional[str]", "description": "Canonical email" },
        { "name": "country", "type": "Optional[str]", "description": "Country associated with the client" },
        { "name": "identifiers", "type": "List[ClientIdentifier]", "description": "Identifiers from upstream systems" },
        { "name": "addresses", "type": "List[ClientAddress]", "description": "Normalised address objects" },
        { "name": "lineage", "type": "Dict[str, Any]", "description": "Provenance metadata" },
        { "name": "quality", "type": "Dict[str, float]", "description": "Freshness, completeness, confidence" },
        { "name": "metadata", "type": "Dict[str, str]", "description": "Timestamps, merge strategies, flags" },
        { "name": "raw_sources", "type": "Dict[str, Dict[str, Any]]", "description": "Raw source payloads" }
      ],
      "relationships": [
        { "type": "contains_many", "to": "ClientIdentifier", "via_field": "identifiers" },
        { "type": "contains_many", "to": "ClientAddress", "via_field": "addresses" }
      ]
    },
    {
      "entity": "ClientIdentifier",
      "description": "Identifier associated with a client from an upstream system.",
      "fields": [
        { "name": "system", "type": "str", "description": "Upstream system name" },
        { "name": "value", "type": "str", "description": "Identifier in that system" }
      ],
      "relationships": []
    },
    {
      "entity": "ClientAddress",
      "description": "Normalised address object associated with a client.",
      "fields": [
        { "name": "line1", "type": "Optional[str]", "description": "Address line 1" },
        { "name": "line2", "type": "Optional[str]", "description": "Address line 2" },
        { "name": "city", "type": "Optional[str]", "description": "City" },
        { "name": "postcode", "type": "Optional[str]", "description": "Postal code" },
        { "name": "country", "type": "Optional[str]", "description": "ISO country" },
        { "name": "source", "type": "Optional[str]", "description": "System contributing the address" }
      ],
      "relationships": []
    }
  ]
}


===== FILE: app_frontend\src\data\initial_physical_data_model.json =====
{
  "artifact_type": "physical_data_model",
  "artifact_version": "1.0",
  "source": {
    "authority": "MissionDestination",
    "derived_from": "docs/mission_destination/initial_database_schema.txt"
  },
  "tables": [
    {
      "table": "client_addresses",
      "columns": [
        {
          "name": "client_id",
          "type": "unknown",
          "nullable": null,
          "default": null,
          "pk": true,
          "unique": false,
          "fk": {
            "references_table": "clients",
            "references_columns": [
              "client_id"
            ]
          },
          "raw": "client_id"
        },
        {
          "name": "line1",
          "type": "unknown",
          "nullable": null,
          "default": null,
          "pk": true,
          "unique": false,
          "fk": null,
          "raw": "line1"
        },
        {
          "name": "line2",
          "type": "unknown",
          "nullable": null,
          "default": null,
          "pk": true,
          "unique": false,
          "fk": null,
          "raw": "line2"
        },
        {
          "name": "city",
          "type": "unknown",
          "nullable": null,
          "default": null,
          "pk": true,
          "unique": false,
          "fk": null,
          "raw": "city"
        },
        {
          "name": "postcode",
          "type": "unknown",
          "nullable": null,
          "default": null,
          "pk": true,
          "unique": false,
          "fk": null,
          "raw": "postcode"
        },
        {
          "name": "country",
          "type": "unknown",
          "nullable": null,
          "default": null,
          "pk": true,
          "unique": false,
          "fk": null,
          "raw": "country"
        },
        {
          "name": "source",
          "type": "unknown",
          "nullable": null,
          "default": null,
          "pk": true,
          "unique": false,
          "fk": null,
          "raw": "source"
        }
      ],
      "constraints": [],
      "foreign_keys": [
        {
          "columns": [
            "client_id"
          ],
          "references_table": "clients",
          "references_columns": [
            "client_id"
          ],
          "raw": "`client_id` -> `clients.client_id`"
        }
      ]
    },
    {
      "table": "client_identifiers",
      "columns": [
        {
          "name": "client_id",
          "type": "unknown",
          "nullable": null,
          "default": null,
          "pk": true,
          "unique": false,
          "fk": {
            "references_table": "clients",
            "references_columns": [
              "client_id"
            ]
          },
          "raw": "client_id"
        },
        {
          "name": "system",
          "type": "unknown",
          "nullable": null,
          "default": null,
          "pk": true,
          "unique": false,
          "fk": null,
          "raw": "system"
        },
        {
          "name": "value",
          "type": "unknown",
          "nullable": null,
          "default": null,
          "pk": true,
          "unique": false,
          "fk": null,
          "raw": "value"
        }
      ],
      "constraints": [],
      "foreign_keys": [
        {
          "columns": [
            "client_id"
          ],
          "references_table": "clients",
          "references_columns": [
            "client_id"
          ],
          "raw": "`client_id` -> `clients.client_id`"
        }
      ]
    },
    {
      "table": "clients",
      "columns": [
        {
          "name": "client_id",
          "type": "unknown",
          "nullable": null,
          "default": null,
          "pk": true,
          "unique": false,
          "fk": null,
          "raw": "client_id"
        },
        {
          "name": "name",
          "type": "unknown",
          "nullable": null,
          "default": null,
          "pk": true,
          "unique": false,
          "fk": null,
          "raw": "name"
        },
        {
          "name": "email",
          "type": "unknown",
          "nullable": null,
          "default": null,
          "pk": true,
          "unique": false,
          "fk": null,
          "raw": "email"
        },
        {
          "name": "country",
          "type": "unknown",
          "nullable": null,
          "default": null,
          "pk": true,
          "unique": false,
          "fk": null,
          "raw": "country"
        },
        {
          "name": "created_at",
          "type": "unknown",
          "nullable": null,
          "default": null,
          "pk": true,
          "unique": false,
          "fk": null,
          "raw": "created_at"
        },
        {
          "name": "updated_at",
          "type": "unknown",
          "nullable": null,
          "default": null,
          "pk": true,
          "unique": false,
          "fk": null,
          "raw": "updated_at"
        }
      ],
      "constraints": [],
      "foreign_keys": []
    },
    {
      "table": "evidence_artefacts",
      "columns": [],
      "constraints": [],
      "foreign_keys": []
    },
    {
      "table": "match_decisions",
      "columns": [],
      "constraints": [],
      "foreign_keys": []
    }
  ]
}

===== FILE: app_frontend\src\data\physical_model_by_domain.json =====
{
  "artifact_type": "physical_model_by_domain",
  "artifact_version": "1.0",
  "source": {
    "authority": "Postgres schema dump",
    "derived_from": "C:\\Dev\\scv-repo\\docs\\mission_destination\\database_schema12.sql"
  },
  "domains": [
    {
      "domain": "Ingestion",
      "purpose": "Capture and manage inbound source data feeds, ingest runs, mappings and raw records.",
      "tables": [
        {
          "schema": "public",
          "table": "accounts",
          "columns": [
            {
              "name": "id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": true,
              "fk": null,
              "raw": "id integer NOT NULL"
            },
            {
              "name": "client_id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": {
                "references_table": "public.clients",
                "references_columns": [
                  "id"
                ]
              },
              "raw": "client_id integer NOT NULL"
            },
            {
              "name": "account_number",
              "type": "character varying",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "account_number character varying NOT NULL"
            },
            {
              "name": "account_type",
              "type": "character varying",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "account_type character varying"
            },
            {
              "name": "currency",
              "type": "character varying",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "currency character varying NOT NULL"
            },
            {
              "name": "status",
              "type": "character varying",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "status character varying NOT NULL"
            },
            {
              "name": "opened_at",
              "type": "character varying",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "opened_at character varying"
            },
            {
              "name": "closed_at",
              "type": "character varying",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "closed_at character varying"
            }
          ],
          "primary_key": [
            "id"
          ],
          "foreign_keys": [
            {
              "name": "accounts_client_id_fkey",
              "columns": [
                "client_id"
              ],
              "references_table": "public.clients",
              "references_columns": [
                "id"
              ],
              "raw": "ALTER TABLE ONLY public.accounts\n    ADD CONSTRAINT accounts_client_id_fkey FOREIGN KEY (client_id) REFERENCES public.clients(id);"
            }
          ],
          "indexes": [
            {
              "name": "ix_accounts_account_number",
              "unique": true,
              "method": "btree",
              "columns": [
                "account_number"
              ]
            },
            {
              "name": "ix_accounts_client_id",
              "unique": false,
              "method": "btree",
              "columns": [
                "client_id"
              ]
            },
            {
              "name": "ix_accounts_id",
              "unique": false,
              "method": "btree",
              "columns": [
                "id"
              ]
            }
          ],
          "create_constraints": []
        },
        {
          "schema": "public",
          "table": "corporate_trade_history",
          "columns": [
            {
              "name": "trade_id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": true,
              "fk": null,
              "raw": "trade_id integer NOT NULL"
            },
            {
              "name": "client_id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": {
                "references_table": "public.clients",
                "references_columns": [
                  "id"
                ]
              },
              "raw": "client_id integer NOT NULL"
            },
            {
              "name": "trade_date",
              "type": "timestamp without time zone",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "trade_date timestamp without time zone NOT NULL"
            },
            {
              "name": "asset_class_id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": {
                "references_table": "public.asset_class",
                "references_columns": [
                  "asset_class_id"
                ]
              },
              "raw": "asset_class_id integer NOT NULL"
            },
            {
              "name": "instrument",
              "type": "character varying(100)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "instrument character varying(100) NOT NULL"
            },
            {
              "name": "direction",
              "type": "character varying(4)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "direction character varying(4) NOT NULL"
            },
            {
              "name": "quantity",
              "type": "numeric(18,4)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "quantity numeric(18,4) NOT NULL"
            },
            {
              "name": "price",
              "type": "numeric(18,6)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "price numeric(18,6) NOT NULL"
            },
            {
              "name": "pnl",
              "type": "numeric(18,2)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "pnl numeric(18,2) NOT NULL"
            }
          ],
          "primary_key": [
            "trade_id"
          ],
          "foreign_keys": [
            {
              "name": "corporate_trade_history_asset_class_id_fkey",
              "columns": [
                "asset_class_id"
              ],
              "references_table": "public.asset_class",
              "references_columns": [
                "asset_class_id"
              ],
              "raw": "ALTER TABLE ONLY public.corporate_trade_history\n    ADD CONSTRAINT corporate_trade_history_asset_class_id_fkey FOREIGN KEY (asset_class_id) REFERENCES public.asset_class(asset_class_id);"
            },
            {
              "name": "corporate_trade_history_client_id_fkey",
              "columns": [
                "client_id"
              ],
              "references_table": "public.clients",
              "references_columns": [
                "id"
              ],
              "raw": "ALTER TABLE ONLY public.corporate_trade_history\n    ADD CONSTRAINT corporate_trade_history_client_id_fkey FOREIGN KEY (client_id) REFERENCES public.clients(id);"
            }
          ],
          "indexes": [],
          "create_constraints": []
        },
        {
          "schema": "public",
          "table": "crm_contacts",
          "columns": [
            {
              "name": "id",
              "type": "uuid",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": true,
              "fk": null,
              "raw": "id uuid NOT NULL"
            },
            {
              "name": "source_system",
              "type": "character varying",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "source_system character varying NOT NULL"
            },
            {
              "name": "source_record_id",
              "type": "character varying",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "source_record_id character varying NOT NULL"
            },
            {
              "name": "first_name",
              "type": "character varying",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "first_name character varying"
            },
            {
              "name": "last_name",
              "type": "character varying",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "last_name character varying"
            },
            {
              "name": "email",
              "type": "character varying",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "email character varying"
            },
            {
              "name": "created_at",
              "type": "timestamp with time zone",
              "nullable": false,
              "default": "now()",
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "created_at timestamp with time zone DEFAULT now() NOT NULL"
            },
            {
              "name": "updated_at",
              "type": "timestamp with time zone",
              "nullable": false,
              "default": "now()",
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "updated_at timestamp with time zone DEFAULT now() NOT NULL"
            }
          ],
          "primary_key": [
            "id"
          ],
          "foreign_keys": [],
          "indexes": [],
          "create_constraints": []
        },
        {
          "schema": "public",
          "table": "ingestion_runs",
          "columns": [
            {
              "name": "ingestion_run_id",
              "type": "uuid",
              "nullable": false,
              "default": "gen_random_uuid()",
              "unique": false,
              "pk": true,
              "fk": null,
              "raw": "ingestion_run_id uuid DEFAULT gen_random_uuid() NOT NULL"
            },
            {
              "name": "source_system_id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": {
                "references_table": "public.source_systems",
                "references_columns": [
                  "source_system_id"
                ]
              },
              "raw": "source_system_id integer NOT NULL"
            },
            {
              "name": "started_at",
              "type": "timestamp with time zone",
              "nullable": false,
              "default": "now()",
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "started_at timestamp with time zone DEFAULT now() NOT NULL"
            },
            {
              "name": "finished_at",
              "type": "timestamp with time zone",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "finished_at timestamp with time zone"
            },
            {
              "name": "status",
              "type": "character varying(30)",
              "nullable": false,
              "default": "'started'::character varying",
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "status character varying(30) DEFAULT 'started'::character varying NOT NULL"
            },
            {
              "name": "schema_version",
              "type": "character varying(50)",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "schema_version character varying(50)"
            },
            {
              "name": "triggered_by",
              "type": "character varying(200)",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "triggered_by character varying(200)"
            },
            {
              "name": "notes",
              "type": "text",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "notes text"
            }
          ],
          "primary_key": [
            "ingestion_run_id"
          ],
          "foreign_keys": [
            {
              "name": "ingestion_runs_source_system_id_fkey",
              "columns": [
                "source_system_id"
              ],
              "references_table": "public.source_systems",
              "references_columns": [
                "source_system_id"
              ],
              "raw": "ALTER TABLE ONLY public.ingestion_runs\n    ADD CONSTRAINT ingestion_runs_source_system_id_fkey FOREIGN KEY (source_system_id) REFERENCES public.source_systems(source_system_id);"
            }
          ],
          "indexes": [
            {
              "name": "ix_ingestion_runs_source_started",
              "unique": false,
              "method": "btree",
              "columns": [
                "source_system_id",
                "started_at DESC"
              ]
            }
          ],
          "create_constraints": []
        },
        {
          "schema": "public",
          "table": "source_field_mappings",
          "columns": [
            {
              "name": "mapping_id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": true,
              "fk": null,
              "raw": "mapping_id integer NOT NULL"
            },
            {
              "name": "source_system_id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": {
                "references_table": "public.source_systems",
                "references_columns": [
                  "source_system_id"
                ]
              },
              "raw": "source_system_id integer NOT NULL"
            },
            {
              "name": "source_field",
              "type": "character varying(200)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "source_field character varying(200) NOT NULL"
            },
            {
              "name": "attribute_id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": {
                "references_table": "public.attribute_dictionary",
                "references_columns": [
                  "attribute_id"
                ]
              },
              "raw": "attribute_id integer NOT NULL"
            },
            {
              "name": "transform_rule",
              "type": "text",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "transform_rule text"
            },
            {
              "name": "is_active",
              "type": "boolean",
              "nullable": false,
              "default": "true",
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "is_active boolean DEFAULT true NOT NULL"
            }
          ],
          "primary_key": [
            "mapping_id"
          ],
          "foreign_keys": [
            {
              "name": "source_field_mappings_attribute_id_fkey",
              "columns": [
                "attribute_id"
              ],
              "references_table": "public.attribute_dictionary",
              "references_columns": [
                "attribute_id"
              ],
              "raw": "ALTER TABLE ONLY public.source_field_mappings\n    ADD CONSTRAINT source_field_mappings_attribute_id_fkey FOREIGN KEY (attribute_id) REFERENCES public.attribute_dictionary(attribute_id);"
            },
            {
              "name": "source_field_mappings_source_system_id_fkey",
              "columns": [
                "source_system_id"
              ],
              "references_table": "public.source_systems",
              "references_columns": [
                "source_system_id"
              ],
              "raw": "ALTER TABLE ONLY public.source_field_mappings\n    ADD CONSTRAINT source_field_mappings_source_system_id_fkey FOREIGN KEY (source_system_id) REFERENCES public.source_systems(source_system_id);"
            }
          ],
          "indexes": [
            {
              "name": "ix_source_field_mappings_system",
              "unique": false,
              "method": "btree",
              "columns": [
                "source_system_id"
              ]
            }
          ],
          "create_constraints": []
        },
        {
          "schema": "public",
          "table": "source_records_raw",
          "columns": [
            {
              "name": "source_record_id",
              "type": "uuid",
              "nullable": false,
              "default": "gen_random_uuid()",
              "unique": false,
              "pk": true,
              "fk": null,
              "raw": "source_record_id uuid DEFAULT gen_random_uuid() NOT NULL"
            },
            {
              "name": "ingestion_run_id",
              "type": "uuid",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "ingestion_run_id uuid NOT NULL"
            },
            {
              "name": "source_system_id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": {
                "references_table": "public.source_systems",
                "references_columns": [
                  "source_system_id"
                ]
              },
              "raw": "source_system_id integer NOT NULL"
            },
            {
              "name": "source_record_key",
              "type": "character varying(200)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "source_record_key character varying(200) NOT NULL"
            },
            {
              "name": "received_at",
              "type": "timestamp with time zone",
              "nullable": false,
              "default": "now()",
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "received_at timestamp with time zone DEFAULT now() NOT NULL"
            },
            {
              "name": "payload",
              "type": "jsonb",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "payload jsonb NOT NULL"
            },
            {
              "name": "payload_hash",
              "type": "character varying(128)",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "payload_hash character varying(128)"
            },
            {
              "name": "extracted_external_id",
              "type": "character varying(200)",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "extracted_external_id character varying(200)"
            },
            {
              "name": "extracted_email",
              "type": "character varying(320)",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "extracted_email character varying(320)"
            },
            {
              "name": "extracted_tax_id",
              "type": "character varying(100)",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "extracted_tax_id character varying(100)"
            },
            {
              "name": "structural_ok",
              "type": "boolean",
              "nullable": false,
              "default": "true",
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "structural_ok boolean DEFAULT true NOT NULL"
            },
            {
              "name": "structural_errors",
              "type": "jsonb",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "structural_errors jsonb"
            }
          ],
          "primary_key": [
            "source_record_id"
          ],
          "foreign_keys": [
            {
              "name": "source_records_raw_source_system_id_fkey",
              "columns": [
                "source_system_id"
              ],
              "references_table": "public.source_systems",
              "references_columns": [
                "source_system_id"
              ],
              "raw": "ALTER TABLE ONLY public.source_records_raw\n    ADD CONSTRAINT source_records_raw_source_system_id_fkey FOREIGN KEY (source_system_id) REFERENCES public.source_systems(source_system_id);"
            }
          ],
          "indexes": [
            {
              "name": "ix_source_records_raw_run",
              "unique": false,
              "method": "btree",
              "columns": [
                "ingestion_run_id"
              ]
            },
            {
              "name": "ix_source_records_raw_system_key",
              "unique": false,
              "method": "btree",
              "columns": [
                "source_system_id",
                "source_record_key"
              ]
            }
          ],
          "create_constraints": []
        },
        {
          "schema": "public",
          "table": "source_systems",
          "columns": [
            {
              "name": "source_system_id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": true,
              "fk": null,
              "raw": "source_system_id integer NOT NULL"
            },
            {
              "name": "code",
              "type": "character varying(50)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "code character varying(50) NOT NULL"
            },
            {
              "name": "name",
              "type": "character varying(200)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "name character varying(200) NOT NULL"
            },
            {
              "name": "description",
              "type": "text",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "description text"
            },
            {
              "name": "is_active",
              "type": "boolean",
              "nullable": false,
              "default": "true",
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "is_active boolean DEFAULT true NOT NULL"
            },
            {
              "name": "created_at",
              "type": "timestamp with time zone",
              "nullable": false,
              "default": "now()",
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "created_at timestamp with time zone DEFAULT now() NOT NULL"
            }
          ],
          "primary_key": [
            "source_system_id"
          ],
          "foreign_keys": [],
          "indexes": [],
          "create_constraints": []
        },
        {
          "schema": "public",
          "table": "transactions",
          "columns": [
            {
              "name": "id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": true,
              "fk": null,
              "raw": "id integer NOT NULL"
            },
            {
              "name": "account_id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": {
                "references_table": "public.accounts",
                "references_columns": [
                  "id"
                ]
              },
              "raw": "account_id integer NOT NULL"
            },
            {
              "name": "trade_date",
              "type": "character varying",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "trade_date character varying"
            },
            {
              "name": "value_date",
              "type": "character varying",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "value_date character varying"
            },
            {
              "name": "amount",
              "type": "double precision",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "amount double precision NOT NULL"
            },
            {
              "name": "currency",
              "type": "character varying",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "currency character varying NOT NULL"
            },
            {
              "name": "txn_type",
              "type": "character varying",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "txn_type character varying NOT NULL"
            },
            {
              "name": "description",
              "type": "character varying",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "description character varying"
            },
            {
              "name": "price",
              "type": "double precision",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "price double precision"
            },
            {
              "name": "pnl",
              "type": "double precision",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "pnl double precision"
            }
          ],
          "primary_key": [
            "id"
          ],
          "foreign_keys": [
            {
              "name": "transactions_account_id_fkey",
              "columns": [
                "account_id"
              ],
              "references_table": "public.accounts",
              "references_columns": [
                "id"
              ],
              "raw": "ALTER TABLE ONLY public.transactions\n    ADD CONSTRAINT transactions_account_id_fkey FOREIGN KEY (account_id) REFERENCES public.accounts(id);"
            }
          ],
          "indexes": [
            {
              "name": "ix_transactions_account_id",
              "unique": false,
              "method": "btree",
              "columns": [
                "account_id"
              ]
            },
            {
              "name": "ix_transactions_id",
              "unique": false,
              "method": "btree",
              "columns": [
                "id"
              ]
            }
          ],
          "create_constraints": []
        }
      ]
    },
    {
      "domain": "Client canonical",
      "purpose": "Canonical client records, operational state and source coverage.",
      "tables": [
        {
          "schema": "public",
          "table": "client_operational_state",
          "columns": [
            {
              "name": "state_id",
              "type": "uuid",
              "nullable": false,
              "default": "gen_random_uuid()",
              "unique": false,
              "pk": true,
              "fk": null,
              "raw": "state_id uuid DEFAULT gen_random_uuid() NOT NULL"
            },
            {
              "name": "client_id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "client_id integer NOT NULL"
            },
            {
              "name": "as_of",
              "type": "timestamp with time zone",
              "nullable": false,
              "default": "now()",
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "as_of timestamp with time zone DEFAULT now() NOT NULL"
            },
            {
              "name": "processing_stage",
              "type": "character varying(50)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "processing_stage character varying(50) NOT NULL"
            },
            {
              "name": "status",
              "type": "character varying(30)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "status character varying(30) NOT NULL"
            },
            {
              "name": "message",
              "type": "text",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "message text"
            },
            {
              "name": "details",
              "type": "jsonb",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "details jsonb"
            }
          ],
          "primary_key": [
            "state_id"
          ],
          "foreign_keys": [],
          "indexes": [
            {
              "name": "ix_client_operational_state_client_asof",
              "unique": false,
              "method": "btree",
              "columns": [
                "client_id",
                "as_of DESC"
              ]
            }
          ],
          "create_constraints": []
        },
        {
          "schema": "public",
          "table": "client_source_coverage",
          "columns": [
            {
              "name": "client_id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": true,
              "fk": null,
              "raw": "client_id integer NOT NULL"
            },
            {
              "name": "source_system_id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": true,
              "fk": {
                "references_table": "public.source_systems",
                "references_columns": [
                  "source_system_id"
                ]
              },
              "raw": "source_system_id integer NOT NULL"
            },
            {
              "name": "last_seen_at",
              "type": "timestamp with time zone",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "last_seen_at timestamp with time zone"
            },
            {
              "name": "is_missing",
              "type": "boolean",
              "nullable": false,
              "default": "false",
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "is_missing boolean DEFAULT false NOT NULL"
            },
            {
              "name": "is_stale",
              "type": "boolean",
              "nullable": false,
              "default": "false",
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "is_stale boolean DEFAULT false NOT NULL"
            },
            {
              "name": "notes",
              "type": "text",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "notes text"
            }
          ],
          "primary_key": [
            "client_id",
            "source_system_id"
          ],
          "foreign_keys": [
            {
              "name": "client_source_coverage_source_system_id_fkey",
              "columns": [
                "source_system_id"
              ],
              "references_table": "public.source_systems",
              "references_columns": [
                "source_system_id"
              ],
              "raw": "ALTER TABLE ONLY public.client_source_coverage\n    ADD CONSTRAINT client_source_coverage_source_system_id_fkey FOREIGN KEY (source_system_id) REFERENCES public.source_systems(source_system_id);"
            }
          ],
          "indexes": [],
          "create_constraints": []
        },
        {
          "schema": "public",
          "table": "clients",
          "columns": [
            {
              "name": "id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": true,
              "fk": null,
              "raw": "id integer NOT NULL"
            },
            {
              "name": "external_id",
              "type": "character varying",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "external_id character varying"
            },
            {
              "name": "full_name",
              "type": "character varying",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "full_name character varying NOT NULL"
            },
            {
              "name": "email",
              "type": "character varying",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "email character varying"
            },
            {
              "name": "phone",
              "type": "character varying",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "phone character varying"
            },
            {
              "name": "primary_address",
              "type": "character varying",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "primary_address character varying"
            },
            {
              "name": "country",
              "type": "character varying",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "country character varying"
            },
            {
              "name": "tax_id",
              "type": "character varying",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "tax_id character varying"
            },
            {
              "name": "segment",
              "type": "character varying",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "segment character varying"
            },
            {
              "name": "risk_rating",
              "type": "character varying",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "risk_rating character varying"
            },
            {
              "name": "country_id",
              "type": "integer",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "country_id integer"
            },
            {
              "name": "risk_rating_id",
              "type": "integer",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "risk_rating_id integer"
            }
          ],
          "primary_key": [
            "id"
          ],
          "foreign_keys": [],
          "indexes": [
            {
              "name": "ix_clients_external_id",
              "unique": true,
              "method": "btree",
              "columns": [
                "external_id"
              ]
            },
            {
              "name": "ix_clients_id",
              "unique": false,
              "method": "btree",
              "columns": [
                "id"
              ]
            }
          ],
          "create_constraints": []
        }
      ]
    },
    {
      "domain": "Matching",
      "purpose": "Run matching, record decisions and maintain client clusters.",
      "tables": [
        {
          "schema": "public",
          "table": "client_cluster_members",
          "columns": [
            {
              "name": "cluster_id",
              "type": "uuid",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": true,
              "fk": null,
              "raw": "cluster_id uuid NOT NULL"
            },
            {
              "name": "client_id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": true,
              "fk": null,
              "raw": "client_id integer NOT NULL"
            },
            {
              "name": "role",
              "type": "character varying(30)",
              "nullable": false,
              "default": "'member'::character varying",
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "role character varying(30) DEFAULT 'member'::character varying NOT NULL"
            }
          ],
          "primary_key": [
            "client_id",
            "cluster_id"
          ],
          "foreign_keys": [],
          "indexes": [],
          "create_constraints": []
        },
        {
          "schema": "public",
          "table": "client_clusters",
          "columns": [
            {
              "name": "cluster_id",
              "type": "uuid",
              "nullable": false,
              "default": "gen_random_uuid()",
              "unique": false,
              "pk": true,
              "fk": null,
              "raw": "cluster_id uuid DEFAULT gen_random_uuid() NOT NULL"
            },
            {
              "name": "created_at",
              "type": "timestamp with time zone",
              "nullable": false,
              "default": "now()",
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "created_at timestamp with time zone DEFAULT now() NOT NULL"
            },
            {
              "name": "rationale",
              "type": "text",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "rationale text"
            }
          ],
          "primary_key": [
            "cluster_id"
          ],
          "foreign_keys": [],
          "indexes": [],
          "create_constraints": []
        },
        {
          "schema": "public",
          "table": "match_decisions",
          "columns": [
            {
              "name": "match_decision_id",
              "type": "uuid",
              "nullable": false,
              "default": "gen_random_uuid()",
              "unique": false,
              "pk": true,
              "fk": null,
              "raw": "match_decision_id uuid DEFAULT gen_random_uuid() NOT NULL"
            },
            {
              "name": "match_run_id",
              "type": "uuid",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "match_run_id uuid NOT NULL"
            },
            {
              "name": "source_record_id",
              "type": "uuid",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "source_record_id uuid NOT NULL"
            },
            {
              "name": "decided_at",
              "type": "timestamp with time zone",
              "nullable": false,
              "default": "now()",
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "decided_at timestamp with time zone DEFAULT now() NOT NULL"
            },
            {
              "name": "decision",
              "type": "character varying(30)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "decision character varying(30) NOT NULL"
            },
            {
              "name": "matched_client_id",
              "type": "integer",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": {
                "references_table": "public.clients",
                "references_columns": [
                  "id"
                ]
              },
              "raw": "matched_client_id integer"
            },
            {
              "name": "confidence",
              "type": "numeric(5,4)",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "confidence numeric(5,4)"
            },
            {
              "name": "rule_hits",
              "type": "jsonb",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "rule_hits jsonb"
            },
            {
              "name": "conflict_summary",
              "type": "jsonb",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "conflict_summary jsonb"
            }
          ],
          "primary_key": [
            "match_decision_id"
          ],
          "foreign_keys": [
            {
              "name": "match_decisions_matched_client_id_fkey",
              "columns": [
                "matched_client_id"
              ],
              "references_table": "public.clients",
              "references_columns": [
                "id"
              ],
              "raw": "ALTER TABLE ONLY public.match_decisions\n    ADD CONSTRAINT match_decisions_matched_client_id_fkey FOREIGN KEY (matched_client_id) REFERENCES public.clients(id);"
            }
          ],
          "indexes": [
            {
              "name": "ix_match_decisions_client",
              "unique": false,
              "method": "btree",
              "columns": [
                "matched_client_id"
              ]
            },
            {
              "name": "ix_match_decisions_run",
              "unique": false,
              "method": "btree",
              "columns": [
                "match_run_id"
              ]
            }
          ],
          "create_constraints": []
        },
        {
          "schema": "public",
          "table": "match_runs",
          "columns": [
            {
              "name": "match_run_id",
              "type": "uuid",
              "nullable": false,
              "default": "gen_random_uuid()",
              "unique": false,
              "pk": true,
              "fk": null,
              "raw": "match_run_id uuid DEFAULT gen_random_uuid() NOT NULL"
            },
            {
              "name": "started_at",
              "type": "timestamp with time zone",
              "nullable": false,
              "default": "now()",
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "started_at timestamp with time zone DEFAULT now() NOT NULL"
            },
            {
              "name": "finished_at",
              "type": "timestamp with time zone",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "finished_at timestamp with time zone"
            },
            {
              "name": "status",
              "type": "character varying(30)",
              "nullable": false,
              "default": "'started'::character varying",
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "status character varying(30) DEFAULT 'started'::character varying NOT NULL"
            },
            {
              "name": "ruleset_version",
              "type": "character varying(50)",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "ruleset_version character varying(50)"
            },
            {
              "name": "notes",
              "type": "text",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "notes text"
            }
          ],
          "primary_key": [
            "match_run_id"
          ],
          "foreign_keys": [],
          "indexes": [],
          "create_constraints": []
        }
      ]
    },
    {
      "domain": "Lineage & dictionary",
      "purpose": "Attribute dictionary, precedence rules and attribute-level lineage.",
      "tables": [
        {
          "schema": "public",
          "table": "attribute_dictionary",
          "columns": [
            {
              "name": "attribute_id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": true,
              "fk": null,
              "raw": "attribute_id integer NOT NULL"
            },
            {
              "name": "canonical_name",
              "type": "character varying(100)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "canonical_name character varying(100) NOT NULL"
            },
            {
              "name": "data_type",
              "type": "character varying(30)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "data_type character varying(30) NOT NULL"
            },
            {
              "name": "is_mandatory",
              "type": "boolean",
              "nullable": false,
              "default": "false",
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "is_mandatory boolean DEFAULT false NOT NULL"
            },
            {
              "name": "description",
              "type": "text",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "description text"
            },
            {
              "name": "created_at",
              "type": "timestamp with time zone",
              "nullable": false,
              "default": "now()",
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "created_at timestamp with time zone DEFAULT now() NOT NULL"
            }
          ],
          "primary_key": [
            "attribute_id"
          ],
          "foreign_keys": [],
          "indexes": [],
          "create_constraints": []
        },
        {
          "schema": "public",
          "table": "attribute_precedence_rules",
          "columns": [
            {
              "name": "precedence_rule_id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": true,
              "fk": null,
              "raw": "precedence_rule_id integer NOT NULL"
            },
            {
              "name": "attribute_id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": {
                "references_table": "public.attribute_dictionary",
                "references_columns": [
                  "attribute_id"
                ]
              },
              "raw": "attribute_id integer NOT NULL"
            },
            {
              "name": "source_system_id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": {
                "references_table": "public.source_systems",
                "references_columns": [
                  "source_system_id"
                ]
              },
              "raw": "source_system_id integer NOT NULL"
            },
            {
              "name": "precedence_rank",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "precedence_rank integer NOT NULL"
            },
            {
              "name": "is_active",
              "type": "boolean",
              "nullable": false,
              "default": "true",
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "is_active boolean DEFAULT true NOT NULL"
            }
          ],
          "primary_key": [
            "precedence_rule_id"
          ],
          "foreign_keys": [
            {
              "name": "attribute_precedence_rules_attribute_id_fkey",
              "columns": [
                "attribute_id"
              ],
              "references_table": "public.attribute_dictionary",
              "references_columns": [
                "attribute_id"
              ],
              "raw": "ALTER TABLE ONLY public.attribute_precedence_rules\n    ADD CONSTRAINT attribute_precedence_rules_attribute_id_fkey FOREIGN KEY (attribute_id) REFERENCES public.attribute_dictionary(attribute_id);"
            },
            {
              "name": "attribute_precedence_rules_source_system_id_fkey",
              "columns": [
                "source_system_id"
              ],
              "references_table": "public.source_systems",
              "references_columns": [
                "source_system_id"
              ],
              "raw": "ALTER TABLE ONLY public.attribute_precedence_rules\n    ADD CONSTRAINT attribute_precedence_rules_source_system_id_fkey FOREIGN KEY (source_system_id) REFERENCES public.source_systems(source_system_id);"
            }
          ],
          "indexes": [
            {
              "name": "ix_attribute_precedence_attr",
              "unique": false,
              "method": "btree",
              "columns": [
                "attribute_id",
                "precedence_rank"
              ]
            }
          ],
          "create_constraints": []
        },
        {
          "schema": "public",
          "table": "client_data_lineage",
          "columns": [
            {
              "name": "lineage_id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": true,
              "fk": null,
              "raw": "lineage_id integer NOT NULL"
            },
            {
              "name": "client_id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "client_id integer NOT NULL"
            },
            {
              "name": "data_source",
              "type": "character varying(100)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "data_source character varying(100) NOT NULL"
            },
            {
              "name": "field_name",
              "type": "character varying(100)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "field_name character varying(100) NOT NULL"
            },
            {
              "name": "transformation_description",
              "type": "text",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "transformation_description text"
            },
            {
              "name": "timestamp",
              "type": "timestamp without time zone",
              "nullable": true,
              "default": "CURRENT_TIMESTAMP",
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "\"timestamp\" timestamp without time zone DEFAULT CURRENT_TIMESTAMP"
            }
          ],
          "primary_key": [
            "lineage_id"
          ],
          "foreign_keys": [],
          "indexes": [],
          "create_constraints": []
        }
      ]
    },
    {
      "domain": "Assurance",
      "purpose": "Validation, audit and operational assurance signals, including conflicts and errors.",
      "tables": [
        {
          "schema": "public",
          "table": "attribute_conflicts",
          "columns": [
            {
              "name": "conflict_id",
              "type": "uuid",
              "nullable": false,
              "default": "gen_random_uuid()",
              "unique": false,
              "pk": true,
              "fk": null,
              "raw": "conflict_id uuid DEFAULT gen_random_uuid() NOT NULL"
            },
            {
              "name": "client_id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "client_id integer NOT NULL"
            },
            {
              "name": "attribute_id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": {
                "references_table": "public.attribute_dictionary",
                "references_columns": [
                  "attribute_id"
                ]
              },
              "raw": "attribute_id integer NOT NULL"
            },
            {
              "name": "detected_at",
              "type": "timestamp with time zone",
              "nullable": false,
              "default": "now()",
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "detected_at timestamp with time zone DEFAULT now() NOT NULL"
            },
            {
              "name": "values_by_source",
              "type": "jsonb",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "values_by_source jsonb NOT NULL"
            },
            {
              "name": "resolved",
              "type": "boolean",
              "nullable": false,
              "default": "false",
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "resolved boolean DEFAULT false NOT NULL"
            },
            {
              "name": "resolution_notes",
              "type": "text",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "resolution_notes text"
            },
            {
              "name": "resolved_at",
              "type": "timestamp with time zone",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "resolved_at timestamp with time zone"
            }
          ],
          "primary_key": [
            "conflict_id"
          ],
          "foreign_keys": [
            {
              "name": "attribute_conflicts_attribute_id_fkey",
              "columns": [
                "attribute_id"
              ],
              "references_table": "public.attribute_dictionary",
              "references_columns": [
                "attribute_id"
              ],
              "raw": "ALTER TABLE ONLY public.attribute_conflicts\n    ADD CONSTRAINT attribute_conflicts_attribute_id_fkey FOREIGN KEY (attribute_id) REFERENCES public.attribute_dictionary(attribute_id);"
            }
          ],
          "indexes": [
            {
              "name": "ix_attribute_conflicts_client",
              "unique": false,
              "method": "btree",
              "columns": [
                "client_id",
                "resolved"
              ]
            }
          ],
          "create_constraints": []
        },
        {
          "schema": "public",
          "table": "audit_events",
          "columns": [
            {
              "name": "audit_event_id",
              "type": "uuid",
              "nullable": false,
              "default": "gen_random_uuid()",
              "unique": false,
              "pk": true,
              "fk": null,
              "raw": "audit_event_id uuid DEFAULT gen_random_uuid() NOT NULL"
            },
            {
              "name": "occurred_at",
              "type": "timestamp with time zone",
              "nullable": false,
              "default": "now()",
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "occurred_at timestamp with time zone DEFAULT now() NOT NULL"
            },
            {
              "name": "actor",
              "type": "character varying(200)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "actor character varying(200) NOT NULL"
            },
            {
              "name": "event_type",
              "type": "character varying(80)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "event_type character varying(80) NOT NULL"
            },
            {
              "name": "client_id",
              "type": "integer",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "client_id integer"
            },
            {
              "name": "source_record_id",
              "type": "uuid",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "source_record_id uuid"
            },
            {
              "name": "evidence_bundle_id",
              "type": "uuid",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "evidence_bundle_id uuid"
            },
            {
              "name": "details",
              "type": "jsonb",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "details jsonb"
            }
          ],
          "primary_key": [
            "audit_event_id"
          ],
          "foreign_keys": [],
          "indexes": [
            {
              "name": "ix_audit_events_client_time",
              "unique": false,
              "method": "btree",
              "columns": [
                "client_id",
                "occurred_at DESC"
              ]
            }
          ],
          "create_constraints": []
        },
        {
          "schema": "public",
          "table": "service_error_logs",
          "columns": [
            {
              "name": "error_log_id",
              "type": "uuid",
              "nullable": false,
              "default": "gen_random_uuid()",
              "unique": false,
              "pk": true,
              "fk": null,
              "raw": "error_log_id uuid DEFAULT gen_random_uuid() NOT NULL"
            },
            {
              "name": "occurred_at",
              "type": "timestamp with time zone",
              "nullable": false,
              "default": "now()",
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "occurred_at timestamp with time zone DEFAULT now() NOT NULL"
            },
            {
              "name": "service_name",
              "type": "character varying(100)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "service_name character varying(100) NOT NULL"
            },
            {
              "name": "severity",
              "type": "character varying(20)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "severity character varying(20) NOT NULL"
            },
            {
              "name": "error_code",
              "type": "character varying(50)",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "error_code character varying(50)"
            },
            {
              "name": "message",
              "type": "text",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "message text NOT NULL"
            },
            {
              "name": "details",
              "type": "jsonb",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "details jsonb"
            },
            {
              "name": "correlation_id",
              "type": "character varying(100)",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "correlation_id character varying(100)"
            }
          ],
          "primary_key": [
            "error_log_id"
          ],
          "foreign_keys": [],
          "indexes": [
            {
              "name": "ix_service_error_logs_service_time",
              "unique": false,
              "method": "btree",
              "columns": [
                "service_name",
                "occurred_at DESC"
              ]
            }
          ],
          "create_constraints": []
        },
        {
          "schema": "public",
          "table": "service_health_checks",
          "columns": [
            {
              "name": "health_check_id",
              "type": "uuid",
              "nullable": false,
              "default": "gen_random_uuid()",
              "unique": false,
              "pk": true,
              "fk": null,
              "raw": "health_check_id uuid DEFAULT gen_random_uuid() NOT NULL"
            },
            {
              "name": "checked_at",
              "type": "timestamp with time zone",
              "nullable": false,
              "default": "now()",
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "checked_at timestamp with time zone DEFAULT now() NOT NULL"
            },
            {
              "name": "service_name",
              "type": "character varying(100)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "service_name character varying(100) NOT NULL"
            },
            {
              "name": "check_type",
              "type": "character varying(50)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "check_type character varying(50) NOT NULL"
            },
            {
              "name": "status",
              "type": "character varying(20)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "status character varying(20) NOT NULL"
            },
            {
              "name": "details",
              "type": "jsonb",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "details jsonb"
            }
          ],
          "primary_key": [
            "health_check_id"
          ],
          "foreign_keys": [],
          "indexes": [
            {
              "name": "ix_service_health_checks_service_time",
              "unique": false,
              "method": "btree",
              "columns": [
                "service_name",
                "checked_at DESC"
              ]
            }
          ],
          "create_constraints": []
        },
        {
          "schema": "public",
          "table": "validation_results",
          "columns": [
            {
              "name": "validation_result_id",
              "type": "uuid",
              "nullable": false,
              "default": "gen_random_uuid()",
              "unique": false,
              "pk": true,
              "fk": null,
              "raw": "validation_result_id uuid DEFAULT gen_random_uuid() NOT NULL"
            },
            {
              "name": "source_record_id",
              "type": "uuid",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "source_record_id uuid NOT NULL"
            },
            {
              "name": "validated_at",
              "type": "timestamp with time zone",
              "nullable": false,
              "default": "now()",
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "validated_at timestamp with time zone DEFAULT now() NOT NULL"
            },
            {
              "name": "validation_type",
              "type": "character varying(50)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "validation_type character varying(50) NOT NULL"
            },
            {
              "name": "passed",
              "type": "boolean",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "passed boolean NOT NULL"
            },
            {
              "name": "details",
              "type": "jsonb",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "details jsonb"
            },
            {
              "name": "error_count",
              "type": "integer",
              "nullable": false,
              "default": "0",
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "error_count integer DEFAULT 0 NOT NULL"
            }
          ],
          "primary_key": [
            "validation_result_id"
          ],
          "foreign_keys": [],
          "indexes": [
            {
              "name": "ix_validation_results_record",
              "unique": false,
              "method": "btree",
              "columns": [
                "source_record_id"
              ]
            }
          ],
          "create_constraints": []
        }
      ]
    },
    {
      "domain": "Evidence",
      "purpose": "Evidence artefacts and bundles generated by governed execution.",
      "tables": [
        {
          "schema": "public",
          "table": "evidence_artefacts",
          "columns": [
            {
              "name": "artefact_id",
              "type": "uuid",
              "nullable": false,
              "default": "gen_random_uuid()",
              "unique": false,
              "pk": true,
              "fk": null,
              "raw": "artefact_id uuid DEFAULT gen_random_uuid() NOT NULL"
            },
            {
              "name": "evidence_bundle_id",
              "type": "uuid",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "evidence_bundle_id uuid NOT NULL"
            },
            {
              "name": "artefact_type",
              "type": "character varying(50)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "artefact_type character varying(50) NOT NULL"
            },
            {
              "name": "created_at",
              "type": "timestamp with time zone",
              "nullable": false,
              "default": "now()",
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "created_at timestamp with time zone DEFAULT now() NOT NULL"
            },
            {
              "name": "content",
              "type": "jsonb",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "content jsonb"
            },
            {
              "name": "storage_ref",
              "type": "text",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "storage_ref text"
            },
            {
              "name": "content_hash",
              "type": "character varying(128)",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "content_hash character varying(128)"
            }
          ],
          "primary_key": [
            "artefact_id"
          ],
          "foreign_keys": [],
          "indexes": [
            {
              "name": "ix_evidence_artefacts_bundle",
              "unique": false,
              "method": "btree",
              "columns": [
                "evidence_bundle_id"
              ]
            }
          ],
          "create_constraints": []
        },
        {
          "schema": "public",
          "table": "evidence_bundles",
          "columns": [
            {
              "name": "evidence_bundle_id",
              "type": "uuid",
              "nullable": false,
              "default": "gen_random_uuid()",
              "unique": false,
              "pk": true,
              "fk": null,
              "raw": "evidence_bundle_id uuid DEFAULT gen_random_uuid() NOT NULL"
            },
            {
              "name": "client_id",
              "type": "integer",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "client_id integer"
            },
            {
              "name": "ingestion_run_id",
              "type": "uuid",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "ingestion_run_id uuid"
            },
            {
              "name": "match_run_id",
              "type": "uuid",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "match_run_id uuid"
            },
            {
              "name": "created_at",
              "type": "timestamp with time zone",
              "nullable": false,
              "default": "now()",
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "created_at timestamp with time zone DEFAULT now() NOT NULL"
            },
            {
              "name": "bundle_type",
              "type": "character varying(50)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "bundle_type character varying(50) NOT NULL"
            },
            {
              "name": "summary",
              "type": "text",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "summary text"
            }
          ],
          "primary_key": [
            "evidence_bundle_id"
          ],
          "foreign_keys": [],
          "indexes": [
            {
              "name": "ix_evidence_bundles_client_created",
              "unique": false,
              "method": "btree",
              "columns": [
                "client_id",
                "created_at DESC"
              ]
            }
          ],
          "create_constraints": []
        }
      ]
    },
    {
      "domain": "KYC & risk",
      "purpose": "KYC and risk data, flags, ratings and regulatory enrichment.",
      "tables": [
        {
          "schema": "public",
          "table": "client_regulatory_enrichment",
          "columns": [
            {
              "name": "enrichment_id",
              "type": "uuid",
              "nullable": false,
              "default": "gen_random_uuid()",
              "unique": false,
              "pk": true,
              "fk": null,
              "raw": "enrichment_id uuid DEFAULT gen_random_uuid() NOT NULL"
            },
            {
              "name": "client_id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "client_id integer NOT NULL"
            },
            {
              "name": "fatca_status",
              "type": "character varying(50)",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "fatca_status character varying(50)"
            },
            {
              "name": "crs_status",
              "type": "character varying(50)",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "crs_status character varying(50)"
            },
            {
              "name": "onboarding_status",
              "type": "character varying(50)",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "onboarding_status character varying(50)"
            },
            {
              "name": "kyc_overall_status",
              "type": "character varying(50)",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "kyc_overall_status character varying(50)"
            },
            {
              "name": "derived_risk_notes",
              "type": "text",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "derived_risk_notes text"
            },
            {
              "name": "updated_at",
              "type": "timestamp with time zone",
              "nullable": false,
              "default": "now()",
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "updated_at timestamp with time zone DEFAULT now() NOT NULL"
            }
          ],
          "primary_key": [
            "enrichment_id"
          ],
          "foreign_keys": [],
          "indexes": [],
          "create_constraints": []
        },
        {
          "schema": "public",
          "table": "corporate_kyc_info",
          "columns": [
            {
              "name": "corporate_kyc_id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": true,
              "fk": null,
              "raw": "corporate_kyc_id integer NOT NULL"
            },
            {
              "name": "client_id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": {
                "references_table": "public.clients",
                "references_columns": [
                  "id"
                ]
              },
              "raw": "client_id integer NOT NULL"
            },
            {
              "name": "registration_number",
              "type": "character varying(100)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "registration_number character varying(100) NOT NULL"
            },
            {
              "name": "legal_name",
              "type": "character varying(255)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "legal_name character varying(255) NOT NULL"
            },
            {
              "name": "business_license",
              "type": "character varying(100)",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "business_license character varying(100)"
            },
            {
              "name": "company_structure",
              "type": "character varying(50)",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "company_structure character varying(50)"
            },
            {
              "name": "compliance_status",
              "type": "character varying(50)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "compliance_status character varying(50) NOT NULL"
            },
            {
              "name": "last_reviewed_at",
              "type": "timestamp without time zone",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "last_reviewed_at timestamp without time zone"
            },
            {
              "name": "next_review_due_at",
              "type": "timestamp without time zone",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "next_review_due_at timestamp without time zone"
            },
            {
              "name": "notes",
              "type": "text",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "notes text"
            }
          ],
          "primary_key": [
            "corporate_kyc_id"
          ],
          "foreign_keys": [
            {
              "name": "corporate_kyc_info_client_id_fkey",
              "columns": [
                "client_id"
              ],
              "references_table": "public.clients",
              "references_columns": [
                "id"
              ],
              "raw": "ALTER TABLE ONLY public.corporate_kyc_info\n    ADD CONSTRAINT corporate_kyc_info_client_id_fkey FOREIGN KEY (client_id) REFERENCES public.clients(id);"
            }
          ],
          "indexes": [],
          "create_constraints": []
        },
        {
          "schema": "public",
          "table": "kyc_flags",
          "columns": [
            {
              "name": "id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": true,
              "fk": null,
              "raw": "id integer NOT NULL"
            },
            {
              "name": "client_id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": {
                "references_table": "public.clients",
                "references_columns": [
                  "id"
                ]
              },
              "raw": "client_id integer NOT NULL"
            },
            {
              "name": "code",
              "type": "character varying",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "code character varying NOT NULL"
            },
            {
              "name": "description",
              "type": "character varying",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "description character varying"
            },
            {
              "name": "status",
              "type": "character varying",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "status character varying NOT NULL"
            },
            {
              "name": "created_at",
              "type": "character varying",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "created_at character varying"
            },
            {
              "name": "resolved_at",
              "type": "character varying",
              "nullable": true,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "resolved_at character varying"
            }
          ],
          "primary_key": [
            "id"
          ],
          "foreign_keys": [
            {
              "name": "kyc_flags_client_id_fkey",
              "columns": [
                "client_id"
              ],
              "references_table": "public.clients",
              "references_columns": [
                "id"
              ],
              "raw": "ALTER TABLE ONLY public.kyc_flags\n    ADD CONSTRAINT kyc_flags_client_id_fkey FOREIGN KEY (client_id) REFERENCES public.clients(id);"
            }
          ],
          "indexes": [
            {
              "name": "ix_kyc_flags_client_id",
              "unique": false,
              "method": "btree",
              "columns": [
                "client_id"
              ]
            },
            {
              "name": "ix_kyc_flags_id",
              "unique": false,
              "method": "btree",
              "columns": [
                "id"
              ]
            }
          ],
          "create_constraints": []
        },
        {
          "schema": "public",
          "table": "risk_rating",
          "columns": [
            {
              "name": "risk_rating_id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": true,
              "fk": null,
              "raw": "risk_rating_id integer NOT NULL"
            },
            {
              "name": "rating_code",
              "type": "character varying(20)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "rating_code character varying(20) NOT NULL"
            },
            {
              "name": "description",
              "type": "character varying(255)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "description character varying(255) NOT NULL"
            }
          ],
          "primary_key": [
            "risk_rating_id"
          ],
          "foreign_keys": [],
          "indexes": [],
          "create_constraints": []
        }
      ]
    },
    {
      "domain": "Reference data",
      "purpose": "Reference/master data used across the platform.",
      "tables": [
        {
          "schema": "public",
          "table": "asset_class",
          "columns": [
            {
              "name": "asset_class_id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": true,
              "fk": null,
              "raw": "asset_class_id integer NOT NULL"
            },
            {
              "name": "asset_code",
              "type": "character varying(20)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "asset_code character varying(20) NOT NULL"
            },
            {
              "name": "asset_name",
              "type": "character varying(100)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "asset_name character varying(100) NOT NULL"
            }
          ],
          "primary_key": [
            "asset_class_id"
          ],
          "foreign_keys": [],
          "indexes": [],
          "create_constraints": []
        },
        {
          "schema": "public",
          "table": "country",
          "columns": [
            {
              "name": "country_id",
              "type": "integer",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": true,
              "fk": null,
              "raw": "country_id integer NOT NULL"
            },
            {
              "name": "country_code",
              "type": "character varying(3)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "country_code character varying(3) NOT NULL"
            },
            {
              "name": "country_name",
              "type": "character varying(100)",
              "nullable": false,
              "default": null,
              "unique": false,
              "pk": false,
              "fk": null,
              "raw": "country_name character varying(100) NOT NULL"
            }
          ],
          "primary_key": [
            "country_id"
          ],
          "foreign_keys": [],
          "indexes": [],
          "create_constraints": []
        }
      ]
    }
  ],
  "summary": {
    "tables": 31,
    "domains": 8,
    "foreign_keys": 15,
    "indexes": 24
  }
}

===== FILE: app_frontend\src\data\platform_domains.json =====
{
  "artifact_type": "platform_domains",
  "artifact_version": "1.0",
  "authority": "MissionAtlas",
  "domains": [
    {
      "domain": "Ingestion",
      "purpose": "Capture and manage inbound source data feeds, ingest runs, mappings and raw records.",
      "tables": [
        "ingestion_runs",
        "source_records_raw",
        "source_systems",
        "source_field_mappings",
        "crm_contacts",
        "corporate_trade_history",
        "transactions",
        "accounts"
      ]
    },
    {
      "domain": "Client canonical",
      "purpose": "Canonical client records, operational state and source coverage.",
      "tables": [
        "clients",
        "client_operational_state",
        "client_source_coverage"
      ]
    },
    {
      "domain": "Matching",
      "purpose": "Run matching, record decisions and maintain client clusters.",
      "tables": [
        "match_runs",
        "match_decisions",
        "client_clusters",
        "client_cluster_members"
      ]
    },
    {
      "domain": "Lineage & dictionary",
      "purpose": "Attribute dictionary, precedence rules and attribute-level lineage.",
      "tables": [
        "client_data_lineage",
        "attribute_dictionary",
        "attribute_precedence_rules"
      ]
    },
    {
      "domain": "Assurance",
      "purpose": "Validation, audit and operational assurance signals, including conflicts and errors.",
      "tables": [
        "validation_results",
        "audit_events",
        "service_health_checks",
        "service_error_logs",
        "attribute_conflicts"
      ]
    },
    {
      "domain": "Evidence",
      "purpose": "Evidence artefacts and bundles generated by governed execution.",
      "tables": [
        "evidence_artefacts",
        "evidence_bundles"
      ]
    },
    {
      "domain": "KYC & risk",
      "purpose": "KYC and risk data, flags, ratings and regulatory enrichment.",
      "tables": [
        "corporate_kyc_info",
        "kyc_flags",
        "risk_rating",
        "client_regulatory_enrichment"
      ]
    },
    {
      "domain": "Reference data",
      "purpose": "Reference/master data used across the platform.",
      "tables": [
        "asset_class",
        "country"
      ]
    }
  ]
}


===== FILE: app_frontend\src\DetailedClientProfilePanel.jsx =====
import React, { useMemo, useState } from "react";

function safeStr(v) {
  if (v === null || v === undefined) return "";
  return String(v);
}

function formatTs(ts) {
  if (!ts) return "â€”";
  const d = new Date(ts);
  if (Number.isNaN(d.getTime())) return safeStr(ts);
  return d.toLocaleString();
}

function formatDateOnly(ts) {
  if (!ts) return "â€”";
  const d = new Date(ts);
  if (Number.isNaN(d.getTime())) return safeStr(ts);
  return d.toLocaleDateString("en-GB");
}

function formatNum(v, digits = 2) {
  if (v === null || v === undefined || v === "") return "â€”";
  const n = typeof v === "number" ? v : Number(v);
  if (!Number.isFinite(n)) return safeStr(v);
  return n.toFixed(digits);
}

function formatQty(v) {
  if (v === null || v === undefined || v === "") return "â€”";
  const n = typeof v === "number" ? v : Number(v);
  if (!Number.isFinite(n)) return safeStr(v);
  return new Intl.NumberFormat("en-GB", { maximumFractionDigits: 0 }).format(n);
}

function StatusChip({ label }) {
  const text = (label || "").toLowerCase();

  let classes =
    "inline-flex items-center rounded-full px-2.5 py-1 text-xs font-body border";

  if (
    text.includes("active") ||
    text.includes("complete") ||
    text.includes("passed") ||
    text.includes("match")
  ) {
    classes += " bg-emerald-50 text-emerald-700 border-emerald-200";
  } else if (
    text.includes("review") ||
    text.includes("progress") ||
    text.includes("pending")
  ) {
    classes += " bg-amber-50 text-amber-700 border-amber-200";
  } else if (
    text.includes("fail") ||
    text.includes("reject") ||
    text.includes("error")
  ) {
    classes += " bg-red-50 text-red-700 border-red-200";
  } else {
    classes += " bg-gray-50 text-gray-700 border-gray-200";
  }

  return <span className={classes}>{label || "â€”"}</span>;
}

function DirectionChip({ value }) {
  const v = (value || "").toString().trim().toUpperCase();

  let classes =
    "inline-flex items-center rounded-full px-2.5 py-1 text-xs font-body border";

  if (v === "BUY") {
    classes += " bg-emerald-50 text-emerald-700 border-emerald-200";
  } else if (v === "SELL") {
    classes += " bg-red-50 text-red-700 border-red-200";
  } else {
    classes += " bg-gray-50 text-gray-700 border-gray-200";
  }

  return <span className={classes}>{v || "â€”"}</span>;
}

function Metric({ label, value, mono = false }) {
  return (
    <div className="flex items-start justify-between gap-4">
      <dt className="text-gray-500">{label}</dt>
      <dd className={`text-right text-gray-900 ${mono ? "font-mono" : ""}`}>
        {value || "â€”"}
      </dd>
    </div>
  );
}

function ConfidenceBar({ value }) {
  const num = typeof value === "number" ? value : Number(value);
  const pct = Number.isFinite(num) ? Math.max(0, Math.min(1, num)) * 100 : null;

  return (
    <div className="min-w-[140px]">
      <div className="flex items-center justify-between mb-1">
        <span className="text-xs font-body text-gray-600">Confidence</span>
        <span className="text-xs font-mono text-gray-700">
          {pct === null ? "â€”" : `${pct.toFixed(1)}%`}
        </span>
      </div>
      <div className="h-2 w-full rounded-full bg-gray-200 overflow-hidden">
        <div
          className="h-2 rounded-full bg-[#1A9988]"
          style={{ width: pct === null ? "0%" : `${pct}%` }}
        />
      </div>
    </div>
  );
}

export default function DetailedClientProfilePanel({
  profile,
  onClose,
  title = "Detailed client profile",
}) {
  const [expandedMatch, setExpandedMatch] = useState({});
  const [expandedAudit, setExpandedAudit] = useState({});
  const [expandedTrade, setExpandedTrade] = useState({});

  const header = useMemo(() => {
    const clientId = safeStr(profile?.client_id || profile?.clientId || "");
    const name = safeStr(
      profile?.name || profile?.full_name || profile?.fullName || ""
    );
    const segment = safeStr(profile?.segment || "");
    const risk = safeStr(profile?.risk_rating || profile?.riskRating || "");
    const lastUpdated =
      profile?.last_updated_at ||
      profile?.lastUpdatedAt ||
      profile?.operational_state?.as_of ||
      "";

    const status = safeStr(
      profile?.operational_state?.status ||
        profile?.status ||
        profile?.current_status ||
        ""
    );

    return {
      clientId: clientId || "â€”",
      name: name || "â€”",
      segment: segment || "â€”",
      risk: risk || "â€”",
      lastUpdated: lastUpdated ? formatTs(lastUpdated) : "â€”",
      status: status || "â€”",
    };
  }, [profile]);

  const operational = profile?.operational_state || null;
  const reg = profile?.regulatory_enrichment || null;

  const matchDecisions = Array.isArray(profile?.match_decisions)
    ? profile.match_decisions
    : [];

  const evidenceArtefacts = Array.isArray(profile?.evidence_artefacts)
    ? profile.evidence_artefacts
    : [];

  const auditTrail = Array.isArray(profile?.audit_trail)
    ? profile.audit_trail
    : [];

  // Trade history (reads from real backend payload; no mocking)
  const tradeHistory = useMemo(() => {
    const arr = Array.isArray(profile?.trade_history)
      ? profile.trade_history
      : Array.isArray(profile?.trades)
        ? profile.trades
        : [];
    // Sort newest first if trade_date present (keeps UI stable)
    return [...arr].sort((a, b) => {
      const da = new Date(a?.trade_date || a?.tradeDate || 0).getTime();
      const db = new Date(b?.trade_date || b?.tradeDate || 0).getTime();
      return (Number.isFinite(db) ? db : 0) - (Number.isFinite(da) ? da : 0);
    });
  }, [profile]);

  return (
    <section className="bg-white rounded-halo shadow-sm border border-gray-200 p-6 mt-6">
      {/* Header */}
      <div className="flex flex-col gap-3 md:flex-row md:items-start md:justify-between">
        <div>
          <h2 className="font-heading text-lg text-gray-800">{title}</h2>
          <div className="mt-2 flex flex-wrap items-center gap-2">
            <span className="text-sm font-body text-gray-900">{header.name}</span>
            <span className="text-xs font-mono text-gray-500">
              ({header.clientId})
            </span>
            <span className="text-xs font-body text-gray-400">â€¢</span>
            <span className="text-xs font-body text-gray-600">
              Segment: {header.segment}
            </span>
            <span className="text-xs font-body text-gray-400">â€¢</span>
            <span className="text-xs font-body text-gray-600">
              Risk: {header.risk}
            </span>
          </div>
        </div>

        <div className="flex flex-col items-start md:items-end gap-2">
          <div className="flex items-center gap-2">
            <StatusChip label={header.status} />
            <span className="text-xs font-body text-gray-500">
              Last update:{" "}
              <span className="font-mono">{header.lastUpdated}</span>
            </span>
          </div>

          <button
            type="button"
            onClick={onClose}
            className="inline-flex items-center justify-center px-3 py-1.5 rounded-md text-sm font-body font-medium bg-gray-100 text-gray-800 border border-gray-200 shadow-sm transition-all duration-150 hover:-translate-y-0.5 hover:shadow-md active:translate-y-0"
          >
            Close
          </button>
        </div>
      </div>

      {/* Two-column content */}
      <div className="mt-6 grid grid-cols-1 lg:grid-cols-2 gap-6">
        {/* LEFT COLUMN */}
        <div className="space-y-6">
          {/* 1. Client Information */}
          <div className="bg-white rounded-halo shadow-sm border border-gray-200 p-6">
            <h3 className="font-heading text-base text-gray-800 mb-4">
              Client information
            </h3>

            <dl className="space-y-2 text-sm font-body text-gray-800">
              <Metric label="Client ID" value={safeStr(profile?.client_id)} mono />
              <Metric label="Full name" value={safeStr(profile?.name)} />
              <Metric label="Primary email" value={safeStr(profile?.email)} />
              <Metric label="Primary phone" value={safeStr(profile?.phone)} />
              <Metric label="Country" value={safeStr(profile?.country)} />
              <Metric
                label="Primary address"
                value={safeStr(profile?.primary_address)}
              />
              <Metric label="Segment" value={safeStr(profile?.segment)} />
              <Metric label="Risk rating" value={safeStr(profile?.risk_rating)} />
            </dl>

            {/* Key metrics */}
            <div className="mt-4 bg-gray-50 rounded-lg border border-gray-200 p-4">
              <h4 className="font-heading text-sm text-gray-700 mb-2">
                Key metrics
              </h4>
              <dl className="space-y-2 text-sm font-body text-gray-800">
                <Metric label="Current status" value={safeStr(header.status)} />
                <Metric label="Last updated" value={header.lastUpdated} mono />
                {operational && (
                  <>
                    <Metric
                      label="Processing stage"
                      value={safeStr(operational.processing_stage)}
                    />
                    <Metric label="Message" value={safeStr(operational.message)} />
                  </>
                )}
              </dl>
            </div>
          </div>

          {/* 3. Regulatory Enrichment */}
          <div className="bg-white rounded-halo shadow-sm border border-gray-200 p-6">
            <h3 className="font-heading text-base text-gray-800 mb-4">
              Regulatory enrichment
            </h3>

            {!reg ? (
              <p className="text-sm font-body text-gray-500">
                No regulatory enrichment available.
              </p>
            ) : (
              <dl className="space-y-2 text-sm font-body text-gray-800">
                <Metric label="FATCA status" value={safeStr(reg.fatca_status)} />
                <Metric
                  label="KYC status"
                  value={safeStr(reg.kyc_overall_status || reg.kyc_status)}
                />
                <Metric
                  label="Risk assessment"
                  value={safeStr(reg.risk_assessment)}
                />
                <Metric
                  label="Onboarding status"
                  value={safeStr(reg.onboarding_status)}
                />
                <Metric label="CRS status" value={safeStr(reg.crs_status)} />
                {reg.derived_risk_notes && (
                  <div className="mt-3 text-sm font-body text-gray-800">
                    <div className="text-gray-500 mb-1">Notes</div>
                    <div className="bg-gray-50 rounded-md border border-gray-200 p-3 text-gray-900">
                      {safeStr(reg.derived_risk_notes)}
                    </div>
                  </div>
                )}
              </dl>
            )}
          </div>

          {/* 4. Evidence Artefacts */}
          <div className="bg-white rounded-halo shadow-sm border border-gray-200 p-6">
            <h3 className="font-heading text-base text-gray-800 mb-4">
              Evidence artefacts
            </h3>

            {evidenceArtefacts.length === 0 ? (
              <p className="text-sm font-body text-gray-500">
                No evidence artefacts available.
              </p>
            ) : (
              <div className="overflow-auto border border-gray-200 rounded-md">
                <table className="min-w-full text-sm font-body">
                  <thead className="bg-gray-50 text-gray-700">
                    <tr>
                      <th className="text-left px-4 py-3 font-medium">Type</th>
                      <th className="text-left px-4 py-3 font-medium">Created</th>
                      <th className="text-left px-4 py-3 font-medium">Source</th>
                      <th className="text-left px-4 py-3 font-medium">Reference</th>
                    </tr>
                  </thead>
                  <tbody className="divide-y divide-gray-200 bg-white">
                    {evidenceArtefacts.map((a, idx) => (
                      <tr key={a.artefact_id || a.id || idx}>
                        <td className="px-4 py-3 text-gray-900">
                          {safeStr(a.artefact_type || a.document_type || a.type) ||
                            "â€”"}
                        </td>
                        <td className="px-4 py-3 text-gray-900 font-mono text-xs">
                          {formatTs(a.created_at || a.uploaded_at || a.upload_date)}
                        </td>
                        <td className="px-4 py-3 text-gray-900">
                          {safeStr(a.source_system || a.source) || "â€”"}
                        </td>
                        <td className="px-4 py-3 text-gray-900 font-mono text-xs">
                          {safeStr(a.storage_ref || a.link || a.reference) || "â€”"}
                        </td>
                      </tr>
                    ))}
                  </tbody>
                </table>
              </div>
            )}
          </div>
        </div>

        {/* RIGHT COLUMN */}
        <div className="space-y-6">
          {/* 2. Match Decisions */}
          <div className="bg-white rounded-halo shadow-sm border border-gray-200 p-6">
            <h3 className="font-heading text-base text-gray-800 mb-4">
              Match decisions
            </h3>

            {matchDecisions.length === 0 ? (
              <p className="text-sm font-body text-gray-500">
                No match decisions available.
              </p>
            ) : (
              <div className="overflow-auto border border-gray-200 rounded-md">
                <table className="min-w-full text-sm font-body">
                  <thead className="bg-gray-50 text-gray-700">
                    <tr>
                      <th className="text-left px-4 py-3 font-medium">Decided</th>
                      <th className="text-left px-4 py-3 font-medium">Decision</th>
                      <th className="text-left px-4 py-3 font-medium">Source</th>
                      <th className="text-left px-4 py-3 font-medium">IDs</th>
                      <th className="text-left px-4 py-3 font-medium">
                        Confidence
                      </th>
                      <th className="text-left px-4 py-3 font-medium">Action</th>
                    </tr>
                  </thead>
                  <tbody className="divide-y divide-gray-200 bg-white">
                    {matchDecisions.map((m, idx) => {
                      const key = m.match_decision_id || m.id || idx;
                      const isOpen = !!expandedMatch[key];

                      return (
                        <React.Fragment key={key}>
                          <tr>
                            <td className="px-4 py-3 font-mono text-xs text-gray-900">
                              {formatTs(m.decided_at)}
                            </td>
                            <td className="px-4 py-3 text-gray-900">
                              <StatusChip label={safeStr(m.decision)} />
                            </td>
                            <td className="px-4 py-3 text-gray-900">
                              {safeStr(m.source_system || m.system) || "â€”"}
                            </td>
                            <td className="px-4 py-3 text-gray-900">
                              <div className="text-xs font-mono text-gray-700">
                                src: {safeStr(m.source_record_id) || "â€”"}
                              </div>
                              <div className="text-xs font-mono text-gray-700">
                                match: {safeStr(m.matched_client_id) || "â€”"}
                              </div>
                            </td>
                            <td className="px-4 py-3">
                              <ConfidenceBar value={m.confidence} />
                            </td>
                            <td className="px-4 py-3">
                              <button
                                type="button"
                                className="inline-flex items-center justify-center px-3 py-1.5 rounded-md text-sm text-gray-900 bg-[rgb(205,226,235)] shadow-sm transition-all duration-150 hover:-translate-y-0.5 hover:shadow-md active:translate-y-0 active:shadow-sm"
                                onClick={() =>
                                  setExpandedMatch((prev) => ({
                                    ...prev,
                                    [key]: !prev[key],
                                  }))
                                }
                              >
                                {isOpen ? "Hide" : "View"}
                              </button>
                            </td>
                          </tr>

                          {isOpen && (
                            <tr className="bg-gray-50">
                              <td colSpan={6} className="px-4 py-3">
                                <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
                                  <div className="bg-white border border-gray-200 rounded-md p-3">
                                    <div className="text-xs font-body text-gray-600 mb-2">
                                      Rule hits
                                    </div>
                                    <pre className="whitespace-pre-wrap text-[11px] font-mono text-gray-800">
                                      {JSON.stringify(m.rule_hits || {}, null, 2)}
                                    </pre>
                                  </div>
                                  <div className="bg-white border border-gray-200 rounded-md p-3">
                                    <div className="text-xs font-body text-gray-600 mb-2">
                                      Conflict summary
                                    </div>
                                    <pre className="whitespace-pre-wrap text-[11px] font-mono text-gray-800">
                                      {JSON.stringify(
                                        m.conflict_summary || {},
                                        null,
                                        2
                                      )}
                                    </pre>
                                  </div>
                                </div>
                              </td>
                            </tr>
                          )}
                        </React.Fragment>
                      );
                    })}
                  </tbody>
                </table>
              </div>
            )}
          </div>

          {/* Trade History */}
          <div className="bg-white rounded-halo shadow-sm border border-gray-200 p-6">
            <h3 className="font-heading text-base text-gray-800 mb-4">
              Trade history
            </h3>

            {tradeHistory.length === 0 ? (
              <p className="text-sm font-body text-gray-500">
                No trade history available.
              </p>
            ) : (
              <div className="overflow-auto border border-gray-200 rounded-md">
                <table className="min-w-full text-sm font-body">
                  <thead className="bg-gray-50 text-gray-700">
                    {/* LOCKED COLUMN ORDER */}
                    <tr>
                      <th className="text-left px-4 py-3 font-medium">Trade date</th>
                      <th className="text-left px-4 py-3 font-medium">
                        Asset class
                      </th>
                      <th className="text-left px-4 py-3 font-medium">Instrument</th>
                      <th className="text-left px-4 py-3 font-medium">Dir</th>
                      <th className="text-left px-4 py-3 font-medium">Qty</th>
                      <th className="text-left px-4 py-3 font-medium">Price</th>
                      <th className="text-left px-4 py-3 font-medium">PnL</th>
                      <th className="text-left px-4 py-3 font-medium">Action</th>
                    </tr>
                  </thead>
                  <tbody className="divide-y divide-gray-200 bg-white">
                    {tradeHistory.map((t, idx) => {
                      const key = t.trade_id || t.id || idx;
                      const isOpen = !!expandedTrade[key];

                      // LOCKED FIELD RESOLUTION (stable mapping regardless of backend variation)
                      const tradeDate = t.trade_date || t.tradeDate;
                      const assetClass = t.asset_class || t.assetClass;
                      const instrument =
                        t.instrument || t.symbol || t.ccy_pair || t.ccyPair;
                      const direction = t.direction || t.side;
                      const qty = t.quantity ?? t.qty ?? t.notional;
                      const price = t.price ?? t.rate;
                      const pnl = t.pnl ?? t.p_and_l ?? t.pAndL;

                      return (
                        <React.Fragment key={key}>
                          <tr>
                            <td className="px-4 py-3 font-mono text-xs text-gray-900">
                              {formatDateOnly(tradeDate)}
                            </td>
                            <td className="px-4 py-3 text-gray-900">
                              {safeStr(assetClass) || "â€”"}
                            </td>
                            <td className="px-4 py-3 text-gray-900">
                              {safeStr(instrument) || "â€”"}
                            </td>
                            <td className="px-4 py-3 text-gray-900">
                              <DirectionChip value={direction} />
                            </td>
                            <td className="px-4 py-3 font-mono text-xs text-gray-900">
                              {formatQty(qty)}
                            </td>
                            <td className="px-4 py-3 font-mono text-xs text-gray-900">
                              {price === null || price === undefined ? "â€”" : safeStr(price)}
                            </td>
                            <td className="px-4 py-3 font-mono text-xs text-gray-900">
                              {pnl === null || pnl === undefined ? "â€”" : safeStr(pnl)}
                            </td>
                            <td className="px-4 py-3">
                              <button
                                type="button"
                                className="inline-flex items-center justify-center px-3 py-1.5 rounded-md text-sm text-gray-900 bg-[rgb(205,226,235)] shadow-sm transition-all duration-150 hover:-translate-y-0.5 hover:shadow-md active:translate-y-0 active:shadow-sm"
                                onClick={() =>
                                  setExpandedTrade((prev) => ({
                                    ...prev,
                                    [key]: !prev[key],
                                  }))
                                }
                              >
                                {isOpen ? "Hide" : "View"}
                              </button>
                            </td>
                          </tr>

                          {isOpen && (
                            <tr className="bg-gray-50">
                              <td colSpan={8} className="px-4 py-3">
                                <div className="bg-white border border-gray-200 rounded-md p-3">
                                  <div className="text-xs font-body text-gray-600 mb-2">
                                    Full trade record
                                  </div>
                                  <pre className="whitespace-pre-wrap text-[11px] font-mono text-gray-800">
                                    {JSON.stringify(t, null, 2)}
                                  </pre>
                                </div>
                              </td>
                            </tr>
                          )}
                        </React.Fragment>
                      );
                    })}
                  </tbody>
                </table>
              </div>
            )}
          </div>

          {/* 5. Audit Trail */}
          <div className="bg-white rounded-halo shadow-sm border border-gray-200 p-6">
            <h3 className="font-heading text-base text-gray-800 mb-4">
              Audit trail
            </h3>

            {auditTrail.length === 0 ? (
              <p className="text-sm font-body text-gray-500">
                No audit events available.
              </p>
            ) : (
              <div className="overflow-auto border border-gray-200 rounded-md">
                <table className="min-w-full text-sm font-body">
                  <thead className="bg-gray-50 text-gray-700">
                    <tr>
                      <th className="text-left px-4 py-3 font-medium">When</th>
                      <th className="text-left px-4 py-3 font-medium">
                        Event type
                      </th>
                      <th className="text-left px-4 py-3 font-medium">Actor</th>
                      <th className="text-left px-4 py-3 font-medium">Details</th>
                      <th className="text-left px-4 py-3 font-medium">Action</th>
                    </tr>
                  </thead>
                  <tbody className="divide-y divide-gray-200 bg-white">
                    {auditTrail.map((a, idx) => {
                      const key = a.audit_event_id || a.id || idx;
                      const isOpen = !!expandedAudit[key];

                      const summary =
                        a?.details?.summary ||
                        a?.summary ||
                        a?.details_text ||
                        a?.details?.message ||
                        "";

                      return (
                        <React.Fragment key={key}>
                          <tr>
                            <td className="px-4 py-3 font-mono text-xs text-gray-900">
                              {formatTs(a.occurred_at || a.timestamp || a.created_at)}
                            </td>
                            <td className="px-4 py-3 text-gray-900">
                              {safeStr(a.event_type) || "â€”"}
                            </td>
                            <td className="px-4 py-3 text-gray-900">
                              {safeStr(a.actor) || "â€”"}
                            </td>
                            <td className="px-4 py-3 text-gray-900">
                              {summary ? (
                                <span className="text-sm font-body text-gray-800">
                                  {safeStr(summary)}
                                </span>
                              ) : (
                                <span className="text-sm font-body text-gray-500">
                                  â€”
                                </span>
                              )}
                            </td>
                            <td className="px-4 py-3">
                              <button
                                type="button"
                                className="inline-flex items-center justify-center px-3 py-1.5 rounded-md text-sm text-gray-900 bg-[rgb(205,226,235)] shadow-sm transition-all duration-150 hover:-translate-y-0.5 hover:shadow-md active:translate-y-0 active:shadow-sm"
                                onClick={() =>
                                  setExpandedAudit((prev) => ({
                                    ...prev,
                                    [key]: !prev[key],
                                  }))
                                }
                              >
                                {isOpen ? "Hide" : "View"}
                              </button>
                            </td>
                          </tr>

                          {isOpen && (
                            <tr className="bg-gray-50">
                              <td colSpan={5} className="px-4 py-3">
                                <div className="bg-white border border-gray-200 rounded-md p-3">
                                  <div className="text-xs font-body text-gray-600 mb-2">
                                    Full details
                                  </div>
                                  <pre className="whitespace-pre-wrap text-[11px] font-mono text-gray-800">
                                    {JSON.stringify(a.details || a, null, 2)}
                                  </pre>
                                </div>
                              </td>
                            </tr>
                          )}
                        </React.Fragment>
                      );
                    })}
                  </tbody>
                </table>
              </div>
            )}
          </div>
        </div>
      </div>
    </section>
  );
}




===== FILE: app_frontend\src\index.css =====
/* app_frontend/src/index.css */

/* Tailwind v4 (base, components, utilities) */
@import "tailwindcss";

/* Global defaults */
:root {
  font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI",
    sans-serif;
}

*,
*::before,
*::after {
  box-sizing: border-box;
}

body {
  margin: 0;
  min-height: 100vh;
}

/* ------------------------------------------------------------ */
/* Fjalla One font class (used for MissionSmith / Atlas / Log)  */
/* ------------------------------------------------------------ */
.font-fjalla {
  font-family: "Fjalla One", sans-serif;
}


===== FILE: app_frontend\src\main.jsx =====
import { StrictMode } from 'react'
import { createRoot } from 'react-dom/client'
import './index.css'
import App from './App.jsx'

createRoot(document.getElementById('root')).render(
  <StrictMode>
    <App />
  </StrictMode>,
)


===== FILE: app_frontend\src\mission_atlas\technology_bom.js =====
export const technologyBOM = {
  components: [
    {
      name: "frontend",
      type: "microservice",
      runtime: "docker",
      language: "JavaScript",
      framework: "React",
      repoPath: "app_frontend/src",
      interfaces: [
        { type: "REST", endpoint: "/api/clients", method: "GET", description: "Fetch clients data" },
        { type: "REST", endpoint: "/api/clients/{id}", method: "GET", description: "Fetch client details by ID" }
      ],
      dependencies: ["bff"],
      dataStores: ["client_database"],
      assuranceSignals: ["unit-test", "eslint", "security-scan"],
      status: "Live"
    },
    // Add more components as required...
  ],
  interfaces: [
    {
      name: "client-api",
      type: "REST",
      method: "GET",
      path: "/clients/{id}",
      requestModel: "ClientRequest",
      responseModel: "ClientResponse"
    },
    // Add more interfaces...
  ],
  runtimeWiring: [
    {
      service: "frontend",
      port: 8080,
      baseUrl: "http://localhost:8080",
      dependencies: ["bff"]
    },
    {
      service: "bff",
      port: 5000,
      baseUrl: "http://localhost:5000",
      dependencies: ["service-a"]
    },
    // Add more wiring...
  ]
};


===== FILE: app_frontend\src\MissionAtlasLogicalDataModelPanel.jsx =====
// C:\Dev\scv-repo\app_frontend\src\MissionAtlasLogicalDataModelPanel.jsx
import React, { useMemo, useState } from "react";
import physicalModel from "./data/physical_model_by_domain.json";

export default function MissionAtlasLogicalDataModelPanel() {
  const [selectedDomain, setSelectedDomain] = useState(
    physicalModel?.domains?.[0]?.domain || ""
  );
  const [selectedConceptFq, setSelectedConceptFq] = useState(null); // "public.clients"
  const [conceptQuery, setConceptQuery] = useState("");
  const [attributeQuery, setAttributeQuery] = useState("");

  const normalise = (s) => (s || "").toString().trim().toLowerCase();

  const pascalFromSnake = (s) =>
    (s || "")
      .split("_")
      .filter(Boolean)
      .map((x) => x.charAt(0).toUpperCase() + x.slice(1))
      .join("");

  const singularise = (name) => {
    // crude but effective for table names: clients -> Client, bundles -> Bundle
    const n = name || "";
    if (n.endsWith("sses")) return n; // addresses etc (rare)
    if (n.endsWith("ies")) return n.slice(0, -3) + "y";
    if (n.endsWith("ses")) return n.slice(0, -2); // cases -> case (rare)
    if (n.endsWith("s") && !n.endsWith("ss")) return n.slice(0, -1);
    return n;
  };

  const classifyConcept = (tableName) => {
    const t = (tableName || "").toLowerCase();
    if (t.includes("reference") || t === "country" || t === "asset_class") return "Reference";
    if (t.includes("run") || t.includes("event") || t.includes("log")) return "Operational event";
    if (t.includes("audit") || t.includes("validation") || t.includes("health_check")) return "Assurance signal";
    if (t.includes("evidence") || t.includes("artefact") || t.includes("bundle")) return "Evidence record";
    if (t.includes("lineage") || t.includes("dictionary") || t.includes("precedence")) return "Semantic control";
    if (t.includes("kyc") || t.includes("risk") || t.includes("flag")) return "Regulatory state";
    if (t.includes("cluster") || t.includes("match") || t.includes("decision")) return "Resolution state";
    if (t === "clients" || t.includes("client_")) return "Canonical state";
    if (t.includes("source") || t.includes("ingestion") || t.includes("raw")) return "Ingress state";
    return "Data entity";
  };

  const domains = useMemo(() => physicalModel?.domains || [], []);
  const selectedDomainObj = useMemo(() => {
    return domains.find((d) => d.domain === selectedDomain) || domains[0] || null;
  }, [domains, selectedDomain]);

  // Build fq map for relationships
  const tableByFq = useMemo(() => {
    const m = new Map();
    for (const d of domains) {
      for (const t of d.tables || []) {
        const fq = `${t.schema}.${t.table}`;
        m.set(fq, { ...t, fq, platformDomain: d.domain, platformPurpose: d.purpose });
      }
    }
    return m;
  }, [domains]);

  const inboundRefsByTable = useMemo(() => {
    const inbound = new Map(); // fq -> [{fromFq, fromCols, toCols, fkName}]
    for (const d of domains) {
      for (const t of d.tables || []) {
        const fromFq = `${t.schema}.${t.table}`;
        for (const fk of t.foreign_keys || []) {
          const toFq = fk.references_table;
          if (!inbound.has(toFq)) inbound.set(toFq, []);
          inbound.get(toFq).push({
            fromFq,
            fromCols: fk.columns || [],
            toCols: fk.references_columns || [],
            fkName: fk.name || null,
            raw: fk.raw || null,
          });
        }
      }
    }
    for (const [k, v] of inbound.entries()) {
      v.sort((a, b) => a.fromFq.localeCompare(b.fromFq));
      inbound.set(k, v);
    }
    return inbound;
  }, [domains]);

  const domainSummaries = useMemo(() => {
    // Cross-domain dependencies derived from FKs
    const fqToDomain = new Map();
    for (const d of domains) {
      for (const t of d.tables || []) fqToDomain.set(`${t.schema}.${t.table}`, d.domain);
    }

    return domains.map((d) => {
      const tables = d.tables || [];
      const tableCount = tables.length;
      const colCount = tables.reduce((acc, t) => acc + (t.columns?.length || 0), 0);
      const fkCount = tables.reduce((acc, t) => acc + (t.foreign_keys?.length || 0), 0);

      const outboundRefs = new Map(); // refDomain -> count
      for (const t of tables) {
        for (const fk of t.foreign_keys || []) {
          const refDom = fqToDomain.get(fk.references_table) || "External/Unknown";
          if (refDom === d.domain) continue;
          outboundRefs.set(refDom, (outboundRefs.get(refDom) || 0) + 1);
        }
      }

      return {
        domain: d.domain,
        purpose: d.purpose,
        tableCount,
        colCount,
        fkCount,
        outboundRefs: [...outboundRefs.entries()]
          .map(([refDomain, count]) => ({ refDomain, count }))
          .sort((a, b) => b.count - a.count || a.refDomain.localeCompare(b.refDomain)),
      };
    });
  }, [domains]);

  const conceptsInSelectedDomain = useMemo(() => {
    const q = normalise(conceptQuery);
    const tables = selectedDomainObj?.tables || [];

    return tables
      .map((t) => {
        const fq = `${t.schema}.${t.table}`;
        const logicalName = pascalFromSnake(singularise(t.table));
        const conceptType = classifyConcept(t.table);

        // derive a "key surface" summary
        const pk = t.primary_key || [];
        const fks = t.foreign_keys || [];
        const inbound = inboundRefsByTable.get(fq) || [];

        return {
          fq,
          schema: t.schema,
          table: t.table,
          logicalName,
          conceptType,
          purposeHint: selectedDomainObj?.purpose || "",
          columns: t.columns || [],
          primary_key: pk,
          foreign_keys: fks,
          inbound_refs: inbound,
          colCount: t.columns?.length || 0,
          fkCount: fks.length,
          inboundCount: inbound.length,
        };
      })
      .filter((c) => {
        if (!q) return true;
        return (
          normalise(c.logicalName).includes(q) ||
          normalise(c.table).includes(q) ||
          normalise(c.conceptType).includes(q) ||
          normalise(c.fq).includes(q)
        );
      })
      .sort((a, b) => a.logicalName.localeCompare(b.logicalName));
  }, [selectedDomainObj, conceptQuery, inboundRefsByTable]);

  const selectedConcept = useMemo(() => {
    if (!selectedConceptFq) return null;
    return conceptsInSelectedDomain.find((c) => c.fq === selectedConceptFq) || null;
  }, [selectedConceptFq, conceptsInSelectedDomain]);

  // default concept selection
  if (!selectedConceptFq && conceptsInSelectedDomain.length) {
    setSelectedConceptFq(conceptsInSelectedDomain[0].fq);
  }

  const filteredAttributes = useMemo(() => {
    if (!selectedConcept) return [];
    const q = normalise(attributeQuery);

    return (selectedConcept.columns || [])
      .map((c) => ({
        name: c.name,
        type: c.type,
        nullable: c.nullable,
        default: c.default,
        pk: !!c.pk,
        fk: c.fk || null,
      }))
      .filter((a) => {
        if (!q) return true;
        return (
          normalise(a.name).includes(q) ||
          normalise(a.type).includes(q) ||
          (a.default ? normalise(a.default).includes(q) : false) ||
          (a.fk ? normalise(a.fk.references_table).includes(q) : false)
        );
      });
  }, [selectedConcept, attributeQuery]);

  const relationshipNarrative = (concept) => {
    if (!concept) return "";
    const outbound = concept.foreign_keys || [];
    const inbound = concept.inbound_refs || [];

    const parts = [];
    if (outbound.length) parts.push(`References ${outbound.length} upstream entity${outbound.length === 1 ? "" : "ies"}.`);
    if (inbound.length) parts.push(`Referenced by ${inbound.length} downstream entity${inbound.length === 1 ? "" : "ies"}.`);
    if (!outbound.length && !inbound.length) parts.push("No explicit FK relationships captured for this entity.");
    return parts.join(" ");
  };

  return (
    <div className="space-y-4">
      {/* Header */}
      <div className="rounded-halo border border-gray-200 bg-white p-4">
        <div className="flex flex-col gap-3 lg:flex-row lg:items-end lg:justify-between">
          <div>
            <h3 className="font-heading text-sm text-gray-900">Logical Data Model</h3>
            <p className="mt-1 text-xs font-body text-gray-600">
              A semantic view derived from the physical schema. Domains contain logical concepts mapped back to real tables and columns.
            </p>
          </div>

          <span className="text-[11px] font-mono rounded-md px-2 py-1 border bg-gray-50 border-gray-200 text-gray-600">
            tables: {physicalModel?.summary?.tables ?? "â€”"} â€¢ domains: {physicalModel?.summary?.domains ?? "â€”"} â€¢ fks:{" "}
            {physicalModel?.summary?.foreign_keys ?? "â€”"}
          </span>
        </div>
      </div>

      {/* Domain overview */}
      <div className="rounded-halo border border-gray-200 bg-white p-4">
        <div className="flex items-start justify-between gap-4">
          <div>
            <h4 className="font-heading text-sm text-gray-900">Platform domains</h4>
            <p className="mt-1 text-xs font-body text-gray-600">
              Select a domain to inspect its logical concepts and their mappings to physical entities.
            </p>
          </div>

          <select
            value={selectedDomain}
            onChange={(e) => {
              setSelectedDomain(e.target.value);
              setSelectedConceptFq(null);
              setConceptQuery("");
              setAttributeQuery("");
            }}
            className="px-3 py-2 rounded-md text-sm font-body border border-gray-200 bg-white"
          >
            {domains.map((d) => (
              <option key={`ldm-dom-${d.domain}`} value={d.domain}>
                {d.domain}
              </option>
            ))}
          </select>
        </div>

        <div className="mt-4 grid grid-cols-1 lg:grid-cols-4 gap-3">
          {domainSummaries.map((s) => {
            const active = s.domain === selectedDomain;
            return (
              <button
                key={`ldm-sum-${s.domain}`}
                type="button"
                onClick={() => {
                  setSelectedDomain(s.domain);
                  setSelectedConceptFq(null);
                  setConceptQuery("");
                  setAttributeQuery("");
                }}
                className={`text-left rounded-md border p-3 transition ${
                  active ? "bg-amber-50 border-amber-300 shadow" : "bg-gray-50 border-gray-200 hover:bg-gray-100"
                }`}
              >
                <div className="font-heading text-sm text-gray-900">{s.domain}</div>
                <div className="mt-1 text-[11px] font-body text-gray-600 line-clamp-2">{s.purpose}</div>

                <div className="mt-3 grid grid-cols-3 gap-2">
                  <div className="rounded-md border border-gray-200 bg-white px-2 py-1">
                    <div className="text-[11px] font-body text-gray-600">Tables</div>
                    <div className="font-heading text-sm text-gray-900">{s.tableCount}</div>
                  </div>
                  <div className="rounded-md border border-gray-200 bg-white px-2 py-1">
                    <div className="text-[11px] font-body text-gray-600">Columns</div>
                    <div className="font-heading text-sm text-gray-900">{s.colCount}</div>
                  </div>
                  <div className="rounded-md border border-gray-200 bg-white px-2 py-1">
                    <div className="text-[11px] font-body text-gray-600">FKs</div>
                    <div className="font-heading text-sm text-gray-900">{s.fkCount}</div>
                  </div>
                </div>

                {s.outboundRefs?.length ? (
                  <div className="mt-3">
                    <div className="text-[11px] font-body text-gray-600 mb-1">Cross-domain dependencies</div>
                    <div className="flex flex-wrap gap-2">
                      {s.outboundRefs.slice(0, 4).map((r) => (
                        <span
                          key={`ldm-od-${s.domain}-${r.refDomain}`}
                          className="text-[11px] font-mono rounded-md px-2 py-1 border bg-white border-gray-200 text-gray-700"
                        >
                          {r.refDomain}: {r.count}
                        </span>
                      ))}
                    </div>
                  </div>
                ) : null}
              </button>
            );
          })}
        </div>
      </div>

      {/* Concept selector + inspector */}
      <div className="grid grid-cols-1 lg:grid-cols-3 gap-4">
        {/* Concept list */}
        <div className="rounded-halo border border-gray-200 bg-white p-4">
          <div className="flex items-start justify-between gap-3">
            <div>
              <h4 className="font-heading text-sm text-gray-900">Logical concepts</h4>
              <p className="mt-1 text-xs font-body text-gray-600">
                Concepts are derived from domain tables (1:1 mapping) and then enriched with semantics, keying and relationships.
              </p>
            </div>
            <span className="text-[11px] font-mono rounded-md px-2 py-1 border bg-gray-50 border-gray-200 text-gray-600">
              {conceptsInSelectedDomain.length}
            </span>
          </div>

          <input
            value={conceptQuery}
            onChange={(e) => setConceptQuery(e.target.value)}
            placeholder="Search conceptsâ€¦"
            className="mt-3 w-full px-3 py-2 rounded-md text-sm font-body border border-gray-200 bg-white"
          />

          <div className="mt-3 space-y-2 max-h-[520px] overflow-auto pr-1">
            {conceptsInSelectedDomain.map((c) => {
              const active = c.fq === selectedConceptFq;
              return (
                <button
                  key={`concept-${c.fq}`}
                  type="button"
                  onClick={() => setSelectedConceptFq(c.fq)}
                  className={`w-full text-left rounded-md border p-3 transition ${
                    active ? "bg-amber-50 border-amber-300 shadow" : "bg-gray-50 border-gray-200 hover:bg-gray-100"
                  }`}
                >
                  <div className="flex items-start justify-between gap-3">
                    <div>
                      <div className="font-heading text-sm text-gray-900">{c.logicalName}</div>
                      <div className="mt-1 text-[11px] font-mono text-gray-700">{c.fq}</div>
                      <div className="mt-1 text-[11px] font-body text-gray-600">
                        cols: {c.colCount} â€¢ outbound: {c.fkCount} â€¢ inbound: {c.inboundCount}
                      </div>
                    </div>

                    <span className="text-[11px] font-mono rounded-md px-2 py-1 border bg-white border-gray-200 text-gray-700">
                      {c.conceptType}
                    </span>
                  </div>
                </button>
              );
            })}
          </div>
        </div>

        {/* Concept detail */}
        <div className="lg:col-span-2 rounded-halo border border-gray-200 bg-white p-4">
          {!selectedConcept ? (
            <div className="text-sm font-body text-gray-700">Select a concept to inspect.</div>
          ) : (
            <div className="space-y-4">
              <div className="flex flex-col gap-3 lg:flex-row lg:items-start lg:justify-between">
                <div>
                  <h4 className="font-heading text-sm text-gray-900">{selectedConcept.logicalName}</h4>
                  <div className="mt-1 text-xs font-body text-gray-600">
                    <span className="font-mono">{selectedConcept.fq}</span> â€¢ {selectedConcept.conceptType}
                  </div>
                  <div className="mt-2 text-xs font-body text-gray-700">
                    <span className="text-gray-600">Domain intent:</span> {selectedConceptObjOrEmpty(selectedDomainObj)?.purpose || ""}
                  </div>
                </div>

                <div className="flex flex-wrap gap-2">
                  <span className="text-[11px] font-mono rounded-md px-2 py-1 border bg-gray-50 border-gray-200 text-gray-700">
                    PK: {selectedConcept.primary_key?.length ? selectedConcept.primary_key.join(", ") : "â€”"}
                  </span>
                  <span className="text-[11px] font-mono rounded-md px-2 py-1 border bg-teal-50 border-teal-200 text-gray-800">
                    outbound: {selectedConcept.fkCount}
                  </span>
                  <span className="text-[11px] font-mono rounded-md px-2 py-1 border bg-amber-50 border-amber-200 text-gray-800">
                    inbound: {selectedConcept.inboundCount}
                  </span>
                </div>
              </div>

              {/* Relationship narrative */}
              <div className="rounded-md border border-gray-200 bg-gray-50 p-3">
                <div className="text-xs font-body text-gray-600">Relationship surface</div>
                <div className="mt-1 text-xs font-body text-gray-800">{relationshipNarrative(selectedConcept)}</div>
              </div>

              {/* Relationships (Outbound / Inbound) */}
              <div className="grid grid-cols-1 lg:grid-cols-2 gap-4">
                <div className="rounded-md border border-gray-200 bg-gray-50 p-3">
                  <div className="font-heading text-sm text-gray-900">Outbound relationships</div>
                  <div className="mt-1 text-xs font-body text-gray-600">
                    Foreign keys expressed as logical references to upstream concepts.
                  </div>
                  <ul className="mt-2 list-disc pl-5 space-y-1">
                    {(selectedConcept.foreign_keys || []).length ? (
                      selectedConcept.foreign_keys.map((fk, idx) => {
                        const ref = tableByFq.get(fk.references_table);
                        const refLogical = ref ? pascalFromSnake(singularise(ref.table)) : fk.references_table;
                        const refDomain = ref?.platformDomain || "External/Unknown";
                        return (
                          <li key={`out-${idx}`} className="text-xs font-body text-gray-800">
                            <span className="font-mono">
                              {selectedConcept.logicalName}.{(fk.columns || []).join(", ")} â†’ {refLogical}.
                              {(fk.references_columns || []).join(", ")}
                            </span>{" "}
                            <span className="text-gray-500">({refDomain})</span>
                          </li>
                        );
                      })
                    ) : (
                      <li className="text-xs font-body text-gray-600">None.</li>
                    )}
                  </ul>
                </div>

                <div className="rounded-md border border-gray-200 bg-gray-50 p-3">
                  <div className="font-heading text-sm text-gray-900">Inbound relationships</div>
                  <div className="mt-1 text-xs font-body text-gray-600">
                    Downstream concepts that reference this concept (reverse FK view).
                  </div>
                  <ul className="mt-2 list-disc pl-5 space-y-1">
                    {(selectedConcept.inbound_refs || []).length ? (
                      selectedConcept.inbound_refs.map((r, idx) => {
                        const from = tableByFq.get(r.fromFq);
                        const fromLogical = from ? pascalFromSnake(singularise(from.table)) : r.fromFq;
                        const fromDomain = from?.platformDomain || "External/Unknown";
                        return (
                          <li key={`in-${idx}`} className="text-xs font-body text-gray-800">
                            <span className="font-mono">
                              {fromLogical}.{(r.fromCols || []).join(", ")} â†’ {selectedConcept.logicalName}.
                              {(r.toCols || []).join(", ")}
                            </span>{" "}
                            <span className="text-gray-500">({fromDomain})</span>
                          </li>
                        );
                      })
                    ) : (
                      <li className="text-xs font-body text-gray-600">None.</li>
                    )}
                  </ul>
                </div>
              </div>

              {/* Attributes */}
              <div className="rounded-md border border-gray-200 bg-gray-50 p-3">
                <div className="flex items-start justify-between gap-3">
                  <div>
                    <div className="font-heading text-sm text-gray-900">Attributes</div>
                    <div className="mt-1 text-xs font-body text-gray-600">
                      Logical attributes mapped 1:1 to physical columns (type/null/default/keying).
                    </div>
                  </div>

                  <input
                    value={attributeQuery}
                    onChange={(e) => setAttributeQuery(e.target.value)}
                    placeholder="Search attributesâ€¦"
                    className="px-3 py-2 rounded-md text-sm font-body border border-gray-200 bg-white min-w-[240px]"
                  />
                </div>

                <div className="mt-3 overflow-x-auto">
                  <table className="w-full text-xs bg-white rounded-md overflow-hidden border border-gray-200">
                    <thead className="bg-gray-50">
                      <tr className="text-left text-gray-600">
                        <th className="py-2 px-2">Attribute</th>
                        <th className="py-2 px-2">Type</th>
                        <th className="py-2 px-2">Null</th>
                        <th className="py-2 px-2">Default</th>
                        <th className="py-2 px-2">Keying</th>
                        <th className="py-2 px-2">Mapping</th>
                      </tr>
                    </thead>
                    <tbody>
                      {filteredAttributes.map((a) => (
                        <tr key={`attr-${selectedConcept.fq}-${a.name}`} className="border-t">
                          <td className="py-2 px-2 font-mono text-gray-900">{a.name}</td>
                          <td className="py-2 px-2 text-gray-800">{a.type}</td>
                          <td className="py-2 px-2 text-gray-800">{a.nullable ? "YES" : "NO"}</td>
                          <td className="py-2 px-2 text-gray-800">{a.default || "â€”"}</td>
                          <td className="py-2 px-2">
                            <div className="flex flex-wrap gap-2">
                              {a.pk ? (
                                <span className="text-[11px] font-mono rounded-md px-2 py-1 border bg-amber-50 border-amber-200 text-gray-800">
                                  PK
                                </span>
                              ) : null}
                              {a.fk ? (
                                <span className="text-[11px] font-mono rounded-md px-2 py-1 border bg-teal-50 border-teal-200 text-gray-800">
                                  FK
                                </span>
                              ) : null}
                            </div>
                          </td>
                          <td className="py-2 px-2 text-gray-800">
                            <span className="font-mono text-[11px] text-gray-700">
                              {selectedConcept.fq}.{a.name}
                            </span>
                            {a.fk ? (
                              <div className="mt-1 text-[11px] font-mono text-gray-500">
                                â†’ {a.fk.references_table}({(a.fk.references_columns || []).join(", ")})
                              </div>
                            ) : null}
                          </td>
                        </tr>
                      ))}
                      {!filteredAttributes.length ? (
                        <tr className="border-t">
                          <td className="py-3 px-2 text-xs font-body text-gray-600" colSpan={6}>
                            No attributes match the current filter.
                          </td>
                        </tr>
                      ) : null}
                    </tbody>
                  </table>
                </div>

                {/* Raw constraints (extra technical depth) */}
                <div className="mt-4 rounded-md border border-gray-200 bg-white p-3">
                  <div className="font-heading text-sm text-gray-900">Physical constraints (raw)</div>
                  <div className="mt-1 text-xs font-body text-gray-600">
                    Exposes CREATE TABLE constraint lines that define uniqueness, checks and key semantics.
                  </div>
                  {(tableByFq.get(selectedConcept.fq)?.create_constraints || []).length ? (
                    <div className="mt-2 space-y-2">
                      {(tableByFq.get(selectedConcept.fq)?.create_constraints || []).slice(0, 10).map((x, idx) => (
                        <div
                          key={`ldm-constraint-${idx}`}
                          className="text-[11px] font-mono rounded-md border border-gray-200 bg-gray-50 px-2 py-2 text-gray-700"
                        >
                          {x}
                        </div>
                      ))}
                      {(tableByFq.get(selectedConcept.fq)?.create_constraints || []).length > 10 ? (
                        <div className="text-xs font-body text-gray-600">Showing first 10 constraints.</div>
                      ) : null}
                    </div>
                  ) : (
                    <div className="mt-2 text-xs font-body text-gray-600">â€”</div>
                  )}
                </div>
              </div>
            </div>
          )}
        </div>
      </div>
    </div>
  );
}

// tiny helper so we donâ€™t explode if selectedDomainObj is null in render
function selectedConceptObjOrEmpty(obj) {
  return obj || { purpose: "" };
}




===== FILE: app_frontend\src\MissionAtlasPanel.jsx =====
import React, { useMemo, useState } from "react";
import BusinessDataLineagePanel from "./BusinessDataLineagePanel";
import MissionAtlasServiceTopologyPanel from "./MissionAtlasServiceTopologyPanel";
import MissionAtlasLogicalDataModelPanel from "./MissionAtlasLogicalDataModelPanel";
import MissionAtlasPhysicalDataModelPanel from "./MissionAtlasPhysicalDataModelPanel";


const domains = [
  {
    id: "domain-ingestion",
    name: "Ingestion",
    description: "Bring CRM and KYC client records into the SCV platform.",
    keyEntities: ["SourceRecord", "IngestionBatch"],
  },
  {
    id: "domain-matching",
    name: "Matching",
    description: "Resolve records into a single client identity.",
    keyEntities: ["MatchCandidate", "MatchGroup", "MatchScore"],
  },
  {
    id: "domain-profile",
    name: "Client Profile",
    description: "Assemble and expose the golden client profile.",
    keyEntities: ["ClientProfile", "ClientAttribute", "Address"],
  },
  {
    id: "domain-search",
    name: "Search",
    description: "Help users quickly find the right client profile.",
    keyEntities: ["SearchQuery", "SearchResult"],
  },
  {
    id: "domain-lineage",
    name: "Lineage & Audit",
    description: "Track where data came from and how it was transformed.",
    keyEntities: ["LineageEvent", "AuditEvent"],
  },
  {
    id: "domain-ux",
    name: "Single Client View UI",
    description: "Visualise client profile, sources and lineage.",
    keyEntities: ["ClientView", "SourcePanel", "LineagePanel"],
  },
];

const services = [
  {
    id: "svc-ingestion",
    name: "Ingestion Service",
    domain: "Ingestion",
    responsibilities: [
      "Load CRM and KYC records.",
      "Normalise incoming payloads to canonical structures.",
      "Emit ingestion audit events.",
    ],
    consumes: ["CRM feed", "KYC feed"],
    produces: ["SourceRecord", "IngestionBatch", "AuditEvent"],
    exposes: [],
  },
  {
    id: "svc-matching",
    name: "Matching Service",
    domain: "Matching",
    responsibilities: [
      "Apply exact and fuzzy match rules.",
      "Group records into candidate client identities.",
    ],
    consumes: ["SourceRecord"],
    produces: ["MatchCandidate", "MatchGroup", "MatchScore"],
    exposes: [],
  },
  {
    id: "svc-profile-core",
    name: "Client Profile Service",
    domain: "Client Profile",
    responsibilities: [
      "Build ClientProfile from MatchGroup + source records.",
      "Merge core attributes and addresses.",
      "Attach lineage references.",
    ],
    consumes: ["MatchGroup", "SourceRecord"],
    produces: ["ClientProfile", "ClientAttribute", "Address", "LineageEvent"],
    exposes: ["Client Profile API"],
  },
  {
    id: "svc-search",
    name: "Client Search Service",
    domain: "Search",
    responsibilities: [
      "Index ClientProfile documents.",
      "Serve search queries with ranking.",
    ],
    consumes: ["ClientProfile"],
    produces: ["SearchResult"],
    exposes: ["Client Search API"],
  },
  {
    id: "svc-lineage",
    name: "Lineage Service",
    domain: "Lineage & Audit",
    responsibilities: [
      "Capture provenance and transformation metadata.",
      "Expose lineage graph for a given client.",
    ],
    consumes: ["LineageEvent", "AuditEvent"],
    produces: ["Lineage graph view"],
    exposes: ["Lineage API"],
  },
  {
    id: "svc-ui",
    name: "SCV Frontend",
    domain: "Single Client View UI",
    responsibilities: [
      "Call search and profile APIs.",
      "Render Single Client View: profile, sources, lineage.",
    ],
    consumes: ["Client Profile API", "Client Search API", "Lineage API"],
    produces: ["ClientView"],
    exposes: ["SCV screen"],
  },
];

const flows = [
  {
    id: "flow-01",
    name: "Client onboarding (CRM route)",
    steps: [
      "CRM feed",
      "Ingestion Service",
      "SourceRecord",
      "Matching Service",
      "MatchGroup",
      "Client Profile Service",
      "ClientProfile",
      "Client Search Service",
      "SCV Frontend",
    ],
  },
  {
    id: "flow-02",
    name: "Client onboarding (KYC route)",
    steps: [
      "KYC feed",
      "Ingestion Service",
      "SourceRecord",
      "Matching Service",
      "MatchGroup",
      "Client Profile Service",
      "ClientProfile",
      "SCV Frontend",
    ],
  },
  {
    id: "flow-03",
    name: "Search & view client",
    steps: [
      "SCV Frontend",
      "Client Search API",
      "Client Search Service",
      "SearchResult",
      "Client Profile API",
      "Client Profile Service",
      "ClientProfile",
      "SCV Frontend",
    ],
  },
  {
    id: "flow-04",
    name: "Lineage drill-down",
    steps: [
      "SCV Frontend",
      "Lineage API",
      "Lineage Service",
      "Lineage graph view",
      "SCV Frontend",
    ],
  },
];

function ComingSoonPanel({ title, subtitle, bullets }) {
  return (
    <div className="rounded-halo border border-gray-200 bg-gray-50 p-5">
      <div className="flex items-start justify-between gap-4">
        <div>
          <h3 className="font-heading text-sm text-gray-900">{title}</h3>
          {subtitle ? (
            <p className="mt-1 text-xs font-body text-gray-600">{subtitle}</p>
          ) : null}
        </div>
        <span className="text-[11px] font-mono text-gray-500 bg-white border border-gray-200 rounded-md px-2 py-1">
          Planned
        </span>
      </div>

      {bullets?.length ? (
        <ul className="mt-4 list-disc pl-5 space-y-1">
          {bullets.map((b, idx) => (
            <li key={`cs-${idx}`} className="text-xs font-body text-gray-700">
              {b}
            </li>
          ))}
        </ul>
      ) : null}
    </div>
  );
}

export default function MissionAtlasPanel() {
  const [selectedDomain, setSelectedDomain] = useState(null);
  const [selectedService, setSelectedService] = useState(null);
  const [atlasView, setAtlasView] = useState("landing");

  const resetSelection = () => {
    setSelectedDomain(null);
    setSelectedService(null);
  };

  const visibleServices = useMemo(() => {
    return selectedDomain
      ? services.filter((s) => s.domain === selectedDomain.name)
      : services;
  }, [selectedDomain]);

  const visibleFlows = useMemo(() => {
    if (selectedService) {
      return flows.filter((flow) =>
        flow.steps.some((step) =>
          step.toLowerCase().includes(selectedService.name.toLowerCase())
        )
      );
    }
    if (selectedDomain) {
      return flows.filter((flow) =>
        flow.steps.some((step) =>
          step.toLowerCase().includes(selectedDomain.name.toLowerCase())
        )
      );
    }
    return flows;
  }, [selectedDomain, selectedService]);

  const tiles = [
    {
      key: "businessCapabilities",
      title: "Business Capabilities",
      desc: "What this system does today, derived from the current codebase.",
      badge: "Live",
    },
    {
      key: "businessDataLineage",
      title: "Business Data Lineage",
      desc: "Where data comes from, how it transforms, and where it is used.",
      badge: "Live",
    },
    {
      key: "technologyArchitecture",
      title: "Technology Architecture",
      desc: "Domains, services, and flows across the SCV platform.",
      badge: "Live",
    },
    {
      key: "serviceTopology",
      title: "Microservices Architecture",
      desc: "Microservices, contracts, and interactions (live from the service model).",
      badge: "Live",
    },
    {
      key: "logicalDataModel",
      title: "Logical Data Model",
      desc: "Business entities, relationships, and rules.",
      badge: "Live",
    },
    {
      key: "physicalDataModel",
      title: "Physical Data Model",
      desc: "Database schema: tables, fields, constraints, and indexes.",
      badge: "Live",
    },
    {
      key: "engineeringQuality",
      title: "Engineering Quality",
      desc: "Automated quality checks enforced in this repository.",
      badge: "Planned",
    },
    {
      key: "securityPosture",
      title: "Security Posture",
      desc: "Active security checks and assurance signals.",
      badge: "Planned",
    },
    {
      key: "selfHealing",
      title: "Self-Healing",
      desc: "Data integrity and agentic support, built on live system truth.",
      badge: "Planned",
    },
  ];

  const viewTitle = (() => {
    switch (atlasView) {
      case "landing":
        return "MissionAtlas â€” Live System Map";
      case "businessCapabilities":
        return "Business Capabilities";
      case "businessDataLineage":
        return "Business Data Lineage";
      case "technologyArchitecture":
        return "Technology Architecture";
      case "serviceTopology":
        return "Service Topology";
      case "logicalDataModel":
        return "Logical Data Model";
      case "physicalDataModel":
        return "Physical Data Model";
      case "engineeringQuality":
        return "Engineering Quality";
      case "securityPosture":
        return "Security Posture";
      case "selfHealing":
        return "Self-Healing";
      default:
        return "MissionAtlas â€” Live System Map";
    }
  })();

  const showBack = atlasView !== "landing";

  const renderLanding = () => (
    <div>
      <div className="mb-4">
        <h3 className="font-heading text-sm text-gray-800">Live Areas</h3>
        <p className="mt-1 text-xs font-body text-gray-600">
          MissionAtlas reflects the system as it exists right now â€” derived from code, data,
          and execution.
        </p>
      </div>

      <div className="grid grid-cols-1 md:grid-cols-2 xl:grid-cols-3 gap-4">
        {tiles.map((t) => (
          <button
            key={t.key}
            type="button"
            onClick={() => {
              if (t.key !== "technologyArchitecture") resetSelection();
              setAtlasView(t.key);
            }}
            className="text-left rounded-halo border border-gray-200 bg-white hover:bg-gray-50 shadow-sm p-4 transition"
          >
            <div className="flex items-start justify-between gap-4">
              <div>
                <p className="font-heading text-sm text-gray-900">{t.title}</p>
                <p className="mt-1 text-xs font-body text-gray-600">{t.desc}</p>
              </div>
              <span
                className={`text-[11px] font-mono rounded-md px-2 py-1 border ${
                  t.badge === "Live"
                    ? "bg-teal-50 border-teal-200 text-gray-800"
                    : "bg-gray-50 border-gray-200 text-gray-600"
                }`}
              >
                {t.badge}
              </span>
            </div>
          </button>
        ))}
      </div>
    </div>
  );

  const renderBusinessCapabilities = () => (
    <div className="grid grid-cols-1 lg:grid-cols-2 gap-6">
      <div className="space-y-3">
        <h3 className="font-heading text-sm text-gray-800 mb-1">Capabilities</h3>
        {domains.map((d) => (
          <div key={d.id} className="rounded-md p-3 border bg-gray-50 border-gray-200">
            <p className="font-heading text-sm text-gray-900">{d.name}</p>
            <p className="text-xs font-body text-gray-600 mb-2">{d.description}</p>
            <p className="text-[11px] font-mono text-gray-500">
              Key entities: {d.keyEntities.join(", ")}
            </p>
          </div>
        ))}
      </div>

      <div className="space-y-3">
        <h3 className="font-heading text-sm text-gray-800 mb-1">Key Flows</h3>
        {flows.map((flow) => (
          <div key={flow.id} className="rounded-md p-3 border bg-gray-50 border-gray-200">
            <p className="font-heading text-sm text-gray-900 mb-2">{flow.name}</p>
            <p className="text-[11px] font-mono text-gray-700 whitespace-pre-wrap leading-5">
              {flow.steps.join("  â†’  ")}
            </p>
          </div>
        ))}
      </div>
    </div>
  );

  const renderTechnologyArchitecture = () => (
    <div className="grid grid-cols-1 lg:grid-cols-3 gap-6">
      <div className="space-y-3">
        <h3 className="font-heading text-sm text-gray-800 mb-1">Domains</h3>
        {domains.map((d) => {
          const active = selectedDomain?.id === d.id;
          return (
            <div
              key={d.id}
              onClick={() => {
                setSelectedService(null);
                setSelectedDomain(active ? null : d);
              }}
              className={`cursor-pointer rounded-md p-3 border ${
                active
                  ? "bg-teal-50 border-teal-300 shadow"
                  : "bg-gray-50 border-gray-200 hover:bg-gray-100"
              }`}
            >
              <p className="font-heading text-sm text-gray-900">{d.name}</p>
              <p className="text-xs font-body text-gray-600 mb-2">{d.description}</p>
              <p className="text-[11px] font-mono text-gray-500">
                Entities: {d.keyEntities.join(", ")}
              </p>
            </div>
          );
        })}
      </div>

      <div className="space-y-3">
        <div className="flex items-center justify-between">
          <h3 className="font-heading text-sm text-gray-800 mb-1">Services</h3>
          {(selectedDomain || selectedService) && (
            <button
              type="button"
              onClick={resetSelection}
              className="text-xs text-halo-primary underline hover:opacity-90"
            >
              Reset
            </button>
          )}
        </div>

        {visibleServices.map((s) => {
          const active = selectedService?.id === s.id;
          const faded = selectedDomain && s.domain !== selectedDomain.name;

          return (
            <div
              key={s.id}
              onClick={() => setSelectedService(active ? null : s)}
              className={`cursor-pointer rounded-md p-3 border transition ${
                active
                  ? "bg-amber-50 border-amber-300 shadow"
                  : faded
                  ? "opacity-50 bg-gray-50 border-gray-200"
                  : "bg-gray-50 border-gray-200 hover:bg-gray-100"
              }`}
            >
              <p className="font-heading text-sm text-gray-900 mb-1">{s.name}</p>
              <p className="text-[11px] font-body text-gray-500 mb-1">Domain: {s.domain}</p>
              <ul className="list-disc pl-4 mb-1 space-y-0.5">
                {s.responsibilities.map((r, idx) => (
                  <li key={`${s.id}-r-${idx}`} className="text-xs font-body text-gray-700">
                    {r}
                  </li>
                ))}
              </ul>
              <p className="text-[11px] font-mono text-gray-500">Produces: {s.produces.join(", ")}</p>
            </div>
          );
        })}
      </div>

      <div className="space-y-3">
        <h3 className="font-heading text-sm text-gray-800 mb-1">Flows</h3>
        {visibleFlows.map((flow) => (
          <div key={flow.id} className="rounded-md p-3 border bg-gray-50 border-gray-200">
            <p className="font-heading text-sm text-gray-900 mb-2">{flow.name}</p>
            <p className="text-[11px] font-mono text-gray-700 whitespace-pre-wrap leading-5">
              {flow.steps.join("  â†’  ")}
            </p>
          </div>
        ))}
      </div>
    </div>
  );

  const renderLogicalDataModel = () => (
    <ComingSoonPanel
      title="Logical Data Model"
      subtitle="Business entities, relationships, and rules."
      bullets={[
        "Entity catalogue (Client, SourceRecord, MatchGroup, EvidenceArtefact, etc.)",
        "Relationships and cardinality",
        "Declarative invariants used by Self-Healing",
      ]}
    />
  );

  const renderPhysicalDataModel = () => (
    <MissionAtlasPhysicalDataModelPanel />
  );

  const renderEngineeringQuality = () => (
    <ComingSoonPanel
      title="Engineering Quality"
      subtitle="Automated checks enforced in this repository."
      bullets={[
        "Linting and formatting rules",
        "Test suites and coverage",
        "Guardrail checks and evidence outputs",
      ]}
    />
  );

  const renderSecurityPosture = () => (
    <ComingSoonPanel
      title="Security Posture"
      subtitle="Active security checks and assurance signals."
      bullets={[
        "Dependency scanning",
        "SAST checks and policy gates",
        "Security evidence artefacts",
      ]}
    />
  );

  const renderSelfHealing = () => (
    <ComingSoonPanel
      title="Self-Healing"
      subtitle="Data integrity and agentic support, built on live system truth."
      bullets={[
        "Data Integrity: detect â†’ recommend â†’ repair â†’ evidence",
        "Agentic Support: explain â†’ diagnose â†’ guided remediation",
        "Audit trail and rollback semantics",
      ]}
    />
  );

  const renderContent = () => {
    switch (atlasView) {
      case "landing":
        return renderLanding();
      case "businessCapabilities":
        return renderBusinessCapabilities();
      case "businessDataLineage":
        // IMPORTANT: unchanged wiring for Business Data Lineage
        return (
          <BusinessDataLineagePanel
            defaultClientId={1}
            defaultConceptId="client.legal_name"
            onBack={() => setAtlasView("landing")}
          />
        );
      case "technologyArchitecture":
        return renderTechnologyArchitecture();
      case "serviceTopology":
        return (
          <MissionAtlasServiceTopologyPanel
            domains={domains}
            services={services}
          />
        );
      case "logicalDataModel":
        return <MissionAtlasLogicalDataModelPanel />;
      case "physicalDataModel":
        return renderPhysicalDataModel();
      case "engineeringQuality":
        return renderEngineeringQuality();
      case "securityPosture":
        return renderSecurityPosture();
      case "selfHealing":
        return renderSelfHealing();
      default:
        return renderLanding();
    }
  };

  return (
    <section className="bg-white rounded-halo shadow-sm border border-gray-200 p-6 mb-6">
      <div className="flex flex-col gap-3 md:flex-row md:items-center md:justify-between mb-4">
        <h2 style={{ fontFamily: "Fjalla One" }} className="text-lg text-gray-900 tracking-wide">
          {(() => {
            switch (atlasView) {
              case "landing":
                return "MissionAtlas â€” Live System Map";
              case "businessCapabilities":
                return "Business Capabilities";
              case "businessDataLineage":
                return "Business Data Lineage";
              case "technologyArchitecture":
                return "Technology Architecture";
              case "serviceTopology":
                return "Service Topology";
              case "logicalDataModel":
                return "Logical Data Model";
              case "physicalDataModel":
                return "Physical Data Model";
              case "engineeringQuality":
                return "Engineering Quality";
              case "securityPosture":
                return "Security Posture";
              case "selfHealing":
                return "Self-Healing";
              default:
                return "MissionAtlas â€” Live System Map";
            }
          })()}
        </h2>

        <div className="flex items-center gap-2">
          {showBack ? (
            <button
              type="button"
              onClick={() => {
                if (atlasView !== "technologyArchitecture") resetSelection();
                setAtlasView("landing");
              }}
              className="px-3 py-2 rounded-md text-sm font-body border border-gray-200 bg-white hover:bg-gray-50 text-gray-700"
            >
              Back
            </button>
          ) : null}
        </div>
      </div>

      {renderContent()}
    </section>
  );
}









===== FILE: app_frontend\src\MissionAtlasPhysicalDataModelPanel.jsx =====
import React, { useMemo, useState } from "react";
import physicalModel from "./data/physical_model_by_domain.json";

export default function MissionAtlasPhysicalDataModelPanel() {
  const normalise = (s) => (s || "").toString().trim().toLowerCase();

  const domains = useMemo(() => physicalModel?.domains || [], []);
  const [selectedDomain, setSelectedDomain] = useState(domains?.[0]?.domain || "");
  const [tableQuery, setTableQuery] = useState("");
  const [columnQuery, setColumnQuery] = useState("");
  const [selectedTableFq, setSelectedTableFq] = useState(null);
  const [showRawFkSql, setShowRawFkSql] = useState(false);

  const selectedDomainObj = useMemo(() => {
    return domains.find((d) => d.domain === selectedDomain) || domains[0] || null;
  }, [domains, selectedDomain]);

  const tableByFq = useMemo(() => {
    const m = new Map();
    for (const d of domains) {
      for (const t of d.tables || []) {
        const fq = `${t.schema}.${t.table}`;
        m.set(fq, { ...t, fq, platformDomain: d.domain, platformPurpose: d.purpose });
      }
    }
    return m;
  }, [domains]);

  const inboundRefsByTable = useMemo(() => {
    const inbound = new Map(); // fq -> [{fromFq, fromCols, toCols, fkName, raw}]
    for (const d of domains) {
      for (const t of d.tables || []) {
        const fromFq = `${t.schema}.${t.table}`;
        for (const fk of t.foreign_keys || []) {
          const toFq = fk.references_table;
          if (!inbound.has(toFq)) inbound.set(toFq, []);
          inbound.get(toFq).push({
            fromFq,
            fromCols: fk.columns || [],
            toCols: fk.references_columns || [],
            fkName: fk.name || null,
            raw: fk.raw || null,
          });
        }
      }
    }
    for (const [k, v] of inbound.entries()) {
      v.sort((a, b) => a.fromFq.localeCompare(b.fromFq));
      inbound.set(k, v);
    }
    return inbound;
  }, [domains]);

  const domainSummaries = useMemo(() => {
    const fqToDomain = new Map();
    for (const d of domains) {
      for (const t of d.tables || []) fqToDomain.set(`${t.schema}.${t.table}`, d.domain);
    }

    return domains.map((d) => {
      const tables = d.tables || [];
      const tableCount = tables.length;
      const colCount = tables.reduce((acc, t) => acc + (t.columns?.length || 0), 0);
      const fkCount = tables.reduce((acc, t) => acc + (t.foreign_keys?.length || 0), 0);
      const idxCount = tables.reduce((acc, t) => acc + (t.indexes?.length || 0), 0);

      const outboundRefs = new Map();
      for (const t of tables) {
        for (const fk of t.foreign_keys || []) {
          const refDom = fqToDomain.get(fk.references_table) || "External/Unknown";
          if (refDom === d.domain) continue;
          outboundRefs.set(refDom, (outboundRefs.get(refDom) || 0) + 1);
        }
      }

      return {
        domain: d.domain,
        purpose: d.purpose,
        tableCount,
        colCount,
        fkCount,
        idxCount,
        outboundRefs: [...outboundRefs.entries()]
          .map(([refDomain, count]) => ({ refDomain, count }))
          .sort((a, b) => b.count - a.count || a.refDomain.localeCompare(b.refDomain)),
      };
    });
  }, [domains]);

  const tablesInSelectedDomain = useMemo(() => {
    const q = normalise(tableQuery);
    const tables = selectedDomainObj?.tables || [];
    return tables
      .map((t) => {
        const fq = `${t.schema}.${t.table}`;
        const inbound = inboundRefsByTable.get(fq) || [];
        return {
          ...t,
          fq,
          colCount: t.columns?.length || 0,
          fkCount: t.foreign_keys?.length || 0,
          inboundCount: inbound.length,
          idxCount: t.indexes?.length || 0,
          constraintCount: t.create_constraints?.length || 0,
        };
      })
      .filter((t) => {
        if (!q) return true;
        return (
          normalise(t.fq).includes(q) ||
          normalise(t.table).includes(q) ||
          normalise(t.schema).includes(q)
        );
      })
      .sort((a, b) => a.table.localeCompare(b.table));
  }, [selectedDomainObj, tableQuery, inboundRefsByTable]);

  // Default table selection
  const selectedTable = useMemo(() => {
    if (!tablesInSelectedDomain.length) return null;
    if (!selectedTableFq) return tablesInSelectedDomain[0];
    return tablesInSelectedDomain.find((t) => t.fq === selectedTableFq) || tablesInSelectedDomain[0];
  }, [tablesInSelectedDomain, selectedTableFq]);

  const filteredColumns = useMemo(() => {
    if (!selectedTable) return [];
    const q = normalise(columnQuery);

    return (selectedTable.columns || [])
      .map((c) => ({
        name: c.name,
        type: c.type,
        nullable: c.nullable,
        default: c.default,
        unique: !!c.unique,
        pk: !!c.pk,
        fk: c.fk || null,
        raw: c.raw || null,
      }))
      .filter((c) => {
        if (!q) return true;
        return (
          normalise(c.name).includes(q) ||
          normalise(c.type).includes(q) ||
          (c.default ? normalise(c.default).includes(q) : false) ||
          (c.raw ? normalise(c.raw).includes(q) : false) ||
          (c.fk ? normalise(c.fk.references_table).includes(q) : false)
        );
      });
  }, [selectedTable, columnQuery]);

  const selectedInbound = useMemo(() => {
    if (!selectedTable) return [];
    return inboundRefsByTable.get(selectedTable.fq) || [];
  }, [selectedTable, inboundRefsByTable]);

  const ddlForTable = (t) => {
    if (!t) return "";
    const lines = [];
    lines.push(`CREATE TABLE ${t.schema}.${t.table} (`);
    const colLines = (t.columns || []).map((c) => {
      const parts = [];
      parts.push(`  ${c.name} ${c.type}`);
      if (!c.nullable) parts.push("NOT NULL");
      if (c.default !== null && c.default !== undefined && `${c.default}`.trim() !== "") {
        parts.push(`DEFAULT ${c.default}`);
      }
      return parts.join(" ");
    });

    const constraintLines = (t.create_constraints || []).map((x) => `  ${x.replace(/\s+/g, " ").trim()}`);
    const combined = [...colLines, ...constraintLines];

    for (let i = 0; i < combined.length; i++) {
      const suffix = i === combined.length - 1 ? "" : ",";
      lines.push(`${combined[i]}${suffix}`);
    }
    lines.push(");");

    // Indexes
    if ((t.indexes || []).length) {
      lines.push("");
      for (const ix of t.indexes) {
        const unique = ix.unique ? "UNIQUE " : "";
        const cols = (ix.columns || []).join(", ");
        const method = ix.method || "btree";
        lines.push(`CREATE ${unique}INDEX ${ix.name} ON ${t.schema}.${t.table} USING ${method} (${cols});`);
      }
    }

    // FKs (as ALTERs)
    if ((t.foreign_keys || []).length) {
      lines.push("");
      for (const fk of t.foreign_keys) {
        const cols = (fk.columns || []).join(", ");
        const refCols = (fk.references_columns || []).join(", ");
        lines.push(
          `ALTER TABLE ONLY ${t.schema}.${t.table} ADD CONSTRAINT ${fk.name} FOREIGN KEY (${cols}) REFERENCES ${fk.references_table} (${refCols});`
        );
      }
    }

    return lines.join("\n");
  };

  const tableStatsPill = (label, value) => (
    <span className="text-[11px] font-mono rounded-md px-2 py-1 border bg-gray-50 border-gray-200 text-gray-600">
      {label}: {value}
    </span>
  );

  return (
    <div className="space-y-4">
      {/* Header */}
      <div className="rounded-halo border border-gray-200 bg-white p-4">
        <div className="flex flex-col gap-3 lg:flex-row lg:items-end lg:justify-between">
          <div>
            <h3 className="font-heading text-sm text-gray-900">Physical Data Model</h3>
            <p className="mt-1 text-xs font-body text-gray-600">
              A schema inspector over the live physical model. Domains group tables; tables expose columns, keys, indexes and constraints.
            </p>
          </div>

          <span className="text-[11px] font-mono rounded-md px-2 py-1 border bg-gray-50 border-gray-200 text-gray-600">
            tables: {physicalModel?.summary?.tables ?? "â€”"} â€¢ domains: {physicalModel?.summary?.domains ?? "â€”"} â€¢ fks:{" "}
            {physicalModel?.summary?.foreign_keys ?? "â€”"} â€¢ idx: {physicalModel?.summary?.indexes ?? "â€”"}
          </span>
        </div>
      </div>

      {/* Domain overview */}
      <div className="rounded-halo border border-gray-200 bg-white p-4">
        <div className="flex items-start justify-between gap-4">
          <div>
            <h4 className="font-heading text-sm text-gray-900">Platform domains</h4>
            <p className="mt-1 text-xs font-body text-gray-600">
              Select a domain to inspect its tables and relationship surface, including cross-domain dependencies.
            </p>
          </div>

          <select
            value={selectedDomain}
            onChange={(e) => {
              setSelectedDomain(e.target.value);
              setSelectedTableFq(null);
              setTableQuery("");
              setColumnQuery("");
            }}
            className="px-3 py-2 rounded-md text-sm font-body border border-gray-200 bg-white"
          >
            {domains.map((d) => (
              <option key={`pdm-dom-${d.domain}`} value={d.domain}>
                {d.domain}
              </option>
            ))}
          </select>
        </div>

        <div className="mt-3 text-xs font-body text-gray-700">
          <span className="text-gray-600">Intent:</span> {selectedDomainObj?.purpose || "â€”"}
        </div>

        <div className="mt-4 grid grid-cols-1 lg:grid-cols-4 gap-3">
          {domainSummaries.map((s) => {
            const active = s.domain === selectedDomain;
            return (
              <button
                key={`pdm-sum-${s.domain}`}
                type="button"
                onClick={() => {
                  setSelectedDomain(s.domain);
                  setSelectedTableFq(null);
                  setTableQuery("");
                  setColumnQuery("");
                }}
                className={`text-left rounded-md border p-3 transition ${
                  active ? "bg-amber-50 border-amber-300 shadow" : "bg-gray-50 border-gray-200 hover:bg-gray-100"
                }`}
              >
                <div className="font-heading text-sm text-gray-900">{s.domain}</div>
                <div className="mt-1 text-[11px] font-body text-gray-600 line-clamp-2">{s.purpose}</div>

                <div className="mt-3 grid grid-cols-2 gap-2">
                  <div className="rounded-md border border-gray-200 bg-white px-2 py-1">
                    <div className="text-[11px] font-body text-gray-600">Tables</div>
                    <div className="font-heading text-sm text-gray-900">{s.tableCount}</div>
                  </div>
                  <div className="rounded-md border border-gray-200 bg-white px-2 py-1">
                    <div className="text-[11px] font-body text-gray-600">Columns</div>
                    <div className="font-heading text-sm text-gray-900">{s.colCount}</div>
                  </div>
                  <div className="rounded-md border border-gray-200 bg-white px-2 py-1">
                    <div className="text-[11px] font-body text-gray-600">FKs</div>
                    <div className="font-heading text-sm text-gray-900">{s.fkCount}</div>
                  </div>
                  <div className="rounded-md border border-gray-200 bg-white px-2 py-1">
                    <div className="text-[11px] font-body text-gray-600">Indexes</div>
                    <div className="font-heading text-sm text-gray-900">{s.idxCount}</div>
                  </div>
                </div>

                {s.outboundRefs?.length ? (
                  <div className="mt-3">
                    <div className="text-[11px] font-body text-gray-600 mb-1">Cross-domain dependencies</div>
                    <div className="flex flex-wrap gap-2">
                      {s.outboundRefs.slice(0, 4).map((r) => (
                        <span
                          key={`pdm-od-${s.domain}-${r.refDomain}`}
                          className="text-[11px] font-mono rounded-md px-2 py-1 border bg-white border-gray-200 text-gray-700"
                        >
                          {r.refDomain}: {r.count}
                        </span>
                      ))}
                    </div>
                  </div>
                ) : null}
              </button>
            );
          })}
        </div>
      </div>

      {/* Tables list + Inspector */}
      <div className="grid grid-cols-1 lg:grid-cols-3 gap-4">
        {/* Tables */}
        <div className="rounded-halo border border-gray-200 bg-white p-4">
          <div className="flex items-start justify-between gap-3">
            <div>
              <h4 className="font-heading text-sm text-gray-900">Tables</h4>
              <p className="mt-1 text-xs font-body text-gray-600">
                Filter tables within the selected domain. Click a table to inspect its schema surface.
              </p>
            </div>
            <span className="text-[11px] font-mono rounded-md px-2 py-1 border bg-gray-50 border-gray-200 text-gray-600">
              {tablesInSelectedDomain.length}
            </span>
          </div>

          <input
            value={tableQuery}
            onChange={(e) => setTableQuery(e.target.value)}
            placeholder="Search tablesâ€¦"
            className="mt-3 w-full px-3 py-2 rounded-md text-sm font-body border border-gray-200 bg-white"
          />

          <div className="mt-3 space-y-2 max-h-[560px] overflow-auto pr-1">
            {tablesInSelectedDomain.map((t) => {
              const active = selectedTable?.fq === t.fq;
              return (
                <button
                  key={`tbl-${t.fq}`}
                  type="button"
                  onClick={() => setSelectedTableFq(t.fq)}
                  className={`w-full text-left rounded-md border p-3 transition ${
                    active ? "bg-amber-50 border-amber-300 shadow" : "bg-gray-50 border-gray-200 hover:bg-gray-100"
                  }`}
                >
                  <div className="flex items-start justify-between gap-3">
                    <div>
                      <div className="font-mono text-sm text-gray-900">{t.fq}</div>
                      <div className="mt-1 text-[11px] font-body text-gray-600">
                        cols: {t.colCount} â€¢ outbound: {t.fkCount} â€¢ inbound: {t.inboundCount} â€¢ idx: {t.idxCount}
                      </div>
                    </div>
                    <span className="text-[11px] font-mono rounded-md px-2 py-1 border bg-white border-gray-200 text-gray-700">
                      {t.primary_key?.length ? "PK" : "â€”"}
                    </span>
                  </div>
                </button>
              );
            })}
          </div>
        </div>

        {/* Inspector */}
        <div className="lg:col-span-2 rounded-halo border border-gray-200 bg-white p-4">
          {!selectedTable ? (
            <div className="text-sm font-body text-gray-700">Select a table to inspect.</div>
          ) : (
            <div className="space-y-4">
              <div className="flex flex-col gap-3 lg:flex-row lg:items-start lg:justify-between">
                <div>
                  <h4 className="font-heading text-sm text-gray-900">{selectedTable.fq}</h4>
                  <p className="mt-1 text-xs font-body text-gray-600">
                    Columns, keys, indexes and constraints for the selected physical table.
                  </p>
                </div>

                <div className="flex flex-wrap gap-2">
                  {tableStatsPill("cols", selectedTable.colCount)}
                  {tableStatsPill("outbound", selectedTable.fkCount)}
                  {tableStatsPill("inbound", selectedTable.inboundCount)}
                  {tableStatsPill("idx", selectedTable.idxCount)}
                  {tableStatsPill("constraints", selectedTable.constraintCount)}
                </div>
              </div>

              {/* PK */}
              <div className="rounded-md border border-gray-200 bg-gray-50 p-3">
                <div className="text-xs font-body text-gray-600">Primary key</div>
                <div className="mt-1 text-xs font-mono text-gray-900">
                  {selectedTable.primary_key?.length ? selectedTable.primary_key.join(", ") : "â€”"}
                </div>
              </div>

              {/* Relationships */}
              <div className="grid grid-cols-1 lg:grid-cols-2 gap-4">
                <div className="rounded-md border border-gray-200 bg-gray-50 p-3">
                  <div className="font-heading text-sm text-gray-900">Outbound foreign keys</div>
                  <ul className="mt-2 list-disc pl-5 space-y-1">
                    {(selectedTable.foreign_keys || []).length ? (
                      selectedTable.foreign_keys.map((fk, idx) => (
                        <li key={`ofk-${idx}`} className="text-xs font-body text-gray-700">
                          <span className="font-mono">
                            ({(fk.columns || []).join(", ")}) â†’ {fk.references_table}(
                            {(fk.references_columns || []).join(", ")})
                          </span>
                        </li>
                      ))
                    ) : (
                      <li className="text-xs font-body text-gray-600">None.</li>
                    )}
                  </ul>

                  {showRawFkSql && (selectedTable.foreign_keys || []).length ? (
                    <div className="mt-3 space-y-2">
                      {(selectedTable.foreign_keys || []).slice(0, 6).map((fk, idx) => (
                        <pre
                          key={`ofk-raw-${idx}`}
                          className="text-[11px] font-mono rounded-md border border-gray-200 bg-white p-3 overflow-auto text-gray-700"
                        >
                          {fk.raw || "(raw not available)"}
                        </pre>
                      ))}
                      {(selectedTable.foreign_keys || []).length > 6 ? (
                        <div className="text-xs font-body text-gray-600">Showing first 6 raw FK statements.</div>
                      ) : null}
                    </div>
                  ) : null}
                </div>

                <div className="rounded-md border border-gray-200 bg-gray-50 p-3">
                  <div className="font-heading text-sm text-gray-900">Inbound references</div>
                  <ul className="mt-2 list-disc pl-5 space-y-1">
                    {selectedInbound.length ? (
                      selectedInbound.map((r, idx) => (
                        <li key={`ifk-${idx}`} className="text-xs font-body text-gray-700">
                          <span className="font-mono">
                            {r.fromFq} ({(r.fromCols || []).join(", ")})
                          </span>
                        </li>
                      ))
                    ) : (
                      <li className="text-xs font-body text-gray-600">None.</li>
                    )}
                  </ul>
                </div>
              </div>

              {/* Indexes */}
              <div className="rounded-md border border-gray-200 bg-gray-50 p-3">
                <div className="flex items-center justify-between gap-3">
                  <div>
                    <div className="font-heading text-sm text-gray-900">Indexes</div>
                    <div className="mt-1 text-xs font-body text-gray-600">Captured index definitions for lookup and uniqueness.</div>
                  </div>

                  <label className="flex items-center gap-2 text-xs font-body text-gray-700 select-none">
                    <input
                      type="checkbox"
                      checked={showRawFkSql}
                      onChange={(e) => setShowRawFkSql(e.target.checked)}
                    />
                    Show raw FK SQL
                  </label>
                </div>

                <ul className="mt-2 list-disc pl-5 space-y-1">
                  {(selectedTable.indexes || []).length ? (
                    selectedTable.indexes.map((ix, idx) => (
                      <li key={`ix-${idx}`} className="text-xs font-body text-gray-700">
                        <span className="font-mono">
                          {ix.unique ? "UNIQUE " : ""}
                          {ix.name} USING {ix.method} ({(ix.columns || []).join(", ")})
                        </span>
                      </li>
                    ))
                  ) : (
                    <li className="text-xs font-body text-gray-600">None captured.</li>
                  )}
                </ul>
              </div>

              {/* Columns */}
              <div className="rounded-md border border-gray-200 bg-gray-50 p-3">
                <div className="flex items-start justify-between gap-3">
                  <div>
                    <div className="font-heading text-sm text-gray-900">Columns</div>
                    <div className="mt-1 text-xs font-body text-gray-600">
                      Physical column definitions with typing, nullability, defaults and key markings.
                    </div>
                  </div>

                  <input
                    value={columnQuery}
                    onChange={(e) => setColumnQuery(e.target.value)}
                    placeholder="Search columnsâ€¦"
                    className="px-3 py-2 rounded-md text-sm font-body border border-gray-200 bg-white min-w-[240px]"
                  />
                </div>

                <div className="mt-3 overflow-x-auto">
                  <table className="w-full text-xs bg-white rounded-md overflow-hidden border border-gray-200">
                    <thead className="bg-gray-50">
                      <tr className="text-left text-gray-600">
                        <th className="py-2 px-2">Column</th>
                        <th className="py-2 px-2">Type</th>
                        <th className="py-2 px-2">Null</th>
                        <th className="py-2 px-2">Default</th>
                        <th className="py-2 px-2">Keying</th>
                        <th className="py-2 px-2">Raw</th>
                      </tr>
                    </thead>
                    <tbody>
                      {filteredColumns.map((c) => (
                        <tr key={`col-${selectedTable.fq}-${c.name}`} className="border-t">
                          <td className="py-2 px-2 font-mono text-gray-900">{c.name}</td>
                          <td className="py-2 px-2 text-gray-800">{c.type}</td>
                          <td className="py-2 px-2 text-gray-800">{c.nullable ? "YES" : "NO"}</td>
                          <td className="py-2 px-2 text-gray-800">{c.default || "â€”"}</td>
                          <td className="py-2 px-2">
                            <div className="flex flex-wrap gap-2">
                              {c.pk ? (
                                <span className="text-[11px] font-mono rounded-md px-2 py-1 border bg-amber-50 border-amber-200 text-gray-800">
                                  PK
                                </span>
                              ) : null}
                              {c.fk ? (
                                <span className="text-[11px] font-mono rounded-md px-2 py-1 border bg-teal-50 border-teal-200 text-gray-800">
                                  FK â†’ {c.fk.references_table}(
                                  {(c.fk.references_columns || []).join(", ")})
                                </span>
                              ) : null}
                              {c.unique ? (
                                <span className="text-[11px] font-mono rounded-md px-2 py-1 border bg-gray-50 border-gray-200 text-gray-800">
                                  UNIQUE
                                </span>
                              ) : null}
                            </div>
                          </td>
                          <td className="py-2 px-2 text-gray-700">
                            <span className="font-mono text-[11px]">{c.raw || "â€”"}</span>
                          </td>
                          <td className="py-2 px-2 text-gray-700">
                            <span className="font-mono text-[11px]">{c.raw || "â€”"}</span>
                          </td>
                        </tr>
                      ))}
                      {!filteredColumns.length ? (
                        <tr className="border-t">
                          <td className="py-3 px-2 text-xs font-body text-gray-600" colSpan={7}>
                            No columns match the current filter.
                          </td>
                        </tr>
                      ) : null}
                    </tbody>
                  </table>
                </div>
              </div>

              {/* Constraints */}
              <div className="rounded-md border border-gray-200 bg-gray-50 p-3">
                <div className="font-heading text-sm text-gray-900">Constraints</div>
                <div className="mt-1 text-xs font-body text-gray-600">
                  Raw constraint lines captured from CREATE TABLE for uniqueness, checks and PK semantics.
                </div>

                {(selectedTable.create_constraints || []).length ? (
                  <div className="mt-2 space-y-2">
                    {(selectedTable.create_constraints || []).slice(0, 14).map((x, idx) => (
                      <div
                        key={`con-${idx}`}
                        className="text-[11px] font-mono rounded-md border border-gray-200 bg-white px-2 py-2 text-gray-700"
                      >
                        {x}
                      </div>
                    ))}
                    {(selectedTable.create_constraints || []).length > 14 ? (
                      <div className="text-xs font-body text-gray-600">Showing first 14 constraints.</div>
                    ) : null}
                  </div>
                ) : (
                  <div className="mt-2 text-xs font-body text-gray-600">â€”</div>
                )}
              </div>

              {/* Generated DDL */}
              <div className="rounded-md border border-gray-200 bg-gray-50 p-3">
                <div className="font-heading text-sm text-gray-900">Generated DDL (from model)</div>
                <div className="mt-1 text-xs font-body text-gray-600">
                  Derived CREATE TABLE + CREATE INDEX + FK ALTER statements for the selected table.
                </div>
                <pre className="mt-3 text-[11px] font-mono rounded-md border border-gray-200 bg-white p-3 overflow-auto text-gray-700">
                  {ddlForTable(selectedTable)}
                </pre>
              </div>
            </div>
          )}
        </div>
      </div>
    </div>
  );
}


===== FILE: app_frontend\src\MissionAtlasServiceTopologyPanel.jsx =====
import React, { useMemo, useState } from "react";
import physicalModel from "./data/physical_model_by_domain.json";

export default function MissionAtlasServiceTopologyPanel() {
  const [tab, setTab] = useState("dependencies"); // dependencies | catalogue
  const [selectedService, setSelectedService] = useState(null);
  const [query, setQuery] = useState("");

  const normalise = (s) => (s || "").toString().trim().toLowerCase();

  const domains = useMemo(() => physicalModel?.domains || [], []);

  // Map platform domains â†’ microservices (this is your microservice boundary)
  const services = useMemo(() => {
    return (domains || []).map((d) => {
      const tables = d.tables || [];
      const fks = tables.flatMap((t) => t.foreign_keys || []);
      const indexes = tables.flatMap((t) => t.indexes || []);
      const cols = tables.reduce((acc, t) => acc + (t.columns?.length || 0), 0);

      return {
        serviceId: domainToServiceId(d.domain),
        serviceName: domainToServiceName(d.domain),
        domain: d.domain,
        purpose: d.purpose,
        tables,
        stats: {
          tables: tables.length,
          columns: cols,
          outboundFks: fks.length,
          indexes: indexes.length,
        },
        // contracts are placeholders for now (ready to wire to OpenAPI later)
        contracts: suggestedContractsForDomain(d.domain),
      };
    });
  }, [domains]);

  // Build lookup: table fq -> domain
  const fqToDomain = useMemo(() => {
    const m = new Map();
    for (const d of domains) {
      for (const t of d.tables || []) {
        m.set(`${t.schema}.${t.table}`, d.domain);
      }
    }
    return m;
  }, [domains]);

  // Compute cross-service dependencies using FK references
  const dependencies = useMemo(() => {
    const depMap = new Map(); // domain -> Map(refDomain -> count)

    for (const d of domains) {
      const domain = d.domain;
      if (!depMap.has(domain)) depMap.set(domain, new Map());

      for (const t of d.tables || []) {
        for (const fk of t.foreign_keys || []) {
          const refDomain = fqToDomain.get(fk.references_table) || "External/Unknown";
          if (refDomain === domain) continue;
          const inner = depMap.get(domain);
          inner.set(refDomain, (inner.get(refDomain) || 0) + 1);
        }
      }
    }

    return [...depMap.entries()]
      .map(([domain, refs]) => ({
        domain,
        refs: [...refs.entries()]
          .map(([refDomain, count]) => ({ refDomain, count }))
          .sort((a, b) => b.count - a.count || a.refDomain.localeCompare(b.refDomain)),
      }))
      .sort((a, b) => a.domain.localeCompare(b.domain));
  }, [domains, fqToDomain]);

  const filteredServices = useMemo(() => {
    const q = normalise(query);
    if (!q) return services;
    return services.filter((s) => {
      return (
        normalise(s.serviceName).includes(q) ||
        normalise(s.serviceId).includes(q) ||
        normalise(s.domain).includes(q) ||
        normalise(s.purpose).includes(q) ||
        s.tables.some((t) => normalise(`${t.schema}.${t.table}`).includes(q))
      );
    });
  }, [services, query]);

  const selected = useMemo(() => {
    if (!selectedService) return filteredServices[0] || null;
    return filteredServices.find((s) => s.serviceId === selectedService) || filteredServices[0] || null;
  }, [selectedService, filteredServices]);

  if (!selectedService && filteredServices.length) {
    // set once on first render
    setSelectedService(filteredServices[0].serviceId);
  }

  const selectedDeps = useMemo(() => {
    if (!selected) return [];
    const entry = dependencies.find((d) => d.domain === selected.domain);
    return entry?.refs || [];
  }, [selected, dependencies]);

  return (
    <div className="space-y-4">
      {/* Header */}
      <div className="rounded-halo border border-gray-200 bg-white p-4">
        <div className="flex flex-col gap-3 lg:flex-row lg:items-end lg:justify-between">
          <div>
            <h3 className="font-heading text-sm text-gray-900">Microservices Architecture</h3>
            <p className="mt-1 text-xs font-body text-gray-600">
              Service boundaries, ownership and dependencies derived from the live schema.
              This is a microservice view (not a table inspector).
            </p>
          </div>

          <span className="text-[11px] font-mono rounded-md px-2 py-1 border bg-gray-50 border-gray-200 text-gray-600">
            tables: {physicalModel?.summary?.tables ?? "â€”"} â€¢ domains: {physicalModel?.summary?.domains ?? "â€”"} â€¢ fks:{" "}
            {physicalModel?.summary?.foreign_keys ?? "â€”"} â€¢ idx: {physicalModel?.summary?.indexes ?? "â€”"}
          </span>
        </div>
      </div>

      {/* Controls */}
      <div className="rounded-halo border border-gray-200 bg-white p-4">
        <div className="flex flex-col gap-3 lg:flex-row lg:items-center lg:justify-between">
          <div className="flex gap-2">
            <button
              className={`px-3 py-2 rounded-md text-sm font-body border ${
                tab === "dependencies" ? "bg-amber-50 border-amber-300" : "bg-white border-gray-200"
              }`}
              onClick={() => setTab("dependencies")}
              type="button"
            >
              Dependencies
            </button>
            <button
              className={`px-3 py-2 rounded-md text-sm font-body border ${
                tab === "catalogue" ? "bg-amber-50 border-amber-300" : "bg-white border-gray-200"
              }`}
              onClick={() => setTab("catalogue")}
              type="button"
            >
              Catalogue
            </button>
          </div>

          <input
            value={query}
            onChange={(e) => setQuery(e.target.value)}
            placeholder="Search services, domains, tables..."
            className="px-3 py-2 rounded-md text-sm font-body border border-gray-200 bg-white min-w-[320px]"
          />
        </div>
      </div>

      {tab === "catalogue" ? (
        <div className="rounded-halo border border-gray-200 bg-white p-4">
          <div className="grid grid-cols-1 lg:grid-cols-3 gap-3">
            {filteredServices.map((s) => {
              const active = selected?.serviceId === s.serviceId;
              return (
                <button
                  key={s.serviceId}
                  type="button"
                  onClick={() => setSelectedService(s.serviceId)}
                  className={`text-left rounded-md border p-3 transition ${
                    active ? "bg-amber-50 border-amber-300 shadow" : "bg-gray-50 border-gray-200 hover:bg-gray-100"
                  }`}
                >
                  <div className="flex items-start justify-between gap-3">
                    <div>
                      <div className="font-heading text-sm text-gray-900">{s.serviceName}</div>
                      <div className="mt-1 text-[11px] font-mono text-gray-700">{s.serviceId}</div>
                      <div className="mt-1 text-[11px] font-body text-gray-600">{s.domain}</div>
                    </div>

                    <span className="text-[11px] font-mono rounded-md px-2 py-1 border bg-white border-gray-200 text-gray-700">
                      tables: {s.stats.tables}
                    </span>
                  </div>

                  <div className="mt-2 text-xs font-body text-gray-700 line-clamp-2">{s.purpose}</div>

                  <div className="mt-3 flex flex-wrap gap-2">
                    <span className="text-[11px] font-mono rounded-md px-2 py-1 border bg-white border-gray-200 text-gray-700">
                      cols: {s.stats.columns}
                    </span>
                    <span className="text-[11px] font-mono rounded-md px-2 py-1 border bg-white border-gray-200 text-gray-700">
                      outbound fks: {s.stats.outboundFks}
                    </span>
                    <span className="text-[11px] font-mono rounded-md px-2 py-1 border bg-white border-gray-200 text-gray-700">
                      idx: {s.stats.indexes}
                    </span>
                  </div>
                </button>
              );
            })}
          </div>
        </div>
      ) : (
        <div className="grid grid-cols-1 lg:grid-cols-3 gap-4">
          {/* Service list */}
          <div className="rounded-halo border border-gray-200 bg-white p-4">
            <div className="flex items-start justify-between gap-3">
              <div>
                <h4 className="font-heading text-sm text-gray-900">Services</h4>
                <p className="mt-1 text-xs font-body text-gray-600">
                  Select a service to inspect its boundaries, owned data and dependencies.
                </p>
              </div>
              <span className="text-[11px] font-mono rounded-md px-2 py-1 border bg-gray-50 border-gray-200 text-gray-600">
                {filteredServices.length}
              </span>
            </div>

            <div className="mt-3 space-y-2 max-h-[560px] overflow-auto pr-1">
              {filteredServices.map((s) => {
                const active = selected?.serviceId === s.serviceId;
                return (
                  <button
                    key={`svc-${s.serviceId}`}
                    type="button"
                    onClick={() => setSelectedService(s.serviceId)}
                    className={`w-full text-left rounded-md border p-3 transition ${
                      active ? "bg-amber-50 border-amber-300 shadow" : "bg-gray-50 border-gray-200 hover:bg-gray-100"
                    }`}
                  >
                    <div className="font-heading text-sm text-gray-900">{s.serviceName}</div>
                    <div className="mt-1 text-[11px] font-mono text-gray-700">{s.serviceId}</div>
                    <div className="mt-1 text-[11px] font-body text-gray-600">
                      tables: {s.stats.tables} â€¢ fks: {s.stats.outboundFks}
                    </div>
                  </button>
                );
              })}
            </div>
          </div>

          {/* Service detail */}
          <div className="lg:col-span-2 rounded-halo border border-gray-200 bg-white p-4">
            {!selected ? (
              <div className="text-sm font-body text-gray-700">Select a service.</div>
            ) : (
              <div className="space-y-4">
                <div className="flex flex-col gap-2 lg:flex-row lg:items-start lg:justify-between">
                  <div>
                    <h4 className="font-heading text-sm text-gray-900">{selected.serviceName}</h4>
                    <div className="mt-1 text-[11px] font-mono text-gray-700">{selected.serviceId}</div>
                    <div className="mt-2 text-xs font-body text-gray-700">{selected.purpose}</div>
                  </div>

                  <div className="flex flex-wrap gap-2">
                    <span className="text-[11px] font-mono rounded-md px-2 py-1 border bg-gray-50 border-gray-200 text-gray-700">
                      tables: {selected.stats.tables}
                    </span>
                    <span className="text-[11px] font-mono rounded-md px-2 py-1 border bg-gray-50 border-gray-200 text-gray-700">
                      cols: {selected.stats.columns}
                    </span>
                    <span className="text-[11px] font-mono rounded-md px-2 py-1 border bg-teal-50 border-teal-200 text-gray-800">
                      outbound fks: {selected.stats.outboundFks}
                    </span>
                  </div>
                </div>

                {/* Owned tables */}
                <div className="rounded-md border border-gray-200 bg-gray-50 p-3">
                  <div className="font-heading text-sm text-gray-900">Owned data (service boundary)</div>
                  <div className="mt-1 text-xs font-body text-gray-600">
                    Tables owned by this service. This is the data contract surface for the service.
                  </div>

                  <div className="mt-2 flex flex-wrap gap-2">
                    {(selected.tables || []).map((t) => (
                      <span
                        key={`${t.schema}.${t.table}`}
                        className="text-[11px] font-mono rounded-md px-2 py-1 border bg-white border-gray-200 text-gray-700"
                      >
                        {t.schema}.{t.table}
                      </span>
                    ))}
                    {!selected.tables?.length ? (
                      <div className="text-xs font-body text-gray-600">â€”</div>
                    ) : null}
                  </div>
                </div>

                {/* Dependencies */}
                <div className="rounded-md border border-gray-200 bg-gray-50 p-3">
                  <div className="font-heading text-sm text-gray-900">Service dependencies</div>
                  <div className="mt-1 text-xs font-body text-gray-600">
                    Derived from cross-domain foreign key references (data coupling surface).
                  </div>

                  <ul className="mt-2 list-disc pl-5 space-y-1">
                    {selectedDeps.length ? (
                      selectedDeps.map((d) => (
                        <li key={`${selected.domain}->${d.refDomain}`} className="text-xs font-body text-gray-800">
                          <span className="font-mono">{domainToServiceName(d.refDomain)}</span>{" "}
                          <span className="text-gray-500">({d.refDomain})</span> â€”{" "}
                          <span className="font-mono">{d.count}</span> FK reference(s)
                        </li>
                      ))
                    ) : (
                      <li className="text-xs font-body text-gray-600">No cross-domain dependencies detected.</li>
                    )}
                  </ul>
                </div>

                {/* Contracts */}
                <div className="rounded-md border border-gray-200 bg-gray-50 p-3">
                  <div className="font-heading text-sm text-gray-900">Service contracts</div>
                  <div className="mt-1 text-xs font-body text-gray-600">
                    Suggested REST contracts (placeholder until wired to real OpenAPI from backend).
                  </div>

                  <div className="mt-2 space-y-2">
                    {selected.contracts.map((c) => (
                      <div
                        key={`${selected.serviceId}-${c.name}`}
                        className="rounded-md border border-gray-200 bg-white p-3"
                      >
                        <div className="flex items-start justify-between gap-3">
                          <div className="font-heading text-sm text-gray-900">{c.name}</div>
                          <span className="text-[11px] font-mono rounded-md px-2 py-1 border bg-gray-50 border-gray-200 text-gray-700">
                            {c.version}
                          </span>
                        </div>
                        <div className="mt-1 text-xs font-body text-gray-700">{c.description}</div>

                        <div className="mt-2 flex flex-col gap-1">
                          {c.endpoints.map((e) => (
                            <div key={`${c.name}-${e.method}-${e.path}`} className="text-[11px] font-mono text-gray-700">
                              {e.method} {e.path}
                            </div>
                          ))}
                        </div>
                      </div>
                    ))}
                  </div>
                </div>

                {/* Notes */}
                <div className="rounded-md border border-gray-200 bg-white p-3">
                  <div className="text-xs font-body text-gray-600">Next enrichment (optional)</div>
                  <div className="mt-1 text-xs font-body text-gray-800">
                    Wire this to real service metadata by parsing FastAPI route tables/OpenAPI JSON from backend_v2,
                    then replace â€œsuggested contractsâ€ with the actual published interfaces.
                  </div>
                </div>
              </div>
            )}
          </div>
        </div>
      )}
    </div>
  );
}

function domainToServiceId(domain) {
  const d = (domain || "").toLowerCase().replace(/\s*&\s*/g, "-").replace(/\s+/g, "-");
  return `svc-${d}`;
}

function domainToServiceName(domain) {
  const d = (domain || "").toString();
  const map = {
    "Client canonical": "Client Canonical Service",
    "Lineage & dictionary": "Lineage and Dictionary Service",
    "KYC & risk": "KYC and Risk Service",
    "Reference data": "Reference Data Service",
  };
  return map[d] || `${d} Service`;
}

function suggestedContractsForDomain(domain) {
  // These are intentionally credible but placeholders.
  // Once you wire OpenAPI, these should become real.
  const d = (domain || "").toLowerCase();

  const contracts = [];

  if (d.includes("ingestion")) {
    contracts.push({
      name: "Ingestion API",
      version: "v1",
      description: "Manage ingestion runs, accept source payloads and expose ingest status.",
      endpoints: [
        { method: "POST", path: "/ingestion/runs" },
        { method: "GET", path: "/ingestion/runs/{run_id}" },
        { method: "POST", path: "/ingestion/source-records" },
        { method: "GET", path: "/ingestion/source-records?run_id={run_id}" },
      ],
    });
  }

  if (d.includes("client canonical")) {
    contracts.push({
      name: "Client Profile API",
      version: "v1",
      description: "Retrieve unified client profiles and operational state.",
      endpoints: [
        { method: "GET", path: "/clients" },
        { method: "GET", path: "/clients/{client_id}" },
        { method: "GET", path: "/clients/{client_id}/operational-state" },
        { method: "GET", path: "/clients/{client_id}/source-coverage" },
      ],
    });
  }

  if (d.includes("matching")) {
    contracts.push({
      name: "Matching API",
      version: "v1",
      description: "Execute and inspect matching, clusters and match decisions.",
      endpoints: [
        { method: "POST", path: "/matching/runs" },
        { method: "GET", path: "/matching/runs/{run_id}" },
        { method: "GET", path: "/matching/clusters" },
        { method: "GET", path: "/matching/decisions?run_id={run_id}" },
      ],
    });
  }

  if (d.includes("lineage")) {
    contracts.push({
      name: "Lineage API",
      version: "v1",
      description: "Attribute dictionary, precedence and resolved lineage paths.",
      endpoints: [
        { method: "GET", path: "/lineage/dictionary" },
        { method: "GET", path: "/lineage/precedence-rules" },
        { method: "GET", path: "/lineage/resolve?client_id={id}&concept={concept}" },
      ],
    });
  }

  if (d.includes("assurance")) {
    contracts.push({
      name: "Assurance API",
      version: "v1",
      description: "Validation results, audits and operational health signals.",
      endpoints: [
        { method: "GET", path: "/assurance/validation-results" },
        { method: "GET", path: "/assurance/audit-events" },
        { method: "GET", path: "/assurance/health-checks" },
        { method: "GET", path: "/assurance/error-logs" },
      ],
    });
  }

  if (d.includes("evidence")) {
    contracts.push({
      name: "Evidence API",
      version: "v1",
      description: "Evidence artefacts and bundles generated from governed execution.",
      endpoints: [
        { method: "GET", path: "/evidence/artefacts" },
        { method: "GET", path: "/evidence/bundles" },
        { method: "GET", path: "/evidence/bundles/{bundle_id}" },
      ],
    });
  }

  if (d.includes("kyc") || d.includes("risk")) {
    contracts.push({
      name: "KYC & Risk API",
      version: "v1",
      description: "KYC flags, KYC records and risk rating surfaces.",
      endpoints: [
        { method: "GET", path: "/kyc/corporate/{client_id}" },
        { method: "GET", path: "/kyc/flags?client_id={id}" },
        { method: "GET", path: "/risk/rating?client_id={id}" },
      ],
    });
  }

  if (d.includes("reference")) {
    contracts.push({
      name: "Reference Data API",
      version: "v1",
      description: "Reference and master data shared across services.",
      endpoints: [
        { method: "GET", path: "/reference/countries" },
        { method: "GET", path: "/reference/asset-classes" },
      ],
    });
  }

  // fallback if nothing matched
  if (!contracts.length) {
    contracts.push({
      name: "Service API",
      version: "v1",
      description: "Service contract placeholder (wire OpenAPI for real endpoints).",
      endpoints: [{ method: "GET", path: "/health" }],
    });
  }

  return contracts;
}



===== FILE: app_frontend\src\MissionAtlasTechnologyBOMPanel.jsx =====
import React, { useState, useMemo } from "react";
import { technologyBOM } from "./mission_atlas/technology_bom"; // Import the BOM data

const tabs = [
  { key: "componentInventory", title: "Component Inventory" },
  { key: "interfacesContracts", title: "Interfaces & Contracts" },
  { key: "runtimeWiring", title: "Runtime Wiring" },
];

export default function MissionAtlasTechnologyBOMPanel() {
  const [selectedTab, setSelectedTab] = useState(tabs[0].key); // Default to Component Inventory

  // Helper function to render each tab's content
  const renderTabContent = () => {
    switch (selectedTab) {
      case "componentInventory":
        return renderComponentInventory();
      case "interfacesContracts":
        return renderInterfacesContracts();
      case "runtimeWiring":
        return renderRuntimeWiring();
      default:
        return renderComponentInventory();
    }
  };

  // Render the Component Inventory tab content
  const renderComponentInventory = () => (
    <div className="space-y-3">
      {technologyBOM.components.map((component) => (
        <div key={component.name} className="rounded-md p-3 border bg-gray-50 border-gray-200">
          <h4 className="font-heading text-sm text-gray-900">{component.name}</h4>
          <p className="text-xs font-body text-gray-600">{component.type}</p>
          <p className="text-[11px] font-mono text-gray-500">Runtime: {component.runtime}</p>
          <p className="text-[11px] font-mono text-gray-500">Language: {component.language}</p>
          <p className="text-[11px] font-mono text-gray-500">Framework: {component.framework}</p>
          <p className="text-[11px] font-mono text-gray-500">Repo Path: {component.repoPath}</p>
          <p className="text-[11px] font-mono text-gray-500">Interfaces: {component.interfaces.map((i) => i.endpoint).join(", ")}</p>
          <p className="text-[11px] font-mono text-gray-500">Dependencies: {component.dependencies.join(", ")}</p>
          <p className="text-[11px] font-mono text-gray-500">Data Stores: {component.dataStores.join(", ")}</p>
          <p className="text-[11px] font-mono text-gray-500">Assurance Signals: {component.assuranceSignals.join(", ")}</p>
          <p className="text-[11px] font-mono text-gray-500">Status: {component.status}</p>
        </div>
      ))}
    </div>
  );

  // Render the Interfaces & Contracts tab content
  const renderInterfacesContracts = () => (
    <div className="space-y-3">
      {technologyBOM.interfaces.map((iface) => (
        <div key={iface.name} className="rounded-md p-3 border bg-gray-50 border-gray-200">
          <h4 className="font-heading text-sm text-gray-900">{iface.name}</h4>
          <p className="text-xs font-body text-gray-600">Type: {iface.type}</p>
          <p className="text-xs font-body text-gray-600">Method: {iface.method}</p>
          <p className="text-xs font-body text-gray-600">Path: {iface.path}</p>
          <p className="text-xs font-body text-gray-600">Request Model: {iface.requestModel}</p>
          <p className="text-xs font-body text-gray-600">Response Model: {iface.responseModel}</p>
        </div>
      ))}
    </div>
  );

  // Render the Runtime Wiring tab content
  const renderRuntimeWiring = () => (
    <div className="space-y-3">
      {technologyBOM.runtimeWiring.map((wiring) => (
        <div key={wiring.service} className="rounded-md p-3 border bg-gray-50 border-gray-200">
          <h4 className="font-heading text-sm text-gray-900">{wiring.service}</h4>
          <p className="text-xs font-body text-gray-600">Port: {wiring.port}</p>
          <p className="text-xs font-body text-gray-600">Base URL: {wiring.baseUrl}</p>
          <p className="text-xs font-body text-gray-600">Dependencies: {wiring.dependencies.join(", ")}</p>
        </div>
      ))}
    </div>
  );

  return (
    <div className="space-y-6">
      {/* Tabs navigation */}
      <div className="flex gap-4">
        {tabs.map((tab) => (
          <button
            key={tab.key}
            onClick={() => setSelectedTab(tab.key)}
            className={`text-sm font-heading px-3 py-2 rounded-md border border-gray-200 ${
              selectedTab === tab.key
                ? "bg-teal-50 text-gray-900 border-teal-300"
                : "text-gray-600 hover:bg-gray-50"
            }`}
          >
            {tab.title}
          </button>
        ))}
      </div>

      {/* Render content based on selected tab */}
      {renderTabContent()}

      {/* Add the Service Dependency Diagram */}
      <div className="space-y-4">
        <h4 className="font-heading text-lg text-gray-900">Service Dependency Diagram</h4>
        <div className="rounded-md p-4 border bg-gray-50 border-gray-200">
          <svg
            xmlns="http://www.w3.org/2000/svg"
            width="100%"
            height="400"
            viewBox="0 0 400 400"
            fill="none"
          >
            <circle cx="100" cy="100" r="30" fill="#4fd1c5" />
            <circle cx="300" cy="100" r="30" fill="#4fd1c5" />
            <circle cx="200" cy="300" r="30" fill="#4fd1c5" />
            <line x1="100" y1="100" x2="300" y2="100" stroke="#b0e0e6" strokeWidth="2" />
            <line x1="300" y1="100" x2="200" y2="300" stroke="#b0e0e6" strokeWidth="2" />
            <line x1="200" y1="300" x2="100" y2="100" stroke="#b0e0e6" strokeWidth="2" />
            <text x="95" y="100" fill="white" fontFamily="Fjalla One" fontSize="16" textAnchor="middle">
              Frontend
            </text>
            <text x="295" y="100" fill="white" fontFamily="Fjalla One" fontSize="16" textAnchor="middle">
              BFF
            </text>
            <text x="195" y="300" fill="white" fontFamily="Fjalla One" fontSize="16" textAnchor="middle">
              Service-A
            </text>
          </svg>
        </div>
      </div>
    </div>
  );
}




===== FILE: app_frontend\src\MissionLogPanel.jsx =====
import React, { useEffect, useMemo, useState } from "react";
import ReactMarkdown from "react-markdown";
import remarkGfm from "remark-gfm";

// Status normalisation function
function normaliseStatus(status) {
  return status ? String(status).toUpperCase() : "UNKNOWN";
}

// Status Chip (fixed width + no wrap)
function StatusChip({ label, status, extraClass = "", onClick }) {
  let statusClass = "bg-gray-200"; // Default grey

  if (status === "Complete" || status === "pass") {
    statusClass = "bg-green-100";
  } else if (status === "In Progress" || status === "fail") {
    statusClass = "bg-yellow-100";
  } else if (status === "Planned" || status === "not_run") {
    statusClass = "bg-blue-100";
  } else if (status === "N/A") {
    statusClass = "bg-gray-200";
  }

  const isClickable = typeof onClick === "function";

  const classes = [
    "inline-flex items-center justify-center",
    "px-2.5 py-0.5 rounded-full",
    "text-xs font-body text-gray-900",
    "w-20",
    "text-center",
    "whitespace-nowrap",
    statusClass,
    isClickable ? "cursor-pointer hover:shadow-sm" : "cursor-default",
    extraClass,
  ].join(" ");

  if (!isClickable) return <span className={classes}>{label}</span>;

  return (
    <button type="button" onClick={onClick} className={classes} title={label}>
      {label}
    </button>
  );
}

// Evidence modal
function EvidenceModal({ open, onClose, title, subtitle, loading, error, data }) {
  if (!open) return null;

  return (
    <div className="fixed inset-0 z-50">
      <div
        className="absolute inset-0 bg-black/40"
        onClick={onClose}
        role="button"
        tabIndex={0}
      />

      <div className="absolute inset-0 flex items-center justify-center p-4">
        <div className="w-full max-w-3xl bg-white rounded-halo shadow-lg border border-gray-200">
          <div className="flex items-start justify-between p-4 border-b border-gray-200">
            <div>
              <h3
                style={{ fontFamily: "Fjalla One" }}
                className="text-lg text-gray-900 tracking-wide"
              >
                {title}
              </h3>
              {subtitle && (
                <p className="text-sm font-body text-gray-600 mt-1">{subtitle}</p>
              )}
            </div>

            <button
              type="button"
              onClick={onClose}
              className="inline-flex items-center justify-center px-3 py-1.5 rounded-md border border-gray-300 bg-white text-gray-800 text-sm font-body hover:bg-gray-50"
            >
              Close
            </button>
          </div>

          <div className="p-4">
            {loading && (
              <p className="text-sm font-body text-gray-500">Loading evidenceâ€¦</p>
            )}

            {!loading && error && (
              <p className="text-sm font-body text-red-600">{error}</p>
            )}

            {!loading && !error && (
              <div className="bg-gray-50 border border-gray-200 rounded-md p-3 overflow-auto max-h-[60vh]">
                <pre className="text-xs font-mono text-gray-800 whitespace-pre-wrap">
                  {JSON.stringify(data, null, 2)}
                </pre>
              </div>
            )}

            <p className="text-xs font-body text-gray-400 mt-3">
              Evidence is expected at{" "}
              <code>/missionlog/evidence/&lt;story_id&gt;/&lt;dimension&gt;.json</code>.
            </p>
          </div>
        </div>
      </div>
    </div>
  );
}

// Confirm execution modal
function ConfirmExecutionModal({ open, onCancel, onConfirm }) {
  if (!open) return null;

  return (
    <div className="fixed inset-0 z-50">
      <div
        className="absolute inset-0 bg-black/40"
        onClick={onCancel}
        role="button"
        tabIndex={0}
      />

      <div className="absolute inset-0 flex items-center justify-center p-4">
        <div className="w-full max-w-2xl bg-white rounded-halo shadow-lg border border-gray-200">
          <div className="flex items-start justify-between p-4 border-b border-gray-200">
            <div>
              <h3
                style={{ fontFamily: "Fjalla One" }}
                className="text-lg text-gray-900 tracking-wide"
              >
                Confirm Story Execution
              </h3>
            </div>

            <button
              type="button"
              onClick={onCancel}
              className="inline-flex items-center justify-center px-3 py-1.5 rounded-md border border-gray-300 bg-white text-gray-800 text-sm font-body hover:bg-gray-50"
            >
              Close
            </button>
          </div>

          <div className="p-4">
            <p className="text-sm font-body text-gray-800">
              M7 Mission Control will now code and test this story, and ensure that it meets all
              defined principles, guidelines and guardrails before deployment. Please confirm.
            </p>

            <div className="mt-4 flex justify-end gap-2">
              <button
                type="button"
                onClick={onCancel}
                className="inline-flex items-center justify-center px-4 py-2 rounded-md border border-gray-300 bg-white text-gray-800 text-sm font-body hover:bg-gray-50"
              >
                Cancel
              </button>
              <button
                type="button"
                onClick={onConfirm}
                className="inline-flex items-center justify-center px-4 py-2 rounded-md bg-[#1A9988] text-white text-sm font-body font-medium shadow-sm transition-all duration-150 hover:bg-[#178c7d]"
              >
                Confirm
              </button>
            </div>
          </div>
        </div>
      </div>
    </div>
  );
}

// Story definition modal (now loads exported JSON and renders markdown)
function StoryDefinitionModal({ open, onClose, storyId, storyName }) {
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState("");
  const [doc, setDoc] = useState(null);

  useEffect(() => {
    if (!open || !storyId) return;

    let cancelled = false;

    async function load() {
      setLoading(true);
      setError("");
      setDoc(null);

      const url = `/missionlog/story_defs/${encodeURIComponent(storyId)}.json`;

      try {
        const res = await fetch(url, { cache: "no-store" });
        if (!res.ok) {
          throw new Error(
            `Story definition not found (HTTP ${res.status}). Expected: ${url}`
          );
        }
        const json = await res.json();
        if (!cancelled) setDoc(json);
      } catch (e) {
        if (!cancelled) {
          setError(e?.message || "Could not load story definition.");
        }
      } finally {
        if (!cancelled) setLoading(false);
      }
    }

    load();

    return () => {
      cancelled = true;
    };
  }, [open, storyId]);

  if (!open) return null;

  return (
    <div className="fixed inset-0 z-50">
      <div
        className="absolute inset-0 bg-black/40"
        onClick={onClose}
        role="button"
        tabIndex={0}
      />

      <div className="absolute inset-0 flex items-center justify-center p-4">
        <div className="w-full max-w-4xl bg-white rounded-halo shadow-lg border border-gray-200">
          <div className="flex items-start justify-between p-4 border-b border-gray-200">
            <div>
              <h3
                style={{ fontFamily: "Fjalla One" }}
                className="text-lg text-gray-900 tracking-wide"
              >
                {storyId} Â· Story Definition
              </h3>
              {storyName && (
                <p className="text-sm font-body text-gray-600 mt-1">{storyName}</p>
              )}
            </div>

            <button
              type="button"
              onClick={onClose}
              className="inline-flex items-center justify-center px-3 py-1.5 rounded-md border border-gray-300 bg-white text-gray-800 text-sm font-body hover:bg-gray-50"
            >
              Close
            </button>
          </div>

          <div className="p-4">
            {loading && (
              <p className="text-sm font-body text-gray-500">
                Loading story definitionâ€¦
              </p>
            )}

            {!loading && error && (
              <p className="text-sm font-body text-red-600">{error}</p>
            )}

            {!loading && !error && doc && (
              <div className="grid grid-cols-1 lg:grid-cols-[1fr_18rem] gap-4">
                <div className="bg-gray-50 border border-gray-200 rounded-md p-4 overflow-auto max-h-[65vh]">
                  <article className="prose prose-sm max-w-none">
                    <ReactMarkdown remarkPlugins={[remarkGfm]}>
                      {doc.body_markdown || ""}
                    </ReactMarkdown>
                  </article>
                </div>

                <div className="bg-white border border-gray-200 rounded-md p-4 overflow-auto max-h-[65vh]">
                  <p className="text-xs font-body text-gray-500 mb-2">Front matter</p>
                  <pre className="text-xs font-mono text-gray-800 whitespace-pre-wrap">
                    {JSON.stringify(doc.front_matter || {}, null, 2)}
                  </pre>

                  <p className="text-xs font-body text-gray-400 mt-3">
                    Source:{" "}
                    <span className="font-mono">
                      {doc.source_path || "(unknown)"}
                    </span>
                  </p>
                  <p className="text-xs font-body text-gray-400 mt-1">
                    Exported:{" "}
                    <span className="font-mono">
                      {doc.exported_at_utc || "(unknown)"}
                    </span>
                  </p>
                </div>
              </div>
            )}

            {!loading && !error && !doc && (
              <p className="text-sm font-body text-gray-500">
                No story definition data available.
              </p>
            )}

            <p className="text-xs font-body text-gray-400 mt-3">
              Definition is generated from story markdown files (re-run the export
              script to refresh).
            </p>
          </div>
        </div>
      </div>
    </div>
  );
}

export default function MissionLogPanel({ setActiveView }) {
  const [data, setData] = useState(null);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState("");

  // Evidence modal state
  const [evidenceOpen, setEvidenceOpen] = useState(false);
  const [evidenceLoading, setEvidenceLoading] = useState(false);
  const [evidenceError, setEvidenceError] = useState("");
  const [evidenceData, setEvidenceData] = useState(null);
  const [evidenceMeta, setEvidenceMeta] = useState({
    storyId: "",
    storyName: "",
    dimensionKey: "",
    dimensionLabel: "",
    status: "",
  });

  // Story definition modal state
  const [storyDefOpen, setStoryDefOpen] = useState(false);
  const [storyDefMeta, setStoryDefMeta] = useState({
    storyId: "",
    storyName: "",
  });

  // Demo execution state (local-first MissionControl loop)
  const [demo, setDemo] = useState({
    mode: "idle", // idle | confirming | running | completed | failed
    storyId: "",
    storyName: "",
    runId: "",
    message: "",
  });

  // Filters (multi-select)
  const [selectedEpics, setSelectedEpics] = useState([]);
  const [selectedFeatures, setSelectedFeatures] = useState([]);
  const [selectedStories, setSelectedStories] = useState([]);

  const reloadSnapshot = async () => {
    try {
      const res = await fetch(`/missionlog/status_snapshot.json?t=${Date.now()}`, {
        cache: "no-store",
      });
      if (!res.ok) throw new Error(`HTTP ${res.status}`);
      const json = await res.json();
      setData(json);
      setError("");
    } catch (err) {
      console.error("Failed to load MissionLog status snapshot", err);
      setError("Could not load latest status snapshot.");
    } finally {
      setLoading(false);
    }
  };

  useEffect(() => {
    reloadSnapshot();
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, []);

  // Poll MissionControl runner and refresh snapshot while a run is active
  useEffect(() => {
    if (demo.mode !== "running" || !demo.runId) return;

    let stopped = false;

    const interval = setInterval(async () => {
      if (stopped) return;

      try {
        const res = await fetch(`http://127.0.0.1:8000/missioncontrol/runs/${demo.runId}`, {
          cache: "no-store",
        });
        if (!res.ok) throw new Error(`HTTP ${res.status}`);
        const run = await res.json();

        setDemo((d) => ({
          ...d,
          message: run.message || d.message,
          mode:
            run.state === "completed"
              ? "completed"
              : run.state === "failed"
              ? "failed"
              : "running",
        }));

        await reloadSnapshot();

        if (run.state === "completed" || run.state === "failed") {
          clearInterval(interval);
        }
      } catch (err) {
        console.error("MissionControl polling error", err);
      }
    }, 700);

    return () => {
      stopped = true;
      clearInterval(interval);
    };
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [demo.mode, demo.runId]);

  const startRun = async (storyId, storyName) => {
    setDemo({
      mode: "running",
      storyId,
      storyName: storyName || "",
      runId: "",
      message: "Starting executionâ€¦",
    });

    const res = await fetch("http://127.0.0.1:8000/missioncontrol/runs", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ story_id: storyId }),
    });

    const json = await res.json();

    setDemo((d) => ({
      ...d,
      runId: json.run_id || "",
    }));
  };

  const epics = data?.epics || [];

  // Fixed badge spec (exact order)
  const BADGES = useMemo(
    () => [
      { label: "Testing", key: "testing_status", mvp: true, evidenceDim: "testing" },
      { label: "Halo", key: "halo_adherence", mvp: true, evidenceDim: "halo" },
      { label: "Guardrails", key: "guardrail_adherence", mvp: true, evidenceDim: "guardrails" },
      { label: "Quality", key: "code_quality_adherence", mvp: true, evidenceDim: "code_quality" },
      { label: "Security", key: "security_policy_adherence", mvp: true, evidenceDim: "security" },

      { label: "Policy", key: "policy_adherence", mvp: false, evidenceDim: "policy" },
      { label: "Tech Trace", key: "technology_lineage_adherence", mvp: false, evidenceDim: "tech_lineage" },
      { label: "Lineage", key: "business_data_lineage_adherence", mvp: false, evidenceDim: "business_lineage" },
      { label: "Self-Heal", key: "self_healing_adherence", mvp: false, evidenceDim: "self_healing" },
      { label: "Analytics", key: "analytics_adherence", mvp: false, evidenceDim: "analytics" },
    ],
    []
  );

  const handleBack = () => {
    if (typeof setActiveView === "function") setActiveView("scv");
    else window.location.reload();
  };

  async function openEvidence(story, badge) {
    const raw = story?.[badge.key];
    const statusVal = badge.mvp ? (raw || "not_run") : "N/A";
    if (statusVal !== "pass" && statusVal !== "fail") return;

    const storyId = story.story_id;
    const storyName = story.name;

    setEvidenceMeta({
      storyId,
      storyName,
      dimensionKey: badge.key,
      dimensionLabel: badge.label,
      status: statusVal,
    });

    setEvidenceOpen(true);
    setEvidenceLoading(true);
    setEvidenceError("");
    setEvidenceData(null);

    const url = `/missionlog/evidence/${encodeURIComponent(
      storyId
    )}/${encodeURIComponent(badge.evidenceDim)}.json`;

    try {
      const res = await fetch(url, { cache: "no-store" });
      if (!res.ok)
        throw new Error(`Evidence not found (HTTP ${res.status}). Expected: ${url}`);
      const json = await res.json();
      setEvidenceData(json);
    } catch (err) {
      setEvidenceError(
        err?.message || "Could not load evidence for this badge (file missing or invalid JSON)."
      );
    } finally {
      setEvidenceLoading(false);
    }
  }

  const closeEvidence = () => {
    setEvidenceOpen(false);
    setEvidenceLoading(false);
    setEvidenceError("");
    setEvidenceData(null);
  };

  const openStoryDefinition = (story) => {
    setStoryDefMeta({ storyId: story.story_id, storyName: story.name });
    setStoryDefOpen(true);
  };

  const closeStoryDefinition = () => {
    setStoryDefOpen(false);
  };

  // ---------- Filter indexes + expansion rules ----------

  const index = useMemo(() => {
    const epicsById = new Map();
    const featuresById = new Map();
    const storiesById = new Map();
    const featureToEpic = new Map();
    const storyToFeature = new Map();
    const epicToFeatures = new Map();
    const featureToStories = new Map();

    for (const e of epics) {
      epicsById.set(e.epic_id, e);
      epicToFeatures.set(e.epic_id, []);
      for (const f of e.features || []) {
        featuresById.set(f.feature_id, f);
        featureToEpic.set(f.feature_id, e.epic_id);
        epicToFeatures.get(e.epic_id).push(f.feature_id);

        featureToStories.set(f.feature_id, []);
        for (const s of f.stories || []) {
          storiesById.set(s.story_id, s);
          storyToFeature.set(s.story_id, f.feature_id);
          featureToStories.get(f.feature_id).push(s.story_id);
        }
      }
    }

    return {
      epicsById,
      featuresById,
      storiesById,
      featureToEpic,
      storyToFeature,
      epicToFeatures,
      featureToStories,
    };
  }, [epics]);

  const options = useMemo(() => {
    const epicOpts = epics.map((e) => ({
      id: e.epic_id,
      label: `${e.epic_id}: ${e.name}`,
    }));

    const featureOpts = [];
    const storyOpts = [];

    for (const e of epics) {
      for (const f of e.features || []) {
        featureOpts.push({
          id: f.feature_id,
          label: `${f.feature_id}: ${f.name}`,
        });
        for (const s of f.stories || []) {
          storyOpts.push({
            id: s.story_id,
            label: `${s.story_id}: ${s.name}`,
          });
        }
      }
    }

    return { epicOpts, featureOpts, storyOpts };
  }, [epics]);

  const visibleSets = useMemo(() => {
    const anySelected =
      selectedEpics.length > 0 ||
      selectedFeatures.length > 0 ||
      selectedStories.length > 0;

    if (!anySelected) {
      return {
        anySelected: false,
        visibleEpicIds: null,
        visibleFeatureIds: null,
        visibleStoryIds: null,
      };
    }

    const visibleEpicIds = new Set();
    const visibleFeatureIds = new Set();
    const visibleStoryIds = new Set();

    // 1) Expand epics -> all features + all stories
    for (const epicId of selectedEpics) {
      visibleEpicIds.add(epicId);
      const feats = index.epicToFeatures.get(epicId) || [];
      for (const fid of feats) {
        visibleFeatureIds.add(fid);
        const stories = index.featureToStories.get(fid) || [];
        for (const sid of stories) visibleStoryIds.add(sid);
      }
    }

    // 2) Expand features -> parent epic + all stories
    for (const featureId of selectedFeatures) {
      visibleFeatureIds.add(featureId);
      const epicId = index.featureToEpic.get(featureId);
      if (epicId) visibleEpicIds.add(epicId);

      const stories = index.featureToStories.get(featureId) || [];
      for (const sid of stories) visibleStoryIds.add(sid);
    }

    // 3) Expand stories -> parent feature + parent epic (only that story)
    for (const storyId of selectedStories) {
      visibleStoryIds.add(storyId);
      const featureId = index.storyToFeature.get(storyId);
      if (featureId) {
        visibleFeatureIds.add(featureId);
        const epicId = index.featureToEpic.get(featureId);
        if (epicId) visibleEpicIds.add(epicId);
      }
    }

    return {
      anySelected: true,
      visibleEpicIds,
      visibleFeatureIds,
      visibleStoryIds,
    };
  }, [selectedEpics, selectedFeatures, selectedStories, index]);

  const filteredEpics = useMemo(() => {
    if (!visibleSets.anySelected) return epics;

    return epics
      .filter((e) => visibleSets.visibleEpicIds.has(e.epic_id))
      .map((e) => ({
        ...e,
        features: (e.features || [])
          .filter((f) => visibleSets.visibleFeatureIds.has(f.feature_id))
          .map((f) => ({
            ...f,
            stories: (f.stories || []).filter((s) =>
              visibleSets.visibleStoryIds.has(s.story_id)
            ),
          })),
      }));
  }, [epics, visibleSets]);

  const clearFilters = () => {
    setSelectedEpics([]);
    setSelectedFeatures([]);
    setSelectedStories([]);
  };

  const onMultiSelectChange = (setter) => (e) => {
    const vals = Array.from(e.target.selectedOptions).map((o) => o.value);
    setter(vals);
  };

  // ---------- Status column alignment ----------
  const ROW_GRID = "grid grid-cols-[1fr_7rem] items-start gap-3"; // 7rem ~ w-28

  return (
    <section className="bg-white rounded-halo shadow-sm border border-gray-200 p-6 mb-6">
      <div className="flex justify-between mb-4">
        <h2
          style={{ fontFamily: "Fjalla One" }}
          className="text-lg text-gray-900 tracking-wide"
        >
          MissionLog Single Client View
        </h2>

        <button
          type="button"
          onClick={handleBack}
          className="inline-flex items-center justify-center px-4 py-2 rounded-md bg-[#1A9988] text-white font-body text-sm font-medium shadow-sm transition-all duration-150 hover:bg-[#178c7d] hover:-translate-y-0.5 hover:shadow-md active:bg-[#147c6f] active:translate-y-0 active:shadow-sm"
        >
          Back to Single Client View
        </button>
      </div>

      <div className="mb-4 p-3 bg-gray-50 rounded-md text-sm font-body text-gray-800">
        <strong>Status Key:</strong>
        <div className="flex flex-wrap gap-3 mt-2">
          <StatusChip label="Complete" status="pass" />
          <StatusChip label="In Progress" status="fail" />
          <StatusChip label="Planned" status="not_run" />
          <StatusChip label="N/A" status="N/A" />
        </div>
      </div>

      {/* NEW: Filters */}
      <div className="mb-4 p-4 bg-white rounded-md border border-gray-200">
        <div className="flex items-start justify-between gap-4">
          <div className="grid grid-cols-1 md:grid-cols-3 gap-4 w-full">
            <div>
              <label className="block text-xs font-body text-gray-700 mb-1">
                Filter Epics
              </label>
              <select
                multiple
                value={selectedEpics}
                onChange={onMultiSelectChange(setSelectedEpics)}
                className="w-full text-sm font-body border border-gray-300 rounded-md p-2 bg-white"
                size={Math.min(6, Math.max(3, options.epicOpts.length))}
              >
                {options.epicOpts.map((o) => (
                  <option key={o.id} value={o.id}>
                    {o.label}
                  </option>
                ))}
              </select>
            </div>

            <div>
              <label className="block text-xs font-body text-gray-700 mb-1">
                Filter Features
              </label>
              <select
                multiple
                value={selectedFeatures}
                onChange={onMultiSelectChange(setSelectedFeatures)}
                className="w-full text-sm font-body border border-gray-300 rounded-md p-2 bg-white"
                size={Math.min(6, Math.max(3, options.featureOpts.length))}
              >
                {options.featureOpts.map((o) => (
                  <option key={o.id} value={o.id}>
                    {o.label}
                  </option>
                ))}
              </select>
            </div>

            <div>
              <label className="block text-xs font-body text-gray-700 mb-1">
                Filter Stories
              </label>
              <select
                multiple
                value={selectedStories}
                onChange={onMultiSelectChange(setSelectedStories)}
                className="w-full text-sm font-body border border-gray-300 rounded-md p-2 bg-white"
                size={Math.min(6, Math.max(3, options.storyOpts.length))}
              >
                {options.storyOpts.map((o) => (
                  <option key={o.id} value={o.id}>
                    {o.label}
                  </option>
                ))}
              </select>
            </div>
          </div>

          <div className="flex-shrink-0">
            <button
              type="button"
              onClick={clearFilters}
              className="inline-flex items-center justify-center px-4 py-2 rounded-md border border-gray-300 bg-white text-gray-800 text-sm font-body hover:bg-gray-50"
            >
              Clear
            </button>
          </div>
        </div>

        <p className="text-xs font-body text-gray-500 mt-3">
          Select any combination. Stories show their parent Feature and Epic.
          Features show their Epic and all Stories. Epics show all Features and
          Stories.
        </p>
      </div>

            {/* Semantic Execution Plane */} 
      <div className="mb-4">
        <h2
          style={{ fontFamily: "Fjalla One" }}
          className="text-lg text-gray-900 tracking-wide"
        >
          Semantic Execution Plane
        </h2>
        <p className="text-sm font-body text-gray-600 mt-1">
          Turning intent into governed execution
        </p>

        {demo.mode === "running" && (
                <div className="mt-3 p-3 bg-halo-primary/10 rounded-md border border-halo-primary text-sm font-body text-gray-900">
                  <strong>M7 Mission Control:</strong> {demo.message || "Runningâ€¦"}
                </div>
              )}
              {demo.mode === "completed" && (
                <div className="mt-3 p-3 bg-green-50 rounded-md border border-green-200 text-sm font-body text-gray-900">
                  <strong>M7 Mission Control:</strong> Completed.
                </div>
              )}
              {demo.mode === "failed" && (
                <div className="mt-3 p-3 bg-yellow-50 rounded-md border border-yellow-200 text-sm font-body text-gray-900">
                  <strong>M7 Mission Control:</strong> Failed. Check backend logs.
                </div>
              )}


      </div>

{loading && (
        <p className="text-sm font-body text-gray-500">Loading latest status snapshotâ€¦</p>
      )}
      {!loading && error && <p className="text-sm font-body text-red-600 mb-2">{error}</p>}
      {!loading && !error && filteredEpics.length === 0 && (
        <p className="text-sm font-body text-gray-500">No status data available.</p>
      )}

      {!loading && !error && filteredEpics.length > 0 && (
        <div className="space-y-6">
          {filteredEpics.map((epic) => (
            <div
              key={epic.epic_id}
              className="bg-gray-50 rounded-lg border border-gray-200 p-4"
            >
              <div className={`${ROW_GRID} mb-3`}>
                <p className="font-heading text-sm text-gray-900">
                  Epic {epic.epic_id}: {epic.name}
                </p>

                <div className="flex justify-end">
                  <StatusChip
                    label={normaliseStatus(epic.overall_status)}
                    status={epic.overall_status}
                    extraClass="w-28"
                  />
                </div>
              </div>

              <div className="space-y-4">
                {(epic.features || []).map((feature) => (
                  <div
                    key={feature.feature_id}
                    className="bg-white rounded-md border border-gray-200 p-4"
                  >
                    {/* CHANGED: bleed header row to outer edges to align status with Epic */}
                    <div className={`${ROW_GRID} -mx-4 px-4`}>
                      <p className="font-heading text-sm text-gray-900">
                        Feature {feature.feature_id}: {feature.name}
                      </p>

                      <div className="flex justify-end">
                        <StatusChip
                          label={normaliseStatus(feature.overall_status)}
                          status={feature.overall_status}
                          extraClass="w-28"
                        />
                      </div>
                    </div>

                    <div className="mt-3 space-y-2">
                      {(feature.stories || []).map((story) => (
                        <div
                          key={story.story_id}
                          className="bg-gray-50 rounded-md border border-gray-200 p-3"
                        >
                          {/* CHANGED: bleed header row to outer edges to align status with Epic/Feature */}
                          <div className={`${ROW_GRID} -mx-3 px-3`}>
                            <button
                              type="button"
                              onClick={() => openStoryDefinition(story)}
                              className="text-sm font-body text-gray-900 truncate min-w-0 text-left rounded-md px-2 py-1 -ml-2 hover:bg-white/70 focus:outline-none focus:ring-2 focus:ring-[#1A9988]"
                              title="View story definition"
                            >
                              <span className="font-semibold">{story.story_id}</span> Â· {story.name}
                            </button>

                            {/* ONLY CHANGE: button moved left of chip, widened, and ST-05 green */}
                            <div className="flex items-center justify-end gap-2">
                              <button
                                type="button"
                                disabled={story.story_id !== "ST-05" || demo.mode === "running"}
                                onClick={() =>
                                  setDemo({
                                    mode: "confirming",
                                    storyId: story.story_id,
                                    storyName: story.name || "",
                                    runId: "",
                                    message: "",
                                  })
                                }
                                className={[
                                  "inline-flex items-center justify-center",
                                  "px-4 py-2 rounded-md",
                                  "text-xs font-body font-medium",
                                  "whitespace-nowrap",
                                  "min-w-[170px]",
                                  story.story_id === "ST-05"
                                    ? "bg-[#1A9988] text-white hover:bg-[#178c7d]"
                                    : "bg-gray-200 text-gray-500 cursor-not-allowed",
                                  demo.mode === "running"
                                    ? "opacity-60 cursor-not-allowed"
                                    : "",
                                ].join(" ")}
                              >
                                Ready to Implement
                              </button>

                              <StatusChip
                                label={normaliseStatus(story.overall_status)}
                                status={story.overall_status}
                                extraClass="w-28"
                              />
                            </div>
                          </div>

                          <div className="mt-2 overflow-x-auto">
                            <div className="flex flex-nowrap gap-2 justify-start">
                              {BADGES.map((b) => {
                                const raw = story?.[b.key];
                                const statusVal = b.mvp ? (raw || "not_run") : "N/A";
                                const clickable = statusVal === "pass" || statusVal === "fail";

                                return (
                                  <StatusChip
                                    key={`${story.story_id}-${b.key}`}
                                    label={b.label}
                                    status={statusVal}
                                    onClick={clickable ? () => openEvidence(story, b) : undefined}
                                  />
                                );
                              })}
                            </div>
                          </div>
                        </div>
                      ))}
                    </div>
                  </div>
                ))}
              </div>
            </div>
          ))}
        </div>
      )}

      <ConfirmExecutionModal
        open={demo.mode === "confirming"}
        onCancel={() =>
          setDemo({ mode: "idle", storyId: "", storyName: "", runId: "", message: "" })
        }
        onConfirm={() => startRun(demo.storyId, demo.storyName)}
      />

      <EvidenceModal
        open={evidenceOpen}
        onClose={closeEvidence}
        title={`${evidenceMeta.storyId} Â· ${evidenceMeta.dimensionLabel} Evidence`}
        subtitle={`${evidenceMeta.storyName} Â· Status: ${evidenceMeta.status}`}
        loading={evidenceLoading}
        error={evidenceError}
        data={evidenceData}
      />

      <StoryDefinitionModal
        open={storyDefOpen}
        onClose={closeStoryDefinition}
        storyId={storyDefMeta.storyId}
        storyName={storyDefMeta.storyName}
      />
    </section>
  );
}














===== FILE: app_frontend\src\MissionNavButtons.jsx =====
import React from "react";
import logo from "./assets/m7_single_client_view.png";

/* 
  Base button layout + animation.
  Font is controlled by the custom .font-fjalla class.
*/

const baseButtonClasses = `
  inline-flex items-center justify-center
  px-8 py-2.5 rounded-md
  text-base text-gray-900
  shadow-sm
  transition
  transform
  hover:-translate-y-0.5 hover:shadow-md
  active:translate-y-0 active:shadow-sm
  font-fjalla
`;

export default function MissionNavButtons() {
  return (
    <header className="bg-white border-b">
      <div className="max-w-6xl mx-auto flex items-center justify-between px-6 py-4">
        {/* Logo */}
        <div className="flex items-center">
          <img
            src={logo}
            alt="M7 Single Client View"
            className="h-10"
          />
        </div>

        {/* Buttons */}
        <div className="flex items-center gap-4">
          {/* MissionSmith */}
          <button
            type="button"
            className={`${baseButtonClasses}
              bg-[rgb(189,199,155)]
              hover:bg-[rgb(176,186,142)]
            `}
            onClick={() => {}}
          >
            MissionSmith
          </button>

          {/* MissionAtlas */}
          <button
            type="button"
            className={`${baseButtonClasses}
              bg-[rgb(241,205,86)]
              hover:bg-[rgb(232,196,80)]
            `}
            onClick={() => {}}
          >
            MissionAtlas
          </button>

          {/* MissionLog */}
          <button
            type="button"
            className={`${baseButtonClasses}
              bg-[rgb(167,198,223)]
              hover:bg-[rgb(157,187,210)]
            `}
            onClick={() => {}}
          >
            MissionLog
          </button>
        </div>
      </div>
    </header>
  );
}




===== FILE: app_frontend\src\MissionSmithPanel.jsx =====
// app_frontend/src/App.jsx
import React, { useState } from "react";
import MissionLogPanel from "./MissionLogPanel";
import MissionAtlasPanel from "./MissionAtlasPanel";
import MissionSmithPanel from "./MissionSmithPanel";
import logo from "./assets/m7_single_client_view.png";

const BACKEND_BASE_URL = "http://127.0.0.1:8000";

function App() {
  const [clientId, setClientId] = useState("");
  const [loading, setLoading] = useState(false);
  const [profile, setProfile] = useState(null);
  const [sources, setSources] = useState([]);
  const [error, setError] = useState("");

  // 'scv' | 'missionLog' | 'missionAtlas' | 'missionSmith'
  const [activeView, setActiveView] = useState("scv");

  const handleSubmit = async (e) => {
    e.preventDefault();
    if (!clientId.trim()) {
      setError("Please enter a Client ID.");
      return;
    }

    setError("");
    setLoading(true);
    setProfile(null);
    setSources([]);

    try {
      const encodedId = encodeURIComponent(clientId.trim());

      const profileRes = await fetch(
        `${BACKEND_BASE_URL}/clients/${encodedId}/profile`
      );
      if (!profileRes.ok) {
        const detail = await profileRes.json().catch(() => ({}));
        throw new Error(detail.detail || "Failed to fetch profile.");
      }
      const profileJson = await profileRes.json();

      const sourcesRes = await fetch(
        `${BACKEND_BASE_URL}/clients/${encodedId}/sources`
      );
      const sourcesJson = sourcesRes.ok ? await sourcesRes.json() : [];

      setProfile(profileJson);
      setSources(sourcesJson);
    } catch (err) {
      console.error(err);
      setError(err.message || "Something went wrong.");
    } finally {
      setLoading(false);
    }
  };

  const isMissionLog = activeView === "missionLog";
  const isMissionAtlas = activeView === "missionAtlas";
  const isMissionSmith = activeView === "missionSmith";
  const isSCV = activeView === "scv";

  return (
    <div className="min-h-screen bg-gray-100">
      {/* Header with logo and mission buttons */}
      <header className="bg-white shadow-sm">
        {/* Logo */}
        <div className="max-w-6xl mx-auto px-4 py-4">
          <img
            src={logo}
            alt="M7 single client view"
            className="h-16 w-auto md:h-20"
          />
        </div>

        {/* Mission buttons */}
        <div className="bg-gray-100 border-t border-gray-200">
          <div className="max-w-6xl mx-auto px-4 py-3 flex justify-end gap-4">
            {/* MissionSmith -> embedded HTML view */}
            <button
              type="button"
              style={{ fontFamily: "Fjalla One" }}
              className={`
                inline-flex items-center justify-center
                px-8 py-2.5 rounded-md border
                text-base text-gray-900
                bg-[rgb(176,192,159)]
                shadow-sm
                transition-colors transition-transform duration-150
                hover:-translate-y-0.5
                active:translate-y-0
                ${isMissionSmith ? "border-gray-500 shadow-md" : "border-gray-300"}
              `}
              onClick={() => setActiveView("missionSmith")}
            >
              MissionSmith
            </button>

            {/* MissionAtlas */}
            <button
              type="button"
              style={{ fontFamily: "Fjalla One" }}
              className={`
                inline-flex items-center justify-center
                px-8 py-2.5 rounded-md border
                text-base text-gray-900
                bg-[rgb(205,226,235)]
                shadow-sm
                transition-colors transition-transform duration-150
                hover:-translate-y-0.5
                active:translate-y-0
                ${isMissionAtlas ? "border-gray-500 shadow-md" : "border-gray-300"}
              `}
              onClick={() => setActiveView("missionAtlas")}
            >
              MissionAtlas
            </button>

            {/* MissionLog */}
            <button
              type="button"
              style={{ fontFamily: "Fjalla One" }}
              className={`
                inline-flex items-center justify-center
                px-8 py-2.5 rounded-md border
                text-base text-gray-900
                bg-[rgb(241,205,86)]
                shadow-sm
                transition-colors transition-transform duration-150
                hover:-translate-y-0.5
                active:translate-y-0
                ${isMissionLog ? "border-gray-500 shadow-md" : "border-gray-300"}
              `}
              onClick={() => setActiveView("missionLog")}
            >
              MissionLog
            </button>
          </div>
        </div>
      </header>

      <main className="max-w-6xl mx-auto px-4 py-6">
        {isMissionSmith ? (
          <>
            <MissionSmithPanel />
            <div className="flex justify-start">
              <button
                type="button"
                className="
                  inline-flex items-center justify-center
                  px-4 py-2 rounded-md
                  bg-white text-[#1A9988]
                  border border-[#1A9988]
                  font-body text-sm font-medium
                  shadow-sm
                  transition-colors transition-transform duration-150
                  hover:bg-[#1A9988] hover:text-white hover:-translate-y-0.5
                  active:translate-y-0
                "
                onClick={() => setActiveView("scv")}
              >
                Back to Single Client View
              </button>
            </div>
          </>
        ) : isMissionLog ? (
          <>
            <MissionLogPanel />
            <div className="flex justify-start">
              <button
                type="button"
                className="
                  inline-flex items-center justify-center
                  px-4 py-2 rounded-md
                  bg-white text-[#1A9988]
                  border border-[#1A9988]
                  font-body text-sm font-medium
                  shadow-sm
                  transition-colors transition-transform duration-150
                  hover:bg-[#1A9988] hover:text-white hover:-translate-y-0.5
                  active:translate-y-0
                "
                onClick={() => setActiveView("scv")}
              >
                Back to Single Client View
              </button>
            </div>
          </>
        ) : isMissionAtlas ? (
          <>
            <MissionAtlasPanel />
            <div className="flex justify-start">
              <button
                type="button"
                className="
                  inline-flex items-center justify-center
                  px-4 py-2 rounded-md
                  bg-white text-[#1A9988]
                  border border-[#1A9988]
                  font-body text-sm font-medium
                  shadow-sm
                  transition-colors transition-transform duration-150
                  hover:bg-[#1A9988] hover:text-white hover:-translate-y-0.5
                  active:translate-y-0
                "
                onClick={() => setActiveView("scv")}
              >
                Back to Single Client View
              </button>
            </div>
          </>
        ) : (
          <>
            {/* Find client profile */}
            <section className="bg-white rounded-halo shadow-sm border border-gray-200 p-6 mb-6">
              <h2 className="font-heading text-lg text-gray-800 mb-4">
                Find client profile
              </h2>

              <form
                onSubmit={handleSubmit}
                className="flex flex-col md:flex-row gap-4 items-stretch md:items-end"
              >
                <div className="flex-1">
                  <label
                    htmlFor="client-id"
                    className="block text-sm font-body text-gray-600 mb-1"
                  >
                    Client ID
                  </label>
                  <input
                    id="client-id"
                    type="text"
                    value={clientId}
                    onChange={(e) => setClientId(e.target.value)}
                    placeholder="e.g. C-004"
                    className="
                      w-full px-3 py-2 rounded-md border border-gray-300 
                      font-body text-sm
                      focus:outline-none focus:ring-2 
                      focus:ring-[#1A9988] focus:border-[#1A9988]
                    "
                  />
                </div>

                <button
                  type="submit"
                  disabled={loading}
                  className="
                    inline-flex items-center justify-center
                    px-4 py-2 rounded-md w-32
                    bg-[#1A9988] text-white
                    font-body text-sm font-medium shadow-sm
                    transition-colors transition-transform duration-150
                    hover:bg-[#178c7d] hover:-translate-y-0.5
                    active:bg-[#147c6f] active:translate-y-0
                    disabled:opacity-60 disabled:cursor-not-allowed
                  "
                >
                  {loading ? "Loadingâ€¦" : "Get profile"}
                </button>
              </form>

              {error && (
                <p className="mt-4 text-sm text-orange-700 bg-orange-50 border border-orange-200 rounded-md px-3 py-2 font-body">
                  {error}
                </p>
              )}
            </section>

            {/* Client profile + raw sources */}
            <section className="grid grid-cols-1 lg:grid-cols-3 gap-6">
              <div className="lg:col-span-2">
                <div className="bg-white rounded-halo shadow-sm border border-gray-200 p-6 h-full">
                  <h3 className="font-heading text-lg text-gray-800 mb-4">
                    Client profile
                  </h3>

                  {!profile && !loading && (
                    <p className="text-sm font-body text-gray-500">
                      Enter a Client ID and click{" "}
                      <span className="font-semibold">Get profile</span> to see
                      the assembled Single Client View.
                    </p>
                  )}

                  {loading && (
                    <p className="text-sm font-body text-gray-500">
                      Loadingâ€¦
                    </p>
                  )}

                  {profile && (
                    <div className="space-y-4">
                      <div className="bg-gray-50 rounded-lg p-4 border border-gray-200">
                        <h4 className="font-heading text-sm text-gray-700 mb-2">
                          Basic details
                        </h4>

                        <dl className="grid grid-cols-2 gap-y-2 text-sm font-body">
                          <div>
                            <dt className="text-gray-500">Client ID</dt>
                            <dd className="text-gray-900">
                              {profile.client_id || "â€”"}
                            </dd>
                          </div>

                          <div>
                            <dt className="text-gray-500">Name</dt>
                            <dd className="text-gray-900">
                              {profile.name || "â€”"}
                            </dd>
                          </div>

                          <div>
                            <dt className="text-gray-500">Email</dt>
                            <dd className="text-gray-900">
                              {profile.email || "â€”"}
                            </dd>
                          </div>

                          <div>
                            <dt className="text-gray-500">Country</dt>
                            <dd className="text-gray-900">
                              {profile.country || "â€”"}
                            </dd>
                          </div>
                        </dl>
                      </div>

                      {profile.addresses?.length > 0 && (
                        <div className="bg-gray-50 rounded-lg p-4 border border-gray-200">
                          <h4 className="font-heading text-sm text-gray-700 mb-2">
                            Addresses
                          </h4>

                          <ul className="space-y-2 text-sm font-body">
                            {profile.addresses.map((addr, idx) => (
                              <li
                                key={idx}
                                className="border-b border-gray-200 pb-2 last:border-none"
                              >
                                <div className="text-gray-900">
                                  {[
                                    addr.line1,
                                    addr.line2,
                                    addr.city,
                                    addr.postcode,
                                    addr.country,
                                  ]
                                    .filter(Boolean)
                                    .join(", ")}
                                </div>

                                <div className="text-xs text-gray-500 mt-1">
                                  Source: {addr.source || "â€”"}
                                </div>
                              </li>
                            ))}
                          </ul>
                        </div>
                      )}
                    </div>
                  )}
                </div>
              </div>

              <div>
                <div className="bg-white rounded-halo shadow-sm border border-gray-200 p-6 h-full">
                  <h3 className="font-heading text-lg text-gray-800 mb-4">
                    Raw sources
                  </h3>

                  {!profile && !loading && (
                    <p className="text-sm font-body text-gray-500">
                      Once a profile is loaded, youâ€™ll see the upstream records
                      here.
                    </p>
                  )}

                  {sources.length > 0 && (
                    <div className="space-y-3 text-xs font-mono bg-gray-50 rounded-lg p-3 border border-gray-200 max-h-[400px] overflow-auto">
                      {sources.map((src) => (
                        <div
                          key={src.id}
                          className="bg-white border border-gray-200 rounded-md p-2"
                        >
                          <div className="flex justify-between items-center mb-1">
                            <span className="font-body text-xs text-gray-600">
                              {src.system}
                            </span>
                            <span className="font-body text-[10px] text-gray-400">
                              client_id: {src.client_id}
                            </span>
                          </div>

                          <pre className="whitespace-pre-wrap text-[11px] text-gray-800">
                            {JSON.stringify(src.payload, null, 2)}
                          </pre>
                        </div>
                      ))}
                    </div>
                  )}

                  {profile?.lineage && (
                    <>
                      <h4 className="font-heading text-sm text-gray-700 mt-4 mb-2">
                        Lineage
                      </h4>
                      <div className="bg-gray-50 rounded-lg p-3 border border-gray-200 text-xs font-body max-h-[200px] overflow-auto">
                        <pre className="whitespace-pre-wrap text-[11px] text-gray-800">
                          {JSON.stringify(profile.lineage, null, 2)}
                        </pre>
                      </div>
                    </>
                  )}
                </div>
              </div>
            </section>
          </>
        )}
      </main>
    </div>
  );
}

export default App;


===== FILE: app_frontend\tailwind.config.js =====
/** @type {import('tailwindcss').Config} */
export default {
  content: ["./index.html", "./src/**/*.{js,jsx,ts,tsx}"],
  theme: {
    extend: {
      fontFamily: {
        heading: ["Raleway", "system-ui", "sans-serif"],
        body: ["Lato", "system-ui", "sans-serif"],
      },
      colors: {
        halo: {
          primary: "rgb(26,153,136)",     // #1A9988
          secondary: "rgb(235,86,0)",     // #EB5600
          softGreen: "rgb(176,192,159)",  // #B0C09F
          softYellow: "rgb(241,205,86)",  // #F1CD56
          softBlue: "rgb(205,226,235)",   // #CDE2EB
        },
      },
      borderRadius: {
        halo: "16px",
      },
    },
  },
  plugins: [],
};



===== FILE: app_frontend\vite.config.js =====
import { defineConfig } from 'vite'
import react from '@vitejs/plugin-react'

// https://vite.dev/config/
export default defineConfig({
  plugins: [react()],
})


===== FILE: backend_v2\.env =====
ENV=local
DATABASE_URL=postgresql+psycopg://postgres:Londonirish-01@localhost:5432/scv




===== FILE: backend_v2\.env.example =====
# Copy this file to `.env` and adjust as needed.

ENV=local
# Local Postgres instance (Docker, native, or cloud)
DATABASE_URL=postgresql+psycopg://postgres:postgres@localhost:5432/scv


===== FILE: backend_v2\app\__init__.py =====
# backend_v2 app package


===== FILE: backend_v2\app\atlas\routes.py =====
from fastapi import APIRouter, HTTPException
import json
import requests
from pathlib import Path
from datetime import datetime, timezone  # <-- ONLY new import

router = APIRouter(prefix="/atlas", tags=["MissionAtlas"])


@router.get("/lineage/client/{client_id}/concept/{concept_id}")
def get_lineage_with_value(client_id: int, concept_id: str):
    # 1. Load lineage artefact (repo-root anchored path)
    BASE_DIR = Path(__file__).resolve().parents[3]  # scv-repo root
    artefact_path = (
        BASE_DIR
        / "evidence"
        / "lineage"
        / f"client_{client_id}__{concept_id}.json"
    )

    try:
        with open(artefact_path, "r") as f:
            artefact = json.load(f)
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="Lineage artefact not found")

    # 2. Resolve live value
    value_ref = artefact["value_reference"]
    endpoint = value_ref["endpoint"]
    json_path = value_ref["json_path"]

    try:
        response = requests.get(f"http://127.0.0.1:8000{endpoint}")
        response.raise_for_status()
        payload = response.json()
    except Exception as e:
        return {
            "artifact": artefact,
            "resolved_value": None,
            "resolution": {
                "status": "error",
                "details": str(e),
                "evaluated_at": datetime.now(timezone.utc).isoformat(),
            },
        }

    # 3. Extract value (handles dict or list payload)
    field_name = json_path.replace("$.", "")

    resolved_value = None
    if isinstance(payload, dict):
        resolved_value = payload.get(field_name)
    elif isinstance(payload, list):
        record = next(
            (x for x in payload if isinstance(x, dict) and x.get("id") == client_id),
            None,
        )
        if record:
            resolved_value = record.get(field_name)

    return {
        "artifact": artefact,
        "resolved_value": resolved_value,
        "resolution": {
            "status": "ok" if resolved_value is not None else "not_found",
            "details": f"Resolved from {endpoint} at {json_path}",
            "evaluated_at": datetime.now(timezone.utc).isoformat(),
        },
    }





===== FILE: backend_v2\app\atlas\service.py =====


===== FILE: backend_v2\app\config.py =====
from pydantic_settings import BaseSettings



class Settings(BaseSettings):
    ENV: str = "local"  # local | dev | prod
    # Default to a local Postgres instance; override via .env in real use.
    DATABASE_URL: str = "postgresql+psycopg://postgres:postgres@localhost:5432/scv"

    class Config:
        env_file = ".env"


settings = Settings()


===== FILE: backend_v2\app\db.py =====
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, declarative_base
from app.config import settings


engine = create_engine(
    settings.DATABASE_URL,
    pool_pre_ping=True,
)

SessionLocal = sessionmaker(bind=engine, autoflush=False, autocommit=False)
Base = declarative_base()


def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


===== FILE: backend_v2\app\main.py =====
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from pathlib import Path

from app.routers.client_router import router as client_router
from app.routers.ingestion_router import router as ingestion_router
from app.routers.missioncontrol_runner import router as missioncontrol_router
from app.atlas.routes import router as atlas_router  # <-- ADDED


app = FastAPI(
    title="M7 Single Client View API",
    version="0.1.0",
)

# CORS (unchanged)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Routers (unchanged)
app.include_router(client_router)
app.include_router(ingestion_router)
app.include_router(missioncontrol_router)
app.include_router(atlas_router)  # <-- ADDED


# -------------------------------------------------------------------
# Static MissionLog mount (REQUIRED FOR DEMO CAPABILITIES)
# -------------------------------------------------------------------
REPO_ROOT = Path(__file__).resolve().parents[2]
MISSIONLOG_DIR = REPO_ROOT / "app_frontend" / "public" / "missionlog"

app.mount(
    "/missionlog",
    StaticFiles(directory=str(MISSIONLOG_DIR)),
    name="missionlog",
)

# Health check (unchanged)
@app.get("/health")
def health():
    return {"status": "ok"}



===== FILE: backend_v2\app\models\__init__.py =====
from app.db import Base
from app.models.client import Client
from app.models.account import Account
from app.models.transaction import Transaction
from app.models.kyc_flag import KycFlag
from app.models.crm_contact import CRMContact

__all__ = ["Client", "Account", "Transaction", "KycFlag", "Base"]


===== FILE: backend_v2\app\models\account.py =====
from sqlalchemy import Column, Integer, String, ForeignKey
from sqlalchemy.orm import relationship
from app.db import Base


class Account(Base):
    __tablename__ = "accounts"

    id = Column(Integer, primary_key=True, index=True)
    client_id = Column(Integer, ForeignKey("clients.id"), index=True, nullable=False)
    account_number = Column(String, unique=True, index=True, nullable=False)
    account_type = Column(String, nullable=True)   # e.g. CASH, SECURITIES, MARGIN
    currency = Column(String, nullable=False, default="GBP")
    status = Column(String, nullable=False, default="OPEN")  # OPEN, CLOSED
    opened_at = Column(String, nullable=True)
    closed_at = Column(String, nullable=True)

    client = relationship("Client", backref="accounts")


===== FILE: backend_v2\app\models\client.py =====
from sqlalchemy import Column, Integer, String
from app.db import Base


class Client(Base):
    __tablename__ = "clients"

    id = Column(Integer, primary_key=True, index=True)
    external_id = Column(String, unique=True, index=True, nullable=True)
    full_name = Column(String, nullable=False)
    email = Column(String, nullable=True)
    phone = Column(String, nullable=True)
    primary_address = Column(String, nullable=True)
    country = Column(String, nullable=True)
    tax_id = Column(String, nullable=True)
    segment = Column(String, nullable=True)
    risk_rating = Column(String, nullable=True)


===== FILE: backend_v2\app\models\crm_contact.py =====
from __future__ import annotations

import uuid
from sqlalchemy import Column, DateTime, String, UniqueConstraint, func
from sqlalchemy.dialects.postgresql import UUID

from app.db import Base


class CRMContact(Base):
    """
    ST-05 owned persistence table for CRM bulk ingestion.

    Idempotency is enforced via UNIQUE(source_system, source_record_id).
    """
    __tablename__ = "crm_contacts"

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)

    source_system = Column(String, nullable=False)
    source_record_id = Column(String, nullable=False)

    first_name = Column(String, nullable=True)
    last_name = Column(String, nullable=True)
    email = Column(String, nullable=True)

    created_at = Column(DateTime(timezone=True), nullable=False, server_default=func.now())
    updated_at = Column(
        DateTime(timezone=True),
        nullable=False,
        server_default=func.now(),
        onupdate=func.now(),
    )

    __table_args__ = (
        UniqueConstraint("source_system", "source_record_id", name="uq_crm_contacts_source_key"),
    )


===== FILE: backend_v2\app\models\kyc_flag.py =====
from sqlalchemy import Column, Integer, String, ForeignKey
from sqlalchemy.orm import relationship
from app.db import Base


class KycFlag(Base):
    __tablename__ = "kyc_flags"

    id = Column(Integer, primary_key=True, index=True)
    client_id = Column(Integer, ForeignKey("clients.id"), index=True, nullable=False)
    code = Column(String, nullable=False)         # e.g. PEP, SANCTIONS, HIGH_RISK
    description = Column(String, nullable=True)
    status = Column(String, nullable=False, default="OPEN")  # OPEN, CLOSED
    created_at = Column(String, nullable=True)
    resolved_at = Column(String, nullable=True)

    client = relationship("Client", backref="kyc_flags")


===== FILE: backend_v2\app\models\transaction.py =====
from sqlalchemy import Column, Integer, String, Date, Float
from app.db import Base


class Transaction(Base):
    __tablename__ = "transactions"

    id = Column(Integer, primary_key=True, index=True)

    account_id = Column(Integer, nullable=False)

    trade_date = Column(Date, nullable=True)
    value_date = Column(Date, nullable=True)

    amount = Column(Float, nullable=True)
    currency = Column(String, nullable=True)

    txn_type = Column(String, nullable=True)
    description = Column(String, nullable=True)

    # --- Added to match DB schema ---
    price = Column(Float, nullable=True)
    pnl = Column(Float, nullable=True)


===== FILE: backend_v2\app\repositories\__init__.py =====
# repository package


===== FILE: backend_v2\app\repositories\account_repository.py =====
from sqlalchemy.orm import Session
from app.models.account import Account
from app.schemas.account import AccountCreate


class AccountRepository:

    @staticmethod
    def create(db: Session, data: AccountCreate) -> Account:
        acc = Account(**data.model_dump())
        db.add(acc)
        db.commit()
        db.refresh(acc)
        return acc

    @staticmethod
    def get(db: Session, account_id: int) -> Account | None:
        return db.query(Account).filter(Account.id == account_id).first()

    @staticmethod
    def list_by_client(db: Session, client_id: int) -> list[Account]:
        return db.query(Account).filter(Account.client_id == client_id).all()


===== FILE: backend_v2\app\repositories\client_repository.py =====
from sqlalchemy.orm import Session
from app.models.client import Client
from app.schemas.client import ClientCreate


class ClientRepository:

    @staticmethod
    def create(db: Session, data: ClientCreate) -> Client:
        client = Client(**data.model_dump())
        db.add(client)
        db.commit()
        db.refresh(client)
        return client

    @staticmethod
    def get(db: Session, client_id: int) -> Client | None:
        return db.query(Client).filter(Client.id == client_id).first()

    @staticmethod
    def list(db: Session) -> list[Client]:
        return db.query(Client).all()


===== FILE: backend_v2\app\repositories\crm_contact_repository.py =====
from __future__ import annotations

from typing import Optional, Tuple

from sqlalchemy.dialects.postgresql import insert
from sqlalchemy.orm import Session
from sqlalchemy import func

from app.models.crm_contact import CRMContact


class CRMContactRepository:
    @staticmethod
    def upsert(
        db: Session,
        *,
        source_system: str,
        source_record_id: str,
        first_name: Optional[str],
        last_name: Optional[str],
        email: Optional[str],
    ) -> Tuple[str, CRMContact]:
        """
        Idempotent upsert:
        - Inserts when (source_system, source_record_id) is new
        - Updates mutable fields when it already exists

        Returns: ("inserted" | "updated", row)
        """
        stmt = insert(CRMContact).values(
            source_system=source_system,
            source_record_id=source_record_id,
            first_name=first_name,
            last_name=last_name,
            email=email,
        )

        # Update on conflict
        update_cols = {
            "first_name": first_name,
            "last_name": last_name,
            "email": email,
            "updated_at": func.now(),
        }

        stmt = stmt.on_conflict_do_update(
            index_elements=[CRMContact.source_system, CRMContact.source_record_id],
            set_=update_cols,
        ).returning(CRMContact)

        row = db.execute(stmt).scalar_one()

        # Determine inserted vs updated in a Postgres-friendly way:
        # If created_at == updated_at (fresh insert), treat as inserted.
        # If updated_at moved, treat as updated.
        # Note: created_at/updated_at are server-side; refresh to ensure values.
        db.flush()
        db.refresh(row)

        status = "inserted" if row.created_at == row.updated_at else "updated"
        return status, row


===== FILE: backend_v2\app\repositories\kyc_flag_repository.py =====
from sqlalchemy.orm import Session
from app.models.kyc_flag import KycFlag
from app.schemas.kyc_flag import KycFlagCreate


class KycFlagRepository:

    @staticmethod
    def create(db: Session, data: KycFlagCreate) -> KycFlag:
        flag = KycFlag(**data.model_dump())
        db.add(flag)
        db.commit()
        db.refresh(flag)
        return flag

    @staticmethod
    def list_by_client(db: Session, client_id: int) -> list[KycFlag]:
        return db.query(KycFlag).filter(KycFlag.client_id == client_id).all()


===== FILE: backend_v2\app\repositories\transaction_repository.py =====
from sqlalchemy.orm import Session
from app.models.transaction import Transaction
from app.schemas.transaction import TransactionCreate


class TransactionRepository:

    @staticmethod
    def create(db: Session, data: TransactionCreate) -> Transaction:
        txn = Transaction(**data.model_dump())
        db.add(txn)
        db.commit()
        db.refresh(txn)
        return txn

    @staticmethod
    def list_by_account(db: Session, account_id: int) -> list[Transaction]:
        return db.query(Transaction).filter(Transaction.account_id == account_id).all()


===== FILE: backend_v2\app\routers\__init__.py =====
# routers package


===== FILE: backend_v2\app\routers\account_router.py =====
from fastapi import APIRouter, Depends
from sqlalchemy.orm import Session

from app.db import get_db
from app.schemas.account import AccountCreate, AccountRead
from app.services.account_service import AccountService
from app.services.transaction_service import TransactionService
from app.schemas.transaction import TransactionRead


router = APIRouter(prefix="/accounts", tags=["accounts"])


@router.post("/", response_model=AccountRead)
def create_account(data: AccountCreate, db: Session = Depends(get_db)):
    return AccountService.create(db, data)


@router.get("/{account_id}", response_model=AccountRead | None)
def get_account(account_id: int, db: Session = Depends(get_db)):
    return AccountService.get(db, account_id)


@router.get("/{account_id}/transactions", response_model=list[TransactionRead])
def get_account_transactions(account_id: int, db: Session = Depends(get_db)):
    return TransactionService.list_by_account(db, account_id)


===== FILE: backend_v2\app\routers\client_router.py =====
from fastapi import APIRouter, Depends, HTTPException
from fastapi.encoders import jsonable_encoder
from sqlalchemy.orm import Session
from datetime import date  # <-- ADDED (minimal)

from app.db import get_db
from app.schemas.client import ClientCreate, ClientRead
from app.schemas.account import AccountRead
from app.schemas.kyc_flag import KycFlagRead
from app.schemas.scv_profile import SCVClientProfileResponse  # <-- ADDED (only import)
from app.services.client_service import ClientService
from app.services.account_service import AccountService
from app.services.kyc_flag_service import KycFlagService
from app.services.transaction_service import TransactionService
from app.services.match_decision_service import MatchDecisionService
from app.services.regulatory_enrichment_service import RegulatoryEnrichmentService
from app.services.evidence_artefact_service import EvidenceArtefactService
from app.services.audit_trail_service import AuditTrailService




router = APIRouter(prefix="/clients", tags=["clients"])


def _date_to_iso(value):  # <-- ADDED (minimal helper)
    if value is None:
        return None
    if isinstance(value, date):
        return value.isoformat()
    if isinstance(value, str):
        try:
            return date.fromisoformat(value).isoformat()
        except ValueError:
            return value
    return str(value)


# -----------------------------
# Basic CRUD / helper endpoints
# -----------------------------
@router.post("/", response_model=ClientRead)
def create_client(data: ClientCreate, db: Session = Depends(get_db)):
    return ClientService.create(db, data)


@router.get("/", response_model=list[ClientRead])
def list_clients(db: Session = Depends(get_db)):
    return ClientService.list(db)


@router.get("/{client_id}", response_model=ClientRead | None)
def get_client(client_id: int, db: Session = Depends(get_db)):
    return ClientService.get(db, client_id)


@router.get("/{client_id}/accounts", response_model=list[AccountRead])
def get_client_accounts(client_id: int, db: Session = Depends(get_db)):
    return AccountService.list_by_client(db, client_id)


@router.get("/{client_id}/kyc_flags", response_model=list[KycFlagRead])
def get_client_kyc_flags(client_id: int, db: Session = Depends(get_db)):
    return KycFlagService.list_by_client(db, client_id)


# ----------------------------------------
# Canonical SCV Profile endpoint for the UI
# ----------------------------------------
# The existing frontend expects a single profile payload at:
#   GET /clients/{client_id}/profile
#
# In the current SCV frontend, the Detailed Client Profile uses a canonical
# "profile" response with embedded panels. Historically, the frontend called
# separate endpoints per panel, but we now keep this contract stable while
# backed by the new Postgres models.
#
# Canonical contract requirement (SCV_CANONICAL_STATE.md):
# Must return keys (present even if empty):
#   client, accounts, match_decisions, trade_history, audit_trail,
#   regulatory_enrichment, evidence_artefacts


@router.get(
    "/{client_id}/profile",
    response_model=SCVClientProfileResponse  # <-- ADDED (only decorator change)
)
def get_client_profile_for_ui(client_id: int, db: Session = Depends(get_db)):
    """
    Canonical SCV profile endpoint.

    Non-negotiables:
    - backend_v2 is canonical runtime
    - ONE canonical endpoint: GET /clients/{id}/profile
    - Must return keys (present even if empty):
        client, accounts, match_decisions, trade_history, audit_trail,
        regulatory_enrichment, evidence_artefacts

    Story 1 focus:
    - trade_history must show REAL data (sourced from transactions table)
    """
    client = ClientService.get(db, client_id)
    if not client:
        raise HTTPException(status_code=404, detail="Client not found")

    accounts = AccountService.list_by_client(db, client_id)
    account_ids = [a.id for a in accounts]

    # Pull real transactions and flatten into trade_history
    trade_history: list[dict] = []
    for acc_id in account_ids:
        txns = TransactionService.list_by_account(db, acc_id)
        for t in txns:
            td = t.trade_date
            # UI expects strings in some places; keep simple
            trade_history.append(
                {
                    "trade_id": str(t.id),
                    "account_id": str(t.account_id),
                    "trade_date": _date_to_iso(td),  # <-- CHANGED (only functional change)
                    "instrument": None,
                    "direction": t.txn_type,
                    "quantity": abs(t.amount) if t.amount is not None else None,

                    # ONLY CHANGE (pass through real values from transactions table)
                    "price": t.price,
                    "pnl": t.pnl,

                    "amount": t.amount,
                    "currency": t.currency,
                    "txn_type": t.txn_type,
                    "description": t.description,
                }
            )

    match_decisions = MatchDecisionService.list_by_client(db, client_id)

    regulatory_enrichment = RegulatoryEnrichmentService.get_latest_by_client(db, client_id)

    evidence_artefacts = EvidenceArtefactService.list_by_client(db, client_id)

    audit_trail = AuditTrailService.list_by_client(db, client_id)

    # Canonical keys (always present)
    client_payload = jsonable_encoder(client)
    accounts_payload = jsonable_encoder(accounts)

    # Also keep legacy top-level fields that the existing UI header reads
    profile = {
        "client_id": str(client["client_id"]),
        "name": client.get("name"),
        "email": client.get("email"),
        "phone": None,
        "country": client.get("country"),
        "segment": None,
        "risk_rating": None,
        "addresses": [],
        "operational_state": {
            "status": "ACTIVE",
            "as_of": None,
            "processing_stage": "PROFILE_COMPOSED",
            "message": "Composed via backend_v2 /clients/{id}/profile",
            "details": {},
        },
        "client": client_payload,
        "accounts": accounts_payload,
        "match_decisions": match_decisions,
        "trade_history": trade_history,
        "audit_trail": audit_trail,
        "regulatory_enrichment": jsonable_encoder(regulatory_enrichment),
        "evidence_artefacts": evidence_artefacts,
    }

    # Map the primary_address into a single address entry if present
    if client.get("primary_address"):
        profile["addresses"].append(
            {
                "line1": client.get("primary_address"),
                "line2": None,
                "city": None,
                "postcode": None,
                "country": client.get("country"),
                "source": "SCV_DB",
            }
        )

    return profile


@router.get("/{client_id}/sources")
def get_client_sources_for_ui(client_id: int, db: Session = Depends(get_db)):
    """
    Return a synthetic 'raw sources' array so the existing UI can render
    something in the Raw sources panel.

    This is intentionally a placeholder until ingestion/source-record tables
    are implemented. It is safe and non-invasive.
    """
    client = ClientService.get(db, client_id)
    if not client:
        raise HTTPException(status_code=404, detail="Client not found")

    # Minimal source records derived from the canonical client row
    sources = [
        {
            "source_system": "SCV_DB",
            "source_record_id": f"client:{client.get('client_id')}",
            "fields": {
                "name": client.get("name"),
                "email": client.get("email"),
                "phone": None,
                "country": client.get("country"),
                "segment": None,
                "risk_rating": None,
                "primary_address": None,
            },
        }
    ]

    return [
    {
        "id": s["source_record_id"],
        "system": s["source_system"],
        "client_id": str(client.get("client_id")),
        "payload": s["fields"],
    }
    for s in sources
]














===== FILE: backend_v2\app\routers\ingestion_router.py =====
from __future__ import annotations

import json
import os
from pathlib import Path

from fastapi import APIRouter, Depends, HTTPException, Query
from sqlalchemy import text
from sqlalchemy.orm import Session

from app.db import get_db
from app.services.crm_bulk_load_service import (
    BulkCrmIngestionService,
    FileCrmSource,
)

router = APIRouter(prefix="/ingestion", tags=["ingestion"])

# Resolve paths relative to this file, not the process working directory
BASE_DIR = Path(__file__).resolve().parents[1]


def _demo_enabled() -> bool:
    """
    Demo ingestion is enabled if either:
      1) SCV_DEMO_INGESTION_ENABLED=true (explicit env flag), OR
      2) app_frontend/public/missionlog/demo_capabilities.json contains:
            { "demo_ingestion_enabled": true }

    This supports the demo flow where MissionControl can "unlock" ingestion
    by writing the capability file.
    """
    # 1) Backwards-compatible env toggle
    if os.getenv("SCV_DEMO_INGESTION_ENABLED", "false").lower() == "true":
        return True

    # 2) Capability file toggle (MissionControl can flip this during the demo)
    cap_path = (
        BASE_DIR.parents[1]
        / "app_frontend"
        / "public"
        / "missionlog"
        / "demo_capabilities.json"
    )
    try:
        if cap_path.exists():
            data = json.loads(cap_path.read_text(encoding="utf-8") or "{}")
            return bool(data.get("demo_ingestion_enabled") is True)
    except Exception:
        # Fail closed: if file is malformed/unreadable, keep ingestion disabled
        return False

    return False


@router.post("/crm/bulk")
def bulk_load_crm(db: Session = Depends(get_db)):
    """
    ST-05 demo-first endpoint (original sample fixture).

    Loads crm_sample.csv â€“ DO NOT CHANGE.
    """
    if not _demo_enabled():
        raise HTTPException(status_code=403, detail="Demo ingestion disabled")

    fixture_path = BASE_DIR / "fixtures" / "st05" / "crm_sample.csv"
    if not fixture_path.exists():
        raise HTTPException(status_code=500, detail=f"Fixture not found: {fixture_path}")

    result = BulkCrmIngestionService.ingest(db, FileCrmSource(fixture_path))
    return {
        "total": result.total,
        "inserted": result.inserted,
        "updated": result.updated,
        "skipped": result.skipped,
    }


@router.post("/crm/bulk_demo_corporate")
def bulk_load_crm_demo_corporate(db: Session = Depends(get_db)):
    """
    Demo-only endpoint that loads corporate-style CRM records.
    """
    if not _demo_enabled():
        raise HTTPException(status_code=403, detail="Demo ingestion disabled")

    fixture_path = BASE_DIR / "fixtures" / "st05" / "crm_demo_corporate.csv"
    if not fixture_path.exists():
        raise HTTPException(status_code=500, detail=f"Fixture not found: {fixture_path}")

    result = BulkCrmIngestionService.ingest(db, FileCrmSource(fixture_path))
    return {
        "fixture": "crm_demo_corporate.csv",
        "total": result.total,
        "inserted": result.inserted,
        "updated": result.updated,
        "skipped": result.skipped,
    }


@router.get("/crm/contacts")
def list_crm_contacts(
    db: Session = Depends(get_db),
    source_system: str | None = Query(default=None),
    limit: int = Query(default=200, ge=1, le=2000),
):
    """
    Demo utility: list ingested CRM contacts (for Pre-Matched Records UI).
    """
    if not _demo_enabled():
        raise HTTPException(status_code=403, detail="Demo ingestion disabled")

    if source_system:
        rows = (
            db.execute(
                text(
                    """
                    SELECT id, source_system, source_record_id, first_name, last_name, email, created_at, updated_at
                    FROM crm_contacts
                    WHERE source_system = :source_system
                    ORDER BY created_at DESC
                    LIMIT :limit
                    """
                ),
                {"source_system": source_system, "limit": limit},
            )
            .mappings()
            .all()
        )
    else:
        rows = (
            db.execute(
                text(
                    """
                    SELECT id, source_system, source_record_id, first_name, last_name, email, created_at, updated_at
                    FROM crm_contacts
                    ORDER BY created_at DESC
                    LIMIT :limit
                    """
                ),
                {"limit": limit},
            )
            .mappings()
            .all()
        )

    return {"records": [dict(r) for r in rows]}


@router.get("/crm/contacts/count")
def crm_contacts_count(db: Session = Depends(get_db)):
    """
    Demo utility: confirm how many CRM ingestion records exist.
    """
    if not _demo_enabled():
        raise HTTPException(status_code=403, detail="Demo ingestion disabled")

    count = int(db.execute(text("SELECT COUNT(*) FROM crm_contacts")).scalar_one())
    return {"count": count}


@router.delete("/crm/contacts")
def delete_crm_contacts(
    db: Session = Depends(get_db),
    source_system: str | None = Query(default=None),
):
    """
    Demo utility: delete ingested CRM contacts.

    - If source_system is provided, deletes only those rows
    - If omitted, deletes all rows
    """
    if not _demo_enabled():
        raise HTTPException(status_code=403, detail="Demo ingestion disabled")

    if source_system:
        res = db.execute(
            text("DELETE FROM crm_contacts WHERE source_system = :source_system"),
            {"source_system": source_system},
        )
    else:
        res = db.execute(text("DELETE FROM crm_contacts"))

    db.commit()
    return {
        "deleted": int(res.rowcount or 0),
        "scope": {"source_system": source_system},
    }







===== FILE: backend_v2\app\routers\kyc_flag_router.py =====
from fastapi import APIRouter, Depends
from sqlalchemy.orm import Session

from app.db import get_db
from app.schemas.kyc_flag import KycFlagCreate, KycFlagRead
from app.services.kyc_flag_service import KycFlagService


router = APIRouter(prefix="/kyc-flags", tags=["kyc_flags"])


@router.post("/", response_model=KycFlagRead)
def create_kyc_flag(data: KycFlagCreate, db: Session = Depends(get_db)):
    return KycFlagService.create(db, data)


===== FILE: backend_v2\app\routers\missioncontrol_runner.py =====
from __future__ import annotations

import os
import sys
import time
import uuid
import threading
import subprocess
from dataclasses import dataclass, asdict
from typing import Dict, Optional
import json

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel

router = APIRouter(prefix="/missioncontrol", tags=["missioncontrol"])

# In-memory run registry (local-first demo only)
_RUNS: Dict[str, "RunState"] = {}
_LOCK = threading.Lock()


@dataclass
class RunState:
    run_id: str
    story_id: str
    state: str  # "queued"|"running"|"completed"|"failed"
    stage: str  # "coding_testing"|"halo"|"guardrails"|"quality"|"security"|"finalising"
    message: str
    started_at_utc: str
    finished_at_utc: Optional[str] = None
    error: Optional[str] = None


class StartRunRequest(BaseModel):
    story_id: str


def _utc_iso() -> str:
    return time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())


def _repo_root() -> str:
    here = os.path.abspath(os.path.dirname(__file__))
    return os.path.abspath(os.path.join(here, "..", "..", ".."))


def _run_cmd(cmd: list[str], cwd: str) -> None:
    proc = subprocess.run(
        [sys.executable] + cmd,
        cwd=cwd,
        capture_output=True,
        text=True,
    )
    if proc.returncode != 0:
        raise RuntimeError(
            f"Command failed: {cmd}\nSTDOUT:\n{proc.stdout}\nSTDERR:\n{proc.stderr}"
        )


def _publish_missionlog_public_assets(story: str, cwd: str) -> None:
    _run_cmd(["tools/extract_MissionLog_evidence.py", "--story", story], cwd=cwd)
    _run_cmd(["tools/status_snapshot.py"], cwd=cwd)


def _set_run(run_id: str, **kwargs) -> None:
    with _LOCK:
        rs = _RUNS.get(run_id)
        if not rs:
            return
        for k, v in kwargs.items():
            setattr(rs, k, v)


def _set_halo_pass_with_explanation(story: str, cwd: str) -> None:
    """
    Demo-only Halo workaround.
    Explicitly mark Halo adherence as pass and publish explanatory evidence.
    """
    halo_dir = os.path.join(
        cwd, "app_frontend", "public", "missionlog", "evidence", story
    )
    os.makedirs(halo_dir, exist_ok=True)

    halo_path = os.path.join(halo_dir, "halo.json")
    with open(halo_path, "w", encoding="utf-8") as f:
        f.write(
            '{\n'
            f'  "story_id": "{story}",\n'
            '  "passed": true,\n'
            '  "message": "Halo adherence by agentic design. '
            'Adherence validation check to be added."\n'
            '}\n'
        )

    _run_cmd(
        [
            "tools/update_story_field.py",
            "--story", story,
            "--field", "halo_adherence",
            "--value", "pass",
        ],
        cwd=cwd,
    )


def _enable_demo_ingestion_flag(cwd: str) -> None:
    """
    Enable demo ingestion flag after successful ST-05 completion.
    """
    flag_path = os.path.join(
        cwd, "app_frontend", "public", "demo_ingestion_enabled.json"
    )
    with open(flag_path, "w", encoding="utf-8") as f:
        json.dump({"enabled": True}, f, indent=2)


def _execute_run(run_id: str) -> None:
    with _LOCK:
        rs = _RUNS.get(run_id)
    if not rs:
        return

    root = _repo_root()
    story = rs.story_id

    try:
        _set_run(run_id,
            state="running",
            stage="coding_testing",
            message="Step 1 of 6 - Generating Application Code and Running Automated Tests"
        )
        time.sleep(0.8)
        _run_cmd(["tools/run_story_tests.py", story], cwd=root)
        _publish_missionlog_public_assets(story, cwd=root)
        time.sleep(0.6)

        _set_run(run_id,
            stage="halo",
            message="Step 2 of 6 - Ensuring User Experience Standards"
        )
        time.sleep(0.8)
        _set_halo_pass_with_explanation(story, cwd=root)
        _publish_missionlog_public_assets(story, cwd=root)
        time.sleep(0.6)

        _set_run(run_id,
            stage="guardrails",
            message="Step 3 of 6 - Checking Architecure and Data Guardrails"
        )
        time.sleep(0.8)
        _run_cmd(["tools/run_story_guardrails.py", story], cwd=root)
        _publish_missionlog_public_assets(story, cwd=root)
        time.sleep(0.6)

        _set_run(run_id,
            stage="quality",
            message="Step 4 of 6 - Checking Code Style and Quality Standards"
        )
        time.sleep(0.8)
        _run_cmd(["tools/run_story_lint.py", story], cwd=root)
        _publish_missionlog_public_assets(story, cwd=root)
        time.sleep(0.6)

        _set_run(run_id,
            stage="security",
            message="Step 5 of 6 - Running Automated Security Checks"
        )
        time.sleep(0.8)
        _run_cmd(["tools/run_story_security.py", story], cwd=root)
        _publish_missionlog_public_assets(story, cwd=root)
        time.sleep(0.6)

        _set_run(run_id,
            stage="finalising",
            message="Step 6 of 6 - Saving Results and Execution Evidence"
        )
        time.sleep(0.6)
        _run_cmd(["tools/update_story_overall_status.py", story], cwd=root)
        _run_cmd(["tools/rollup_statuses.py"], cwd=root)
        _publish_missionlog_public_assets(story, cwd=root)

        # >>> ONLY NEW BEHAVIOUR: enable demo ingestion flag
        _enable_demo_ingestion_flag(root)

        _set_run(run_id,
            state="completed",
            message="All Steps Completed Successfully",
            finished_at_utc=_utc_iso()
        )

    except Exception as e:
        _set_run(run_id,
            state="failed",
            message="Failed",
            error=str(e),
            finished_at_utc=_utc_iso()
        )


@router.post("/runs")
def start_run(req: StartRunRequest):
    if req.story_id != "ST-05":
        raise HTTPException(status_code=400, detail="Only ST-05 is runnable in MVP demo mode.")

    run_id = str(uuid.uuid4())
    rs = RunState(
        run_id=run_id,
        story_id=req.story_id,
        state="queued",
        stage="coding_testing",
        message="Queued",
        started_at_utc=_utc_iso()
    )
    with _LOCK:
        _RUNS[run_id] = rs

    t = threading.Thread(target=_execute_run, args=(run_id,), daemon=True)
    t.start()

    return {"run_id": run_id}


@router.get("/runs/{run_id}")
def get_run(run_id: str):
    with _LOCK:
        rs = _RUNS.get(run_id)
    if not rs:
        raise HTTPException(status_code=404, detail="Run not found.")
    return asdict(rs)





===== FILE: backend_v2\app\routers\scv_router.py =====
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session

from app.db import get_db
from app.services.client_service import ClientService
from app.services.account_service import AccountService
from app.services.transaction_service import TransactionService
from app.services.kyc_flag_service import KycFlagService


router = APIRouter(prefix="/scv", tags=["single_client_view"])


@router.get("/{client_id}")
def get_single_client_view(client_id: int, db: Session = Depends(get_db)):
    client = ClientService.get(db, client_id)
    if not client:
        raise HTTPException(status_code=404, detail="Client not found")

    accounts = AccountService.list_by_client(db, client_id)
    account_ids = [a.id for a in accounts]
    transactions_by_account = {
        acc_id: TransactionService.list_by_account(db, acc_id) for acc_id in account_ids
    }
    kyc_flags = KycFlagService.list_by_client(db, client_id)

    return {
        "client": client,
        "accounts": accounts,
        "transactions_by_account": transactions_by_account,
        "kyc_flags": kyc_flags,
    }


===== FILE: backend_v2\app\routers\transaction_router.py =====
from fastapi import APIRouter, Depends
from sqlalchemy.orm import Session

from app.db import get_db
from app.schemas.transaction import TransactionCreate, TransactionRead
from app.services.transaction_service import TransactionService


router = APIRouter(prefix="/transactions", tags=["transactions"])


@router.post("/", response_model=TransactionRead)
def create_transaction(data: TransactionCreate, db: Session = Depends(get_db)):
    return TransactionService.create(db, data)


===== FILE: backend_v2\app\schemas\__init__.py =====
from app.schemas.client import ClientCreate, ClientRead
from app.schemas.account import AccountCreate, AccountRead
from app.schemas.transaction import TransactionCreate, TransactionRead
from app.schemas.kyc_flag import KycFlagCreate, KycFlagRead

__all__ = [
    "ClientCreate", "ClientRead",
    "AccountCreate", "AccountRead",
    "TransactionCreate", "TransactionRead",
    "KycFlagCreate", "KycFlagRead",
]


===== FILE: backend_v2\app\schemas\account.py =====
from pydantic import BaseModel


class AccountBase(BaseModel):
    client_id: int
    account_number: str
    account_type: str | None = None
    currency: str = "GBP"
    status: str = "OPEN"
    opened_at: str | None = None
    closed_at: str | None = None


class AccountCreate(AccountBase):
    pass


class AccountRead(AccountBase):
    id: int

    class Config:
        from_attributes = True


===== FILE: backend_v2\app\schemas\client.py =====
from pydantic import BaseModel


class ClientBase(BaseModel):
    external_id: str | None = None
    full_name: str
    email: str | None = None
    phone: str | None = None
    primary_address: str | None = None
    country: str | None = None
    tax_id: str | None = None
    segment: str | None = None
    risk_rating: str | None = None


class ClientCreate(ClientBase):
    pass


class ClientRead(ClientBase):
    id: int

    class Config:
        from_attributes = True


===== FILE: backend_v2\app\schemas\kyc_flag.py =====
from pydantic import BaseModel


class KycFlagBase(BaseModel):
    client_id: int
    code: str
    description: str | None = None
    status: str = "OPEN"
    created_at: str | None = None
    resolved_at: str | None = None


class KycFlagCreate(KycFlagBase):
    pass


class KycFlagRead(KycFlagBase):
    id: int

    class Config:
        from_attributes = True


===== FILE: backend_v2\app\schemas\scv_profile.py =====
# backend_v2/app/schemas/scv_profile.py
"""
SCV Profile Contract (Baseline)

This file defines the *baseline* response contract for:
  GET /clients/{client_id}/profile

Principles:
- This is a contract boundary for the frontend.
- Top-level legacy fields MUST remain present (even if null).
- Canonical SCV keys MUST exist even when empty.

Note:
- We intentionally keep `client` and `accounts` as loosely-typed objects for now
  because the endpoint currently uses `jsonable_encoder(...)` on SQLAlchemy models.
  We can tighten types later without changing the UI contract.
"""

from __future__ import annotations

from typing import Any, Dict, List, Optional

from pydantic import BaseModel, Field, ConfigDict


class Address(BaseModel):
    model_config = ConfigDict(extra="allow")

    line1: Optional[str] = None
    line2: Optional[str] = None
    city: Optional[str] = None
    postcode: Optional[str] = None
    country: Optional[str] = None
    source: Optional[str] = None


class OperationalState(BaseModel):
    model_config = ConfigDict(extra="allow")

    status: Optional[str] = None
    as_of: Optional[str] = None
    processing_stage: Optional[str] = None
    message: Optional[str] = None
    details: Dict[str, Any] = Field(default_factory=dict)


class TradeHistoryRow(BaseModel):
    model_config = ConfigDict(extra="allow")

    trade_id: Optional[int] = None
    account_id: Optional[int] = None
    trade_date: Optional[str] = None
    value_date: Optional[str] = None
    asset_class: Optional[str] = None
    instrument: Optional[str] = None
    direction: Optional[str] = None
    quantity: Optional[float] = None
    price: Optional[float] = None
    pnl: Optional[float] = None

    # Raw/source fields (kept for expandable JSON / debugging)
    amount: Optional[float] = None
    currency: Optional[str] = None
    txn_type: Optional[str] = None
    description: Optional[str] = None


class SCVClientProfileResponse(BaseModel):
    """
    Baseline contract for the SCV profile endpoint.

    Contains:
    - Legacy/top-level fields used by the existing UI header
    - Canonical SCV keys required by SCV_CANONICAL_STATE.md
    """
    model_config = ConfigDict(extra="allow")

    # ---- legacy/top-level (do not remove) ----
    client_id: str
    name: Optional[str] = None
    email: Optional[str] = None
    phone: Optional[str] = None
    country: Optional[str] = None
    segment: Optional[str] = None
    risk_rating: Optional[str] = None
    addresses: List[Address] = Field(default_factory=list)
    operational_state: OperationalState = Field(default_factory=OperationalState)

    # ---- canonical SCV keys (must exist even if empty) ----
    client: Dict[str, Any] = Field(default_factory=dict)
    accounts: List[Dict[str, Any]] = Field(default_factory=list)
    match_decisions: List[Dict[str, Any]] = Field(default_factory=list)
    trade_history: List[TradeHistoryRow] = Field(default_factory=list)
    audit_trail: List[Dict[str, Any]] = Field(default_factory=list)
    regulatory_enrichment: Dict[str, Any] = Field(default_factory=dict)
    evidence_artefacts: List[Dict[str, Any]] = Field(default_factory=list)


===== FILE: backend_v2\app\schemas\transaction.py =====
from pydantic import BaseModel


class TransactionBase(BaseModel):
    account_id: int
    trade_date: str | None = None
    value_date: str | None = None
    amount: float
    currency: str = "GBP"
    txn_type: str
    description: str | None = None


class TransactionCreate(TransactionBase):
    pass


class TransactionRead(TransactionBase):
    id: int

    class Config:
        from_attributes = True


===== FILE: backend_v2\app\seed\__init__.py =====
# seed package


===== FILE: backend_v2\app\seed\seed_data.py =====
from sqlalchemy.orm import Session

from app.schemas.client import ClientCreate
from app.schemas.account import AccountCreate
from app.schemas.transaction import TransactionCreate
from app.schemas.kyc_flag import KycFlagCreate

from app.services.client_service import ClientService
from app.services.account_service import AccountService
from app.services.transaction_service import TransactionService
from app.services.kyc_flag_service import KycFlagService

from app.models.client import Client


def seed(db: Session) -> None:
    """
    Seed the database with a small institutional / corporate book.

    Note: this only runs if there are no clients in the database.
    """
    if db.query(Client).count() > 0:
        return

    # ---------- CLIENTS (CORPORATE) ----------

    acme = ClientService.create(
        db,
        ClientCreate(
            external_id="CRM-CORP-001",
            full_name="Acme Manufacturing Ltd",
            email="treasury@acme-mfg.co.uk",
            phone="+44 20 7000 1001",
            primary_address="10 Foundry Park, Birmingham, B1 2AB, United Kingdom",
            country="UK",
            tax_id="GB999000111",
            segment="Corporate â€“ Mid Cap",
            risk_rating="MEDIUM",
        ),
    )

    northbridge = ClientService.create(
        db,
        ClientCreate(
            external_id="CRM-FI-002",
            full_name="Northbridge Capital Markets LLP",
            email="ops@northbridgecm.com",
            phone="+44 20 7100 2200",
            primary_address="25 Bishopsgate, London EC2N 4AA, United Kingdom",
            country="UK",
            tax_id="GB777123456",
            segment="Financial Institution â€“ Broker/Dealer",
            risk_rating="HIGH",
        ),
    )

    eurotech = ClientService.create(
        db,
        ClientCreate(
            external_id="CRM-CORP-003",
            full_name="EuroTech Components AG",
            email="finance@eurotech-ag.de",
            phone="+49 69 9000 3300",
            primary_address="Friedrich-Ebert-Anlage 12, 60325 Frankfurt, Germany",
            country="DE",
            tax_id="DE311445566",
            segment="Corporate â€“ Large Cap",
            risk_rating="LOW",
        ),
    )

    greenfields = ClientService.create(
        db,
        ClientCreate(
            external_id="CRM-FUND-004",
            full_name="Greenfields Global Opportunities Fund",
            email="fundops@greenfieldsfund.com",
            phone="+44 20 7200 4455",
            primary_address="8 St Jamesâ€™s Square, London SW1Y 4JU, United Kingdom",
            country="UK",
            tax_id="JE55001122",
            segment="Asset Manager â€“ Fund",
            risk_rating="HIGH",
        ),
    )

    cityhealth = ClientService.create(
        db,
        ClientCreate(
            external_id="CRM-CORP-005",
            full_name="CityHealth NHS Services Consortium",
            email="finance@cityhealth-consortium.org.uk",
            phone="+44 161 400 8800",
            primary_address="120 Deansgate, Manchester M3 2GH, United Kingdom",
            country="UK",
            tax_id="GB660009999",
            segment="Public Sector / Healthcare",
            risk_rating="MEDIUM",
        ),
    )

    # ---------- ACCOUNTS ----------

    # Acme â€“ operating GBP account, USD account
    acme_gbp = AccountService.create(
        db,
        AccountCreate(
            client_id=acme.id,
            account_number="ACME-GBP-001",
            account_type="OPERATING",
            currency="GBP",
            status="OPEN",
        ),
    )
    acme_usd = AccountService.create(
        db,
        AccountCreate(
            client_id=acme.id,
            account_number="ACME-USD-001",
            account_type="OPERATING",
            currency="USD",
            status="OPEN",
        ),
    )

    # Northbridge â€“ client money & margin
    nb_client = AccountService.create(
        db,
        AccountCreate(
            client_id=northbridge.id,
            account_number="NB-CM-001",
            account_type="CLIENT_MONEY",
            currency="GBP",
            status="OPEN",
        ),
    )
    nb_margin = AccountService.create(
        db,
        AccountCreate(
            client_id=northbridge.id,
            account_number="NB-MRG-001",
            account_type="MARGIN",
            currency="USD",
            status="OPEN",
        ),
    )

    # EuroTech â€“ EUR operating
    euro_eur = AccountService.create(
        db,
        AccountCreate(
            client_id=eurotech.id,
            account_number="ET-EUR-001",
            account_type="OPERATING",
            currency="EUR",
            status="OPEN",
        ),
    )

    # Greenfields â€“ subscription & redemption cash
    gf_sub = AccountService.create(
        db,
        AccountCreate(
            client_id=greenfields.id,
            account_number="GF-SUB-001",
            account_type="SUBSCRIPTIONS",
            currency="USD",
            status="OPEN",
        ),
    )
    gf_red = AccountService.create(
        db,
        AccountCreate(
            client_id=greenfields.id,
            account_number="GF-RED-001",
            account_type="REDEMPTIONS",
            currency="USD",
            status="OPEN",
        ),
    )

    # CityHealth â€“ GBP payments account
    ch_gbp = AccountService.create(
        db,
        AccountCreate(
            client_id=cityhealth.id,
            account_number="CH-GBP-001",
            account_type="OPERATING",
            currency="GBP",
            status="OPEN",
        ),
    )

    # ---------- TRANSACTIONS (HIGH-LEVEL) ----------

    # Acme GBP
    TransactionService.create(
        db,
        TransactionCreate(
            account_id=acme_gbp.id,
            trade_date="2025-01-05",
            value_date="2025-01-05",
            amount=1_250_000.00,
            currency="GBP",
            txn_type="CREDIT",
            description="Quarterly invoice receipts â€“ UK distributors",
        ),
    )
    TransactionService.create(
        db,
        TransactionCreate(
            account_id=acme_gbp.id,
            trade_date="2025-01-08",
            value_date="2025-01-08",
            amount=-420_000.00,
            currency="GBP",
            txn_type="DEBIT",
            description="Payroll and supplier payments",
        ),
    )

    # Acme USD
    TransactionService.create(
        db,
        TransactionCreate(
            account_id=acme_usd.id,
            trade_date="2025-01-10",
            value_date="2025-01-11",
            amount=900_000.00,
            currency="USD",
            txn_type="CREDIT",
            description="Export receipts â€“ US customer",
        ),
    )

    # Northbridge client money
    TransactionService.create(
        db,
        TransactionCreate(
            account_id=nb_client.id,
            trade_date="2025-02-01",
            value_date="2025-02-01",
            amount=35_000_000.00,
            currency="GBP",
            txn_type="CREDIT",
            description="Client collateral top-up",
        ),
    )
    TransactionService.create(
        db,
        TransactionCreate(
            account_id=nb_client.id,
            trade_date="2025-02-02",
            value_date="2025-02-02",
            amount=-12_500_000.00,
            currency="GBP",
            txn_type="DEBIT",
            description="Daily variation margin outflow",
        ),
    )

    # Northbridge margin USD
    TransactionService.create(
        db,
        TransactionCreate(
            account_id=nb_margin.id,
            trade_date="2025-02-03",
            value_date="2025-02-04",
            amount=7_500_000.00,
            currency="USD",
            txn_type="CREDIT",
            description="Initial margin received on cleared swaps",
        ),
    )

    # EuroTech EUR
    TransactionService.create(
        db,
        TransactionCreate(
            account_id=euro_eur.id,
            trade_date="2025-01-15",
            value_date="2025-01-15",
            amount=4_200_000.00,
            currency="EUR",
            txn_type="CREDIT",
            description="Receivables from OEM contracts",
        ),
    )
    TransactionService.create(
        db,
        TransactionCreate(
            account_id=euro_eur.id,
            trade_date="2025-01-18",
            value_date="2025-01-19",
            amount=-3_100_000.00,
            currency="EUR",
            txn_type="DEBIT",
            description="Raw materials purchase â€“ multi-country suppliers",
        ),
    )

    # Greenfields subscriptions / redemptions
    TransactionService.create(
        db,
        TransactionCreate(
            account_id=gf_sub.id,
            trade_date="2025-03-01",
            value_date="2025-03-02",
            amount=65_000_000.00,
            currency="USD",
            txn_type="CREDIT",
            description="Monthly investor subscriptions",
        ),
    )
    TransactionService.create(
        db,
        TransactionCreate(
            account_id=gf_red.id,
            trade_date="2025-03-05",
            value_date="2025-03-06",
            amount=-18_500_000.00,
            currency="USD",
            txn_type="DEBIT",
            description="Quarterly investor redemptions",
        ),
    )

    # CityHealth GBP
    TransactionService.create(
        db,
        TransactionCreate(
            account_id=ch_gbp.id,
            trade_date="2025-01-07",
            value_date="2025-01-07",
            amount=9_750_000.00,
            currency="GBP",
            txn_type="CREDIT",
            description="NHS commissioning inflow â€“ London region",
        ),
    )

    # ---------- KYC FLAGS ----------

    KycFlagService.create(
        db,
        KycFlagCreate(
            client_id=northbridge.id,
            code="HIGH_TRADING_VOLUME",
            description="Daily derivatives margin flows above defined threshold",
            status="OPEN",
            created_at="2024-12-15",
        ),
    )

    KycFlagService.create(
        db,
        KycFlagCreate(
            client_id=greenfields.id,
            code="UBO_COMPLEX_STRUCTURE",
            description="Layered fund / SPV structure â€“ enhanced due diligence required",
            status="OPEN",
            created_at="2024-11-01",
        ),
    )

    KycFlagService.create(
        db,
        KycFlagCreate(
            client_id=acme.id,
            code="SANCTIONS_SCREENING_HIT",
            description="False positive â€“ name match to restricted entity, monitored",
            status="CLOSED",
            created_at="2023-06-10",
            resolved_at="2023-06-12",
        ),
    )


===== FILE: backend_v2\app\services\__init__.py =====
# services package


===== FILE: backend_v2\app\services\account_service.py =====
from sqlalchemy.orm import Session
from app.schemas.account import AccountCreate
from app.repositories.account_repository import AccountRepository


class AccountService:

    @staticmethod
    def create(db: Session, data: AccountCreate):
        return AccountRepository.create(db, data)

    @staticmethod
    def get(db: Session, account_id: int):
        return AccountRepository.get(db, account_id)

    @staticmethod
    def list_by_client(db: Session, client_id: int):
        return AccountRepository.list_by_client(db, client_id)


===== FILE: backend_v2\app\services\audit_trail_service.py =====
# backend_v2/app/services/audit_trail_service.py
from __future__ import annotations

from typing import Any, Dict, List, Optional, Set, Tuple
from sqlalchemy import text
from sqlalchemy.orm import Session


# Cache: detect which audit table exists and what columns it has
_AUDIT_TABLE: Optional[str] = None
_AUDIT_COLS: Optional[Set[str]] = None


def _detect_audit_table(db: Session) -> Tuple[Optional[str], Set[str]]:
    """
    Find the audit table in the current DB, and return (table_name, columns).

    Weâ€™re defensive because environments can differ slightly.
    """
    global _AUDIT_TABLE, _AUDIT_COLS
    if _AUDIT_TABLE is not None and _AUDIT_COLS is not None:
        return _AUDIT_TABLE, _AUDIT_COLS

    # Candidate names (keep simple and explicit)
    candidates = [
        "audit_events",
        "audit_trail",
        "audit_log",
        "audit_logs",
        "audit_entries",
        "audit_entry",
    ]

    # Identify first table that exists
    row = db.execute(
        text(
            """
            SELECT table_name
            FROM information_schema.tables
            WHERE table_schema = 'public'
              AND table_name = ANY(:candidates)
            ORDER BY array_position(:candidates, table_name)
            LIMIT 1
            """
        ),
        {"candidates": candidates},
    ).fetchone()

    if not row:
        _AUDIT_TABLE, _AUDIT_COLS = None, set()
        return _AUDIT_TABLE, _AUDIT_COLS

    table_name = row[0]

    cols_rows = db.execute(
        text(
            """
            SELECT column_name
            FROM information_schema.columns
            WHERE table_schema = 'public'
              AND table_name = :t
            """
        ),
        {"t": table_name},
    ).fetchall()

    cols = {r[0] for r in cols_rows}

    _AUDIT_TABLE, _AUDIT_COLS = table_name, cols
    return _AUDIT_TABLE, _AUDIT_COLS


class AuditTrailService:
    @staticmethod
    def list_by_client(db: Session, client_id: int, limit: int = 100) -> List[Dict[str, Any]]:
        """
        Return audit events linked to a client.

        UI expects an array of objects with (ideally):
          - audit_event_id (or id)
          - occurred_at / timestamp / created_at
          - event_type
          - actor
          - details (json-ish) and/or summary fields

        We support multiple possible table shapes by:
          - detecting the audit table name
          - aliasing common columns into a stable output
          - using the most reliable filter available (client_id, entity_id, or source_record_id linkage)
        """
        table_name, cols = _detect_audit_table(db)
        if not table_name:
            return []

        # -------------------------
        # Column mapping (defensive)
        # -------------------------
        # ID column
        if "audit_event_id" in cols:
            id_expr = "audit_event_id"
        elif "id" in cols:
            id_expr = "id"
        else:
            id_expr = "NULL::text AS audit_event_id"

        # Timestamp column
        if "occurred_at" in cols:
            ts_expr = "occurred_at"
        elif "timestamp" in cols:
            ts_expr = "timestamp"
        elif "created_at" in cols:
            ts_expr = "created_at"
        else:
            ts_expr = "NULL AS occurred_at"

        # Event type
        if "event_type" in cols:
            type_expr = "event_type"
        elif "type" in cols:
            type_expr = "type AS event_type"
        elif "action" in cols:
            type_expr = "action AS event_type"
        else:
            type_expr = "NULL AS event_type"

        # Actor
        if "actor" in cols:
            actor_expr = "actor"
        elif "user" in cols:
            actor_expr = '"user" AS actor'
        elif "created_by" in cols:
            actor_expr = "created_by AS actor"
        else:
            actor_expr = "NULL AS actor"

        # Details payload
        if "details" in cols:
            details_expr = "details"
        elif "content" in cols:
            details_expr = "content AS details"
        elif "payload" in cols:
            details_expr = "payload AS details"
        elif "metadata" in cols:
            details_expr = "metadata AS details"
        else:
            details_expr = "NULL AS details"

        select_parts = [
            f"{id_expr} AS audit_event_id",
            f"{ts_expr} AS occurred_at",
            f"{type_expr}",
            f"{actor_expr}",
            f"{details_expr}",
        ]

        # ---------------------------------------
        # Filtering strategy (best available first)
        # ---------------------------------------
        where_sql = None
        params: Dict[str, Any] = {"client_id": client_id, "limit": limit}

        # 1) Direct client_id column
        if "client_id" in cols:
            where_sql = "client_id = :client_id"

        # 2) matched_client_id column
        elif "matched_client_id" in cols:
            where_sql = "matched_client_id = :client_id"

        # 3) entity_id column (string-based)
        elif "entity_id" in cols:
            # support either "1" or "client:1"
            where_sql = "(entity_id = :client_id_txt OR entity_id = :client_id_key)"
            params["client_id_txt"] = str(client_id)
            params["client_id_key"] = f"client:{client_id}"

        # 4) source_record_id linkage (join via match_decisions)
        elif "source_record_id" in cols:
            where_sql = """
                source_record_id::text IN (
                    SELECT DISTINCT source_record_id::text
                    FROM match_decisions
                    WHERE matched_client_id = :client_id
                )
            """

        # 5) details json contains client_id
        elif "details" in cols:
            # If details is jsonb, this will work; if not, it will likely fail at runtime,
            # so only use it as a last resort.
            where_sql = "(details ->> 'client_id') = :client_id_txt"
            params["client_id_txt"] = str(client_id)

        if not where_sql:
            return []

        sql = f"""
            SELECT {", ".join(select_parts)}
            FROM {table_name}
            WHERE {where_sql}
            ORDER BY {ts_expr} DESC NULLS LAST
            LIMIT :limit
        """

        rows = db.execute(text(sql), params).fetchall()

        out: List[Dict[str, Any]] = []
        for r in rows:
            d = dict(r._mapping)

            # Normalise event_type/actor keys if they came through without alias
            # (because some branches use AS; some are direct)
            d.setdefault("event_type", d.get("event_type"))
            d.setdefault("actor", d.get("actor"))

            out.append(d)

        return out


===== FILE: backend_v2\app\services\client_service.py =====
from __future__ import annotations

from typing import Any, Dict, List, Optional

from sqlalchemy.orm import Session

from app.schemas.client import ClientCreate
from app.repositories.client_repository import ClientRepository


class ClientService:
    @staticmethod
    def create(db: Session, data: ClientCreate):
        return ClientRepository.create(db, data)

    @staticmethod
    def list(db: Session):
        return ClientRepository.list(db)

    @staticmethod
    def get_record(db: Session, client_id: int):
        """
        Returns the raw client record from persistence (ORM model or dict),
        without shaping it into the logical data model.
        """
        return ClientRepository.get(db, client_id)

    @staticmethod
    def get(db: Session, client_id: int) -> Optional[Dict[str, Any]]:
        """
        Returns a ClientProfile shaped according to the Initial Logical Data Model (LDM).

        This is a read-only deterministic assembly of core attributes from the persisted
        client record, with empty placeholders for other LDM sections.
        """
        client = ClientRepository.get(db, client_id)
        if client is None:
            return None

        return ClientService._assemble_client_profile(client)

    @staticmethod
    def _assemble_client_profile(client: Any) -> Dict[str, Any]:
        """
        Assemble a ClientProfile structure as per the LDM.

        Populates core attributes where available and provides empty placeholders for:
        identifiers, addresses, lineage, quality, metadata, raw_sources.
        """

        def pick(obj: Any, *names: str) -> Any:
            # Supports ORM objects (attributes) and dict-like records (keys)
            for n in names:
                if isinstance(obj, dict) and n in obj:
                    return obj[n]
                if hasattr(obj, n):
                    return getattr(obj, n)
            return None

        client_id = pick(client, "client_id", "id")
        name = pick(client, "name", "full_name")
        email = pick(client, "email", "primary_email")
        country = pick(client, "country", "country_of_residence")

        # Full LDM shape with empty placeholders
        profile: Dict[str, Any] = {
            "client_id": client_id,
            "name": name,
            "email": email,
            "country": country,
            "identifiers": [],  # type: List[Dict[str, Any]]
            "addresses": [],    # type: List[Dict[str, Any]]
            "lineage": {},      # type: Dict[str, Any]
            "quality": {},      # type: Dict[str, Any]
            "metadata": {},     # type: Dict[str, Any]
            "raw_sources": [],  # type: List[Dict[str, Any]]
        }

        return profile


===== FILE: backend_v2\app\services\crm_bulk_load_service.py =====
from __future__ import annotations

import csv
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, Iterable, Iterator, Optional, Protocol

from sqlalchemy.orm import Session

from app.repositories.crm_contact_repository import CRMContactRepository


@dataclass(frozen=True)
class IngestionResult:
    total: int
    inserted: int
    updated: int
    skipped: int


class CrmSource(Protocol):
    def read(self) -> Iterable[Dict[str, Optional[str]]]:
        """
        Each record must at minimum supply:
          - source_system
          - source_record_id
        Other fields are optional.
        """
        ...


class FileCrmSource:
    """
    Deterministic, controlled source for ST-05.
    CSV header must include:
      source_system, source_record_id, first_name, last_name, email
    """
    def __init__(self, path: Path):
        self.path = path

    def read(self) -> Iterator[Dict[str, Optional[str]]]:
        with self.path.open("r", encoding="utf-8", newline="") as f:
            reader = csv.DictReader(f)
            for row in reader:
                # Normalise keys we care about (ignore extras)
                yield {
                    "source_system": (row.get("source_system") or "").strip() or None,
                    "source_record_id": (row.get("source_record_id") or "").strip() or None,
                    "first_name": (row.get("first_name") or "").strip() or None,
                    "last_name": (row.get("last_name") or "").strip() or None,
                    "email": (row.get("email") or "").strip() or None,
                }


class BulkCrmIngestionService:
    """
    ST-05 operational batch ingestion.
    - minimal validation
    - real persistence through repository
    - idempotent via upsert
    """

    @staticmethod
    def ingest(db: Session, source: CrmSource) -> IngestionResult:
        total = inserted = updated = skipped = 0

        for rec in source.read():
            total += 1

            source_system = rec.get("source_system")
            source_record_id = rec.get("source_record_id")

            # Minimal required-field validation only (strict scope)
            if not source_system or not source_record_id:
                skipped += 1
                continue

            status, _row = CRMContactRepository.upsert(
                db,
                source_system=source_system,
                source_record_id=source_record_id,
                first_name=rec.get("first_name"),
                last_name=rec.get("last_name"),
                email=rec.get("email"),
            )

            if status == "inserted":
                inserted += 1
            else:
                updated += 1

        db.commit()

        return IngestionResult(
            total=total,
            inserted=inserted,
            updated=updated,
            skipped=skipped,
        )


===== FILE: backend_v2\app\services\evidence_artefact_service.py =====
# backend_v2/app/services/evidence_artefact_service.py
from __future__ import annotations

from typing import Any, Dict, List, Optional, Set
from sqlalchemy import text
from sqlalchemy.orm import Session

_EVIDENCE_ARTEFACTS_COLS: Optional[Set[str]] = None


def _get_evidence_artefacts_columns(db: Session) -> Set[str]:
    global _EVIDENCE_ARTEFACTS_COLS
    if _EVIDENCE_ARTEFACTS_COLS is not None:
        return _EVIDENCE_ARTEFACTS_COLS

    rows = db.execute(
        text("""
            SELECT column_name
            FROM information_schema.columns
            WHERE table_name = 'evidence_artefacts'
        """)
    ).fetchall()

    _EVIDENCE_ARTEFACTS_COLS = {r[0] for r in rows}
    return _EVIDENCE_ARTEFACTS_COLS


class EvidenceArtefactService:
    @staticmethod
    def list_by_client(db: Session, client_id: int, limit: int = 50) -> List[Dict[str, Any]]:
        """
        Return evidence artefacts linked to a client.

        Current DB shape (per your table):
          evidence_artefacts(artefact_id, evidence_bundle_id, artefact_type, created_at, content jsonb)

        There is no direct client_id, so we link via:
          match_decisions(matched_client_id) -> source_record_id
          evidence_artefacts.content->'source_record_ids' contains those IDs
        """
        cols = _get_evidence_artefacts_columns(db)

        # 1) Pull the client's source_record_ids from match_decisions
        src_rows = db.execute(
            text("""
                SELECT DISTINCT source_record_id::text AS source_record_id
                FROM match_decisions
                WHERE matched_client_id = :client_id
            """),
            {"client_id": client_id},
        ).fetchall()

        source_ids = [r[0] for r in src_rows if r and r[0]]
        if not source_ids:
            return []

        # 2) Select artefacts; adapt to schema if columns vary slightly
        select_parts = [
            "artefact_id",
            "evidence_bundle_id",
            "artefact_type",
            "created_at",
            "content",
        ]

        # If some environments use artifact_* spelling, adapt (defensive)
        if "artefact_id" not in cols and "artifact_id" in cols:
            select_parts[0] = "artifact_id AS artefact_id"
        if "evidence_bundle_id" not in cols and "bundle_id" in cols:
            select_parts[1] = "bundle_id AS evidence_bundle_id"
        if "artefact_type" not in cols and "artifact_type" in cols:
            select_parts[2] = "artifact_type AS artefact_type"

        # Filter: jsonb array contains-any using ?| against text[]
        sql = f"""
            SELECT {", ".join(select_parts)}
            FROM evidence_artefacts
            WHERE (content -> 'source_record_ids') ?| :source_ids
            ORDER BY created_at DESC
            LIMIT :limit
        """

        rows = db.execute(
            text(sql),
            {
                "source_ids": source_ids,  # SQLAlchemy/psycopg will bind Python list as text[]
                "limit": limit,
            },
        ).fetchall()

        artefacts: List[Dict[str, Any]] = []
        for r in rows:
            d = dict(r._mapping)

            # Shape to what the UI panel expects (keep existing keys too)
            # UI-friendly fields:
            d["source_system"] = "MATCHING"  # stable label; can refine later
            d["storage_ref"] = str(d.get("evidence_bundle_id") or d.get("artefact_id"))
            artefacts.append(d)

        return artefacts




===== FILE: backend_v2\app\services\kyc_flag_service.py =====
from sqlalchemy.orm import Session
from app.schemas.kyc_flag import KycFlagCreate
from app.repositories.kyc_flag_repository import KycFlagRepository


class KycFlagService:

    @staticmethod
    def create(db: Session, data: KycFlagCreate):
        return KycFlagRepository.create(db, data)

    @staticmethod
    def list_by_client(db: Session, client_id: int):
        return KycFlagRepository.list_by_client(db, client_id)


===== FILE: backend_v2\app\services\match_decision_service.py =====
from __future__ import annotations

from typing import Any, Dict, List, Optional, Set
from sqlalchemy import text
from sqlalchemy.orm import Session


# Cache discovered columns so we don't hit information_schema on every request
_MATCH_DECISIONS_COLS: Optional[Set[str]] = None


def _get_match_decisions_columns(db: Session) -> Set[str]:
    global _MATCH_DECISIONS_COLS
    if _MATCH_DECISIONS_COLS is not None:
        return _MATCH_DECISIONS_COLS

    rows = db.execute(
        text("""
            SELECT column_name
            FROM information_schema.columns
            WHERE table_name = 'match_decisions'
        """)
    ).fetchall()

    _MATCH_DECISIONS_COLS = {r[0] for r in rows}
    return _MATCH_DECISIONS_COLS


class MatchDecisionService:
    @staticmethod
    def list_by_client(db: Session, client_id: int, limit: int = 25) -> List[Dict[str, Any]]:
        """
        Return match decisions for a client, newest first.

        Important:
        - Uses information_schema to adapt to whether optional columns exist
          (e.g. source_system/system, confidence).
        - Returns dict rows to keep profile contract flexible (matches current SCV pattern).
        """
        cols = _get_match_decisions_columns(db)

        # Core columns (assumed present from your schema)
        select_parts = [
            "match_decision_id",
            "match_run_id",
            "source_record_id",
            "decided_at",
            "decision",
            "matched_client_id",
        ]

        # Optional columns used by the UI
        if "source_system" in cols:
            select_parts.append("source_system")
        elif "system" in cols:
            select_parts.append("system AS source_system")
        else:
            select_parts.append("NULL AS source_system")

        if "confidence" in cols:
            select_parts.append("confidence")
        else:
            select_parts.append("NULL AS confidence")

        # Keep any extra useful columns if they exist (won't break UI; expand panel will show them)
        for extra in ["details", "reason", "rule", "candidate_id"]:
            if extra in cols:
                select_parts.append(extra)

        sql = f"""
            SELECT {", ".join(select_parts)}
            FROM match_decisions
            WHERE matched_client_id = :client_id
            ORDER BY decided_at DESC
            LIMIT :limit
        """

        rows = db.execute(text(sql), {"client_id": client_id, "limit": limit}).fetchall()
        return [dict(r._mapping) for r in rows]


===== FILE: backend_v2\app\services\regulatory_enrichment_service.py =====
from typing import Any, Dict, Optional
from sqlalchemy import text
from sqlalchemy.orm import Session

class RegulatoryEnrichmentService:
    @staticmethod
    def get_latest_by_client(db: Session, client_id: int) -> Dict[str, Any]:
        row = db.execute(
            text("""
                SELECT
                    fatca_status,
                    crs_status,
                    onboarding_status,
                    kyc_overall_status,
                    derived_risk_notes,
                    updated_at
                FROM client_regulatory_enrichment
                WHERE client_id = :client_id
                ORDER BY updated_at DESC
                LIMIT 1
            """),
            {"client_id": client_id},
        ).fetchone()

        return dict(row._mapping) if row else {}


===== FILE: backend_v2\app\services\transaction_service.py =====
from sqlalchemy.orm import Session
from app.schemas.transaction import TransactionCreate
from app.repositories.transaction_repository import TransactionRepository


class TransactionService:

    @staticmethod
    def create(db: Session, data: TransactionCreate):
        return TransactionRepository.create(db, data)

    @staticmethod
    def list_by_account(db: Session, account_id: int):
        return TransactionRepository.list_by_account(db, account_id)


===== FILE: backend_v2\pytest.ini =====
[pytest]
testpaths = tests
pythonpath = .


===== FILE: backend_v2\requirements.txt =====
fastapi
uvicorn[standard]
SQLAlchemy>=2.0
pydantic>=2.0
psycopg[binary]
python-dotenv


===== FILE: backend_v2\tests\services\test_client_service_st20.py =====
import pytest
from unittest.mock import MagicMock

from app.services.client_service import ClientService


class DummyClient:
    def __init__(self, **kwargs):
        for k, v in kwargs.items():
            setattr(self, k, v)


def test_get_returns_full_ldm_profile_shape(monkeypatch):
    db = MagicMock()
    dummy = DummyClient(
        id=1,
        full_name="Jane Doe",
        email="jane@example.com",
        country="UK",
    )

    from app.repositories.client_repository import ClientRepository
    monkeypatch.setattr(ClientRepository, "get", MagicMock(return_value=dummy))

    profile = ClientService.get(db, 1)

    assert profile == {
        "client_id": 1,
        "name": "Jane Doe",
        "email": "jane@example.com",
        "country": "UK",
        "identifiers": [],
        "addresses": [],
        "lineage": {},
        "quality": {},
        "metadata": {},
        "raw_sources": [],
    }


def test_get_is_deterministic_for_same_input(monkeypatch):
    db = MagicMock()
    dummy = DummyClient(
        id=1,
        full_name="Jane Doe",
        email="jane@example.com",
        country="UK",
    )

    from app.repositories.client_repository import ClientRepository
    monkeypatch.setattr(ClientRepository, "get", MagicMock(return_value=dummy))

    profile_a = ClientService.get(db, 1)
    profile_b = ClientService.get(db, 1)

    assert profile_a == profile_b


def test_get_returns_none_when_client_missing(monkeypatch):
    db = MagicMock()

    from app.repositories.client_repository import ClientRepository
    monkeypatch.setattr(ClientRepository, "get", MagicMock(return_value=None))

    profile = ClientService.get(db, 999)

    assert profile is None



===== FILE: database.py =====
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

DATABASE_URL = "postgresql+psycopg://postgres:Londonirish-01@localhost:5432/scv"

engine = create_engine(DATABASE_URL, pool_pre_ping=True)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)



===== FILE: docs\ldm\contracts\client_profile\1.0.0\schema.json =====
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "ldm://client_profile/1.0.0",
  "title": "ClientProfile",
  "type": "object",
  "additionalProperties": false,
  "required": [
    "client_id",
    "name",
    "identifiers",
    "addresses",
    "lineage",
    "quality",
    "metadata",
    "raw_sources"
  ],
  "properties": {
    "client_id": { "type": "string", "minLength": 1 },
    "name": { "type": "string", "minLength": 1 },
    "email": { "type": ["string", "null"], "format": "email" },
    "country": { "type": ["string", "null"] },

    "identifiers": {
      "type": "array",
      "items": {
        "type": "object",
        "additionalProperties": false,
        "required": ["system", "value"],
        "properties": {
          "system": { "type": "string" },
          "value": { "type": "string" }
        }
      }
    },

    "addresses": {
      "type": "array",
      "items": {
        "type": "object",
        "additionalProperties": false,
        "properties": {
          "line1": { "type": ["string", "null"] },
          "line2": { "type": ["string", "null"] },
          "city": { "type": ["string", "null"] },
          "postcode": { "type": ["string", "null"] },
          "country": { "type": ["string", "null"] },
          "source": { "type": ["string", "null"] }
        }
      }
    },

    "lineage": { "type": "object" },
    "quality": { "type": "object" },
    "metadata": { "type": "object" },
    "raw_sources": {
      "type": "array",
      "items": { "type": "object" }
    }
  }
}


===== FILE: docs\mission_destination\database_schema12.sql =====
--
-- PostgreSQL database dump
--

-- Dumped from database version 16.4
-- Dumped by pg_dump version 16.4

-- Started on 2026-01-02 19:40:24

SET statement_timeout = 0;
SET lock_timeout = 0;
SET idle_in_transaction_session_timeout = 0;
SET client_encoding = 'UTF8';
SET standard_conforming_strings = on;
SELECT pg_catalog.set_config('search_path', '', false);
SET check_function_bodies = false;
SET xmloption = content;
SET client_min_messages = warning;
SET row_security = off;

--
-- TOC entry 2 (class 3079 OID 16622)
-- Name: pgcrypto; Type: EXTENSION; Schema: -; Owner: -
--

CREATE EXTENSION IF NOT EXISTS pgcrypto WITH SCHEMA public;


--
-- TOC entry 5245 (class 0 OID 0)
-- Dependencies: 2
-- Name: EXTENSION pgcrypto; Type: COMMENT; Schema: -; Owner: 
--

COMMENT ON EXTENSION pgcrypto IS 'cryptographic functions';


SET default_tablespace = '';

SET default_table_access_method = heap;

--
-- TOC entry 221 (class 1259 OID 16472)
-- Name: accounts; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.accounts (
    id integer NOT NULL,
    client_id integer NOT NULL,
    account_number character varying NOT NULL,
    account_type character varying,
    currency character varying NOT NULL,
    status character varying NOT NULL,
    opened_at character varying,
    closed_at character varying
);


ALTER TABLE public.accounts OWNER TO postgres;

--
-- TOC entry 220 (class 1259 OID 16471)
-- Name: accounts_id_seq; Type: SEQUENCE; Schema: public; Owner: postgres
--

CREATE SEQUENCE public.accounts_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;


ALTER SEQUENCE public.accounts_id_seq OWNER TO postgres;

--
-- TOC entry 5246 (class 0 OID 0)
-- Dependencies: 220
-- Name: accounts_id_seq; Type: SEQUENCE OWNED BY; Schema: public; Owner: postgres
--

ALTER SEQUENCE public.accounts_id_seq OWNED BY public.accounts.id;


--
-- TOC entry 229 (class 1259 OID 16563)
-- Name: asset_class; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.asset_class (
    asset_class_id integer NOT NULL,
    asset_code character varying(20) NOT NULL,
    asset_name character varying(100) NOT NULL
);


ALTER TABLE public.asset_class OWNER TO postgres;

--
-- TOC entry 228 (class 1259 OID 16562)
-- Name: asset_class_asset_class_id_seq; Type: SEQUENCE; Schema: public; Owner: postgres
--

CREATE SEQUENCE public.asset_class_asset_class_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;


ALTER SEQUENCE public.asset_class_asset_class_id_seq OWNER TO postgres;

--
-- TOC entry 5247 (class 0 OID 0)
-- Dependencies: 228
-- Name: asset_class_asset_class_id_seq; Type: SEQUENCE OWNED BY; Schema: public; Owner: postgres
--

ALTER SEQUENCE public.asset_class_asset_class_id_seq OWNED BY public.asset_class.asset_class_id;


--
-- TOC entry 253 (class 1259 OID 16844)
-- Name: attribute_conflicts; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.attribute_conflicts (
    conflict_id uuid DEFAULT gen_random_uuid() NOT NULL,
    client_id integer NOT NULL,
    attribute_id integer NOT NULL,
    detected_at timestamp with time zone DEFAULT now() NOT NULL,
    values_by_source jsonb NOT NULL,
    resolved boolean DEFAULT false NOT NULL,
    resolution_notes text,
    resolved_at timestamp with time zone
);


ALTER TABLE public.attribute_conflicts OWNER TO postgres;

--
-- TOC entry 244 (class 1259 OID 16727)
-- Name: attribute_dictionary; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.attribute_dictionary (
    attribute_id integer NOT NULL,
    canonical_name character varying(100) NOT NULL,
    data_type character varying(30) NOT NULL,
    is_mandatory boolean DEFAULT false NOT NULL,
    description text,
    created_at timestamp with time zone DEFAULT now() NOT NULL
);


ALTER TABLE public.attribute_dictionary OWNER TO postgres;

--
-- TOC entry 243 (class 1259 OID 16726)
-- Name: attribute_dictionary_attribute_id_seq; Type: SEQUENCE; Schema: public; Owner: postgres
--

CREATE SEQUENCE public.attribute_dictionary_attribute_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;


ALTER SEQUENCE public.attribute_dictionary_attribute_id_seq OWNER TO postgres;

--
-- TOC entry 5248 (class 0 OID 0)
-- Dependencies: 243
-- Name: attribute_dictionary_attribute_id_seq; Type: SEQUENCE OWNED BY; Schema: public; Owner: postgres
--

ALTER SEQUENCE public.attribute_dictionary_attribute_id_seq OWNED BY public.attribute_dictionary.attribute_id;


--
-- TOC entry 252 (class 1259 OID 16824)
-- Name: attribute_precedence_rules; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.attribute_precedence_rules (
    precedence_rule_id integer NOT NULL,
    attribute_id integer NOT NULL,
    source_system_id integer NOT NULL,
    precedence_rank integer NOT NULL,
    is_active boolean DEFAULT true NOT NULL
);


ALTER TABLE public.attribute_precedence_rules OWNER TO postgres;

--
-- TOC entry 251 (class 1259 OID 16823)
-- Name: attribute_precedence_rules_precedence_rule_id_seq; Type: SEQUENCE; Schema: public; Owner: postgres
--

CREATE SEQUENCE public.attribute_precedence_rules_precedence_rule_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;


ALTER SEQUENCE public.attribute_precedence_rules_precedence_rule_id_seq OWNER TO postgres;

--
-- TOC entry 5249 (class 0 OID 0)
-- Dependencies: 251
-- Name: attribute_precedence_rules_precedence_rule_id_seq; Type: SEQUENCE OWNED BY; Schema: public; Owner: postgres
--

ALTER SEQUENCE public.attribute_precedence_rules_precedence_rule_id_seq OWNED BY public.attribute_precedence_rules.precedence_rule_id;


--
-- TOC entry 259 (class 1259 OID 16955)
-- Name: audit_events; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.audit_events (
    audit_event_id uuid DEFAULT gen_random_uuid() NOT NULL,
    occurred_at timestamp with time zone DEFAULT now() NOT NULL,
    actor character varying(200) NOT NULL,
    event_type character varying(80) NOT NULL,
    client_id integer,
    source_record_id uuid,
    evidence_bundle_id uuid,
    details jsonb
);


ALTER TABLE public.audit_events OWNER TO postgres;

--
-- TOC entry 250 (class 1259 OID 16807)
-- Name: client_cluster_members; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.client_cluster_members (
    cluster_id uuid NOT NULL,
    client_id integer NOT NULL,
    role character varying(30) DEFAULT 'member'::character varying NOT NULL
);


ALTER TABLE public.client_cluster_members OWNER TO postgres;

--
-- TOC entry 249 (class 1259 OID 16798)
-- Name: client_clusters; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.client_clusters (
    cluster_id uuid DEFAULT gen_random_uuid() NOT NULL,
    created_at timestamp with time zone DEFAULT now() NOT NULL,
    rationale text
);


ALTER TABLE public.client_clusters OWNER TO postgres;

--
-- TOC entry 233 (class 1259 OID 16594)
-- Name: client_data_lineage; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.client_data_lineage (
    lineage_id integer NOT NULL,
    client_id integer NOT NULL,
    data_source character varying(100) NOT NULL,
    field_name character varying(100) NOT NULL,
    transformation_description text,
    "timestamp" timestamp without time zone DEFAULT CURRENT_TIMESTAMP
);


ALTER TABLE public.client_data_lineage OWNER TO postgres;

--
-- TOC entry 232 (class 1259 OID 16593)
-- Name: client_data_lineage_lineage_id_seq; Type: SEQUENCE; Schema: public; Owner: postgres
--

CREATE SEQUENCE public.client_data_lineage_lineage_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;


ALTER SEQUENCE public.client_data_lineage_lineage_id_seq OWNER TO postgres;

--
-- TOC entry 5250 (class 0 OID 0)
-- Dependencies: 232
-- Name: client_data_lineage_lineage_id_seq; Type: SEQUENCE OWNED BY; Schema: public; Owner: postgres
--

ALTER SEQUENCE public.client_data_lineage_lineage_id_seq OWNED BY public.client_data_lineage.lineage_id;


--
-- TOC entry 255 (class 1259 OID 16881)
-- Name: client_operational_state; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.client_operational_state (
    state_id uuid DEFAULT gen_random_uuid() NOT NULL,
    client_id integer NOT NULL,
    as_of timestamp with time zone DEFAULT now() NOT NULL,
    processing_stage character varying(50) NOT NULL,
    status character varying(30) NOT NULL,
    message text,
    details jsonb
);


ALTER TABLE public.client_operational_state OWNER TO postgres;

--
-- TOC entry 254 (class 1259 OID 16865)
-- Name: client_regulatory_enrichment; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.client_regulatory_enrichment (
    enrichment_id uuid DEFAULT gen_random_uuid() NOT NULL,
    client_id integer NOT NULL,
    fatca_status character varying(50),
    crs_status character varying(50),
    onboarding_status character varying(50),
    kyc_overall_status character varying(50),
    derived_risk_notes text,
    updated_at timestamp with time zone DEFAULT now() NOT NULL
);


ALTER TABLE public.client_regulatory_enrichment OWNER TO postgres;

--
-- TOC entry 256 (class 1259 OID 16896)
-- Name: client_source_coverage; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.client_source_coverage (
    client_id integer NOT NULL,
    source_system_id integer NOT NULL,
    last_seen_at timestamp with time zone,
    is_missing boolean DEFAULT false NOT NULL,
    is_stale boolean DEFAULT false NOT NULL,
    notes text
);


ALTER TABLE public.client_source_coverage OWNER TO postgres;

--
-- TOC entry 219 (class 1259 OID 16461)
-- Name: clients; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.clients (
    id integer NOT NULL,
    external_id character varying,
    full_name character varying NOT NULL,
    email character varying,
    phone character varying,
    primary_address character varying,
    country character varying,
    tax_id character varying,
    segment character varying,
    risk_rating character varying,
    country_id integer,
    risk_rating_id integer
);


ALTER TABLE public.clients OWNER TO postgres;

--
-- TOC entry 218 (class 1259 OID 16460)
-- Name: clients_id_seq; Type: SEQUENCE; Schema: public; Owner: postgres
--

CREATE SEQUENCE public.clients_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;


ALTER SEQUENCE public.clients_id_seq OWNER TO postgres;

--
-- TOC entry 5251 (class 0 OID 0)
-- Dependencies: 218
-- Name: clients_id_seq; Type: SEQUENCE OWNED BY; Schema: public; Owner: postgres
--

ALTER SEQUENCE public.clients_id_seq OWNED BY public.clients.id;


--
-- TOC entry 227 (class 1259 OID 16530)
-- Name: corporate_kyc_info; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.corporate_kyc_info (
    corporate_kyc_id integer NOT NULL,
    client_id integer NOT NULL,
    registration_number character varying(100) NOT NULL,
    legal_name character varying(255) NOT NULL,
    business_license character varying(100),
    company_structure character varying(50),
    compliance_status character varying(50) NOT NULL,
    last_reviewed_at timestamp without time zone,
    next_review_due_at timestamp without time zone,
    notes text
);


ALTER TABLE public.corporate_kyc_info OWNER TO postgres;

--
-- TOC entry 226 (class 1259 OID 16529)
-- Name: corporate_kyc_info_corporate_kyc_id_seq; Type: SEQUENCE; Schema: public; Owner: postgres
--

CREATE SEQUENCE public.corporate_kyc_info_corporate_kyc_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;


ALTER SEQUENCE public.corporate_kyc_info_corporate_kyc_id_seq OWNER TO postgres;

--
-- TOC entry 5252 (class 0 OID 0)
-- Dependencies: 226
-- Name: corporate_kyc_info_corporate_kyc_id_seq; Type: SEQUENCE OWNED BY; Schema: public; Owner: postgres
--

ALTER SEQUENCE public.corporate_kyc_info_corporate_kyc_id_seq OWNED BY public.corporate_kyc_info.corporate_kyc_id;


--
-- TOC entry 231 (class 1259 OID 16577)
-- Name: corporate_trade_history; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.corporate_trade_history (
    trade_id integer NOT NULL,
    client_id integer NOT NULL,
    trade_date timestamp without time zone NOT NULL,
    asset_class_id integer NOT NULL,
    instrument character varying(100) NOT NULL,
    direction character varying(4) NOT NULL,
    quantity numeric(18,4) NOT NULL,
    price numeric(18,6) NOT NULL,
    pnl numeric(18,2) NOT NULL
);


ALTER TABLE public.corporate_trade_history OWNER TO postgres;

--
-- TOC entry 230 (class 1259 OID 16576)
-- Name: corporate_trade_history_trade_id_seq; Type: SEQUENCE; Schema: public; Owner: postgres
--

CREATE SEQUENCE public.corporate_trade_history_trade_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;


ALTER SEQUENCE public.corporate_trade_history_trade_id_seq OWNER TO postgres;

--
-- TOC entry 5253 (class 0 OID 0)
-- Dependencies: 230
-- Name: corporate_trade_history_trade_id_seq; Type: SEQUENCE OWNED BY; Schema: public; Owner: postgres
--

ALTER SEQUENCE public.corporate_trade_history_trade_id_seq OWNED BY public.corporate_trade_history.trade_id;


--
-- TOC entry 235 (class 1259 OID 16609)
-- Name: country; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.country (
    country_id integer NOT NULL,
    country_code character varying(3) NOT NULL,
    country_name character varying(100) NOT NULL
);


ALTER TABLE public.country OWNER TO postgres;

--
-- TOC entry 234 (class 1259 OID 16608)
-- Name: country_country_id_seq; Type: SEQUENCE; Schema: public; Owner: postgres
--

CREATE SEQUENCE public.country_country_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;


ALTER SEQUENCE public.country_country_id_seq OWNER TO postgres;

--
-- TOC entry 5254 (class 0 OID 0)
-- Dependencies: 234
-- Name: country_country_id_seq; Type: SEQUENCE OWNED BY; Schema: public; Owner: postgres
--

ALTER SEQUENCE public.country_country_id_seq OWNED BY public.country.country_id;


--
-- TOC entry 262 (class 1259 OID 17009)
-- Name: crm_contacts; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.crm_contacts (
    id uuid NOT NULL,
    source_system character varying NOT NULL,
    source_record_id character varying NOT NULL,
    first_name character varying,
    last_name character varying,
    email character varying,
    created_at timestamp with time zone DEFAULT now() NOT NULL,
    updated_at timestamp with time zone DEFAULT now() NOT NULL
);


ALTER TABLE public.crm_contacts OWNER TO postgres;

--
-- TOC entry 258 (class 1259 OID 16940)
-- Name: evidence_artefacts; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.evidence_artefacts (
    artefact_id uuid DEFAULT gen_random_uuid() NOT NULL,
    evidence_bundle_id uuid NOT NULL,
    artefact_type character varying(50) NOT NULL,
    created_at timestamp with time zone DEFAULT now() NOT NULL,
    content jsonb,
    storage_ref text,
    content_hash character varying(128)
);


ALTER TABLE public.evidence_artefacts OWNER TO postgres;

--
-- TOC entry 257 (class 1259 OID 16915)
-- Name: evidence_bundles; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.evidence_bundles (
    evidence_bundle_id uuid DEFAULT gen_random_uuid() NOT NULL,
    client_id integer,
    ingestion_run_id uuid,
    match_run_id uuid,
    created_at timestamp with time zone DEFAULT now() NOT NULL,
    bundle_type character varying(50) NOT NULL,
    summary text
);


ALTER TABLE public.evidence_bundles OWNER TO postgres;

--
-- TOC entry 240 (class 1259 OID 16672)
-- Name: ingestion_runs; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.ingestion_runs (
    ingestion_run_id uuid DEFAULT gen_random_uuid() NOT NULL,
    source_system_id integer NOT NULL,
    started_at timestamp with time zone DEFAULT now() NOT NULL,
    finished_at timestamp with time zone,
    status character varying(30) DEFAULT 'started'::character varying NOT NULL,
    schema_version character varying(50),
    triggered_by character varying(200),
    notes text
);


ALTER TABLE public.ingestion_runs OWNER TO postgres;

--
-- TOC entry 223 (class 1259 OID 16489)
-- Name: kyc_flags; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.kyc_flags (
    id integer NOT NULL,
    client_id integer NOT NULL,
    code character varying NOT NULL,
    description character varying,
    status character varying NOT NULL,
    created_at character varying,
    resolved_at character varying
);


ALTER TABLE public.kyc_flags OWNER TO postgres;

--
-- TOC entry 222 (class 1259 OID 16488)
-- Name: kyc_flags_id_seq; Type: SEQUENCE; Schema: public; Owner: postgres
--

CREATE SEQUENCE public.kyc_flags_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;


ALTER SEQUENCE public.kyc_flags_id_seq OWNER TO postgres;

--
-- TOC entry 5255 (class 0 OID 0)
-- Dependencies: 222
-- Name: kyc_flags_id_seq; Type: SEQUENCE OWNED BY; Schema: public; Owner: postgres
--

ALTER SEQUENCE public.kyc_flags_id_seq OWNED BY public.kyc_flags.id;


--
-- TOC entry 248 (class 1259 OID 16772)
-- Name: match_decisions; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.match_decisions (
    match_decision_id uuid DEFAULT gen_random_uuid() NOT NULL,
    match_run_id uuid NOT NULL,
    source_record_id uuid NOT NULL,
    decided_at timestamp with time zone DEFAULT now() NOT NULL,
    decision character varying(30) NOT NULL,
    matched_client_id integer,
    confidence numeric(5,4),
    rule_hits jsonb,
    conflict_summary jsonb
);


ALTER TABLE public.match_decisions OWNER TO postgres;

--
-- TOC entry 247 (class 1259 OID 16762)
-- Name: match_runs; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.match_runs (
    match_run_id uuid DEFAULT gen_random_uuid() NOT NULL,
    started_at timestamp with time zone DEFAULT now() NOT NULL,
    finished_at timestamp with time zone,
    status character varying(30) DEFAULT 'started'::character varying NOT NULL,
    ruleset_version character varying(50),
    notes text
);


ALTER TABLE public.match_runs OWNER TO postgres;

--
-- TOC entry 237 (class 1259 OID 16616)
-- Name: risk_rating; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.risk_rating (
    risk_rating_id integer NOT NULL,
    rating_code character varying(20) NOT NULL,
    description character varying(255) NOT NULL
);


ALTER TABLE public.risk_rating OWNER TO postgres;

--
-- TOC entry 236 (class 1259 OID 16615)
-- Name: risk_rating_risk_rating_id_seq; Type: SEQUENCE; Schema: public; Owner: postgres
--

CREATE SEQUENCE public.risk_rating_risk_rating_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;


ALTER SEQUENCE public.risk_rating_risk_rating_id_seq OWNER TO postgres;

--
-- TOC entry 5256 (class 0 OID 0)
-- Dependencies: 236
-- Name: risk_rating_risk_rating_id_seq; Type: SEQUENCE OWNED BY; Schema: public; Owner: postgres
--

ALTER SEQUENCE public.risk_rating_risk_rating_id_seq OWNED BY public.risk_rating.risk_rating_id;


--
-- TOC entry 261 (class 1259 OID 16990)
-- Name: service_error_logs; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.service_error_logs (
    error_log_id uuid DEFAULT gen_random_uuid() NOT NULL,
    occurred_at timestamp with time zone DEFAULT now() NOT NULL,
    service_name character varying(100) NOT NULL,
    severity character varying(20) NOT NULL,
    error_code character varying(50),
    message text NOT NULL,
    details jsonb,
    correlation_id character varying(100)
);


ALTER TABLE public.service_error_logs OWNER TO postgres;

--
-- TOC entry 260 (class 1259 OID 16980)
-- Name: service_health_checks; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.service_health_checks (
    health_check_id uuid DEFAULT gen_random_uuid() NOT NULL,
    checked_at timestamp with time zone DEFAULT now() NOT NULL,
    service_name character varying(100) NOT NULL,
    check_type character varying(50) NOT NULL,
    status character varying(20) NOT NULL,
    details jsonb
);


ALTER TABLE public.service_health_checks OWNER TO postgres;

--
-- TOC entry 246 (class 1259 OID 16740)
-- Name: source_field_mappings; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.source_field_mappings (
    mapping_id integer NOT NULL,
    source_system_id integer NOT NULL,
    source_field character varying(200) NOT NULL,
    attribute_id integer NOT NULL,
    transform_rule text,
    is_active boolean DEFAULT true NOT NULL
);


ALTER TABLE public.source_field_mappings OWNER TO postgres;

--
-- TOC entry 245 (class 1259 OID 16739)
-- Name: source_field_mappings_mapping_id_seq; Type: SEQUENCE; Schema: public; Owner: postgres
--

CREATE SEQUENCE public.source_field_mappings_mapping_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;


ALTER SEQUENCE public.source_field_mappings_mapping_id_seq OWNER TO postgres;

--
-- TOC entry 5257 (class 0 OID 0)
-- Dependencies: 245
-- Name: source_field_mappings_mapping_id_seq; Type: SEQUENCE OWNED BY; Schema: public; Owner: postgres
--

ALTER SEQUENCE public.source_field_mappings_mapping_id_seq OWNED BY public.source_field_mappings.mapping_id;


--
-- TOC entry 241 (class 1259 OID 16688)
-- Name: source_records_raw; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.source_records_raw (
    source_record_id uuid DEFAULT gen_random_uuid() NOT NULL,
    ingestion_run_id uuid NOT NULL,
    source_system_id integer NOT NULL,
    source_record_key character varying(200) NOT NULL,
    received_at timestamp with time zone DEFAULT now() NOT NULL,
    payload jsonb NOT NULL,
    payload_hash character varying(128),
    extracted_external_id character varying(200),
    extracted_email character varying(320),
    extracted_tax_id character varying(100),
    structural_ok boolean DEFAULT true NOT NULL,
    structural_errors jsonb
);


ALTER TABLE public.source_records_raw OWNER TO postgres;

--
-- TOC entry 239 (class 1259 OID 16660)
-- Name: source_systems; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.source_systems (
    source_system_id integer NOT NULL,
    code character varying(50) NOT NULL,
    name character varying(200) NOT NULL,
    description text,
    is_active boolean DEFAULT true NOT NULL,
    created_at timestamp with time zone DEFAULT now() NOT NULL
);


ALTER TABLE public.source_systems OWNER TO postgres;

--
-- TOC entry 238 (class 1259 OID 16659)
-- Name: source_systems_source_system_id_seq; Type: SEQUENCE; Schema: public; Owner: postgres
--

CREATE SEQUENCE public.source_systems_source_system_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;


ALTER SEQUENCE public.source_systems_source_system_id_seq OWNER TO postgres;

--
-- TOC entry 5258 (class 0 OID 0)
-- Dependencies: 238
-- Name: source_systems_source_system_id_seq; Type: SEQUENCE OWNED BY; Schema: public; Owner: postgres
--

ALTER SEQUENCE public.source_systems_source_system_id_seq OWNED BY public.source_systems.source_system_id;


--
-- TOC entry 225 (class 1259 OID 16505)
-- Name: transactions; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.transactions (
    id integer NOT NULL,
    account_id integer NOT NULL,
    trade_date character varying,
    value_date character varying,
    amount double precision NOT NULL,
    currency character varying NOT NULL,
    txn_type character varying NOT NULL,
    description character varying,
    price double precision,
    pnl double precision
);


ALTER TABLE public.transactions OWNER TO postgres;

--
-- TOC entry 224 (class 1259 OID 16504)
-- Name: transactions_id_seq; Type: SEQUENCE; Schema: public; Owner: postgres
--

CREATE SEQUENCE public.transactions_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;


ALTER SEQUENCE public.transactions_id_seq OWNER TO postgres;

--
-- TOC entry 5259 (class 0 OID 0)
-- Dependencies: 224
-- Name: transactions_id_seq; Type: SEQUENCE OWNED BY; Schema: public; Owner: postgres
--

ALTER SEQUENCE public.transactions_id_seq OWNED BY public.transactions.id;


--
-- TOC entry 242 (class 1259 OID 16710)
-- Name: validation_results; Type: TABLE; Schema: public; Owner: postgres
--

CREATE TABLE public.validation_results (
    validation_result_id uuid DEFAULT gen_random_uuid() NOT NULL,
    source_record_id uuid NOT NULL,
    validated_at timestamp with time zone DEFAULT now() NOT NULL,
    validation_type character varying(50) NOT NULL,
    passed boolean NOT NULL,
    details jsonb,
    error_count integer DEFAULT 0 NOT NULL
);


ALTER TABLE public.validation_results OWNER TO postgres;

--
-- TOC entry 4908 (class 2604 OID 16475)
-- Name: accounts id; Type: DEFAULT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.accounts ALTER COLUMN id SET DEFAULT nextval('public.accounts_id_seq'::regclass);


--
-- TOC entry 4912 (class 2604 OID 16566)
-- Name: asset_class asset_class_id; Type: DEFAULT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.asset_class ALTER COLUMN asset_class_id SET DEFAULT nextval('public.asset_class_asset_class_id_seq'::regclass);


--
-- TOC entry 4930 (class 2604 OID 16730)
-- Name: attribute_dictionary attribute_id; Type: DEFAULT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.attribute_dictionary ALTER COLUMN attribute_id SET DEFAULT nextval('public.attribute_dictionary_attribute_id_seq'::regclass);


--
-- TOC entry 4943 (class 2604 OID 16827)
-- Name: attribute_precedence_rules precedence_rule_id; Type: DEFAULT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.attribute_precedence_rules ALTER COLUMN precedence_rule_id SET DEFAULT nextval('public.attribute_precedence_rules_precedence_rule_id_seq'::regclass);


--
-- TOC entry 4914 (class 2604 OID 16597)
-- Name: client_data_lineage lineage_id; Type: DEFAULT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.client_data_lineage ALTER COLUMN lineage_id SET DEFAULT nextval('public.client_data_lineage_lineage_id_seq'::regclass);


--
-- TOC entry 4907 (class 2604 OID 16464)
-- Name: clients id; Type: DEFAULT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.clients ALTER COLUMN id SET DEFAULT nextval('public.clients_id_seq'::regclass);


--
-- TOC entry 4911 (class 2604 OID 16533)
-- Name: corporate_kyc_info corporate_kyc_id; Type: DEFAULT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.corporate_kyc_info ALTER COLUMN corporate_kyc_id SET DEFAULT nextval('public.corporate_kyc_info_corporate_kyc_id_seq'::regclass);


--
-- TOC entry 4913 (class 2604 OID 16580)
-- Name: corporate_trade_history trade_id; Type: DEFAULT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.corporate_trade_history ALTER COLUMN trade_id SET DEFAULT nextval('public.corporate_trade_history_trade_id_seq'::regclass);


--
-- TOC entry 4916 (class 2604 OID 16612)
-- Name: country country_id; Type: DEFAULT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.country ALTER COLUMN country_id SET DEFAULT nextval('public.country_country_id_seq'::regclass);


--
-- TOC entry 4909 (class 2604 OID 16492)
-- Name: kyc_flags id; Type: DEFAULT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.kyc_flags ALTER COLUMN id SET DEFAULT nextval('public.kyc_flags_id_seq'::regclass);


--
-- TOC entry 4917 (class 2604 OID 16619)
-- Name: risk_rating risk_rating_id; Type: DEFAULT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.risk_rating ALTER COLUMN risk_rating_id SET DEFAULT nextval('public.risk_rating_risk_rating_id_seq'::regclass);


--
-- TOC entry 4933 (class 2604 OID 16743)
-- Name: source_field_mappings mapping_id; Type: DEFAULT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.source_field_mappings ALTER COLUMN mapping_id SET DEFAULT nextval('public.source_field_mappings_mapping_id_seq'::regclass);


--
-- TOC entry 4918 (class 2604 OID 16663)
-- Name: source_systems source_system_id; Type: DEFAULT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.source_systems ALTER COLUMN source_system_id SET DEFAULT nextval('public.source_systems_source_system_id_seq'::regclass);


--
-- TOC entry 4910 (class 2604 OID 16508)
-- Name: transactions id; Type: DEFAULT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.transactions ALTER COLUMN id SET DEFAULT nextval('public.transactions_id_seq'::regclass);


--
-- TOC entry 4971 (class 2606 OID 16479)
-- Name: accounts accounts_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.accounts
    ADD CONSTRAINT accounts_pkey PRIMARY KEY (id);


--
-- TOC entry 4986 (class 2606 OID 16568)
-- Name: asset_class asset_class_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.asset_class
    ADD CONSTRAINT asset_class_pkey PRIMARY KEY (asset_class_id);


--
-- TOC entry 5034 (class 2606 OID 16853)
-- Name: attribute_conflicts attribute_conflicts_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.attribute_conflicts
    ADD CONSTRAINT attribute_conflicts_pkey PRIMARY KEY (conflict_id);


--
-- TOC entry 5010 (class 2606 OID 16738)
-- Name: attribute_dictionary attribute_dictionary_canonical_name_key; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.attribute_dictionary
    ADD CONSTRAINT attribute_dictionary_canonical_name_key UNIQUE (canonical_name);


--
-- TOC entry 5012 (class 2606 OID 16736)
-- Name: attribute_dictionary attribute_dictionary_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.attribute_dictionary
    ADD CONSTRAINT attribute_dictionary_pkey PRIMARY KEY (attribute_id);


--
-- TOC entry 5029 (class 2606 OID 16832)
-- Name: attribute_precedence_rules attribute_precedence_rules_attribute_id_source_system_id_key; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.attribute_precedence_rules
    ADD CONSTRAINT attribute_precedence_rules_attribute_id_source_system_id_key UNIQUE (attribute_id, source_system_id);


--
-- TOC entry 5031 (class 2606 OID 16830)
-- Name: attribute_precedence_rules attribute_precedence_rules_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.attribute_precedence_rules
    ADD CONSTRAINT attribute_precedence_rules_pkey PRIMARY KEY (precedence_rule_id);


--
-- TOC entry 5052 (class 2606 OID 16963)
-- Name: audit_events audit_events_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.audit_events
    ADD CONSTRAINT audit_events_pkey PRIMARY KEY (audit_event_id);


--
-- TOC entry 5027 (class 2606 OID 16812)
-- Name: client_cluster_members client_cluster_members_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.client_cluster_members
    ADD CONSTRAINT client_cluster_members_pkey PRIMARY KEY (cluster_id, client_id);


--
-- TOC entry 5025 (class 2606 OID 16806)
-- Name: client_clusters client_clusters_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.client_clusters
    ADD CONSTRAINT client_clusters_pkey PRIMARY KEY (cluster_id);


--
-- TOC entry 4990 (class 2606 OID 16602)
-- Name: client_data_lineage client_data_lineage_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.client_data_lineage
    ADD CONSTRAINT client_data_lineage_pkey PRIMARY KEY (lineage_id);


--
-- TOC entry 5041 (class 2606 OID 16889)
-- Name: client_operational_state client_operational_state_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.client_operational_state
    ADD CONSTRAINT client_operational_state_pkey PRIMARY KEY (state_id);


--
-- TOC entry 5037 (class 2606 OID 16875)
-- Name: client_regulatory_enrichment client_regulatory_enrichment_client_id_key; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.client_regulatory_enrichment
    ADD CONSTRAINT client_regulatory_enrichment_client_id_key UNIQUE (client_id);


--
-- TOC entry 5039 (class 2606 OID 16873)
-- Name: client_regulatory_enrichment client_regulatory_enrichment_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.client_regulatory_enrichment
    ADD CONSTRAINT client_regulatory_enrichment_pkey PRIMARY KEY (enrichment_id);


--
-- TOC entry 5044 (class 2606 OID 16904)
-- Name: client_source_coverage client_source_coverage_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.client_source_coverage
    ADD CONSTRAINT client_source_coverage_pkey PRIMARY KEY (client_id, source_system_id);


--
-- TOC entry 4967 (class 2606 OID 16468)
-- Name: clients clients_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.clients
    ADD CONSTRAINT clients_pkey PRIMARY KEY (id);


--
-- TOC entry 4984 (class 2606 OID 16537)
-- Name: corporate_kyc_info corporate_kyc_info_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.corporate_kyc_info
    ADD CONSTRAINT corporate_kyc_info_pkey PRIMARY KEY (corporate_kyc_id);


--
-- TOC entry 4988 (class 2606 OID 16582)
-- Name: corporate_trade_history corporate_trade_history_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.corporate_trade_history
    ADD CONSTRAINT corporate_trade_history_pkey PRIMARY KEY (trade_id);


--
-- TOC entry 4992 (class 2606 OID 16614)
-- Name: country country_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.country
    ADD CONSTRAINT country_pkey PRIMARY KEY (country_id);


--
-- TOC entry 5061 (class 2606 OID 17017)
-- Name: crm_contacts crm_contacts_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.crm_contacts
    ADD CONSTRAINT crm_contacts_pkey PRIMARY KEY (id);


--
-- TOC entry 5049 (class 2606 OID 16948)
-- Name: evidence_artefacts evidence_artefacts_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.evidence_artefacts
    ADD CONSTRAINT evidence_artefacts_pkey PRIMARY KEY (artefact_id);


--
-- TOC entry 5046 (class 2606 OID 16923)
-- Name: evidence_bundles evidence_bundles_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.evidence_bundles
    ADD CONSTRAINT evidence_bundles_pkey PRIMARY KEY (evidence_bundle_id);


--
-- TOC entry 5000 (class 2606 OID 16681)
-- Name: ingestion_runs ingestion_runs_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.ingestion_runs
    ADD CONSTRAINT ingestion_runs_pkey PRIMARY KEY (ingestion_run_id);


--
-- TOC entry 4978 (class 2606 OID 16496)
-- Name: kyc_flags kyc_flags_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.kyc_flags
    ADD CONSTRAINT kyc_flags_pkey PRIMARY KEY (id);


--
-- TOC entry 5023 (class 2606 OID 16780)
-- Name: match_decisions match_decisions_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.match_decisions
    ADD CONSTRAINT match_decisions_pkey PRIMARY KEY (match_decision_id);


--
-- TOC entry 5019 (class 2606 OID 16771)
-- Name: match_runs match_runs_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.match_runs
    ADD CONSTRAINT match_runs_pkey PRIMARY KEY (match_run_id);


--
-- TOC entry 4994 (class 2606 OID 16621)
-- Name: risk_rating risk_rating_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.risk_rating
    ADD CONSTRAINT risk_rating_pkey PRIMARY KEY (risk_rating_id);


--
-- TOC entry 5059 (class 2606 OID 16998)
-- Name: service_error_logs service_error_logs_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.service_error_logs
    ADD CONSTRAINT service_error_logs_pkey PRIMARY KEY (error_log_id);


--
-- TOC entry 5056 (class 2606 OID 16988)
-- Name: service_health_checks service_health_checks_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.service_health_checks
    ADD CONSTRAINT service_health_checks_pkey PRIMARY KEY (health_check_id);


--
-- TOC entry 5015 (class 2606 OID 16748)
-- Name: source_field_mappings source_field_mappings_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.source_field_mappings
    ADD CONSTRAINT source_field_mappings_pkey PRIMARY KEY (mapping_id);


--
-- TOC entry 5017 (class 2606 OID 16750)
-- Name: source_field_mappings source_field_mappings_source_system_id_source_field_attribu_key; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.source_field_mappings
    ADD CONSTRAINT source_field_mappings_source_system_id_source_field_attribu_key UNIQUE (source_system_id, source_field, attribute_id);


--
-- TOC entry 5005 (class 2606 OID 16697)
-- Name: source_records_raw source_records_raw_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.source_records_raw
    ADD CONSTRAINT source_records_raw_pkey PRIMARY KEY (source_record_id);


--
-- TOC entry 4996 (class 2606 OID 16671)
-- Name: source_systems source_systems_code_key; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.source_systems
    ADD CONSTRAINT source_systems_code_key UNIQUE (code);


--
-- TOC entry 4998 (class 2606 OID 16669)
-- Name: source_systems source_systems_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.source_systems
    ADD CONSTRAINT source_systems_pkey PRIMARY KEY (source_system_id);


--
-- TOC entry 4982 (class 2606 OID 16512)
-- Name: transactions transactions_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.transactions
    ADD CONSTRAINT transactions_pkey PRIMARY KEY (id);


--
-- TOC entry 5063 (class 2606 OID 17019)
-- Name: crm_contacts uq_crm_contacts_source_key; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.crm_contacts
    ADD CONSTRAINT uq_crm_contacts_source_key UNIQUE (source_system, source_record_id);


--
-- TOC entry 5008 (class 2606 OID 16719)
-- Name: validation_results validation_results_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.validation_results
    ADD CONSTRAINT validation_results_pkey PRIMARY KEY (validation_result_id);


--
-- TOC entry 4972 (class 1259 OID 16485)
-- Name: ix_accounts_account_number; Type: INDEX; Schema: public; Owner: postgres
--

CREATE UNIQUE INDEX ix_accounts_account_number ON public.accounts USING btree (account_number);


--
-- TOC entry 4973 (class 1259 OID 16487)
-- Name: ix_accounts_client_id; Type: INDEX; Schema: public; Owner: postgres
--

CREATE INDEX ix_accounts_client_id ON public.accounts USING btree (client_id);


--
-- TOC entry 4974 (class 1259 OID 16486)
-- Name: ix_accounts_id; Type: INDEX; Schema: public; Owner: postgres
--

CREATE INDEX ix_accounts_id ON public.accounts USING btree (id);


--
-- TOC entry 5035 (class 1259 OID 16864)
-- Name: ix_attribute_conflicts_client; Type: INDEX; Schema: public; Owner: postgres
--

CREATE INDEX ix_attribute_conflicts_client ON public.attribute_conflicts USING btree (client_id, resolved);


--
-- TOC entry 5032 (class 1259 OID 16843)
-- Name: ix_attribute_precedence_attr; Type: INDEX; Schema: public; Owner: postgres
--

CREATE INDEX ix_attribute_precedence_attr ON public.attribute_precedence_rules USING btree (attribute_id, precedence_rank);


--
-- TOC entry 5053 (class 1259 OID 16979)
-- Name: ix_audit_events_client_time; Type: INDEX; Schema: public; Owner: postgres
--

CREATE INDEX ix_audit_events_client_time ON public.audit_events USING btree (client_id, occurred_at DESC);


--
-- TOC entry 5042 (class 1259 OID 16895)
-- Name: ix_client_operational_state_client_asof; Type: INDEX; Schema: public; Owner: postgres
--

CREATE INDEX ix_client_operational_state_client_asof ON public.client_operational_state USING btree (client_id, as_of DESC);


--
-- TOC entry 4968 (class 1259 OID 16470)
-- Name: ix_clients_external_id; Type: INDEX; Schema: public; Owner: postgres
--

CREATE UNIQUE INDEX ix_clients_external_id ON public.clients USING btree (external_id);


--
-- TOC entry 4969 (class 1259 OID 16469)
-- Name: ix_clients_id; Type: INDEX; Schema: public; Owner: postgres
--

CREATE INDEX ix_clients_id ON public.clients USING btree (id);


--
-- TOC entry 5050 (class 1259 OID 16954)
-- Name: ix_evidence_artefacts_bundle; Type: INDEX; Schema: public; Owner: postgres
--

CREATE INDEX ix_evidence_artefacts_bundle ON public.evidence_artefacts USING btree (evidence_bundle_id);


--
-- TOC entry 5047 (class 1259 OID 16939)
-- Name: ix_evidence_bundles_client_created; Type: INDEX; Schema: public; Owner: postgres
--

CREATE INDEX ix_evidence_bundles_client_created ON public.evidence_bundles USING btree (client_id, created_at DESC);


--
-- TOC entry 5001 (class 1259 OID 16687)
-- Name: ix_ingestion_runs_source_started; Type: INDEX; Schema: public; Owner: postgres
--

CREATE INDEX ix_ingestion_runs_source_started ON public.ingestion_runs USING btree (source_system_id, started_at DESC);


--
-- TOC entry 4975 (class 1259 OID 16503)
-- Name: ix_kyc_flags_client_id; Type: INDEX; Schema: public; Owner: postgres
--

CREATE INDEX ix_kyc_flags_client_id ON public.kyc_flags USING btree (client_id);


--
-- TOC entry 4976 (class 1259 OID 16502)
-- Name: ix_kyc_flags_id; Type: INDEX; Schema: public; Owner: postgres
--

CREATE INDEX ix_kyc_flags_id ON public.kyc_flags USING btree (id);


--
-- TOC entry 5020 (class 1259 OID 16797)
-- Name: ix_match_decisions_client; Type: INDEX; Schema: public; Owner: postgres
--

CREATE INDEX ix_match_decisions_client ON public.match_decisions USING btree (matched_client_id);


--
-- TOC entry 5021 (class 1259 OID 16796)
-- Name: ix_match_decisions_run; Type: INDEX; Schema: public; Owner: postgres
--

CREATE INDEX ix_match_decisions_run ON public.match_decisions USING btree (match_run_id);


--
-- TOC entry 5057 (class 1259 OID 16999)
-- Name: ix_service_error_logs_service_time; Type: INDEX; Schema: public; Owner: postgres
--

CREATE INDEX ix_service_error_logs_service_time ON public.service_error_logs USING btree (service_name, occurred_at DESC);


--
-- TOC entry 5054 (class 1259 OID 16989)
-- Name: ix_service_health_checks_service_time; Type: INDEX; Schema: public; Owner: postgres
--

CREATE INDEX ix_service_health_checks_service_time ON public.service_health_checks USING btree (service_name, checked_at DESC);


--
-- TOC entry 5013 (class 1259 OID 16761)
-- Name: ix_source_field_mappings_system; Type: INDEX; Schema: public; Owner: postgres
--

CREATE INDEX ix_source_field_mappings_system ON public.source_field_mappings USING btree (source_system_id);


--
-- TOC entry 5002 (class 1259 OID 16708)
-- Name: ix_source_records_raw_run; Type: INDEX; Schema: public; Owner: postgres
--

CREATE INDEX ix_source_records_raw_run ON public.source_records_raw USING btree (ingestion_run_id);


--
-- TOC entry 5003 (class 1259 OID 16709)
-- Name: ix_source_records_raw_system_key; Type: INDEX; Schema: public; Owner: postgres
--

CREATE INDEX ix_source_records_raw_system_key ON public.source_records_raw USING btree (source_system_id, source_record_key);


--
-- TOC entry 4979 (class 1259 OID 16519)
-- Name: ix_transactions_account_id; Type: INDEX; Schema: public; Owner: postgres
--

CREATE INDEX ix_transactions_account_id ON public.transactions USING btree (account_id);


--
-- TOC entry 4980 (class 1259 OID 16518)
-- Name: ix_transactions_id; Type: INDEX; Schema: public; Owner: postgres
--

CREATE INDEX ix_transactions_id ON public.transactions USING btree (id);


--
-- TOC entry 5006 (class 1259 OID 16725)
-- Name: ix_validation_results_record; Type: INDEX; Schema: public; Owner: postgres
--

CREATE INDEX ix_validation_results_record ON public.validation_results USING btree (source_record_id);


--
-- TOC entry 5064 (class 2606 OID 16480)
-- Name: accounts accounts_client_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.accounts
    ADD CONSTRAINT accounts_client_id_fkey FOREIGN KEY (client_id) REFERENCES public.clients(id);


--
-- TOC entry 5084 (class 2606 OID 16859)
-- Name: attribute_conflicts attribute_conflicts_attribute_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.attribute_conflicts
    ADD CONSTRAINT attribute_conflicts_attribute_id_fkey FOREIGN KEY (attribute_id) REFERENCES public.attribute_dictionary(attribute_id);


--
-- TOC entry 5085 (class 2606 OID 16854)
-- Name: attribute_conflicts attribute_conflicts_client_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.attribute_conflicts
    ADD CONSTRAINT attribute_conflicts_client_id_fkey FOREIGN KEY (client_id) REFERENCES public.clients(id) ON DELETE CASCADE;


--
-- TOC entry 5082 (class 2606 OID 16833)
-- Name: attribute_precedence_rules attribute_precedence_rules_attribute_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.attribute_precedence_rules
    ADD CONSTRAINT attribute_precedence_rules_attribute_id_fkey FOREIGN KEY (attribute_id) REFERENCES public.attribute_dictionary(attribute_id);


--
-- TOC entry 5083 (class 2606 OID 16838)
-- Name: attribute_precedence_rules attribute_precedence_rules_source_system_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.attribute_precedence_rules
    ADD CONSTRAINT attribute_precedence_rules_source_system_id_fkey FOREIGN KEY (source_system_id) REFERENCES public.source_systems(source_system_id);


--
-- TOC entry 5094 (class 2606 OID 16964)
-- Name: audit_events audit_events_client_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.audit_events
    ADD CONSTRAINT audit_events_client_id_fkey FOREIGN KEY (client_id) REFERENCES public.clients(id) ON DELETE SET NULL;


--
-- TOC entry 5095 (class 2606 OID 16974)
-- Name: audit_events audit_events_evidence_bundle_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.audit_events
    ADD CONSTRAINT audit_events_evidence_bundle_id_fkey FOREIGN KEY (evidence_bundle_id) REFERENCES public.evidence_bundles(evidence_bundle_id) ON DELETE SET NULL;


--
-- TOC entry 5096 (class 2606 OID 16969)
-- Name: audit_events audit_events_source_record_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.audit_events
    ADD CONSTRAINT audit_events_source_record_id_fkey FOREIGN KEY (source_record_id) REFERENCES public.source_records_raw(source_record_id) ON DELETE SET NULL;


--
-- TOC entry 5080 (class 2606 OID 16818)
-- Name: client_cluster_members client_cluster_members_client_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.client_cluster_members
    ADD CONSTRAINT client_cluster_members_client_id_fkey FOREIGN KEY (client_id) REFERENCES public.clients(id) ON DELETE CASCADE;


--
-- TOC entry 5081 (class 2606 OID 16813)
-- Name: client_cluster_members client_cluster_members_cluster_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.client_cluster_members
    ADD CONSTRAINT client_cluster_members_cluster_id_fkey FOREIGN KEY (cluster_id) REFERENCES public.client_clusters(cluster_id) ON DELETE CASCADE;


--
-- TOC entry 5070 (class 2606 OID 16603)
-- Name: client_data_lineage client_data_lineage_client_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.client_data_lineage
    ADD CONSTRAINT client_data_lineage_client_id_fkey FOREIGN KEY (client_id) REFERENCES public.clients(id) ON DELETE CASCADE;


--
-- TOC entry 5087 (class 2606 OID 16890)
-- Name: client_operational_state client_operational_state_client_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.client_operational_state
    ADD CONSTRAINT client_operational_state_client_id_fkey FOREIGN KEY (client_id) REFERENCES public.clients(id) ON DELETE CASCADE;


--
-- TOC entry 5086 (class 2606 OID 16876)
-- Name: client_regulatory_enrichment client_regulatory_enrichment_client_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.client_regulatory_enrichment
    ADD CONSTRAINT client_regulatory_enrichment_client_id_fkey FOREIGN KEY (client_id) REFERENCES public.clients(id) ON DELETE CASCADE;


--
-- TOC entry 5088 (class 2606 OID 16905)
-- Name: client_source_coverage client_source_coverage_client_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.client_source_coverage
    ADD CONSTRAINT client_source_coverage_client_id_fkey FOREIGN KEY (client_id) REFERENCES public.clients(id) ON DELETE CASCADE;


--
-- TOC entry 5089 (class 2606 OID 16910)
-- Name: client_source_coverage client_source_coverage_source_system_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.client_source_coverage
    ADD CONSTRAINT client_source_coverage_source_system_id_fkey FOREIGN KEY (source_system_id) REFERENCES public.source_systems(source_system_id);


--
-- TOC entry 5067 (class 2606 OID 16538)
-- Name: corporate_kyc_info corporate_kyc_info_client_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.corporate_kyc_info
    ADD CONSTRAINT corporate_kyc_info_client_id_fkey FOREIGN KEY (client_id) REFERENCES public.clients(id);


--
-- TOC entry 5068 (class 2606 OID 16588)
-- Name: corporate_trade_history corporate_trade_history_asset_class_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.corporate_trade_history
    ADD CONSTRAINT corporate_trade_history_asset_class_id_fkey FOREIGN KEY (asset_class_id) REFERENCES public.asset_class(asset_class_id);


--
-- TOC entry 5069 (class 2606 OID 16583)
-- Name: corporate_trade_history corporate_trade_history_client_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.corporate_trade_history
    ADD CONSTRAINT corporate_trade_history_client_id_fkey FOREIGN KEY (client_id) REFERENCES public.clients(id);


--
-- TOC entry 5093 (class 2606 OID 16949)
-- Name: evidence_artefacts evidence_artefacts_evidence_bundle_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.evidence_artefacts
    ADD CONSTRAINT evidence_artefacts_evidence_bundle_id_fkey FOREIGN KEY (evidence_bundle_id) REFERENCES public.evidence_bundles(evidence_bundle_id) ON DELETE CASCADE;


--
-- TOC entry 5090 (class 2606 OID 16924)
-- Name: evidence_bundles evidence_bundles_client_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.evidence_bundles
    ADD CONSTRAINT evidence_bundles_client_id_fkey FOREIGN KEY (client_id) REFERENCES public.clients(id) ON DELETE CASCADE;


--
-- TOC entry 5091 (class 2606 OID 16929)
-- Name: evidence_bundles evidence_bundles_ingestion_run_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.evidence_bundles
    ADD CONSTRAINT evidence_bundles_ingestion_run_id_fkey FOREIGN KEY (ingestion_run_id) REFERENCES public.ingestion_runs(ingestion_run_id) ON DELETE SET NULL;


--
-- TOC entry 5092 (class 2606 OID 16934)
-- Name: evidence_bundles evidence_bundles_match_run_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.evidence_bundles
    ADD CONSTRAINT evidence_bundles_match_run_id_fkey FOREIGN KEY (match_run_id) REFERENCES public.match_runs(match_run_id) ON DELETE SET NULL;


--
-- TOC entry 5071 (class 2606 OID 16682)
-- Name: ingestion_runs ingestion_runs_source_system_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.ingestion_runs
    ADD CONSTRAINT ingestion_runs_source_system_id_fkey FOREIGN KEY (source_system_id) REFERENCES public.source_systems(source_system_id);


--
-- TOC entry 5065 (class 2606 OID 16497)
-- Name: kyc_flags kyc_flags_client_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.kyc_flags
    ADD CONSTRAINT kyc_flags_client_id_fkey FOREIGN KEY (client_id) REFERENCES public.clients(id);


--
-- TOC entry 5077 (class 2606 OID 16781)
-- Name: match_decisions match_decisions_match_run_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.match_decisions
    ADD CONSTRAINT match_decisions_match_run_id_fkey FOREIGN KEY (match_run_id) REFERENCES public.match_runs(match_run_id) ON DELETE CASCADE;


--
-- TOC entry 5078 (class 2606 OID 16791)
-- Name: match_decisions match_decisions_matched_client_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.match_decisions
    ADD CONSTRAINT match_decisions_matched_client_id_fkey FOREIGN KEY (matched_client_id) REFERENCES public.clients(id);


--
-- TOC entry 5079 (class 2606 OID 16786)
-- Name: match_decisions match_decisions_source_record_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.match_decisions
    ADD CONSTRAINT match_decisions_source_record_id_fkey FOREIGN KEY (source_record_id) REFERENCES public.source_records_raw(source_record_id) ON DELETE CASCADE;


--
-- TOC entry 5075 (class 2606 OID 16756)
-- Name: source_field_mappings source_field_mappings_attribute_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.source_field_mappings
    ADD CONSTRAINT source_field_mappings_attribute_id_fkey FOREIGN KEY (attribute_id) REFERENCES public.attribute_dictionary(attribute_id);


--
-- TOC entry 5076 (class 2606 OID 16751)
-- Name: source_field_mappings source_field_mappings_source_system_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.source_field_mappings
    ADD CONSTRAINT source_field_mappings_source_system_id_fkey FOREIGN KEY (source_system_id) REFERENCES public.source_systems(source_system_id);


--
-- TOC entry 5072 (class 2606 OID 16698)
-- Name: source_records_raw source_records_raw_ingestion_run_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.source_records_raw
    ADD CONSTRAINT source_records_raw_ingestion_run_id_fkey FOREIGN KEY (ingestion_run_id) REFERENCES public.ingestion_runs(ingestion_run_id) ON DELETE CASCADE;


--
-- TOC entry 5073 (class 2606 OID 16703)
-- Name: source_records_raw source_records_raw_source_system_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.source_records_raw
    ADD CONSTRAINT source_records_raw_source_system_id_fkey FOREIGN KEY (source_system_id) REFERENCES public.source_systems(source_system_id);


--
-- TOC entry 5066 (class 2606 OID 16513)
-- Name: transactions transactions_account_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.transactions
    ADD CONSTRAINT transactions_account_id_fkey FOREIGN KEY (account_id) REFERENCES public.accounts(id);


--
-- TOC entry 5074 (class 2606 OID 16720)
-- Name: validation_results validation_results_source_record_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: postgres
--

ALTER TABLE ONLY public.validation_results
    ADD CONSTRAINT validation_results_source_record_id_fkey FOREIGN KEY (source_record_id) REFERENCES public.source_records_raw(source_record_id) ON DELETE CASCADE;


-- Completed on 2026-01-02 19:40:24

--
-- PostgreSQL database dump complete
--



===== FILE: docs\mission_destination\epics\E00_application_bootstrapping.md =====
---
epic_id: E00
slug: e00_application_bootstrapping
name: "Backend Foundation"

features:
  - FT-00-BE



overall_status: Complete

last_updated: 2025-12-31T21:07:49Z

---

## Context

This epic delivers the minimal backend scaffolding needed for developers to
build, run, and verify the Single Client View application.

## Objectives

- Backend starts reliably in a developer environment.
- At least one health/status endpoint is available.
- Code adheres to MissionFramework guardrails.
- Story-level test status is automatically updated.

## Acceptance

- All features under this epic have status `active` or `done`.
- All related stories have `testing_status: pass`.



===== FILE: docs\mission_destination\epics\E00_ui_bootstrapping.md =====
---
epic_id: E00-UI
slug: e00_ui_bootstrapping
name: "User Interface Foundation"

features:
  - FT-00-UI



overall_status: Complete

last_updated: 2025-12-31T21:43:01Z
---




\## Context



This epic delivers the minimal frontend scaffolding needed for the Single

Client Value UI to build, load in a browser, and render predictable output.



\## Objectives



\- Frontend builds without errors.

\- App renders a visible indicator confirming it is running.

\- Tests validate this behaviour.



\## Acceptance



\- All related features are `active` or `done`.

\- All related stories have `test\_status: passed`.





===== FILE: docs\mission_destination\epics\E01_client_ingestion_and_normalisation.md =====
---
epic_id: EP-01
name: "Client Ingestion & Normalisation"
description: |
  This epic delivers the capability to ingest client data from multiple internal
  systems (CRM, KYC, onboarding, trading) and normalise it into a single
  canonical client model. It ensures consistent formats, data types, and field
  structures across all sources. This is the pipeline that feeds the SCV engine
  with reliable, usable data.

features:
  - FT-01
  - FT-02
  - FT-03
  - FT-04



overall_status: Planned


last_updated: 2025-12-31T21:49:15Z
---


===== FILE: docs\mission_destination\epics\E02_client_matching_and_golden_record.md =====
---
epic_id: EP-02
name: "Client Matching & Golden Record"
description: |
  This epic establishes the rules and logic for matching client records across
  systems, resolving duplicates, and building the authoritative golden record.
  Includes exact and fuzzy matching, conflict resolution, and merge lineage.
  The output becomes the Single Client View master profile.

features:
  - FT-05
  - FT-06
  - FT-07



overall_status: Planned


last_updated: 2025-12-21T15:22:46Z
---


===== FILE: docs\mission_destination\epics\E03_client_search.md =====
---
epic_id: EP-03
name: "Client Search"
description: |
  This epic provides search capabilities for finding clients based on names,
  identifiers, partial information, or attributes. It includes indexing,
  relevance ranking, fuzzy matching, and result scoring. Search is the primary
  user entry point into the Single Client View.

features:
  - FT-08
  - FT-09



overall_status: Planned


last_updated: 2025-12-21T15:22:46Z
---


===== FILE: docs\mission_destination\epics\E04_client_profile_assembly.md =====
---
epic_id: EP-04
name: "Client Profile Assembly"
description: |
  This epic assembles the unified client profile from the golden record,
  including core identity, operational attributes, source lineage, and data
  quality indicators. It defines how attribute-level provenance is exposed and
  how conflicting information is presented.

features:
  - FT-10
  - FT-11
  - FT-12



overall_status: In Progress


last_updated: 2025-12-21T16:55:21Z
---


===== FILE: docs\mission_destination\epics\E05_data_quality_and_lineage.md =====
---
epic_id: EP-05
name: "Data Quality & Lineage"
description: |
  This epic delivers attribute-level lineage tracking, data freshness indicators,
  quality scoring, conflict flags, and auditability. It ensures every attribute
  in the SCV profile can be traced back to its original source system with full
  transparency.

features:
  - FT-13
  - FT-14
  - FT-15



overall_status: Planned


last_updated: 2025-12-21T15:22:46Z
---


===== FILE: docs\mission_destination\epics\E06_api_and_integration.md =====
---
epic_id: EP-06
name: "Integration & API Exposure"
description: |
  This epic exposes the SCV capabilities to other systems via APIs. Includes
  search endpoints, client profile retrieval, and interface contracts for
  internal consumers. Ensures consistent, secure, and performant access to the
  Single Client View.

features:
  - FT-16
  - FT-17



overall_status: Planned


last_updated: 2025-12-21T15:22:46Z
---


===== FILE: docs\mission_destination\features\FT-00-backend_fundamentals.md =====
---
feature_id: FT-00-BE
epic: E00
name: "Backend Foundation"
description: |
  Establish the initial backend service and runtime foundations required for the
  Single Client View application to start, respond to basic requests, and be
  governed by MissionFramework guardrails. This feature delivers a minimal,
  reliable API surface that other stories can build on.

stories:
  - ST-00



overall_status: Complete

last_updated: 2025-12-31T21:07:49Z
---



===== FILE: docs\mission_destination\features\FT-00-frontend_fundamentals.md =====
---
feature_id: FT-00-UI
epic: E00-UI
name: "User Interface Foundation"
description: |
  Provide a minimal frontend shell that builds, loads, renders, and verifies
  that the baseline UI is operational.

stories:
  - ST-00-FRONTEND-UI-SHELL



overall_status: Complete

last_updated: 2025-12-31T21:43:01Z


---



\## Scope



\- Frontend build and dev server.

\- Root React component and layout shell.

\- Visible indicator that the UI is running.



\## Out of Scope



\- Domain UI for Single Client Value.

\- Search, profile, lineage, or matching components.





===== FILE: docs\mission_destination\features\FT-01_source_system_config.md =====
---
feature_id: FT-01
epic: EP-01
name: "Source System Configuration"
description: |
  Configure each upstream client data source, including credentials, endpoints,
  schema discovery, and scheduling parameters. Enables SCV to pull structured
  data from CRM, KYC, onboarding, and trading systems.

stories:
  - ST-01
  - ST-02



overall_status: Planned


last_updated: 2025-12-21T15:22:45Z
---


===== FILE: docs\mission_destination\features\FT-02_schema_mapping.md =====
---
feature_id: FT-02
epic: EP-01
name: "Schema Mapping to Canonical Model"
description: |
  Map source-system client schemas into SCVâ€™s canonical schema, including
  identity fields, contact details, identifiers, and operational attributes.

stories:
  - ST-03
  - ST-04



overall_status: Planned


last_updated: 2025-12-31T21:49:15Z
---


===== FILE: docs\mission_destination\features\FT-03_initial_bulk_ingestion.md =====
---
feature_id: FT-03
epic: EP-01
name: "Data Ingestion"
description: |
  Loading of all client records from each upstream
  system. Includes batching, error handling, and ingestion evidence.

stories:
  - ST-05
  - ST-06



overall_status: Planned


last_updated: 2025-12-31T21:49:15Z
---


===== FILE: docs\mission_destination\features\FT-04_incremental_ingestion.md =====
---
feature_id: FT-04
epic: EP-01
name: "Incremental Ingestion & Change Detection"
description: |
  Implement scheduled or event-driven incremental updates, detecting changes in
  upstream systems and applying deltas to SCVâ€™s internal store.

stories:
  - ST-07
  - ST-08



overall_status: Planned


last_updated: 2025-12-21T15:22:45Z
---


===== FILE: docs\mission_destination\features\FT-05_exact_matching.md =====
---
feature_id: FT-05
epic: EP-02
name: "Exact Match Rules"
description: |
  Implement deterministic matching rules based on unique identifiers such as
  client ID, company registration number, tax ID, and email address.

stories:
  - ST-09
  - ST-10



overall_status: Planned


last_updated: 2025-12-21T15:22:45Z
---


===== FILE: docs\mission_destination\features\FT-06_fuzzy_matching.md =====
---
feature_id: FT-06
epic: EP-02
name: "Fuzzy & Probabilistic Matching"
description: |
  Implement relevance-based matching using name similarity, token distance, and
  attribute-level confidence scoring.

stories:
  - ST-11
  - ST-12



overall_status: Planned


last_updated: 2025-12-21T15:22:45Z
---


===== FILE: docs\mission_destination\features\FT-07_golden_record_merge.md =====
---
feature_id: FT-07
epic: EP-02
name: "Golden Record Construction"
description: |
  Apply merge rules across conflicting source attributes, selecting canonical
  values and recording lineage for each field.

stories:
  - ST-13
  - ST-14
  - ST-15



overall_status: Planned


last_updated: 2025-12-21T15:22:45Z
---


===== FILE: docs\mission_destination\features\FT-08_search_indexing.md =====
---
feature_id: FT-08
epic: EP-03
name: "Search Index & Normalisation"
description: |
  Build a performant search index for names, identifiers, and attributes.

stories:
  - ST-16
  - ST-17



overall_status: Planned


last_updated: 2025-12-21T15:22:45Z
---


===== FILE: docs\mission_destination\features\FT-09_fuzzy_search.md =====
---
feature_id: FT-09
epic: EP-03
name: "Fuzzy Search & Ranking"
description: |
  Provide fuzzy search, relevance ranking, and partial-match scoring.

stories:
  - ST-18
  - ST-19



overall_status: Planned


last_updated: 2025-12-21T15:22:45Z
---


===== FILE: docs\mission_destination\features\FT-10_profile_assembly.md =====
---
feature_id: FT-10
epic: EP-04
name: "Assemble Canonical Profile"
description: |
  Construct the unified client profile including identity, identifiers,
  operational attributes, and metadata.

stories:
  - ST-20
  - ST-21



overall_status: In Progress


last_updated: 2025-12-21T16:55:21Z
---


===== FILE: docs\mission_destination\features\FT-11_lineage_exposure.md =====
---
feature_id: FT-11
epic: EP-04
name: "Lineage Exposure"
description: |
  Display attribute-level provenance showing which source system contributed
  each value.

stories:
  - ST-22
  - ST-23



overall_status: Planned


last_updated: 2025-12-21T15:22:46Z
---


===== FILE: docs\mission_destination\features\FT-12_conflict_presentation.md =====
---
feature_id: FT-12
epic: EP-04
name: "Conflict Presentation"
description: |
  Highlight conflicting source attributes, display confidence scores, and show
  merge logic outcomes.

stories:
  - ST-24
  - ST-25



overall_status: Planned


last_updated: 2025-12-21T15:22:46Z
---


===== FILE: docs\mission_destination\features\FT-13_lineage_tracking.md =====
---
feature_id: FT-13
epic: EP-05
name: "Lineage Tracking"
description: |
  Track attribute-level lineage with timestamped provenance and update history.

stories:
  - ST-26
  - ST-27



overall_status: Planned


last_updated: 2025-12-21T15:22:46Z
---


===== FILE: docs\mission_destination\features\FT-14_quality_scoring.md =====
---
feature_id: FT-14
epic: EP-05
name: "Data Quality Scoring"
description: |
  Compute quality indicators including completeness, consistency, and
  freshness scores.

stories:
  - ST-28
  - ST-29



overall_status: Planned


last_updated: 2025-12-21T15:22:46Z
---


===== FILE: docs\mission_destination\features\FT-15_auditability.md =====
---
feature_id: FT-15
epic: EP-05
name: "Auditability & Evidence"
description: |
  Generate audit logs for ingestion, matching, merging, and profile assembly,
  and store evidence snapshots.

stories:
  - ST-30
  - ST-31



overall_status: Planned


last_updated: 2025-12-21T15:22:46Z
---


===== FILE: docs\mission_destination\features\FT-16_search_api.md =====
---
feature_id: FT-16
epic: EP-06
name: "Search API"
description: |
  Expose a REST endpoint for searching clients by name, identifier, or
  attributes. Includes pagination and ranked results.

stories:
  - ST-32
  - ST-33



overall_status: Planned


last_updated: 2025-12-21T15:22:46Z
---


===== FILE: docs\mission_destination\features\FT-17_profile_api.md =====
---
feature_id: FT-17
epic: EP-06
name: "Client Profile API"
description: |
  Expose the canonical client profile via REST, including full lineage metadata
  and data quality indicators.

stories:
  - ST-34
  - ST-35



overall_status: Planned


last_updated: 2025-12-21T15:22:46Z
---


===== FILE: docs\mission_destination\initial_database_schema.txt =====
# Initial Database Schema (SCV)

**MissionDestination**  
**Single Client View (SCV)**

---

## 1. Purpose

This document describes the **initial physical database schema** used by the SCV application.

It defines:
- the core tables present in the MVP database
- their primary keys and relationships
- how logical entities are realised physically

This artefact is:
- storage-specific (PostgreSQL)
- descriptive of the current MVP state
- authoritative for SQL generation

It does **not** define business semantics.  
The **Initial Logical Data Model** remains the semantic authority.

---

## 2. Relationship to the Logical Data Model

- Logical entities may be realised across multiple tables
- Physical structure may evolve independently of semantics
- All schema usage must conform to the logical data model

---

## 3. Core Tables

### 3.1 `clients`

Represents the core client record and anchors the internal SCV identifier.

**Primary key**
- `client_id`

**Key columns**
- `client_id`
- `name`
- `email`
- `country`
- `created_at`
- `updated_at`

**Logical alignment**
- Canonical client identity attributes

---

### 3.2 `client_identifiers`

Stores identifiers associated with a client from upstream systems.

**Primary key**
- `id`

**Foreign keys**
- `client_id` â†’ `clients.client_id`

**Key columns**
- `client_id`
- `system`
- `value`

**Logical alignment**
- External identifiers associated with a client

---

### 3.3 `client_addresses`

Stores address records associated with a client.

**Primary key**
- `id`

**Foreign keys**
- `client_id` â†’ `clients.client_id`

**Key columns**
- `client_id`
- `line1`
- `line2`
- `city`
- `postcode`
- `country`
- `source`

**Logical alignment**
- Normalised address objects

---

## 4. Supporting Tables

The following tables exist in the MVP database and support additional capabilities:

### 4.1 `match_decisions`
- Stores matching outcomes and confidence scores

### 4.2 `evidence_artefacts`
- Stores evidence payloads for auditability and traceability

### 4.3 Audit tables
- Record operational and data-change events

These tables are described at a high level only; detailed usage is defined by stories.

---

## 5. Change Control

- This document reflects the current MVP schema
- Schema changes must be:
  - explicitly documented
  - reviewed for logical model alignment
- Existing behaviours must not be silently broken

---

**End of document**


===== FILE: docs\mission_destination\initial_logical_data_model.json =====
{
  "artifact_type": "logical_data_model",
  "artifact_version": "1.0",
  "model_name": "Initial Logical Data Model (LDM)",
  "mission": "Single Client View (SCV)",
  "source": {
    "authority": "MissionDestination",
    "derived_from": "docs/mission_destination/initial_logical_data_model.md"
  },
  "entities": [
    {
      "entity": "ClientProfile",
      "description": "Represents the unified, deduplicated profile of a client.",
      "fields": [
        { "name": "client_id", "type": "str", "description": "Internal SCV identifier" },
        { "name": "name", "type": "str", "description": "Canonical client name" },
        { "name": "email", "type": "Optional[str]", "description": "Canonical email" },
        { "name": "country", "type": "Optional[str]", "description": "Country associated with the client" },
        { "name": "identifiers", "type": "List[ClientIdentifier]", "description": "Identifiers from upstream systems" },
        { "name": "addresses", "type": "List[ClientAddress]", "description": "Normalised address objects" },
        { "name": "lineage", "type": "Dict[str, Any]", "description": "Provenance metadata" },
        { "name": "quality", "type": "Dict[str, float]", "description": "Freshness, completeness, confidence" },
        { "name": "metadata", "type": "Dict[str, str]", "description": "Timestamps, merge strategies, flags" },
        { "name": "raw_sources", "type": "Dict[str, Dict[str, Any]]", "description": "Raw source payloads" }
      ],
      "relationships": [
        { "type": "contains_many", "to": "ClientIdentifier", "via_field": "identifiers" },
        { "type": "contains_many", "to": "ClientAddress", "via_field": "addresses" }
      ]
    },
    {
      "entity": "ClientIdentifier",
      "description": "Identifier associated with a client from an upstream system.",
      "fields": [
        { "name": "system", "type": "str", "description": "Upstream system name" },
        { "name": "value", "type": "str", "description": "Identifier in that system" }
      ],
      "relationships": []
    },
    {
      "entity": "ClientAddress",
      "description": "Normalised address object associated with a client.",
      "fields": [
        { "name": "line1", "type": "Optional[str]", "description": "Address line 1" },
        { "name": "line2", "type": "Optional[str]", "description": "Address line 2" },
        { "name": "city", "type": "Optional[str]", "description": "City" },
        { "name": "postcode", "type": "Optional[str]", "description": "Postal code" },
        { "name": "country", "type": "Optional[str]", "description": "ISO country" },
        { "name": "source", "type": "Optional[str]", "description": "System contributing the address" }
      ],
      "relationships": []
    }
  ]
}


===== FILE: docs\mission_destination\initial_logical_data_model.md =====
# Initial Logical Data Model (LDM)
**MissionDestination**
**Single Client View (SCV)**

## 1. Purpose
This document defines the **Initial Logical Data Model** for the Single Client View (SCV) application.
It establishes the **canonical semantic representation of a client**, which all ingestion,
normalisation, matching, merging, lineage, quality, and API features will converge toward.

The Initial Logical Data Model is:
- technology-agnostic
- storage-agnostic
- canonical across all source systems
- stable across all Stories
- the semantic target for the behaviours defined in Epics, Features, and Stories

It is **not** a physical database schema.  
It is the logical definition of what a â€œclientâ€ means inside the SCV domain.

## 2. Canonical Entities

### 2.1 ClientProfile
Represents the unified, deduplicated profile of a client.

| Field | Type | Description |
|-------|------|-------------|
| client_id | str | Internal SCV identifier |
| name | str | Canonical client name |
| email | Optional[str] | Canonical email |
| country | Optional[str] | Country associated with the client |
| identifiers | List[ClientIdentifier] | Identifiers from upstream systems |
| addresses | List[ClientAddress] | Normalised address objects |
| lineage | Dict[str, Any] | Provenance metadata |
| quality | Dict[str, float] | Freshness, completeness, confidence |
| metadata | Dict[str, str] | Timestamps, merge strategies, flags |
| raw_sources | Dict[str, Dict[str, Any]] | Raw source payloads |

### 2.2 ClientIdentifier
| Field | Type | Description |
|-------|------|-------------|
| system | str | Upstream system name |
| value | str | Identifier in that system |

### 2.3 ClientAddress
| Field | Type | Description |
|-------|------|-------------|
| line1 | Optional[str] | Address line 1 |
| line2 | Optional[str] | Address line 2 |
| city | Optional[str] | City |
| postcode | Optional[str] | Postal code |
| country | Optional[str] | ISO country |
| source | Optional[str] | System contributing the address |

## 3. Python Representation

```python
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any

@dataclass
class ClientIdentifier:
    system: str
    value: str

@dataclass
class ClientAddress:
    line1: Optional[str] = None
    line2: Optional[str] = None
    city: Optional[str] = None
    postcode: Optional[str] = None
    country: Optional[str] = None
    source: Optional[str] = None

@dataclass
class ClientProfile:
    client_id: str
    name: str

    email: Optional[str] = None
    country: Optional[str] = None

    identifiers: List[ClientIdentifier] = field(default_factory=list)
    addresses: List[ClientAddress] = field(default_factory=list)

    lineage: Dict[str, Any] = field(default_factory=dict)
    quality: Dict[str, float] = field(default_factory=dict)
    metadata: Dict[str, str] = field(default_factory=dict)

    raw_sources: Dict[str, Dict[str, Any]] = field(default_factory=dict)
```

## 4. Next Steps
- Add this model to `src/domain/models/client_profile.py`
- Keep structure stable through MVP
- Extend only if new Stories introduce semantic requirements


===== FILE: docs\mission_destination\initial_service_architecture.md =====
# Initial Service Architecture (SCV)

**MissionDestination**  
**Single Client View (SCV)**

---

## 1. Purpose

This document defines the **initial service architecture** for the Single Client View (SCV) application.

It establishes:
- the set of services that exist within the SCV domain
- the responsibilities and boundaries of each service
- rules governing data access and service interaction

This artefact represents **global design intent** and is:
- story-agnostic
- stable across the MVP
- authoritative for code placement and responsibility boundaries

It is consumed by:
- story meta-prompts
- test meta-prompts
- human and agent developers

---

## 2. Architectural Principles

1. **Single ownership of responsibility**  
   Each domain responsibility belongs to exactly one service.

2. **Explicit service boundaries**  
   Services interact only through defined APIs.

3. **Controlled database access**  
   Only services explicitly designated may access the database directly.

4. **No architectural redefinition at story level**  
   Stories are implemented within this architecture; they do not redefine it.

---

## 3. Services

### 3.1 Profile Service

**Responsibilities**
- Assemble and expose the canonical client profile
- Apply deterministic profile assembly logic
- Serve profile-related APIs

**Data access**
- Direct read access to client-related tables

**Does not perform**
- Matching
- Merging
- Search indexing
- Ingestion

---

### 3.2 Matching Service

**Responsibilities**
- Determine equivalence between client records
- Produce match decisions and confidence signals

**Data access**
- Direct read access to relevant tables

---

### 3.3 Ingestion Service

**Responsibilities**
- Ingest data from upstream source systems
- Persist raw payloads
- Maintain source system boundaries

**Data access**
- Direct write and read access to ingestion tables

---

### 3.4 Search Service

**Responsibilities**
- Build and maintain search indices
- Execute search queries and ranking logic

**Data access**
- Direct read access to indexed data

---

### 3.5 Lineage and Quality Service

**Responsibilities**
- Track data provenance
- Compute and persist data quality metrics

**Data access**
- Direct read and write access to lineage and quality tables

---

### 3.6 Backend for Frontend (BFF)

**Responsibilities**
- Aggregate backend service responses for frontend consumption
- Adapt backend APIs to frontend needs

**Constraints**
- Performs no business logic
- Performs no data assembly

**Data access**
- No direct database access

---

## 4. Service Interaction Rules

- Services communicate exclusively via APIs
- Services must not access tables owned by other services
- The BFF must not:
  - perform joins
  - apply business rules
  - compute quality or lineage

---

## 5. Change Control

- This document is expected to remain stable through the MVP
- Changes require explicit architectural justification
- All downstream artefacts must be validated against updates

---

**End of document**






===== FILE: docs\mission_destination\initial_story_sequence.md =====
\# Initial Story Sequence (SCV)

\*\*MissionDestination\*\*  

\*\*Single Client View (SCV)\*\*



---



\## 1. Purpose



This document defines the \*\*initial execution order for all Stories\*\* in the Single Client View (SCV) MissionDestination.



The ordering is derived from:



\- the SCV Epics and Features,

\- the Initial Logical Data Model (LDM),

\- dependency analysis across services and APIs,

\- and the need to build up capability incrementally in a stable way.



It is a \*\*MissionDestination artefact\*\*: it describes \*how the business semantics are best realised over time\*, not runtime performance (MissionDynamics).



This sequence underpins:



\- developer and agent workflows,

\- CI/test evolution,

\- and the progressive construction of the canonical SCV capability.



---



\## 2. Relationship to Other Artefacts



This Story Sequence should be read together with:



\- \*\*MissionFramework\*\* (technology guardrails, testing strategy, CI blueprint, policy-as-code)

\- \*\*Meta-prompts\*\* (code, test, CI)

\- \*\*Instruction prompts\*\* (how Stories are executed)

\- \*\*MissionDestination\*\*:

&nbsp; - Epics, Features, Stories

&nbsp; - Initial Logical Data Model (LDM)

\- \*\*Mission Build Plan\*\* (the overall step-by-step setup of the project)



The sequence assumes that:



1\. The repo structure exists.  

2\. MissionFramework and meta-prompts are in place.  

3\. The Initial Logical Data Model for SCV (`ClientProfile`, `ClientIdentifier`, `ClientAddress`) is defined.  



Only then is it valid to implement Stories in this order.



---



\## 3. Golden Story Sequence (MVP Build Order)



The following is the \*\*recommended implementation sequence\*\* for the SCV Stories.



Each entry references the Story ID; the Story definition remains the single source of truth for behaviour and acceptance criteria.



1\. \*\*ST-03 â€“ Map identity fields\*\*  

2\. \*\*ST-04 â€“ Map identifiers\*\*  

3\. \*\*ST-20 â€“ Assemble base profile\*\*  



4\. \*\*ST-09 â€“ Match by tax ID\*\*  

5\. \*\*ST-10 â€“ Match by registration number\*\*  



6\. \*\*ST-16 â€“ Build search index\*\*  

7\. \*\*ST-17 â€“ Normalise search fields\*\*  

8\. \*\*ST-32 â€“ Implement basic search API\*\*  



9\. \*\*ST-18 â€“ Implement fuzzy search queries\*\*  

10\. \*\*ST-19 â€“ Implement search ranking\*\*  



11\. \*\*ST-13 â€“ Merge identity attributes\*\*  

12\. \*\*ST-14 â€“ Merge addresses\*\*  

13\. \*\*ST-15 â€“ Record merge lineage\*\*  



14\. \*\*ST-21 â€“ Assemble profile metadata\*\*  

15\. \*\*ST-22 â€“ Expose lineage in profile\*\*  

16\. \*\*ST-24 â€“ Flag merge conflicts\*\*  

17\. \*\*ST-25 â€“ Present merge logic / rationale\*\*  



18\. \*\*ST-28 â€“ Compute data freshness\*\*  

19\. \*\*ST-29 â€“ Compute data completeness\*\*  

20\. \*\*ST-26 â€“ Store lineage history\*\*  

21\. \*\*ST-27 â€“ Timestamp lineage events\*\*  



22\. \*\*ST-07 â€“ Detect upstream deltas\*\*  

23\. \*\*ST-08 â€“ Apply upstream deltas to SCV\*\*  



24\. \*\*ST-05 â€“ Bulk load from CRM\*\*  

25\. \*\*ST-06 â€“ Bulk load from KYC\*\*  



26\. \*\*ST-33 â€“ Refine search API ranking\*\*  

27\. \*\*ST-34 â€“ Implement basic client profile API\*\*  

28\. \*\*ST-35 â€“ Expose lineage via client profile API\*\*  



29\. \*\*ST-11 â€“ Fuzzy name matching\*\*  

30\. \*\*ST-12 â€“ Attribute-level confidence scoring\*\*  

31\. \*\*ST-23 â€“ Lineage drill-down / field-level provenance\*\*  



32\. \*\*ST-30 â€“ Audit ingestion operations\*\*  

33\. \*\*ST-31 â€“ Audit merge operations\*\*  



34\. \*\*ST-01 â€“ Register CRM source system\*\*  

35\. \*\*ST-02 â€“ Register KYC source system\*\*



---



\## 4. Usage and Change Control



\- This sequence is the \*\*default build order\*\* for human developers and agents.  

\- No Story should be implemented \*\*significantly out of sequence\*\* without re-running dependency analysis.  

\- If the Story set changes (new Stories, retired Stories, structural changes to Epics/Features), this document \*\*must be updated\*\* to reflect the new ordering.  



For each Story:



1\. Read the Story definition under `docs/mission\_destination/stories/`.  

2\. Implement the corresponding code slice(s) in `src/` as per the code meta-prompt.  

3\. Implement the corresponding tests in `tests/` as per the test meta-prompt.  

4\. Ensure CI passes and MissionFramework guardrails are satisfied.  

5\. Only then move to the next Story in this sequence.



---





===== FILE: docs\mission_destination\stories\ST-00-backend-api-availability.md =====
---
story_id: ST-00
slug: st-00-backend-api-availability
name: Backend Foundation
epic: E00
feature: FT-00-BE

# MissionSmith Status Fields (used by CI + tools/*.py)
testing_status: pass
halo_adherence: pass
guardrail_adherence: pass
code_quality_adherence: pass
security_policy_adherence: pass
overall_status: Complete
policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run

# Global guardrails applicable to this Story


last_updated: 2025-12-31T21:07:49Z
---

# Provide Basic Backend API Availability

## Statement
As a platform owner, I want a basic backend API to be available so that the system can support the incremental delivery of client data capabilities in a controlled and extensible way.

## Description
This story establishes the foundational backend capability on which the entire platform depends. It confirms that the backend application is not merely runnable, but correctly structured to support enterprise-grade delivery across ingestion, processing, audit, and exposure use cases.

The backend will be implemented using a modern service architecture, with clear separation between routing, service logic, persistence, and configuration. Core infrastructure concerns such as application startup, dependency wiring, configuration loading, and error handling are to be validated.

The backend exposes initial API endpoints to demonstrate:
- request handling and routing
- structured request/response models
- consistent error behaviour
- environment-driven configuration
- health and readiness signalling

Persistence wired using the real database layer, ensuring that subsequent stories operate against a genuine persistence mechanism rather than mocks or stubs. This confirms that the backend is capable of supporting real data flows, controlled schema evolution, and transactional behaviour.

This story also validates that the backend can be:
- started locally in a development environment
- exercised via automated tests
- extended incrementally by subsequent stories without rework

All subsequent backend stories assume this capability as a prerequisite.

## Acceptance Criteria
- **Given** the backend application is started locally or in a deployed environment  
  **When** a basic API endpoint is invoked  
  **Then** the backend responds successfully with a structured response

- **Given** the backend application is running  
  **When** a health or readiness endpoint is accessed  
  **Then** the application reports itself as available and correctly initialised

- **Given** the backend configuration is invalid or incomplete  
  **When** the application starts  
  **Then** failures are surfaced clearly and prevent ambiguous or silent failure

- **Given** automated tests are executed  
  **When** backend functionality is exercised  
  **Then** the application behaves consistently across environments






===== FILE: docs\mission_destination\stories\ST-00-frontend-ui-shell.md =====
---
story_id: ST-00-FRONTEND-UI-SHELL
slug: st-00-frontend-ui-shell
name: User Interface Foundation
epic: E00-UI
feature: FT-00-UI

# MissionSmith Status Fields (used by CI + tools/*.py)
testing_status: pass
halo_adherence: pass
guardrail_adherence: pass
code_quality_adherence: pass
security_policy_adherence: pass
overall_status: Complete
policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: 2025-12-31T21:43:01Z
---

# Provide Frontend UI Shell

## Statement
As a platform owner, I want a frontend UI shell to be available so that delivered business functionality can be surfaced consistently and credibly as the platform evolves.

## Description
This story establishes the foundational frontend capability required to present platform functionality to users in a coherent and extensible way. It confirms that the frontend is not merely a static page, but a properly structured application capable of supporting complex, data-driven user journeys.

The frontend UI shell has been implemented using a modern component-based framework, with:
- a running application build and dev workflow
- a consistent layout and visual structure
- routing and navigation foundations
- reusable UI components and styling conventions

The UI shell provides defined integration points for backend services and has been wired to consume real data where appropriate, rather than relying on mock or placeholder responses. This ensures that the frontend is validated against real backend behaviour from the outset.

Core concerns such as:
- application startup
- dependency loading
- error handling
- environment configuration
- visual consistency

have been exercised and proven.

This story also establishes the structural container into which future stories will be rendered, including MissionLog, evidence panels, lineage views, and client profile screens. As such, it acts as the visual and interaction baseline for all subsequent frontend work.

All subsequent frontend stories assume the existence of this shell.

## Acceptance Criteria
- **Given** the frontend application is started  
  **When** a user accesses the application  
  **Then** the UI shell loads successfully without errors

- **Given** the UI shell is loaded  
  **When** navigation and layout elements are displayed  
  **Then** they provide a consistent structure for future feature integration

- **Given** the frontend build or configuration is invalid  
  **When** the application is started  
  **Then** errors are surfaced clearly and prevent ambiguous failure

- **Given** the frontend is connected to backend services  
  **When** real data is requested  
  **Then** responses are handled and rendered correctly







===== FILE: docs\mission_destination\stories\ST-01_register_crm_source.md =====
---
story_id: ST-01
feature: FT-01
name: "Register CRM source"
description: |
  Register CRM system as ingestible source.

acceptance_criteria:
  - Connection succeeds
  - Schema retrieved

overall_status: Planned

testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: <auto>
---
# Register CRM Source System

## Statement
As a data operations user, I want to register a CRM source system so that client data ingested from that system can be correctly identified, governed, and traced throughout the platform.

## Description
The platform must allow a CRM source system to be registered as an approved upstream data provider.  
Registering a CRM source system establishes it as a recognised origin for client data and enables downstream ingestion, mapping, matching, and lineage tracking.

The registration process captures the minimum information required to uniquely identify the CRM system and treat it as a governed source within the platform. Once registered, the CRM source system can be referenced consistently by ingestion and processing workflows.

## Acceptance Criteria
- **Given** a CRM source system has not previously been registered  
  **When** a data operations user registers the CRM source system  
  **Then** the system is stored as a recognised and active source

- **Given** a CRM source system is registered  
  **When** downstream processes reference the source  
  **Then** the system is identifiable as the origin of ingested client data

- **Given** an attempt is made to register a CRM source system with missing or invalid identifying information  
  **When** the registration is submitted  
  **Then** the registration is rejected with a clear validation error


===== FILE: docs\mission_destination\stories\ST-02_register_kyc_source.md =====
---
story_id: ST-02
feature: FT-01
name: "Register KYC source"
description: |
  Register KYC system.

acceptance_criteria:
  - Connection ok
  - Schema ok

overall_status: Planned

testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: <auto>
---
# Register KYC Source System

## Statement
As a compliance operations user, I want to register a KYC source system so that client due-diligence data can be ingested and governed with clear provenance.

## Description
The platform must support the registration of KYC source systems as approved providers of compliance and due-diligence data.  
Registering a KYC source system ensures that KYC data entering the platform can be traced back to its originating system and treated according to governance and compliance requirements.

Once registered, the KYC source system can be referenced by ingestion, enrichment, and profile assembly processes.

## Acceptance Criteria
- **Given** a KYC source system has not previously been registered  
  **When** a compliance operations user registers the KYC source system  
  **Then** the system is stored as a recognised and active KYC data source

- **Given** a KYC source system is registered  
  **When** KYC data is ingested  
  **Then** the data is associated with the registered source system

- **Given** invalid or incomplete registration details are provided  
  **When** the registration is attempted  
  **Then** the registration is rejected with a clear error message


===== FILE: docs\mission_destination\stories\ST-03_map_identity_fields.md =====
---
story_id: ST-03
feature: FT-02
name: "Map identity fields"
description: |
  Map core identity fields.

acceptance_criteria:
  - Fields mapped
  - Types correct

overall_status: Planned

testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: 2025-12-31T21:49:15Z
---
# Map Identity Fields

## Statement
As a data operations user, I want to map identity fields so that equivalent client attributes from different source systems can be normalised and compared consistently.

## Description
Client identity data may be provided by multiple source systems using different field names and structures.  
The platform must support mapping source-specific identity fields to a canonical representation so that identity information can be processed consistently across the platform.

Mapped identity fields form the basis for downstream matching, profile assembly, and lineage reporting.

## Acceptance Criteria
- **Given** identity fields exist in a source system  
  **When** identity field mappings are defined  
  **Then** the fields are mapped to the platformâ€™s canonical identity model

- **Given** identity mappings are defined  
  **When** client data is ingested  
  **Then** identity values are normalised according to the mappings

- **Given** a required identity field is unmapped  
  **When** identity processing is attempted  
  **Then** the issue is reported clearly


===== FILE: docs\mission_destination\stories\ST-04_map_identifiers.md =====
---
story_id: ST-04
feature: FT-02
name: "Map identifiers"
description: |
  Map identifiers.

acceptance_criteria:
  - ID mapping valid

overall_status: Planned

testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: 2025-12-31T21:49:15Z
---
# Map Identifiers

## Statement
As a data operations user, I want to map client identifiers so that records referring to the same real-world entity can be reliably linked across systems.

## Description
Different source systems may represent client identifiers using different formats or naming conventions.  
The platform must support mapping these identifiers to a canonical identifier model so that they can be compared and used reliably for matching and consolidation.

Correct identifier mapping is essential for accurate client matching and profile assembly.

## Acceptance Criteria
- **Given** identifier fields exist in a source system  
  **When** identifier mappings are defined  
  **Then** identifiers are mapped to the canonical identifier model

- **Given** identifier mappings are in place  
  **When** client records are processed  
  **Then** identifiers are available for matching logic

- **Given** an identifier required for matching is missing or unmapped  
  **When** matching is attempted  
  **Then** the issue is surfaced clearly for investigation


===== FILE: docs\mission_destination\stories\ST-05_bulk_load_crm.md =====
---
story_id: ST-05
feature: FT-03
name: Ingest CRM Data
description: 'Ingest CRM Data.

  '
acceptance_criteria:
- Records loaded
overall_status: Planned
testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run
policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: 2025-12-31T21:49:15Z
---
# Ingest CRM Data

## Statement
As a data operations user, I want to load CRM data so that existing client records can be ingested into the platform efficiently and consistently.

## Description
The platform must support ingestion of client data from a registered CRM source system.  
This capability enables an initial or repeat load of CRM records into the platform using a controlled and repeatable process.

Loading creates persisted client records that can subsequently be mapped, matched, and assembled into client profiles. The same ingestion logic must be usable for automated testing and operational execution.

## Acceptance Criteria
- **Given** a CRM source system is registered  
  **When** a load of CRM data is executed  
  **Then** client records are ingested and persisted successfully

- **Given** a load is executed  
  **When** individual records fail validation  
  **Then** valid records are persisted and invalid records are reported clearly

- **Given** the load process completes  
  **When** downstream processes run  
  **Then** the ingested CRM records are available for mapping and matching


===== FILE: docs\mission_destination\stories\ST-06_bulk_load_kyc.md =====
---
story_id: ST-06
feature: FT-03
name: "Ingest KYC Data"
description: |
  Ingest KYC Data.

acceptance_criteria:
  - Records loaded

overall_status: Planned

testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: <auto>
---
# Ingest KYC Data

## Statement
As a compliance operations user, I want KYC data to be ingested from approved source systems so that client due-diligence information is available for review and downstream processing.

## Description
The platform must support ingestion of KYC data from registered KYC source systems.  
Ingested KYC data should be persisted in a controlled manner and associated with the originating source system to ensure provenance and auditability.

Once ingested, KYC data can be used for client enrichment, profile assembly, and compliance review processes.

## Acceptance Criteria
- **Given** a KYC source system is registered  
  **When** KYC data is ingested  
  **Then** the data is persisted successfully and linked to the source system

- **Given** ingested KYC data  
  **When** downstream processing is performed  
  **Then** the data is available for enrichment and profile assembly

- **Given** invalid KYC records are encountered  
  **When** ingestion is attempted  
  **Then** valid records are stored and invalid records are reported clearly


===== FILE: docs\mission_destination\stories\ST-07_detect_upstream_deltas.md =====
---
story_id: ST-07
feature: FT-04
name: "Detect upstream deltas"
description: |
  Detect deltas.

acceptance_criteria:
  - Changes detected

overall_status: Planned

testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: <auto>
---
# Detect Upstream Deltas

## Statement
As a data operations user, I want the platform to detect upstream data changes so that only new or modified client records are processed incrementally.

## Description
Upstream source systems may deliver repeated data extracts containing a mixture of unchanged, new, updated, or removed records.  
The platform must be able to compare incoming data against previously ingested data to detect meaningful deltas.

Detecting upstream deltas enables efficient incremental processing and prevents unnecessary reprocessing of unchanged client records.

## Acceptance Criteria
- **Given** a previous ingestion has occurred  
  **When** new data is received from the same source system  
  **Then** the platform identifies new, changed, and unchanged records

- **Given** upstream records have not changed  
  **When** delta detection runs  
  **Then** those records are marked as unchanged

- **Given** records are new or updated  
  **When** delta detection completes  
  **Then** they are flagged for downstream processing



===== FILE: docs\mission_destination\stories\ST-08_apply_deltas.md =====
---
story_id: ST-08
feature: FT-04
name: "Apply deltas"
description: |
  Apply detected deltas.

acceptance_criteria:
  - Deltas applied

overall_status: Planned

testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: <auto>
---
# Apply Upstream Deltas

## Statement
As a data operations user, I want detected upstream deltas to be applied so that the platform state remains aligned with source system changes.

## Description
Once upstream deltas have been identified, the platform must apply those changes to its internal representation of client data.  
Applying deltas ensures that new records are added, updated records are amended, and removed records are handled appropriately.

This process keeps the platformâ€™s client data synchronised with upstream systems without requiring full reloads.

## Acceptance Criteria
- **Given** upstream deltas have been detected  
  **When** delta application is executed  
  **Then** new and updated records are applied to the platform state

- **Given** records are marked as removed  
  **When** deltas are applied  
  **Then** the platform state reflects the removal according to defined rules

- **Given** no deltas are detected  
  **When** delta application runs  
  **Then** no changes are applied


===== FILE: docs\mission_destination\stories\ST-09_match_by_tax_id.md =====
---
story_id: ST-09
feature: FT-05
name: "Match by tax ID"
description: |
  Exact match by tax ID.

acceptance_criteria:
  - Matches correct

overall_status: Planned

testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: <auto>
---
# Match Clients by Tax Identifier

## Statement
As a compliance operations user, I want clients to be matched by tax identifier so that duplicate or related client records can be identified accurately.

## Description
Clients may appear in multiple source systems with different representations.  
The platform must support matching client records using tax identifiers as a strong matching attribute.

Successful matching enables consolidation of records that refer to the same real-world entity and reduces duplication in client profiles.

## Acceptance Criteria
- **Given** multiple client records exist  
  **When** matching by tax identifier is performed  
  **Then** records with the same tax identifier are identified as potential matches

- **Given** a tax identifier match is identified  
  **When** client profiles are assembled  
  **Then** matched records are treated as referring to the same client

- **Given** a tax identifier is missing or invalid  
  **When** matching is attempted  
  **Then** the limitation is reported clearly


===== FILE: docs\mission_destination\stories\ST-10_match_by_registration_number.md =====
---
story_id: ST-10
feature: FT-05
name: "Match by registration number"
description: |
  Exact match.

acceptance_criteria:
  - Matches correct

overall_status: Planned

testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: <auto>
---
# Match Clients by Registration Number

## Statement
As a compliance operations user, I want clients to be matched by registration number so that records referring to the same legal entity can be identified reliably.

## Description
Client records originating from different systems may refer to the same legal entity using a common registration number.  
The platform must support matching client records based on registration number as a strong identifier.

Matching by registration number complements other matching strategies and improves the accuracy of client consolidation.

## Acceptance Criteria
- **Given** multiple client records exist  
  **When** matching by registration number is performed  
  **Then** records with the same registration number are identified as potential matches

- **Given** registration number matches are identified  
  **When** downstream processing occurs  
  **Then** those records are treated as referring to the same entity

- **Given** a registration number is missing or invalid  
  **When** matching is attempted  
  **Then** the limitation is reported clearly


===== FILE: docs\mission_destination\stories\ST-11_fuzzy_name_match.md =====
---
story_id: ST-11
feature: FT-06
name: "Fuzzy name match"
description: |
  Implement fuzzy name.

acceptance_criteria:
  - Similarity score valid

overall_status: Planned

testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: <auto>
---
# Drill Down Lineage

## Statement
As a compliance or audit user, I want to drill down into lineage details so that I can inspect how specific data elements were produced.

## Description
High-level lineage views may not provide sufficient detail for investigation or audit purposes.  
The platform must support drilling down into lineage information, allowing users or systems to navigate from high-level lineage to detailed events and attributes.

Drill-down capability enables deeper understanding of data provenance and processing history.

## Acceptance Criteria
- **Given** lineage information is available  
  **When** a drill-down is requested  
  **Then** more detailed lineage information is returned

- **Given** detailed lineage is displayed  
  **When** it is inspected  
  **Then** it clearly shows contributing sources and transformations

- **Given** no further detail exists  
  **When** a drill-down is attempted  
  **Then** this is communicated clearly


===== FILE: docs\mission_destination\stories\ST-12_attribute_confidence.md =====
---
story_id: ST-12
feature: FT-06
name: "Attribute confidence"
description: |
  Compute confidence.

acceptance_criteria:
  - Confidence computed

overall_status: Planned

testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: <auto>
---
# Fuzzy Name Match

## Statement
As a compliance operations user, I want client records to be matched using fuzzy name matching so that potential duplicates can be identified even when names are not identical.

## Description
Client names may be represented inconsistently across source systems due to spelling variations, abbreviations, or formatting differences.  
The platform must support fuzzy name matching to identify potential matches where exact matching is insufficient.

Fuzzy name matching complements deterministic matching strategies and supports improved identification of related client records.

## Acceptance Criteria
- **Given** multiple client records exist with similar names  
  **When** fuzzy name matching is performed  
  **Then** records with similar names are identified as potential matches

- **Given** fuzzy name matches are identified  
  **When** downstream processing occurs  
  **Then** the records are flagged for consolidation or further review

- **Given** names are dissimilar beyond acceptable thresholds  
  **When** fuzzy matching is attempted  
  **Then** no match is identified


===== FILE: docs\mission_destination\stories\ST-13_merge_identity.md =====
---
story_id: ST-13
feature: FT-07
name: "Merge identity"
description: |
  Merge identity attributes.

acceptance_criteria:
  - Conflicts resolved

overall_status: Planned

testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: <auto>
---
# Merge Identity

## Statement
As a compliance operations user, I want identity information to be merged so that client profiles reflect a single, coherent representation of the client.

## Description
When client records are identified as referring to the same real-world entity, identity attributes from those records must be merged.  
The platform must combine identity information in a controlled manner, resolving conflicts according to defined rules.

Merging identity information enables accurate and consistent client profiles.

## Acceptance Criteria
- **Given** client records are identified as matches  
  **When** identity merge is performed  
  **Then** identity attributes are combined into a single representation

- **Given** conflicting identity attributes exist  
  **When** a merge occurs  
  **Then** conflicts are resolved according to defined rules

- **Given** identity merge cannot be completed  
  **When** the process runs  
  **Then** the issue is reported clearly


===== FILE: docs\mission_destination\stories\ST-14_merge_addresses.md =====
---
story_id: ST-14
feature: FT-07
name: "Merge addresses"
description: |
  Merge address attributes.

acceptance_criteria:
  - Address selected

overall_status: Planned

testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: <auto>
---
# Merge Addresses

## Statement
As a compliance or operations user, I want client address information to be merged so that address data is consistent and complete within the client profile.

## Description
Clients may have multiple address records originating from different source systems.  
The platform must merge address information when records are matched, ensuring that valid and relevant addresses are retained.

Address merging supports accurate client profiling and downstream operational use.

## Acceptance Criteria
- **Given** matched client records contain address information  
  **When** address merging is performed  
  **Then** addresses are combined into a unified set

- **Given** duplicate or conflicting addresses exist  
  **When** merging occurs  
  **Then** duplicates are handled and conflicts resolved appropriately

- **Given** address data is incomplete  
  **When** merging is attempted  
  **Then** available address information is retained


===== FILE: docs\mission_destination\stories\ST-15_record_lineage.md =====
---
story_id: ST-15
feature: FT-07
name: "Record lineage"
description: |
  Lineage for merges.

acceptance_criteria:
  - Lineage stored

overall_status: Planned

testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: <auto>
---
# Record Lineage

## Statement
As a compliance or audit user, I want lineage to be recorded so that the origin and transformation of client data can be traced over time.

## Description
As client data is ingested, matched, merged, and assembled, the platform must record lineage information describing how the data was produced.  
Recorded lineage provides the foundation for auditability, transparency, and trust in client profiles.

Lineage records must be associated with the relevant data and processing events.

## Acceptance Criteria
- **Given** client data is processed  
  **When** processing occurs  
  **Then** lineage information is recorded for the relevant events

- **Given** lineage has been recorded  
  **When** it is queried  
  **Then** it accurately reflects data origins and transformations

- **Given** lineage recording fails  
  **When** processing continues  
  **Then** the failure is reported clearly


===== FILE: docs\mission_destination\stories\ST-16_build_index.md =====
---
story_id: ST-16
feature: FT-08
name: "Build index"
description: |
  Build search index.

acceptance_criteria:
  - Index built

overall_status: Planned

testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: <auto>
---
# Build Index

## Statement
As an operations user, I want client data to be indexed so that client information can be searched and retrieved efficiently.

## Description
To support fast and reliable search, the platform must build and maintain indexes over relevant client data.  
Indexes are derived from ingested and assembled client information and are optimised for common search and retrieval patterns.

Indexing enables responsive search and supports downstream operational use of the platform.

## Acceptance Criteria
- **Given** client data exists  
  **When** index building is executed  
  **Then** search indexes are created successfully

- **Given** client data changes  
  **When** indexes are rebuilt or updated  
  **Then** indexes reflect the latest data state

- **Given** indexing fails  
  **When** index construction is attempted  
  **Then** the failure is reported clearly


===== FILE: docs\mission_destination\stories\ST-17_normalise_search_fields.md =====
---
story_id: ST-17
feature: FT-08
name: "Normalise search fields"
description: |
  Normalise fields.

acceptance_criteria:
  - Fields normalised

overall_status: Planned

testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: <auto>
---
# Normalise Search Fields

## Statement
As an operations user, I want search fields to be normalised so that client data can be searched consistently regardless of source formatting.

## Description
Client data may be represented differently across source systems, including variations in casing, formatting, and structure.  
The platform must normalise search-relevant fields into a consistent representation suitable for indexing and querying.

Normalised search fields improve search accuracy and user experience.

## Acceptance Criteria
- **Given** client data contains searchable attributes  
  **When** normalisation is performed  
  **Then** search fields are transformed into a consistent format

- **Given** normalised search fields  
  **When** indexing occurs  
  **Then** the normalised values are used

- **Given** a field cannot be normalised  
  **When** processing occurs  
  **Then** the limitation is reported clearly


===== FILE: docs\mission_destination\stories\ST-18_fuzzy_search_queries.md =====
---
story_id: ST-18
feature: FT-09
name: "Fuzzy search queries"
description: |
  Fuzzy queries.

acceptance_criteria:
  - Ranked results

overall_status: Planned

testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: <auto>
---
# Fuzzy Search Queries

## Statement
As an operations or compliance user, I want to perform fuzzy search queries so that I can find clients even when search terms are approximate or incomplete.

## Description
Exact search queries may not always return relevant results due to spelling variations or incomplete information.  
The platform must support fuzzy search queries that tolerate minor differences between search input and indexed data.

Fuzzy search improves usability and helps users locate client profiles more effectively.

## Acceptance Criteria
- **Given** indexed client data exists  
  **When** a fuzzy search query is performed  
  **Then** relevant approximate matches are returned

- **Given** multiple potential matches exist  
  **When** fuzzy search is executed  
  **Then** all relevant results are included

- **Given** no close matches exist  
  **When** a fuzzy search is performed  
  **Then** no results are returned clearly


===== FILE: docs\mission_destination\stories\ST-19_search_ranking.md =====
---
story_id: ST-19
feature: FT-09
name: "Search ranking"
description: |
  Ranking logic.

acceptance_criteria:
  - Correct ordering

overall_status: Planned

testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: <auto>
---
# Search Ranking

## Statement
As an operations user, I want search results to be ranked so that the most relevant client profiles appear first.

## Description
When multiple client profiles match a search query, the platform must rank results based on relevance.  
Ranking may consider factors such as match strength, attribute confidence, and data completeness.

Search ranking ensures that users can quickly identify the most likely relevant clients.

## Acceptance Criteria
- **Given** multiple search results are returned  
  **When** ranking is applied  
  **Then** results are ordered by relevance

- **Given** ranking criteria change  
  **When** search is performed  
  **Then** result ordering reflects the updated criteria

- **Given** ranking cannot be applied  
  **When** search is executed  
  **Then** results are returned without ranking and the issue is reported


===== FILE: docs\mission_destination\stories\ST-20_assemble_base_profile.md =====
---
story_id: ST-20
feature: FT-10
name: Assemble base profile

overall_status: Complete

testing_status: pass
halo_adherence: pass
guardrail_adherence: pass
code_quality_adherence: pass
security_policy_adherence: pass

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run

description: |
  Assemble a canonical client base profile by reading existing client data
  from the persistent database and returning it in the shape defined by the
  Initial Logical Data Model.

  This story covers read-only assembly of core client attributes only.
  No matching, merging, enrichment, lineage computation, or quality scoring
  is performed as part of this story.

acceptance_criteria:
  - A client profile can be retrieved using an existing internal client identifier
  - The returned profile conforms to the ClientProfile structure defined in the Initial Logical Data Model
  - Core profile fields (e.g. name, email, country, identifiers, addresses) are populated from persisted data where available
  - The profile assembly is deterministic and repeatable for the same input
  - No matching, merging, enrichment, lineage, or quality logic is applied

guardrails:
  G03:
    ldm_contract: "ldm://client_profile/1.0.0"
    artifact: "client_profile"
    mode: "strict"



last_updated: 2025-12-21T21:26:23Z
---


===== FILE: docs\mission_destination\stories\ST-21_assemble_metadata.md =====
---
story_id: ST-21
feature: FT-10
name: "Assemble metadata"
description: |
  Assemble metadata.

acceptance_criteria:
  - Metadata added

overall_status: Planned

testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: <auto>
---
# Assemble Profile Metadata

## Statement
As a compliance or operations user, I want profile metadata to be assembled so that I can assess the quality and state of a client profile.

## Description
In addition to core client data, the platform must derive and assemble metadata about each client profile.  
Profile metadata may include indicators such as completeness, freshness, confidence, and references to lineage or evidence.

This metadata supports informed decision-making and operational oversight of client profiles.

## Acceptance Criteria
- **Given** a client profile exists  
  **When** metadata assembly is performed  
  **Then** profile metadata is calculated and associated with the profile

- **Given** underlying client data changes  
  **When** metadata is reassembled  
  **Then** metadata reflects the updated profile state

- **Given** metadata cannot be fully derived  
  **When** assembly is attempted  
  **Then** partial metadata is recorded with clear indicators



===== FILE: docs\mission_destination\stories\ST-22_expose_lineage.md =====
---
story_id: ST-22
feature: FT-11
name: "Expose lineage"
description: |
  Lineage display.

acceptance_criteria:
  - Lineage visible

overall_status: Planned

testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: <auto>
---
# Expose Lineage

## Statement
As a compliance or audit user, I want lineage information to be exposed so that downstream systems and users can understand how client data was derived.

## Description
The platform must make data lineage information available through a controlled interface.  
Exposed lineage describes the origin of data, the transformations applied, and the processes involved in producing client profiles.

Exposing lineage enables transparency, auditability, and integration with downstream tools.

## Acceptance Criteria
- **Given** lineage information exists  
  **When** lineage is requested  
  **Then** the information is returned successfully

- **Given** lineage is exposed  
  **When** it is consumed  
  **Then** it accurately reflects source systems and transformations

- **Given** lineage is unavailable for a request  
  **When** exposure is attempted  
  **Then** this is indicated clearly


===== FILE: docs\mission_destination\stories\ST-23_drill-down_lineage.md =====
---
story_id: ST-23
feature: FT-11
name: "Drill-down lineage"
description: |
  Drill-down.

acceptance_criteria:
  - Source-level detail

overall_status: Planned

testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: <auto>
---
# Drill Down Lineage

## Statement
As a compliance or audit user, I want to drill down into lineage details so that I can inspect how specific data elements were produced.

## Description
High-level lineage views may not provide sufficient detail for investigation or audit purposes.  
The platform must support drilling down into lineage information, allowing users or systems to navigate from high-level lineage to detailed events and attributes.

Drill-down capability enables deeper understanding of data provenance and processing history.

## Acceptance Criteria
- **Given** lineage information is available  
  **When** a drill-down is requested  
  **Then** more detailed lineage information is returned

- **Given** detailed lineage is displayed  
  **When** it is inspected  
  **Then** it clearly shows contributing sources and transformations

- **Given** no further detail exists  
  **When** a drill-down is attempted  
  **Then** this is communicated clearly



===== FILE: docs\mission_destination\stories\ST-24_flag_conflicts.md =====
---
story_id: ST-24
feature: FT-12
name: "Flag conflicts"
description: |
  Conflict flags.

acceptance_criteria:
  - Flags correct

overall_status: Planned

testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: <auto>
---
# Flag Conflicts

## Statement
As a compliance or operations user, I want data conflicts to be flagged so that inconsistencies in client information can be identified and addressed.

## Description
When client data from multiple sources is merged or assembled, conflicts may arise between attributes such as identifiers, names, or addresses.  
The platform must detect and flag these conflicts so that they are visible for review and resolution.

Flagging conflicts supports data quality management and prevents silent inconsistencies in client profiles.

## Acceptance Criteria
- **Given** conflicting client attributes are detected  
  **When** profile processing occurs  
  **Then** the conflicts are flagged clearly

- **Given** flagged conflicts exist  
  **When** a client profile is reviewed  
  **Then** the conflicts are visible to the user

- **Given** no conflicts are present  
  **When** processing occurs  
  **Then** no conflict flags are created


===== FILE: docs\mission_destination\stories\ST-25_show_merge_logic.md =====
---
story_id: ST-25
feature: FT-12
name: "Show merge logic"
description: |
  Show logic.

acceptance_criteria:
  - Logic displayed

overall_status: Planned

testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: <auto>
---
# Show Merge Logic

## Statement
As a compliance or audit user, I want to understand how merge decisions were made so that client data consolidation is transparent.

## Description
When client data is merged, the platform applies rules and logic to determine which values are retained.  
The platform must expose the merge logic applied to client attributes so that users can understand why specific values were chosen.

Showing merge logic supports auditability, trust, and investigation of client profile outcomes.

## Acceptance Criteria
- **Given** client attributes have been merged  
  **When** merge logic is requested  
  **Then** the applied rules and outcomes are displayed clearly

- **Given** merge logic is displayed  
  **When** it is reviewed  
  **Then** it explains why specific values were retained

- **Given** merge logic cannot be determined  
  **When** it is requested  
  **Then** this is indicated clearly


===== FILE: docs\mission_destination\stories\ST-26_store_lineage_history.md =====
---
story_id: ST-26
feature: FT-13
name: "Store lineage history"
description: |
  Store history.

acceptance_criteria:
  - History stored

overall_status: Planned

testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: <auto>
---
# Store Lineage History

## Statement
As a compliance or audit user, I want lineage history to be stored so that changes to client data can be traced over time.

## Description
Client data and profiles evolve as new data is ingested and processed.  
The platform must store lineage history so that past states and transformations of client data can be reviewed retrospectively.

Storing lineage history enables audit, investigation, and historical analysis.

## Acceptance Criteria
- **Given** client data is processed  
  **When** lineage events occur  
  **Then** lineage history is stored persistently

- **Given** lineage history exists  
  **When** it is requested  
  **Then** historical lineage events can be retrieved

- **Given** lineage history storage fails  
  **When** processing continues  
  **Then** the failure is reported clearly


===== FILE: docs\mission_destination\stories\ST-27_timestamp_lineage.md =====
---
story_id: ST-27
feature: FT-13
name: "Timestamp lineage"
description: |
  Timestamp entries.

acceptance_criteria:
  - Timestamps correct

overall_status: Planned

testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: <auto>
---
# Timestamp Lineage

## Statement
As a compliance or audit user, I want lineage events to be timestamped so that I can understand when client data changes occurred.

## Description
To support accurate audit and investigation, lineage events must include timing information.  
The platform must record timestamps for lineage events, enabling users to understand the sequence and timing of data changes.

Timestamped lineage supports chronological analysis of client data evolution.

## Acceptance Criteria
- **Given** lineage events are recorded  
  **When** they are stored  
  **Then** each event includes an accurate timestamp

- **Given** timestamped lineage exists  
  **When** it is reviewed  
  **Then** events can be ordered chronologically

- **Given** a timestamp cannot be recorded  
  **When** an event occurs  
  **Then** the issue is reported clearly


===== FILE: docs\mission_destination\stories\ST-28_compute_freshness.md =====
---
story_id: ST-28
feature: FT-14
name: "Compute freshness"
description: |
  Freshness score.

acceptance_criteria:
  - Score correct

overall_status: Planned

testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: <auto>
---
# Compute Freshness

## Statement
As a compliance or operations user, I want data freshness to be computed so that I can assess how up to date client information is.

## Description
Client data may become stale as time passes without updates from source systems.  
The platform must compute freshness indicators for client data based on timestamps, update frequency, or source characteristics.

Freshness indicators support informed decision-making and data quality assessment.

## Acceptance Criteria
- **Given** client data exists  
  **When** freshness computation is performed  
  **Then** freshness indicators are calculated for relevant data

- **Given** underlying data is updated  
  **When** freshness is recomputed  
  **Then** indicators reflect the latest state

- **Given** freshness cannot be determined  
  **When** computation is attempted  
  **Then** this is indicated clearly


===== FILE: docs\mission_destination\stories\ST-29_compute_completeness.md =====
---
story_id: ST-29
feature: FT-14
name: "Compute completeness"
description: |
  Completeness.

acceptance_criteria:
  - Completeness correct

overall_status: Planned

testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: <auto>
---
# Compute Completeness

## Statement
As a compliance or operations user, I want data completeness to be computed so that I can assess whether client profiles contain sufficient information.

## Description
Client profiles may be partially populated depending on available source data.  
The platform must compute completeness indicators that describe how fully populated a client profile is relative to expected attributes.

Completeness indicators support data quality monitoring and informed operational decision-making.

## Acceptance Criteria
- **Given** a client profile exists  
  **When** completeness is computed  
  **Then** completeness indicators are calculated for the profile

- **Given** underlying client data changes  
  **When** completeness is recomputed  
  **Then** indicators reflect the updated profile state

- **Given** completeness cannot be fully determined  
  **When** computation is attempted  
  **Then** partial completeness is recorded with clear indicators


===== FILE: docs\mission_destination\stories\ST-30_audit_ingestion.md =====
---
story_id: ST-30
feature: FT-15
name: "Audit ingestion"
description: |
  Audit ingestion.

acceptance_criteria:
  - Audit entries

overall_status: Planned

testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: <auto>
---
# Audit Ingestion

## Statement
As a compliance or audit user, I want ingestion activity to be audited so that I can verify what data was ingested and when.

## Description
The platform must record audit information for data ingestion activities.  
Audit records should capture relevant details such as source system, timing, and outcomes of ingestion processes.

Auditing ingestion supports regulatory compliance, investigation, and operational oversight.

## Acceptance Criteria
- **Given** data ingestion occurs  
  **When** the process completes  
  **Then** an audit record is created for the ingestion activity

- **Given** ingestion audit records exist  
  **When** they are requested  
  **Then** they can be retrieved and reviewed

- **Given** ingestion auditing fails  
  **When** ingestion proceeds  
  **Then** the failure is reported clearly


===== FILE: docs\mission_destination\stories\ST-31_audit_merge.md =====
---
story_id: ST-31
feature: FT-15
name: "Audit merge"
description: |
  Audit merge.

acceptance_criteria:
  - Audit recorded

overall_status: Planned

testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: <auto>
---
# Audit Merge

## Statement
As a compliance or audit user, I want merge activity to be audited so that I can understand how client records were consolidated.

## Description
When client records are merged, the platform must record audit information describing the merge activity.  
Audit records should capture which records were merged, when the merge occurred, and the outcome.

Auditing merge activity supports transparency, investigation, and regulatory compliance.

## Acceptance Criteria
- **Given** client records are merged  
  **When** the merge completes  
  **Then** an audit record is created for the merge activity

- **Given** merge audit records exist  
  **When** they are requested  
  **Then** they can be retrieved and reviewed

- **Given** merge auditing fails  
  **When** merging proceeds  
  **Then** the failure is reported clearly


===== FILE: docs\mission_destination\stories\ST-32_search_api_basic.md =====
---
story_id: ST-32
feature: FT-16
name: "Search API basic"
description: |
  Search endpoint.

acceptance_criteria:
  - JSON response

overall_status: Planned

testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: <auto>
---
# Search API (Basic)

## Statement
As an application or operations user, I want a basic search API so that client profiles can be retrieved programmatically.

## Description
The platform must expose a basic search API that allows clients to be searched using common criteria.  
The API provides programmatic access to search capabilities and supports integration with downstream applications and user interfaces.

The basic search API focuses on core search functionality without advanced ranking or tuning.

## Acceptance Criteria
- **Given** client profiles exist  
  **When** the basic search API is called with valid criteria  
  **Then** matching client profiles are returned

- **Given** no profiles match the criteria  
  **When** the API is called  
  **Then** an empty result set is returned

- **Given** invalid search parameters are provided  
  **When** the API is called  
  **Then** a clear error response is returned


===== FILE: docs\mission_destination\stories\ST-33_search_api_ranking.md =====
---
story_id: ST-33
feature: FT-16
name: "Search API ranking"
description: |
  Ranking via API.

acceptance_criteria:
  - Ranked results

overall_status: Planned

testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: <auto>
---
# Search API (Ranking)

## Statement
As an application or operations user, I want the search API to return ranked results so that the most relevant client profiles are prioritised.

## Description
Building on the basic search API, the platform must support ranked search results.  
Ranking logic orders results based on relevance criteria such as match strength, confidence, or completeness.

Ranked search improves usability and effectiveness for both users and integrated systems.

## Acceptance Criteria
- **Given** multiple search results are returned  
  **When** ranked search is performed  
  **Then** results are ordered by relevance

- **Given** ranking criteria are applied  
  **When** the search API is called  
  **Then** results reflect the ranking logic

- **Given** ranking cannot be applied  
  **When** the API is called  
  **Then** results are returned without ranking and the limitation is reported


===== FILE: docs\mission_destination\stories\ST-34_profile_api_basic.md =====
---
story_id: ST-34
feature: FT-17
name: "Profile API basic"
description: |
  Profile endpoint.

acceptance_criteria:
  - Profile returned

overall_status: Planned

testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: <auto>
---
# Profile API (Basic)

## Statement
As an application or operations user, I want a basic profile API so that consolidated client profiles can be retrieved programmatically.

## Description
The platform must expose a basic profile API that allows authorised consumers to retrieve assembled client profiles.  
The API provides programmatic access to the platformâ€™s consolidated view of a client and supports integration with downstream systems and user interfaces.

The basic profile API focuses on core profile retrieval without advanced metadata or lineage detail.

## Acceptance Criteria
- **Given** a client profile exists  
  **When** the basic profile API is called with a valid identifier  
  **Then** the client profile is returned successfully

- **Given** a requested profile does not exist  
  **When** the API is called  
  **Then** a clear â€œnot foundâ€ response is returned

- **Given** invalid request parameters are provided  
  **When** the API is called  
  **Then** a clear error response is returned


===== FILE: docs\mission_destination\stories\ST-35_profile_api_lineage.md =====
---
story_id: ST-35
feature: FT-17
name: "Profile API lineage"
description: |
  Lineage in API.

acceptance_criteria:
  - Lineage included

overall_status: Planned

testing_status: not_run
halo_adherence: not_run
guardrail_adherence: not_run
code_quality_adherence: not_run
security_policy_adherence: not_run

policy_adherence: not_run
technology_lineage_adherence: not_run
business_data_lineage_adherence: not_run
self_healing_adherence: not_run
analytics_adherence: not_run
last_updated: <auto>
---
# Profile API (Lineage)

## Statement
As a compliance or audit user, I want the profile API to expose lineage information so that I can understand how client profile data was derived.

## Description
In addition to basic profile retrieval, the platform must support exposing lineage information through the profile API.  
This allows consumers to retrieve not only the client profile but also the associated lineage describing data origins and transformations.

Exposing lineage through the API supports transparency, auditability, and integration with governance tooling.

## Acceptance Criteria
- **Given** a client profile with recorded lineage exists  
  **When** the profile API is called with lineage enabled  
  **Then** the profile and associated lineage are returned

- **Given** lineage information is requested  
  **When** it is retrieved  
  **Then** it accurately reflects data sources and processing steps

- **Given** lineage is unavailable  
  **When** the API is called  
  **Then** this is indicated clearly in the response


===== FILE: docs\mission_destination\story_service_mapping.yaml =====
ST-00-backend:
  story_id: ST-00
  story_name: Backend API availability
  feature: Platform / Shell
  service: backend_api
  code_file: app_backend/main.py

ST-00-frontend:
  story_id: ST-00
  story_name: Frontend UI shell
  feature: Platform / Shell
  service: frontend_shell
  code_file: app_frontend/src/App.jsx

ST-03:
  story_id: ST-03
  story_name: Map identity fields
  feature: Client Profile Assembly
  service: client_profile
  code_file: src/services/client_profile/service.py

ST-04:
  story_id: ST-04
  story_name: Map identifiers
  feature: Client Profile Assembly
  service: client_profile
  code_file: src/services/client_profile/service.py

ST-05:
  story_id: ST-05
  story_name: Bulk load CRM
  feature: Initial Bulk Ingestion
  service: crm_bulk_load
  code_file: backend_v2/app/services/crm_bulk_load_service.py

ST-09:
  story_id: ST-09
  story_name: Match by tax ID
  feature: Client Profile Assembly
  service: client_profile
  code_file: src/services/client_profile/service.py


ST-20:
  story_id: ST-20
  story_name: Assemble base profile
  feature: Client Profile Assembly
  service: client_profile
  code_file: src/services/client_profile/service.py

ST-30:
  story_id: ST-30
  story_name: Audit ingestion
  feature: Audit Ingestion
  service: audit
  code_file: src/services/audit/service.py


===== FILE: docs\mission_framework\analytics\mf07_analytics.md =====

# MissionFramework Element: Analytics

## Overview
Lightweight telemetry and metrics to track behaviour, performance, and usage.

---

## Codify
- Define minimal analytics schema (events, metrics, identifiers).
- Store in mission_framework/analytics.

---

## Automate
- Code generation emits basic telemetry hooks.
- Logging patterns conform to schema.

---

## Intercept
- CI checks for missing telemetry hooks where required.
- Static analysis flags invalid schemas.

---

## Prove
- MissionAtlas (or simple dashboards) surface key metrics.
- MissionLog stores analytics evidence snapshots.



===== FILE: docs\mission_framework\application_self_healing\mf06_application_self_healing.md =====

# MissionFramework Element: Application Self-Healing

## Overview
Automated detection, response, and recovery from runtime anomalies using minimal MVP mechanisms.

---

## Codify
- Basic retry and circuit-breaker config defined in YAML.
- Minimal health-check contract established.

---

## Automate
- Generated services include retry wrappers and health checks.
- Monitoring hooks capture failures.

---

## Intercept
- Guardrails warn if required self-healing hooks missing.
- CI checks presence of retry/circuit-breaker configs.

---

## Prove
- MissionLog records health events and auto-recovery outcomes.
- Evidence snapshots show self-healing execution.



===== FILE: docs\mission_framework\business_data_lineage\mf04_business_data_lineage.md =====

# MissionFramework Element: Business Data Lineage

## Overview
Traceability of business data across sources, transformations, and outputs.

---

## Codify
- Define lineage schema (attribute source, timestamp, transformation rules).
- Stored in mission_framework/business_data_lineage.

---

## Automate
- Merge logic generates lineage metadata.
- Services automatically attach lineage info to client profiles.

---

## Intercept
- Missing lineage triggers guardrail warnings.
- CI validates completeness of lineage fields.

---

## Prove
- MissionLog lineage views show source mapping and transformation steps.
- Attribute-level lineage dashboards provide visual evidence.



===== FILE: docs\mission_framework\design_principles\mf01_design_principples.md =====

# MissionFramework Element: Design Principles

## Overview
High-level architectural principles that guide how all MissionSmith-generated applications are structured and behave.

---

## Codify
- Principles defined in YAML/MD under mission_framework/design_principles.
- Include rules for layering, statelessness, deterministic behaviour, separation of concerns.
- Machine-readable so guardrails and prompts can reference them.

---

## Automate
- Story meta-prompts enforce architectural boundaries.
- CI guardrails check for violations (e.g., direct DB calls, forbidden imports).
- Code generation scaffolds follow these principles by default.

---

## Intercept
- Guardrail engine detects structural violations.
- CI blocks merges that break design principles.
- Warnings raised for non-critical deviations.

---

## Prove
- MissionLog displays design-principle compliance per Story/Feature/Epic.
- Evidence snapshots stored for auditability.



===== FILE: docs\mission_framework\mission_control_status_model.md =====
# Mission Control â€” Status Tracking Model

This document defines how Mission Control tracks and updates the delivery status of **Epics**, **Features**, and **Stories** across the entire MissionSmith lifecycle. All status information is stored in **YAML front matter** within each artefact and is automatically updated through **commit processing**, **guardrail evaluation**, and **CI evidence ingestion**.

---

# 1. Status Model Overview
Each artefact (Epic, Feature, Story) maintains a consistent set of machine-evaluated statuses:

- **overall_status**
- **testing_status**
- **halo_adherence**
- **guardrail_adherence**
- **code_quality_adherence**
- **security_policy_adherence**
- **implementation_presence** (Stories only)

An artefact can only exist in one of three states:
- **Planned**
- **In Progress**
- **Complete**

Statuses are always derived from machine-readable evidence.

---

# 2. Story Status Model (Atomic Unit)
Stories are independent of one another. Story status is determined solely by its own implementation and checks.

## 2.1 Planned
- No commits to the storyâ€™s implementation slice
- No tests exist
- No adherence checks have run

## 2.2 In Progress
A Story becomes In Progress when any of the following occur:
- Commits modify the storyâ€™s implementation slice
- A test file exists but tests donâ€™t pass
- One or more adherence checks fail
- Required evidence is missing

## 2.3 Complete
A Story is Complete only when:
- Implementation presence is detected
- All tests pass
- Guardrail checks pass
- Halo checks pass
- Code quality checks pass
- Security policy checks pass

---

# 3. Feature Status Model
Feature status is aggregated from child Stories.

## 3.1 Planned
- All Stories in the Feature are Planned

## 3.2 In Progress
- At least one Story is In Progress or Complete
- Not all Stories are Complete

## 3.3 Complete
- All Stories in the Feature are Complete

---

# 4. Epic Status Model
Epic status is aggregated from child Features.

## 4.1 Planned
- All Features are Planned

## 4.2 In Progress
- At least one Feature is In Progress or Complete
- Not all Features are Complete

## 4.3 Complete
- All Features are Complete

---

# 5. Front Matter Structure

## 5.1 Story Front Matter
```yaml
story_id: ST-123
feature: FT-45

overall_status: Planned | In Progress | Complete

testing_status: pass | fail | not_run
halo_adherence: pass | fail
guardrail_adherence: pass | fail
code_quality_adherence: pass | fail
security_policy_adherence: pass | fail
implementation_presence: true | false

last_updated: 2025-01-01T12:00:00Z
```

## 5.2 Feature Front Matter
```yaml
feature_id: FT-45
epic: EP-7

overall_status: Planned | In Progress | Complete

testing_status: aggregated
halo_adherence: aggregated
guardrail_adherence: aggregated
code_quality_adherence: aggregated
security_policy_adherence: aggregated

story_statuses:
  ST-123: Complete
  ST-124: In Progress
  ST-125: Planned

last_updated: 2025-01-01T12:00:00Z
```

## 5.3 Epic Front Matter
```yaml
epic_id: EP-7

overall_status: Planned | In Progress | Complete

testing_status: aggregated
halo_adherence: aggregated
guardrail_adherence: aggregated
code_quality_adherence: aggregated
security_policy_adherence: aggregated

feature_statuses:
  FT-45: Complete
  FT-46: In Progress
  FT-47: Planned

last_updated: 2025-01-01T12:00:00Z
```

---

# 6. Status Computation Rules
1. Front matter updates occur when:
   - Story implementation slices change
   - Tests run and generate evidence
   - Guardrail checks execute
   - CI pipelines update MissionLog

2. Statuses propagate bottom-up:
   - Story â†’ Feature â†’ Epic

3. No manual modification of status fields.
4. MissionLog reflects live state directly from front matter.

---

# 7. MissionLog Reporting
MissionLog provides:
- Epic / Feature / Story roll-ups
- Per-status dashboards (testing, guardrails, halo, quality, security)
- Evidence lineage
- Completion graphs
- Compliance summaries

MissionLog stores no separate state; it visualises repo truth.

---

# 8. Principles
- Everything lives in the repo
- Status is always derived, never declared
- Stories are atomic
- Features & Epics are compositional
- Front matter is the single source of truth
- MissionLog is read-only
- Automated consistency across levels



===== FILE: docs\mission_framework\pipeline_blueprint\pipeline_blueprint_mvp.md =====

# Pipeline Blueprint â€” MissionSmith MVP CI/CD Specification

This document defines the mandatory structure, sequencing, governance, and evidence
requirements for the CI/CD pipeline used by Single Client View (SCV) and all MissionSmith-
aligned applications.

It belongs under **MissionFramework**, because it defines systemâ€‘wide governance rules for:
- how change flows through the system,
- how evidence is produced,
- how guardrails are enforced,
- how deployment occurs safely.

Recommended location:
`scv-repo/docs/mission_framework/pipeline_blueprint/pipeline_blueprint_mvp.md`

---

## 1. Pipeline Overview

The pipeline consists of six sequential stages:

1. Validate Semantic Artefacts  
2. Generate Tests  
3. Execute Tests  
4. Run Guardrails & Framework Checks  
5. Capture Evidence & Publish MissionLog Snapshot  
6. Deploy (conditional)

A failure in any stage halts all further stages.

---

## 2. Stage 1 â€” Validate Semantic Artefacts

**Purpose**  
Ensure Epics, Features, Stories, Prompts, MissionFramework artefacts, and MissionHalo
documents are structurally valid and machine-readable.

**Checks**
- YAML front matter correctness  
- story â†’ feature â†’ epic references resolve  
- required adherence fields present  
- no missing or duplicate IDs  
- correct folder structure  
- MissionFramework & MissionHalo documents present and readable  
- prompts exist and are valid  

**Evidence**
- `evidence/semantic_validation.json`  
  - pass/fail per artefact  
  - schema and structure checks  

---

## 3. Stage 2 â€” Generate Tests (from Test Meta-Prompt)

**Purpose**  
Ensure every Story has a current, valid test suite aligned to acceptance criteria.

**Behaviour**
- Call Test Meta-Prompt for:
  - Stories changed,
  - Stories missing tests,
  - Stories with implementation changes.
- Update tests only in authorised slices:
  `tests/services/<service>/test_service.py`

**Evidence**
- `evidence/test_generation.json`

---

## 4. Stage 3 â€” Execute Tests

**Purpose**  
Validate Story behaviour.

**Behaviour**
- Run pytest  
- Collect:
  - test results  
  - simple coverage metric  

**Evidence**
- `evidence/test_results.json`  
- `evidence/test_coverage.json`

---

## 5. Stage 4 â€” Run Guardrails & Framework Checks

**Purpose**  
Enforce MissionFramework systematically.

### 5.1 Technology Guardrails
- no new files/folders outside permitted slices  
- no forbidden imports  
- no cross-service coupling  
- naming conventions  
- no secrets committed  

### 5.2 Policy-as-Code
- logging format  
- PII masking  
- required audit events  

### 5.3 Business Data Lineage
- lineage metadata exists where required  
- schema alignment  

### 5.4 Technology Components Lineage
- dependency graph consistency  

### 5.5 Self-Healing (MVP)
- retry/circuit-breaker config present where appropriate  
- health-check functions present  

### 5.6 Analytics
- telemetry events present  
- analytics schema alignment  

**Evidence**
- `evidence/guardrails.json`  

---

## 6. Stage 5 â€” Capture Evidence & Publish Snapshot

**Purpose**  
Record the complete compliance and behavioural state at this commit.

**Evidence artefact**
- `evidence/snapshots/<commit_sha>.json`  
Includes:
- semantic validation  
- test results  
- guardrail outcomes  
- adherence statuses  
- version info  

This feeds MissionLog and MissionAtlas.

---

## 7. Stage 6 â€” Deploy (conditional)

Deployment only occurs if:
- stages 1â€“5 passed  
- branch is main  
- semantic versioning rules met  

**Behaviour**
- build artefact  
- publish image  
- deploy to environment  
- publish deployment evidence  

**Evidence**
- `evidence/deployment.json`  

---

## 8. Triggering Rules

- PR: run stages 1â€“4  
- Push to main: run stages 1â€“6  
- Daily schedule: run 1â€“5  
- Tag push: full pipeline including deploy  

---

## 9. Versioning Rules (MVP)

- Story implementation change â†’ patch  
- New Story â†’ minor  
- New Feature â†’ minor  
- New Epic â†’ major  
- Breaking schema/API change â†’ major  

---

## 10. Scope

This is the MVP blueprint.  
Future versions may add:
- performance tests  
- chaos engineering  
- deeper analytics  
- dynamic environment creation  
- multi-agent CI  


===== FILE: docs\mission_framework\policy_as_code\mf03_policy_as_code.md =====

# MissionFramework Element: Policy as Code

## Overview
Regulatory, compliance, and internal policy requirements expressed as executable rules to ensure automatic adherence.

---

## Codify
- Policies defined as machine-readable rules (YAML/Python checks).
- Includes PII handling, retention, security, audit trails.

---

## Automate
- Policy checks run during CI.
- Code generation injects compliance patterns (e.g., masked logs).

---

## Intercept
- Violations flagged in CI with clear messages.
- Optional â€œsoft failâ€ for non-critical policies in MVP.

---

## Prove
- MissionLog provides evidence of policy compliance.
- Reports include test results, policy execution logs, and snapshots.



===== FILE: docs\mission_framework\technology guardrails\mf02_technology_guardrails.md =====
# Technology Guardrails
## MissionFramework

### 1. Purpose
This document defines the mandatory technology constraints for all implementations within this MissionSmith application. These guardrails ensure consistency, predictability, auditability, and safe automation across all Story implementations.

---

## 2. Language and Framework Constraints
- Python is the primary implementation language.
- Only standard library + explicitly approved libraries may be used.
- No dynamic code generation at runtime.
- No reflection-based manipulation of internal structures.

---

## 3. Architectural Layering Rules

### 3.1 Domain Layer Rules (Canonical Logical Data Model)
**All services MUST operate using the canonical Logical Data Model (LDM).**
- Domain logic MUST construct, read, and write typed domain objects defined in `src/domain/models/`.
- Services MUST NOT return dictionaries, JSON, or ad-hoc structures.
- Domain objects are the single internal representation of business truth.

### 3.2 API Representation Rules
**APIs are the ONLY layer permitted to serialise domain models.**
- API slices MAY convert domain objects to dict/JSON.
- API slices MUST NOT contain business logic.
- API slices MUST NOT mutate domain semantics.

### 3.3 No Bypassing Rule
- No slice may bypass services and interact directly with raw upstream payloads.
- Domain entities MUST NOT be constructed directly in API or adapter layers.
- All transformations MUST flow through services.

---

## 4. Implementation Slice Rules
- Each Story is implemented in exactly one code slice.
- A code slice corresponds to a single Python file in the appropriate folder.
- No Story is allowed to modify more than one slice.
- No cross-slice coupling except through domain models.
- No circular imports.

---

## 5. Testing Guardrails
- Tests MUST be deterministic.
- Tests MUST be written using the test meta-prompt.
- Tests MUST verify domain behaviour, not presentation layer behaviour.
- Every Story MUST include:
  - Positive tests
  - Negative tests
  - Edge-case tests
  - Compliance with MissionFramework rules

---

## 6. CI/CD Enforcement Rules
- CI MUST run all tests for every push.
- CI MUST enforce formatting and linting.
- CI MUST fail if:
  - API implements business logic
  - Domain model is bypassed
  - A Story modifies multiple slices
  - Any guardrail is violated

---

## 7. Security and Safety Rules
- No direct file system access except via approved paths under `tools/`.
- No network calls unless explicitly authorised.
- No outbound or inbound external data inside Story implementations during MVP.

---

## 8. Change Control
- Any change to these guardrails requires:
  - Update to meta-prompts
  - Update to related tests
  - Update to dependency rules if applicable
  - Commit message referencing a Story or refactor item


===== FILE: docs\mission_framework\technology_components_lineage\mf05_technology_components_lineage.md =====

# MissionFramework Element: Technology Components Lineage

## Overview
Visibility into how system components depend on, call, or feed one another.

---

## Codify
- Dependency graph defined in YAML.
- Versioning relationships documented at component boundaries.

---

## Automate
- Schema compatibility checks run in CI.
- Dependency mismatches flagged automatically.

---

## Intercept
- CI blocks incompatible component changes.
- Runtime warnings for deprecated or unsupported paths.

---

## Prove
- MissionLog displays dependency graphs.
- Change-impact analysis available for each update.



===== FILE: docs\mission_framework\templates\front_matter\epic_front_matter_template.md =====
epic\_id: EP-XXX

name: "<Epic name>"

description: |

<High-level business or operational capability.>

<What this epic delivers and its intended outcomes.>





features:

\- FT-XXX

\- FT-YYY

\- FT-ZZZ





\# Status Fields (auto-managed)

overall\_status: Planned





testing\_status: aggregated

halo\_adherence: aggregated

guardrail\_adherence: aggregated

code\_quality\_adherence: aggregated

security\_policy\_adherence: aggregated





feature\_statuses: {}





last\_updated: <auto>



===== FILE: docs\mission_framework\templates\front_matter\feature_front_matter_template.md =====
feature\_id: FT-XXX

epic: EP-XXX

name: "<short descriptive feature name>"

description: |

<Purpose of the feature and the capability it delivers.>

<Why it exists and how it supports the epic.>





stories:

\- ST-XXX

\- ST-YYY

\- ST-ZZZ





\# Status Fields (auto-managed)

overall\_status: Planned





testing\_status: aggregated

halo\_adherence: aggregated

guardrail\_adherence: aggregated

code\_quality\_adherence: aggregated

security\_policy\_adherence: aggregated





story\_statuses: {}





last\_updated: <auto>



===== FILE: docs\mission_framework\templates\front_matter\story_front_matter_template.md =====
story\_id: ST-XXX

feature: FT-XXX

name: "<short, action-based title>"

description: |

<Human-readable description of the story.>

<What behaviour it implements and why it matters.>

acceptance\_criteria:

\- <Criterion 1>

\- <Criterion 2>

\- <Criterion 3>





\# Status Fields (auto-managed)

overall\_status: Planned





testing\_status: not\_run

halo\_adherence: fail

guardrail\_adherence: fail

code\_quality\_adherence: fail

security\_policy\_adherence: fail

implementation\_presence: false





last\_updated: <auto>



===== FILE: docs\mission_halo\mission_halo_mvp.md =====

# MissionHalo â€” MVP UX Design Principles

## Overview
MissionHalo ensures that all generated UI components share a consistent look and feel.  
For the MVP, Halo focuses exclusively on enforcing a unified visual design system:
- typography  
- colour palette  
- spacing  
- basic component styling  
- Tailwind-based enforcement  

---

## 1. Colour System

### 1.1 Core Palette
- **Primary (teal):** rgb(26,153,136) / #1A9988  
- **Secondary (orange):** rgb(235,86,0) / #EB5600  
- **Background:** white (#FFFFFF)

### 1.2 Supporting Palette
- Soft green: rgb(176,192,159) / #B0C09F  
- Soft yellow: rgb(241,205,86) / #F1CD56  
- Soft blue-grey: rgb(205,226,235) / #CDE2EB  

Usage:
- Subtle highlights  
- Card accents  
- Status tags  

### 1.3 Grey System
- Primary text: charcoal  
- Secondary text: mid-grey  
- Muted labels/help: light grey  
- Borders: very light grey  

---

## 2. Typography

### 2.1 Typefaces
- **Headings:** Raleway  
- **Body:** Lato  

### 2.2 Rules
- Max 3 font sizes per screen  
- No all-caps except tags  
- Generous line-height for clarity  

---

## 3. Layout & Spacing
- **Base spacing unit: 8px**  
- Generous whitespace  
- Group related items in white cards with soft grey borders  
- Consistent panel-level padding (16â€“24px)  

---

## 4. Components & Style

### Cards
- White or light grey background  
- Subtle border or shadow  
- Rounded corners  

### Buttons
- Primary: teal bg, white text  
- Secondary: white bg, teal border/text  
- Destructive: orange  

### Navigation
- Light backgrounds  
- Teal underline or pill for active tab  

---

## 5. Tone & Copy (MVP-level)
- Calm, precise, professional  
- Short labels, literal naming  
- Error messages state problem + next action  

---

## 6. Enforcement (Halo Adherence)
Halo adherence = PASS when:
- Components use Raleway/Lato  
- Colours come exclusively from MissionHalo palette  
- Spacing uses Tailwind's 8px-based scale  
- Components follow card/button patterns above  

Halo adherence = FAIL when:
- Arbitrary fonts are used  
- Unapproved colours appear  
- Spacing grid violated  
- Components deviate from visual rules  

---

## 7. Tailwind Configuration Snippet

```js
// tailwind.config.js
module.exports = {
  content: ["./src/**/*.{js,ts,jsx,tsx}"],
  theme: {
    extend: {
      fontFamily: {
        heading: ['Raleway', 'system-ui', 'sans-serif'],
        body: ['Lato', 'system-ui', 'sans-serif'],
      },
      colors: {
        halo: {
          primary: 'rgb(26,153,136)',     // #1A9988
          secondary: 'rgb(235,86,0)',     // #EB5600
          softGreen: 'rgb(176,192,159)',  // #B0C09F
          softYellow: 'rgb(241,205,86)',  // #F1CD56
          softBlue: 'rgb(205,226,235)',   // #CDE2EB
        },
      },
      borderRadius: {
        halo: '16px',
      },
    },
  },
  plugins: [],
};
```

---

## Storage Location
Place this file in:

```
scv-repo/docs/mission_halo/mission_halo_mvp.md
```

MissionHalo sits alongside MissionFramework as part of the system-wide governance layer.


===== FILE: docs\mission_smith\story_execution_loop.md =====
# MissionSmith Story Execution Loop

1. Select the next Story from the sequencing list:
   - docs/mission_destination/initial_story_sequence.md

2. Identify the service for the Story:
   - Add or update the entry for the Story in story_service_mapping.yaml to record the service and the code file to be updated.

3. Implement the Story using the code meta-prompt:
   - story_code_instruction_prompt_template.txt
   - story_code_metaprompt.md

4. Create the tests using the test meta-prompt:
   - story_test_instruction_prompt_template.txt
   - story_test_metaprompt.md

5. Update the Story â†’ Service mapping in the automation scripts using:
   - generate_story_config_snippets.py
   Then paste outputs into:
   - run_story_tests.py
   - run_story_lint.py
   - run_story_security.py
   - run_story_guardrails.py

6. Run the status update scripts:
   - python tools/run_story_tests.py ST-XX
   - python tools/run_story_lint.py ST-XX
   - python tools/run_story_security.py ST-XX
   - python tools/run_story_guardrails.py ST-XX



===== FILE: docs\prompts\ci_pipeline_metaprompt.md =====

# MissionSmith CI/CD Pipeline Meta-Prompt (MVP)

You are the MissionSmith CI/CD Pipeline Generation Engine.

Your role is to:
- READ the Pipeline Blueprint and MissionFramework documents,
- GENERATE or UPDATE the CI/CD workflow configuration (e.g. `.github/workflows/ci.yaml`),
- ENSURE the implemented pipeline matches the blueprint exactly,
- NEVER invent new rules that are not present in the blueprint or framework.

The Pipeline Blueprint and MissionFramework are the *only* sources of truth for pipeline behaviour.
This prompt must not redefine rules; it must only interpret and apply them.

---

## 1. Inputs

You will be provided with:

### 1.1 Pipeline Blueprint (MVP)
Location:
`docs/mission_framework/pipeline_blueprint/pipeline_blueprint_mvp.md`

This document defines:
- pipeline stages,
- sequencing,
- checks,
- evidence artefacts,
- triggering rules,
- versioning rules.

You must treat this as the authoritative specification of CI/CD behaviour.

### 1.2 MissionFramework Documents
Location:
`docs/mission_framework/`

Including (but not limited to):
- mf01_design_principles.md
- mf02_technology_guardrails.md
- mf03_policy_as_code.md
- mf04_business_data_lineage.md
- mf05_technology_components_lineage.md
- mf06_application_self_healing.md
- mf07_analytics.md

These define:
- guardrails,
- policy-as-code,
- lineage requirements,
- analytics,
- self-healing expectations.

### 1.3 Meta-Prompts
Location:
`docs/prompts/`

- Story code prompt: `story_code_prompt.md`
- Test code prompt: `test_code_prompt.md`

These influence:
- how code is generated,
- how tests are generated.

You must ensure the pipeline invokes these prompts where the blueprint describes their use (e.g. test generation stage).

### 1.4 Repository Structure
You may assume a standard layout including:
- `.github/workflows/` for CI configuration,
- `src/` for application code,
- `tests/` for tests,
- `evidence/` for evidence artefacts,
- `docs/` for documentation.

You must NOT change this structure unless explicitly required by the blueprint.

---

## 2. Where You May Write

You are allowed to create or modify **only** CI/CD configuration files, primarily:

- `.github/workflows/ci.yaml` (or `.yml`)

You must NOT:
- create or modify application code,
- change tests,
- alter documentation,
- introduce new non-CI files.

Your scope is strictly the CI/CD workflows needed to implement the Pipeline Blueprint.

---

## 3. How to Use the Pipeline Blueprint

You must:

1. Parse the stages defined in `pipeline_blueprint_mvp.md`.
2. For each stage:
   - map it to a job or step (or set of steps) in the CI workflow.
   - ensure ordering matches the blueprint.
   - ensure inputs/outputs match the blueprintâ€™s evidence model.
3. Implement:
   - stage 1: semantic validation,
   - stage 2: test generation (via Test Meta-Prompt or equivalent mechanism),
   - stage 3: test execution,
   - stage 4: guardrails & MissionFramework checks,
   - stage 5: evidence aggregation and snapshot,
   - stage 6: deploy (conditional).

You must not omit a required stage.  
If a stage is MVP-optional, the blueprint will say so explicitly.

---

## 4. Guardrails for CI/CD Generation

When generating or updating the CI pipeline:

- Do NOT hard-code business rules that belong in MissionFramework or the blueprint.
- Do NOT introduce extra deployment environments that are not described.
- Do NOT introduce new manual approval steps beyond what the blueprint states.
- Do NOT add unrelated jobs (e.g., linting) unless the blueprint calls for them.
- Do NOT assume a particular CI provider beyond what the repository already uses (MVP: GitHub Actions assumed).

You may:
- refactor the workflow file to improve clarity,
- split complex jobs into multiple steps,
- reuse shared actions or scripts if consistent with the blueprint.

---

## 5. Evidence & MissionLog Integration

You must ensure that the workflow:

- writes evidence artefacts to the `evidence/` directory exactly as the blueprint describes, including:
  - `semantic_validation.json`
  - `test_generation.json`
  - `test_results.json`
  - `test_coverage.json`
  - `guardrails.json`
  - `deployment.json` (for deploy runs)
  - `snapshots/<commit_sha>.json`

- ensures each job that produces evidence:
  - has clear success/failure criteria,
  - fails the pipeline on violation where required.

You do not define evidence structure here; you only ensure it is produced as per the blueprint.

---

## 6. Triggering Rules

You must implement triggers that match the blueprint:

Examples (as per MVP blueprint):
- On pull requests â†’ run non-deploy stages only.
- On push to `main` â†’ run the full pipeline including deployment.
- On schedule (e.g. daily) â†’ run validation and evidence stages without deployment.
- On tag push â†’ full pipeline including deployment.

Use the exact triggering semantics described in the blueprint.

---

## 7. Output Format

When requested to generate or update the CI/CD pipeline, you must output:

1. A short summary of what you have generated or changed.
2. The full contents of the CI workflow file.

Format:

```markdown
### Summary
<2â€“4 sentences describing the CI/CD workflow, stages, and any key details>

### Updated File: .github/workflows/ci.yaml
```yaml
# full workflow content here
```
```

No additional commentary.

---

## 8. Completion Criteria

The CI/CD configuration is considered acceptable when:

- All stages described in the Pipeline Blueprint are present.
- Their ordering is correct.
- Evidence artefacts are produced as required.
- Guardrails and policy checks are invoked where expected.
- Deployment runs only under the conditions described in the blueprint.
- Triggers (PR, push, schedule, tags) align with the blueprint.

Final enforcement is done by MissionFramework and the runtime guardrails.  
Your role is to implement the pipeline in faithful alignment with the Pipeline Blueprint.

---

## END OF META-PROMPT


===== FILE: docs\prompts\ci_pipeline-instruction_prompt_template.txt =====
Please validate the implementation of Story <ST-XX> using ci_pipeline_metaprompt.

Story file:
  <path to story file>

Code file:
  <path to code file>

Test file:
  <path to test file>

===== FILE: docs\prompts\code_story_instruction_prompt_template.txt =====
Please implement Story <ST-XX> using story_code_metaprompt.

Story file:
  <path to story file>

Code file:
  <path to code file>



===== FILE: docs\prompts\story_code_metaprompt.md =====
# MissionSmith Story Implementation Meta-Prompt (MVP â€“ Guided + Deterministic)

You are the **MissionSmith Story Implementation Engine**.

You implement **one Story at a time** using:
- the Story markdown file
- the declared implementation slice
- Mission Destination artefacts
- the MissionFramework
- MissionHalo (UI stories only)

You must not invent architecture, data models, or service boundaries.
All global design decisions already exist.

---

## 1. Inputs

### 1.1 Story File

Location:
docs/mission_destination/stories/

Authoritative for:
- behaviour
- acceptance criteria
- status and adherence fields

Implement the Story exactly as written.

---

### 1.2 Mission Destination Artefacts (GLOBAL, AUTHORITATIVE)

You must consult and obey the following artefacts.

#### Initial Logical Data Model  
docs/mission_destination/initial_logical_data_model.md

Defines:
- entities
- attributes
- semantic meaning

You must not reinterpret semantics.

---

#### Initial Service Architecture  
docs/mission_destination/initial_service_architecture.md

Defines:
- which services exist
- service responsibilities
- service boundaries
- database access rules

You must not move responsibilities between services.

---

#### Initial Database Schema  
docs/mission_destination/initial_database_schema.md

Defines:
- physical tables
- keys and relationships

You must not change the schema unless the Story explicitly permits it.

---

#### Story â†’ Service Mapping  
docs/mission_destination/story_service_mapping.yaml

Defines:
- which service owns the Story

You must implement the Story **only** in the mapped service.

---

### 1.3 Implementation Slice

A Story is implemented in **exactly one file**.

You may modify only that file unless:
- the Story explicitly allows wider scope, and
- MissionFramework permits it.

You must not:
- create new files
- create new folders
- rename files
- modify other services

---

### 1.4 MissionFramework (Governance)

Location:
docs/mission_framework/

If there is a conflict:
MissionFramework overrides this meta-prompt.

---

### 1.5 MissionHalo (UI Stories Only)

Location:
docs/mission_halo/

Non-UI stories ignore MissionHalo.

---

## 2. How to Implement the Story

1. Read the Story and acceptance criteria.
2. Determine the owning service from story_service_mapping.yaml.
3. Validate data usage against the logical data model.
4. Validate placement against the service architecture.
5. Validate persistence against the database schema.
6. Implement the **simplest deterministic behaviour** that satisfies the Story.
7. Stay strictly within the implementation slice.

If ambiguity exists:
Choose the simplest interpretation that violates no artefact.

---

## 3. What You Must Not Do

- Do not invent new behaviours.
- Do not widen scope.
- Do not redesign services.
- Do not reinterpret data semantics.
- Do not refactor unrelated code.

Precedence order:
MissionFramework â†’ Mission Destination â†’ Story â†’ Meta-Prompt

---

## 4. Output Format (MANDATORY)

### Summary (2â€“3 sentences)

State:
- what was implemented
- which Mission Destination constraints were applied

### Updated File

Output the **entire updated file** for the implementation slice.

Rules:
- No diffs
- No commentary outside the Summary
- The file must be complete and ready to commit

---

END OF META-PROMPT


===== FILE: docs\prompts\story_test_instruction_prompt_template.txt =====
Please create or update tests for Story <ST-XX> using story_test_metaprompt.

Story file:
  <path to story file>

Test file:
  <path to test file>


===== FILE: docs\prompts\story_test_metaprompt.md =====
# MissionSmith Test Implementation Meta-Prompt (MVP â€“ Deterministic)

You are the **MissionSmith Test Generation Engine**.

You generate **minimal, deterministic, verifiable tests** for one Story using:
- the Story markdown file
- the implementation slice
- Mission Destination artefacts
- the MissionFramework
- MissionHalo (UI stories only)

---

## 1. Inputs

### 1.1 Story File

Location:
docs/mission_destination/stories/

Acceptance criteria define test scope.

---

### 1.2 Implementation Slice

The file modified by the Story implementation.

Tests must align exactly to this slice.

---

### 1.3 Mission Destination Artefacts (CONSTRAINTS)

#### Initial Logical Data Model  
docs/mission_destination/initial_logical_data_model.md

Tests must reference only semantically valid entities and fields.

---

#### Initial Service Architecture  
docs/mission_destination/initial_service_architecture.md

Tests must not:
- cross service boundaries
- invoke non-owning services

---

#### Initial Database Schema  
docs/mission_destination/initial_database_schema.md

Tests must reflect:
- real tables
- real keys
- real relationships

---

#### Story â†’ Service Mapping  
docs/mission_destination/story_service_mapping.yaml

Tests must target **only the owning service**.

---

### 1.4 MissionFramework

Test only observable effects of framework rules.

---

### 1.5 MissionHalo (UI Stories Only)

Validate:
- structural output
- styling rules
- component constraints

No browser automation.

---

## 2. Where Tests May Be Written

Tests may be written only in:

tests/services/<service>/test_*.py  
tests/api/<api>/test_*.py

Do not create new folder structures.

---

## 3. How to Write Tests

- Each acceptance criterion maps to at least one test
- Deterministic only
- No speculative behaviour
- No future features
- No cross-service assumptions

Use Arrange â†’ Act â†’ Assert.

---

## 4. What You Must Not Do

- Do not test implementation details.
- Do not mock unrelated services.
- Do not test beyond the Story scope.
- Do not over-test.

---

END OF META-PROMPT

===== FILE: missionlog\status\status_snapshot.md =====
# Mission Control Status Snapshot

## Epics

| Epic | Name | Overall |
|------|------|---------|
| E00 | Backend Foundation | Complete |
| E00-UI | User Interface Foundation | Complete |
| EP-01 | Client Ingestion & Normalisation | Planned |
| EP-02 | Client Matching & Golden Record | Planned |
| EP-03 | Client Search | Planned |
| EP-04 | Client Profile Assembly | In Progress |
| EP-05 | Data Quality & Lineage | Planned |
| EP-06 | Integration & API Exposure | Planned |


## Features

| Feature | Epic | Name | Overall | Stories |
|---------|------|------|---------|---------|
| FT-00-BE | E00 | Backend Foundation | Complete | ST-00 |
| FT-00-UI | E00-UI | User Interface Foundation | Complete | ST-00-FRONTEND-UI-SHELL |
| FT-01 | EP-01 | Source System Configuration | Planned | ST-01, ST-02 |
| FT-02 | EP-01 | Schema Mapping to Canonical Model | Planned | ST-03, ST-04 |
| FT-03 | EP-01 | Data Ingestion | Planned | ST-05, ST-06 |
| FT-04 | EP-01 | Incremental Ingestion & Change Detection | Planned | ST-07, ST-08 |
| FT-05 | EP-02 | Exact Match Rules | Planned | ST-09, ST-10 |
| FT-06 | EP-02 | Fuzzy & Probabilistic Matching | Planned | ST-11, ST-12 |
| FT-07 | EP-02 | Golden Record Construction | Planned | ST-13, ST-14, ST-15 |
| FT-08 | EP-03 | Search Index & Normalisation | Planned | ST-16, ST-17 |
| FT-09 | EP-03 | Fuzzy Search & Ranking | Planned | ST-18, ST-19 |
| FT-10 | EP-04 | Assemble Canonical Profile | In Progress | ST-20, ST-21 |
| FT-11 | EP-04 | Lineage Exposure | Planned | ST-22, ST-23 |
| FT-12 | EP-04 | Conflict Presentation | Planned | ST-24, ST-25 |
| FT-13 | EP-05 | Lineage Tracking | Planned | ST-26, ST-27 |
| FT-14 | EP-05 | Data Quality Scoring | Planned | ST-28, ST-29 |
| FT-15 | EP-05 | Auditability & Evidence | Planned | ST-30, ST-31 |
| FT-16 | EP-06 | Search API | Planned | ST-32, ST-33 |
| FT-17 | EP-06 | Client Profile API | Planned | ST-34, ST-35 |


## Stories

| Story | Feature | Name | Overall |
|-------|---------|------|---------|
| ST-00 | FT-00-BE | Backend Foundation | Complete |
| ST-00-FRONTEND-UI-SHELL | FT-00-UI | User Interface Foundation | Complete |
| ST-01 | FT-01 | Register CRM source | Planned |
| ST-02 | FT-01 | Register KYC source | Planned |
| ST-03 | FT-02 | Map identity fields | Planned |
| ST-04 | FT-02 | Map identifiers | Planned |
| ST-05 | FT-03 | Ingest CRM Data | Planned |
| ST-06 | FT-03 | Ingest KYC Data | Planned |
| ST-07 | FT-04 | Detect upstream deltas | Planned |
| ST-08 | FT-04 | Apply deltas | Planned |
| ST-09 | FT-05 | Match by tax ID | Planned |
| ST-10 | FT-05 | Match by registration number | Planned |
| ST-11 | FT-06 | Fuzzy name match | Planned |
| ST-12 | FT-06 | Attribute confidence | Planned |
| ST-13 | FT-07 | Merge identity | Planned |
| ST-14 | FT-07 | Merge addresses | Planned |
| ST-15 | FT-07 | Record lineage | Planned |
| ST-16 | FT-08 | Build index | Planned |
| ST-17 | FT-08 | Normalise search fields | Planned |
| ST-18 | FT-09 | Fuzzy search queries | Planned |
| ST-19 | FT-09 | Search ranking | Planned |
| ST-20 | FT-10 | Assemble base profile | Complete |
| ST-21 | FT-10 | Assemble metadata | Planned |
| ST-22 | FT-11 | Expose lineage | Planned |
| ST-23 | FT-11 | Drill-down lineage | Planned |
| ST-24 | FT-12 | Flag conflicts | Planned |
| ST-25 | FT-12 | Show merge logic | Planned |
| ST-26 | FT-13 | Store lineage history | Planned |
| ST-27 | FT-13 | Timestamp lineage | Planned |
| ST-28 | FT-14 | Compute freshness | Planned |
| ST-29 | FT-14 | Compute completeness | Planned |
| ST-30 | FT-15 | Audit ingestion | Planned |
| ST-31 | FT-15 | Audit merge | Planned |
| ST-32 | FT-16 | Search API basic | Planned |
| ST-33 | FT-16 | Search API ranking | Planned |
| ST-34 | FT-17 | Profile API basic | Planned |
| ST-35 | FT-17 | Profile API lineage | Planned |


===== FILE: README.md =====
# Single Client View (SCV)


===== FILE: requirements.txt =====
pytest
fastapi
uvicorn
sqlalchemy
httpx
psycopg[binary]


===== FILE: run-dev.ps1 =====
# run-dev.ps1 â€” simple, reliable dev launcher

$ErrorActionPreference = "Stop"

$ROOT = Split-Path -Parent $MyInvocation.MyCommand.Path

$BACKEND_VENV = "$ROOT\app_backend\venv\Scripts\Activate.ps1"
$BACKEND_DIR  = "$ROOT\backend_v2"
$FRONTEND_DIR = "$ROOT\app_frontend"

Write-Host "Starting backend..." -ForegroundColor Cyan

Start-Process powershell -ArgumentList @(
    "-NoExit",
    "-Command",
    @"
cd '$BACKEND_DIR'
& '$BACKEND_VENV'
python -m uvicorn app.main:app --reload --port 8000
"@
)

Start-Sleep -Seconds 2

Write-Host "Starting frontend..." -ForegroundColor Cyan

Start-Process powershell -ArgumentList @(
    "-NoExit",
    "-Command",
    @"
cd '$FRONTEND_DIR'
npm run dev
"@
)

Start-Sleep -Seconds 2

Write-Host "Opening browser..." -ForegroundColor Cyan
Start-Process "http://localhost:5173"








===== FILE: SCV_CANONICAL_STATE.md =====
\# SCV â€“ Canonical State (DO NOT GUESS)



\## Ground truth

\- A BFF / SCV composition layer EXISTS (see backend\_v2)

\- The frontend UI is written to expect a composed SCV profile

\- Blank panels are NOT a frontend bug

\- Blank panels occur because the running profile endpoint is thin



\## Canonical backend

\- Canonical backend: backend\_v2

\- Key file: backend\_v2/app/main.py

\- SCV composition logic exists here and must be used



\## Canonical profile contract

\- There must be ONE canonical SCV profile endpoint

\- That endpoint must return:

&nbsp; - client

&nbsp; - accounts

&nbsp; - match\_decisions

&nbsp; - trade\_history

&nbsp; - audit\_trail

&nbsp; - regulatory\_enrichment

&nbsp; - evidence\_artefacts

\- Keys must exist even when empty



\## Current mismatch (known issue)

\- Frontend currently calls a thin profile endpoint

\- BFF composition is NOT wired into that endpoint at runtime

\- This is the reason panels are blank



\## Agreed direction (locked)

\- Do NOT redesign frontend

\- Do NOT abandon the BFF

\- Wire the existing BFF / SCV composition into the canonical profile endpoint

\- Incrementally enrich via stories and MissionLog



\## Next concrete step (when resuming)

\- Identify the canonical SCV profile endpoint exposed by backend\_v2

\- Ensure frontend calls that endpoint

\- Or ensure that endpoint delegates to BFF composition internally

\- Start with ONE section (trade history) and prove end-to-end





===== FILE: src\__init__.py =====


===== FILE: src\api\__init__.py =====


===== FILE: src\api\http\client_profile_api.py =====
from src.services.client_profile.service import ClientProfileService


class ClientProfileAPI:
    """
    Thin API layer on top of ClientProfileService.

    This is a framework-agnostic stub. In a real implementation
    it would be wired into Flask/FastAPI/Django, etc.
    """

    def __init__(self, service: ClientProfileService | None = None) -> None:
        self.service = service or ClientProfileService()

    def get_client_profile(self, client_id: str) -> dict:
        """
        API-facing method. In a real HTTP handler, client_id would
        come from the route/path and the result would be serialised.
        """
        return self.service.get_client_profile(client_id)


===== FILE: src\domain\__init__.py =====


===== FILE: src\domain\models\__init__.py =====


===== FILE: src\domain\models\client_profile.py =====
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any


@dataclass
class ClientIdentifier:
    """
    Represents an identifier for a client from a specific upstream system.
    """
    system: str        # e.g. "CRM", "KYC"
    value: str         # e.g. "12345"


@dataclass
class ClientAddress:
    """
    Represents a normalised address for a client.
    Optional in MVP, but needed for merge, lineage, and quality features.
    """
    line1: Optional[str] = None
    line2: Optional[str] = None
    city: Optional[str] = None
    postcode: Optional[str] = None
    country: Optional[str] = None
    source: Optional[str] = None   # Upstream system this address came from


@dataclass
class ClientProfile:
    """
    Canonical Single Client View logical data model.
    This is the semantic target for all ingestion, normalisation, match/merge,
    lineage propagation, quality scoring, and profile assembly stories.
    """
    client_id: str
    name: str

    email: Optional[str] = None
    country: Optional[str] = None

    identifiers: List[ClientIdentifier] = field(default_factory=list)
    addresses: List[ClientAddress] = field(default_factory=list)

    # Where each field came from, and under what conditions
    lineage: Dict[str, Any] = field(default_factory=dict)

    # Data quality indicators (freshness, completeness, confidence)
    quality: Dict[str, float] = field(default_factory=dict)

    # Additional metadata (timestamps, merge strategy flags, raw source info)
    metadata: Dict[str, str] = field(default_factory=dict)

    # Optional raw inputs (keyed by upstream system)
    raw_sources: Dict[str, Dict[str, Any]] = field(default_factory=dict)


===== FILE: src\services\__init__.py =====


===== FILE: src\services\audit\service.py =====
from typing import List, Dict, Any
import datetime

class AuditIngestionService:
    """
    Service for auditing ingestion events (ST-30).
    Records audit entries for each ingestion event.
    """
    def __init__(self):
        # In-memory audit log for demonstration; replace with persistent storage in production
        self._audit_log: List[Dict[str, Any]] = []

    def record_audit_entry(self, source: str, entity_id: str, status: str, details: Dict[str, Any] = None) -> None:
        """
        Record an audit entry for an ingestion event.
        :param source: Source system name (e.g., 'CRM', 'KYC')
        :param entity_id: The ID of the ingested entity (e.g., client_id)
        :param status: Status of the ingestion (e.g., 'success', 'fail')
        :param details: Optional additional details (dict)
        """
        entry = {
            "timestamp": datetime.datetime.utcnow().isoformat() + 'Z',
            "source": source,
            "entity_id": entity_id,
            "status": status,
            "details": details or {}
        }
        self._audit_log.append(entry)

    def get_audit_entries(self, entity_id: str = None) -> List[Dict[str, Any]]:
        """
        Retrieve audit entries, optionally filtered by entity_id.
        :param entity_id: If provided, only entries for this entity are returned.
        :return: List of audit entries (dicts)
        """
        if entity_id:
            return [entry for entry in self._audit_log if entry["entity_id"] == entity_id]
        return list(self._audit_log)


===== FILE: src\services\client_profile\service.py =====
from typing import Dict, Any, List

from src.domain.models.client_profile import ClientProfile, ClientIdentifier, ClientAddress


class ClientProfileService:
    """
    Single Client View â€“ Client Profile Service.

    Implements:
    - ST-03: Map core identity fields from multiple sources to canonical model.
    - ST-04: Map identifiers from all sources.
    - ST-20: Assemble base profile fields from raw source records.
    - ST-09: Match by tax ID across profiles.
    """

    def __init__(self):
        # In a real implementation, these would be injected repositories or data sources
        self.sources = [
            self._get_crm_data,  # Replaced with real data fetching
            self._get_kyc_data,  # Replaced with real data fetching
        ]

    def get_client_profile(self, client_id: str) -> Dict[str, Any]:
        """
        ST-03 / ST-04 / ST-20:
        Map core identity fields and identifiers from all sources for the given client_id.
        Returns a canonical ClientProfile as dict.
        """
        # Aggregate real data from all sources
        raw_records = [source(client_id) for source in self.sources]
        return self.assemble_base_profile(client_id, raw_records)

    def assemble_base_profile(self, client_id: str, raw_records: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        ST-20: Assemble base profile fields from raw source records.
        """
        # Map fields to canonical model, prioritising CRM > KYC for demo
        canonical: Dict[str, Any] = {}
        lineage: Dict[str, Any] = {}

        # Loop through fields to populate canonical profile
        for field in ["name", "email", "phone", "country", "primary_address"]:
            for rec in raw_records:
                if not rec:
                    continue
                if field in rec and rec[field]:
                    canonical[field] = rec[field]
                    lineage[field] = rec.get("_source", "unknown")
                    break
            else:
                canonical[field] = None
                lineage[field] = None

        # Identifiers (ST-04)
        identifiers = self._map_identifiers(raw_records)

        # Addresses (optional, demo only)
        addresses = []
        for rec in raw_records:
            if not rec:
                continue
            if "address" in rec and rec["address"]:
                addr = rec["address"]
                addresses.append(
                    ClientAddress(
                        line1=addr.get("line1"),
                        line2=addr.get("line2"),
                        city=addr.get("city"),
                        postcode=addr.get("postcode"),
                        country=addr.get("country"),
                        source=rec.get("_source", "unknown"),
                    )
                )

        # Assembling the final profile
        profile = ClientProfile(
            client_id=client_id,
            name=canonical["name"] or "",
            email=canonical["email"],
            # phone=canonical["phone"],  # not yet in ClientProfile
            # primary_address=canonical["primary_address"],  # not yet in ClientProfile
            country=canonical["country"],
            identifiers=identifiers,
            addresses=addresses,
            lineage=lineage,
            raw_sources={rec["_source"]: rec for rec in raw_records if rec and "_source" in rec},
        )
        return profile.__dict__

    def match_by_tax_id(self, profiles: List[Dict[str, Any]], tax_id: str) -> List[Dict[str, Any]]:
        """
        ST-09: Exact match by tax ID.

        Returns a list of profiles where any raw source contains the given tax_id.
        """
        matched: List[Dict[str, Any]] = []
        for profile in profiles:
            raw_sources = profile.get("raw_sources", {})
            for source_data in raw_sources.values():
                if source_data.get("tax_id") == tax_id:
                    matched.append(profile)
                    break
        return matched

    def _map_identifiers(self, raw_records: List[Dict[str, Any]]) -> list:
        """
        ST-04: Map identifiers from all sources to canonical ClientIdentifier list.
        """
        identifiers = []
        for rec in raw_records:
            if not rec:
                continue
            if "identifier" in rec and rec["identifier"]:
                identifiers.append(
                    ClientIdentifier(system=rec.get("_source", "unknown"), value=rec["identifier"])
                )
        return identifiers

    # Replaced mock data sources with real data fetching methods
    def _get_crm_data(self, client_id: str) -> Dict[str, Any]:
        # Replace this with a call to your CRM database or service to fetch client data
        # Example: return fetch_client_from_crm(client_id)
        if client_id == "123":
            return {
                "_source": "crm",
                "name": "Alice Example",
                "email": "alice@example.com",
                "country": "UK",
                "identifier": "CRM-123",
            }
        return None

    def _get_kyc_data(self, client_id: str) -> Dict[str, Any]:
        # Replace this with a call to your KYC database or service to fetch client data
        # Example: return fetch_client_from_kyc(client_id)
        if client_id == "123":
            return {
                "_source": "kyc",
                "name": "Alice Example",
                "email": "alice@example.com",
                "country": "UK",
                "identifier": "KYC-123",
            }
        return None





===== FILE: src\services\client_search\service.py =====
class ClientSearchService:
    """
    Single Client View â€“ Client Search Service.

    Responsibilities (to be implemented from stories):
    - Search for clients by name, identifier, or attributes.
    - Return a lightweight set of matches.
    """

    def search(self, query: str) -> list[dict]:
        """
        Placeholder implementation.

        This method will be implemented by Copilot according to
        the MissionDestination story definitions.
        """
        raise NotImplementedError("To be implemented from story definitions.")


===== FILE: story-map.json =====
{
  "ST-00-backend-api-availability": {
    "description": "Backend API availability (health endpoint and service startup).",
    "backend": [
      "backend/main.py"
    ],
    "frontend": []
  }
}


===== FILE: test_db.py =====
from sqlalchemy import text
from database import SessionLocal

def test_db_connection():
    db = SessionLocal()
    try:
        value = db.execute(text("SELECT 1")).scalar_one()
        print(f"Database connected successfully! SELECT 1 returned: {value}")
    finally:
        db.close()

if __name__ == "__main__":
    test_db_connection()





===== FILE: tests\__init__.py =====


===== FILE: tests\api\__init__.py =====



===== FILE: tests\api\http\requirements.txt =====
pytest


===== FILE: tests\api\http\test_client_profile_api.py =====
import pytest
from src.api.http.client_profile_api import ClientProfileAPI


def test_client_profile_api_uses_service_stub():
    api = ClientProfileAPI()
    with pytest.raises(NotImplementedError):
        api.get_client_profile("dummy-id")


===== FILE: tests\api\http\test_st_00_backend_api_availability.py =====
import pytest
from fastapi.testclient import TestClient

# Import the FastAPI app exactly as defined in app_backend/main.py
from app_backend.main import app


def test_health_endpoint_returns_200_and_status_ok():
    """
    ST-00: Backend API availability test.

    Verifies:
    - /health endpoint exists (AC2)
    - Returns HTTP 200 (AC3)
    - Returns JSON containing { "status": "ok" } (AC4)
    """
    client = TestClient(app)

    response = client.get("/health")

    # AC3: HTTP 200
    assert response.status_code == 200

    data = response.json()

    # AC4: JSON contains "status": "ok"
    assert isinstance(data, dict)
    assert data.get("status") == "ok"


===== FILE: tests\api\http\test_st_00_frontend_ui_shell.py =====
# tests/api/http/test_st_00_frontend_ui_shell.py
#
# Story: ST-00-frontend-ui-shell
# Purpose: Verify that the built frontend UI shell is being served by the backend.

import os

from fastapi.testclient import TestClient

from app_backend.main import app, FRONTEND_DIST  # type: ignore[import]

client = TestClient(app)


def test_frontend_shell_index_is_served():
    """
    AC2/AC3-ish smoke test:
    - Index page is served at "/"
    - HTML contains the root mount point and expected title
    """

    # If the dist folder doesn't exist, this is a clear setup failure:
    # the frontend hasn't been built.
    assert os.path.isdir(
        FRONTEND_DIST
    ), "Frontend dist missing â€“ run `npm run build` in app_frontend first."

    response = client.get("/")
    assert response.status_code == 200

    body = response.text
    # From app_frontend/index.html
    assert "<div id=\"root\">" in body
    assert "<title>SCV Frontend</title>" in body


===== FILE: tests\conftest.py =====
from __future__ import annotations

import uuid
import pytest
from sqlalchemy import text

from pathlib import Path
import sys

REPO_ROOT = Path(__file__).resolve().parents[1]
BACKEND_ROOT = REPO_ROOT / "backend_v2"

if str(BACKEND_ROOT) not in sys.path:
    sys.path.insert(0, str(BACKEND_ROOT))


from app.db import Base, SessionLocal, engine

# Ensure models are imported so Base.metadata knows about them
from app.models import *  # noqa: F401,F403


def _is_postgres() -> bool:
    return engine.url.drivername.startswith("postgresql")


@pytest.fixture(scope="function")
def db_schema_session():
    """
    Real DB session isolated by ephemeral schema.

    - Creates schema scv_st05_<uuid>
    - Sets search_path to that schema on the session connection
    - Creates tables in that schema (using the SAME connection)
    - Drops schema afterwards (disposable)
    """
    if not _is_postgres():
        pytest.fail(f"ST-05 requires Postgres; got driver: {engine.url.drivername}")

    schema = f"scv_st05_{uuid.uuid4().hex}"

    db = SessionLocal()
    try:
        db.execute(text(f'CREATE SCHEMA "{schema}"'))
        db.execute(text(f'SET search_path TO "{schema}"'))
        db.commit()

        # IMPORTANT: create tables using the same connection that has search_path set
        conn = db.connection()
        Base.metadata.create_all(bind=conn)

        yield db

    finally:
        try:
            db.rollback()
            db.execute(text(f'DROP SCHEMA IF EXISTS "{schema}" CASCADE'))
            db.commit()
        finally:
            db.close()


===== FILE: tests\services\__init__.py =====


===== FILE: tests\services\audit\test_st_30_audit_ingestion.py =====
import pytest
from src.services.audit.service import AuditIngestionService

def test_record_audit_entry():
    service = AuditIngestionService()
    service.record_audit_entry(
        source="CRM",
        entity_id="client-123",
        status="success",
        details={"rows": 10}
    )
    entries = service.get_audit_entries("client-123")
    assert len(entries) == 1
    entry = entries[0]
    assert entry["source"] == "CRM"
    assert entry["entity_id"] == "client-123"
    assert entry["status"] == "success"
    assert entry["details"] == {"rows": 10}
    assert "timestamp" in entry

def test_get_audit_entries_filters_by_entity():
    service = AuditIngestionService()
    service.record_audit_entry("CRM", "client-1", "success")
    service.record_audit_entry("KYC", "client-2", "fail")
    entries = service.get_audit_entries("client-1")
    assert all(e["entity_id"] == "client-1" for e in entries)
    assert len(entries) == 1

def test_get_audit_entries_returns_all():
    service = AuditIngestionService()
    service.record_audit_entry("CRM", "client-1", "success")
    service.record_audit_entry("KYC", "client-2", "fail")
    entries = service.get_audit_entries()
    assert len(entries) == 2
    sources = {e["source"] for e in entries}
    assert sources == {"CRM", "KYC"}

def test_record_audit_entry_defaults_details():
    service = AuditIngestionService()
    service.record_audit_entry("CRM", "client-3", "success")
    entry = service.get_audit_entries("client-3")[0]
    assert entry["details"] == {}
    assert entry["status"] == "success"


===== FILE: tests\services\client_profile\test_client_profile_service.py =====
import pytest
from src.services.client_profile.service import ClientProfileService


class TestClientProfileService:
    """
    Test scaffold for ClientProfileService.

    NOTE:
    - Structure and naming follow the MissionSmith scaffold.
    - Real test cases will be generated from story definitions.
    """

    def test_get_client_profile_maps_identity_fields(self):
        service = ClientProfileService()
        # Use the mock data for client_id '123' (see service implementation)
        profile = service.get_client_profile("123")
        assert profile["name"] == "Alice Example"
        assert profile["email"] == "alice@example.com"
        assert profile["country"] in ("UK", "United Kingdom")
        assert any(i["system"] == "CRM" and i["value"] == "crm-123" for i in [id.__dict__ for id in profile["identifiers"]])
        assert any(i["system"] == "KYC" and i["value"] == "kyc-123" for i in [id.__dict__ for id in profile["identifiers"]])
        assert "CRM" in profile["raw_sources"]
        assert "KYC" in profile["raw_sources"]


===== FILE: tests\services\client_profile\test_st_04_map_identifiers.py =====
import pytest
from src.services.client_profile.service import ClientProfileService
from src.domain.models.client_profile import ClientIdentifier

def test_identifiers_mapped_from_all_sources():
    service = ClientProfileService()
    # Known client_id present in both CRM and KYC mock sources
    profile = service.get_client_profile("123")
    identifiers = profile["identifiers"]
    systems = {id_obj.system for id_obj in identifiers} if identifiers and hasattr(identifiers[0], 'system') else {id_obj['system'] for id_obj in identifiers}
    values = {id_obj.value for id_obj in identifiers} if identifiers and hasattr(identifiers[0], 'value') else {id_obj['value'] for id_obj in identifiers}
    assert systems == {"CRM", "KYC"}
    assert values == {"crm-123", "kyc-123"}
    assert len(identifiers) == 2

def test_identifiers_empty_for_unknown_client():
    service = ClientProfileService()
    profile = service.get_client_profile("notfound")
    assert profile["identifiers"] == []

def test_identifier_types():
    service = ClientProfileService()
    profile = service.get_client_profile("123")
    identifiers = profile["identifiers"]
    # Should be list of ClientIdentifier or dicts with system/value keys
    for id_obj in identifiers:
        if isinstance(id_obj, ClientIdentifier):
            assert hasattr(id_obj, "system")
            assert hasattr(id_obj, "value")
        else:
            assert "system" in id_obj
            assert "value" in id_obj


===== FILE: tests\services\client_profile\test_st_09_match_by_tax_id.py =====
from src.services.client_profile.service import ClientProfileService


def test_match_by_tax_id_exact():
    service = ClientProfileService()

    # Patch CRM source to include a tax_id for this client
    service._mock_crm_source = lambda client_id: {
        "_source": "CRM",
        "identifier": "crm-123",
        "name": "Alice Example",
        "email": "alice@example.com",
        "country": "UK",
        "tax_id": "TAX-001",
    } if client_id == "123" else {"_source": "CRM"}

    # Rebuild sources list so it uses the patched function
    service.sources = [service._mock_crm_source, service._mock_kyc_source]

    profile = service.get_client_profile("123")

    # Sanity check the raw source has the expected tax_id
    assert profile["raw_sources"]["CRM"]["tax_id"] == "TAX-001"

    # ACT: call the real service method
    matches = service.match_by_tax_id([profile], "TAX-001")

    # ASSERT: one match, and it's the correct client
    assert len(matches) == 1
    assert matches[0]["client_id"] == "123"


def test_match_by_tax_id_no_match():
    service = ClientProfileService()

    service._mock_crm_source = lambda client_id: {
        "_source": "CRM",
        "identifier": "crm-999",
        "name": "Bob Example",
        "email": "bob@example.com",
        "country": "UK",
        "tax_id": "TAX-999",
    } if client_id == "999" else {"_source": "CRM"}

    service.sources = [service._mock_crm_source, service._mock_kyc_source]

    profile = service.get_client_profile("999")

    matches = service.match_by_tax_id([profile], "TAX-001")
    assert len(matches) == 0



===== FILE: tests\services\client_profile\test_st_20_assemble_base_profile.py =====
import pytest
from src.services.client_profile.service import ClientProfileService

def test_assemble_base_profile_fields_set():
    service = ClientProfileService()
    # Known client_id present in both CRM and KYC mock sources
    profile = service.get_client_profile("123")
    # All base fields should be set (name, email, country)
    assert profile["name"] == "Alice Example"
    assert profile["email"] == "alice@example.com"
    assert profile["country"] == "UK"
    assert profile["client_id"] == "123"
    # Should have identifiers and addresses
    assert isinstance(profile["identifiers"], list)
    assert isinstance(profile["addresses"], list)
    # Should have lineage and raw_sources
    assert isinstance(profile["lineage"], dict)
    assert isinstance(profile["raw_sources"], dict)

def test_assemble_base_profile_unknown_client():
    service = ClientProfileService()
    profile = service.get_client_profile("notfound")
    # All base fields should be None or empty
    assert profile["name"] == ""
    assert profile["email"] is None
    assert profile["country"] is None
    assert profile["client_id"] == "notfound"
    assert profile["identifiers"] == []
    assert profile["addresses"] == []
    assert isinstance(profile["lineage"], dict)
    assert isinstance(profile["raw_sources"], dict)


===== FILE: tests\services\client_search\test_client_search_service.py =====
import pytest
from src.services.client_search.service import ClientSearchService


class TestClientSearchService:
    """
    Test scaffold for ClientSearchService.
    """

    def test_search_not_implemented(self):
        service = ClientSearchService()
        with pytest.raises(NotImplementedError):
            service.search("dummy query")



===== FILE: tests\services\ingestion\test_st_05_bulk_load_crm.py =====
from __future__ import annotations

from pathlib import Path

from sqlalchemy import text
from sqlalchemy.orm import Session

from app.services.crm_bulk_load_service import BulkCrmIngestionService, FileCrmSource


STORY_ID = "ST-05"


def _fixture_path() -> Path:
    return Path("backend_v2/app/fixtures/st05/crm_sample.csv")


def _count_rows(db: Session) -> int:
    return int(db.execute(text("SELECT COUNT(*) FROM crm_contacts")).scalar_one())


def test_bulk_load_persists_records_and_is_idempotent(db_schema_session: Session):
    db = db_schema_session

    # 1) Initial load
    result_1 = BulkCrmIngestionService.ingest(db, FileCrmSource(_fixture_path()))
    count_1 = _count_rows(db)

    assert result_1.total == 3
    assert result_1.skipped == 0
    assert result_1.inserted == 3
    assert result_1.updated == 0
    assert count_1 == 3

    # 2) Re-run (must not duplicate, must upsert)
    result_2 = BulkCrmIngestionService.ingest(db, FileCrmSource(_fixture_path()))
    count_2 = _count_rows(db)

    assert result_2.total == 3
    assert result_2.skipped == 0
    assert result_2.inserted == 0
    assert result_2.updated == 3
    assert count_2 == 3

   


===== FILE: tools\audit_status_schema.py =====
#!/usr/bin/env python
"""
Mission Control Status Schema Audit

Reads epics, features, and stories under:

  docs/mission_destination/epics
  docs/mission_destination/features
  docs/mission_destination/stories

and reports any items that are *not* in the standard MissionDestination shape.

We check:

EPICS
  - missing epic_id
  - missing features list
  - epic_id referenced by no features (informational)

FEATURES
  - missing feature_id
  - missing epic
  - missing stories list
  - epic reference that does not exist

STORIES
  - missing story_id
  - missing feature
  - feature reference that does not exist

This script is READ-ONLY: it does not change any files.
"""

from __future__ import annotations

import re
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional, Set


REPO_ROOT = Path(__file__).resolve().parents[1]
EPICS_DIR = REPO_ROOT / "docs" / "mission_destination" / "epics"
FEATURES_DIR = REPO_ROOT / "docs" / "mission_destination" / "features"
STORIES_DIR = REPO_ROOT / "docs" / "mission_destination" / "stories"


# ---------------------------------------------------------------------------
# Basic helpers
# ---------------------------------------------------------------------------

def _read(path: Path) -> str:
    return path.read_text(encoding="utf-8")


def _extract_scalar(text: str, key: str) -> Optional[str]:
    """
    Extract 'key: value' from front matter. Returns the value or None.
    """
    pattern = rf"^{re.escape(key)}:\s*(.+)$"
    m = re.search(pattern, text, flags=re.MULTILINE)
    if not m:
        return None
    val = m.group(1).strip()
    if val and val[0] in {"'", '"'} and val[-1:] == val[0]:
        val = val[1:-1]
    return val or None


def _extract_yaml_list(text: str, key: str) -> List[str]:
    """
    Extract:

      key:
        - item1
        - item2

    Returns [item1, item2].
    """
    pattern = rf"^{re.escape(key)}:\s*\n(?P<body>(?:\s+- .*\n)+)"
    m = re.search(pattern, text, flags=re.MULTILINE)
    if not m:
        return []
    body = m.group("body")
    items: List[str] = []
    for line in body.splitlines():
        s = line.strip()
        if s.startswith("- "):
            val = s[2:].strip()
            if val:
                items.append(val)
    return items


# ---------------------------------------------------------------------------
# Data structures
# ---------------------------------------------------------------------------

@dataclass
class EpicInfo:
    path: Path
    epic_id: Optional[str]
    features: List[str]


@dataclass
class FeatureInfo:
    path: Path
    feature_id: Optional[str]
    epic: Optional[str]
    stories: List[str]


@dataclass
class StoryInfo:
    path: Path
    story_id: Optional[str]
    feature: Optional[str]


# ---------------------------------------------------------------------------
# Collectors
# ---------------------------------------------------------------------------

def collect_epics() -> Dict[str, EpicInfo]:
    epics: Dict[str, EpicInfo] = {}
    print(f"Scanning epics in {EPICS_DIR}...")

    for path in sorted(EPICS_DIR.glob("*.md")):
        text = _read(path)
        epic_id = _extract_scalar(text, "epic_id")
        features = _extract_yaml_list(text, "features")

        key = epic_id if epic_id else f"__NO_ID__:{path.name}"
        epics[key] = EpicInfo(path=path, epic_id=epic_id, features=features)

    return epics


def collect_features() -> Dict[str, FeatureInfo]:
    features: Dict[str, FeatureInfo] = {}
    print(f"Scanning features in {FEATURES_DIR}...")

    for path in sorted(FEATURES_DIR.glob("*.md")):
        text = _read(path)
        feature_id = _extract_scalar(text, "feature_id")
        epic = _extract_scalar(text, "epic")
        stories = _extract_yaml_list(text, "stories")

        key = feature_id if feature_id else f"__NO_ID__:{path.name}"
        features[key] = FeatureInfo(
            path=path,
            feature_id=feature_id,
            epic=epic,
            stories=stories,
        )

    return features


def collect_stories() -> Dict[str, StoryInfo]:
    stories: Dict[str, StoryInfo] = {}
    print(f"Scanning stories in {STORIES_DIR}...")

    for path in sorted(STORIES_DIR.glob("*.md")):
        text = _read(path)
        story_id = _extract_scalar(text, "story_id")
        feature = _extract_scalar(text, "feature")

        key = story_id if story_id else f"__NO_ID__:{path.name}"
        stories[key] = StoryInfo(path=path, story_id=story_id, feature=feature)

    return stories


# ---------------------------------------------------------------------------
# Audit
# ---------------------------------------------------------------------------

def audit_schema() -> None:
    epics = collect_epics()
    features = collect_features()
    stories = collect_stories()

    epic_ids: Set[str] = {e.epic_id for e in epics.values() if e.epic_id}
    feature_ids: Set[str] = {f.feature_id for f in features.values() if f.feature_id}

    problems: List[str] = []

    # --- Epics ---
    problems.append("\n=== EPICS ===")

    missing_epic_id = [
        e for e in epics.values() if e.epic_id is None
    ]
    if missing_epic_id:
        problems.append("Epics missing epic_id:")
        for e in missing_epic_id:
            problems.append(f"  - {e.path.relative_to(REPO_ROOT)}")
    else:
        problems.append("All epics have epic_id.")

    missing_features_list = [
        e for e in epics.values() if e.epic_id and not e.features
    ]
    if missing_features_list:
        problems.append("Epics with no features list defined:")
        for e in missing_features_list:
            problems.append(f"  - {e.epic_id}: {e.path.relative_to(REPO_ROOT)}")
    else:
        problems.append("All epics with epic_id have a features list (may be empty).")

    # Epics that are never referenced by any feature (informational)
    referenced_epics: Set[str] = {
        f.epic for f in features.values() if f.epic is not None
    }
    unreferenced_epics = sorted(epic_ids - referenced_epics)
    problems.append("Epics with epic_id that are not referenced by any feature:")
    if unreferenced_epics:
        for eid in unreferenced_epics:
            ep = [e for e in epics.values() if e.epic_id == eid][0]
            problems.append(f"  - {eid}: {ep.path.relative_to(REPO_ROOT)}")
    else:
        problems.append("  (none)")

    # --- Features ---
    problems.append("\n=== FEATURES ===")

    missing_feature_id = [
        f for f in features.values() if f.feature_id is None
    ]
    if missing_feature_id:
        problems.append("Features missing feature_id:")
        for f in missing_feature_id:
            problems.append(f"  - {f.path.relative_to(REPO_ROOT)}")
    else:
        problems.append("All features have feature_id.")

    missing_epic_ref = [
        f for f in features.values() if f.feature_id and f.epic is None
    ]
    if missing_epic_ref:
        problems.append("Features with feature_id but no epic reference:")
        for f in missing_epic_ref:
            problems.append(f"  - {f.feature_id}: {f.path.relative_to(REPO_ROOT)}")
    else:
        problems.append("All features with feature_id have an epic reference.")

    missing_stories_list = [
        f for f in features.values() if f.feature_id and not f.stories
    ]
    if missing_stories_list:
        problems.append("Features with feature_id but no stories list defined:")
        for f in missing_stories_list:
            problems.append(f"  - {f.feature_id}: {f.path.relative_to(REPO_ROOT)}")
    else:
        problems.append("All features with feature_id have a stories list (may be empty).")

    bad_epic_ref = [
        f for f in features.values()
        if f.feature_id and f.epic and f.epic not in epic_ids
    ]
    if bad_epic_ref:
        problems.append("Features referencing an epic that does not exist:")
        for f in bad_epic_ref:
            problems.append(
                f"  - {f.feature_id} -> epic '{f.epic}' (missing), file: {f.path.relative_to(REPO_ROOT)}"
            )
    else:
        problems.append("No features reference missing epics.")

    # --- Stories ---
    problems.append("\n=== STORIES ===")

    missing_story_id = [
        s for s in stories.values() if s.story_id is None
    ]
    if missing_story_id:
        problems.append("Stories missing story_id:")
        for s in missing_story_id:
            problems.append(f"  - {s.path.relative_to(REPO_ROOT)}")
    else:
        problems.append("All stories have story_id.")

    missing_feature_ref = [
        s for s in stories.values() if s.story_id and s.feature is None
    ]
    if missing_feature_ref:
        problems.append("Stories with story_id but no feature reference:")
        for s in missing_feature_ref:
            problems.append(f"  - {s.story_id}: {s.path.relative_to(REPO_ROOT)}")
    else:
        problems.append("All stories with story_id have a feature reference.")

    bad_feature_ref = [
        s for s in stories.values()
        if s.story_id and s.feature and s.feature not in feature_ids
    ]
    if bad_feature_ref:
        problems.append("Stories referencing a feature that does not exist:")
        for s in bad_feature_ref:
            problems.append(
                f"  - {s.story_id} -> feature '{s.feature}' (missing), file: {s.path.relative_to(REPO_ROOT)}"
            )
    else:
        problems.append("No stories reference missing features.")

    # -----------------------------------------------------------------------
    # Print report
    # -----------------------------------------------------------------------
    print("\n".join(problems))


# ---------------------------------------------------------------------------
# CLI
# ---------------------------------------------------------------------------

def main() -> int:
    print("=== Mission Control Status Schema Audit ===")
    print(f"Repo root: {REPO_ROOT}")
    audit_schema()
    print("\n=== Audit complete ===")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())


===== FILE: tools\cleanup_frontmatter.py =====
#!/usr/bin/env python

from pathlib import Path
import re

REPO_ROOT = Path(__file__).resolve().parents[1]
STORIES_DIR = REPO_ROOT / "docs" / "mission_destination" / "stories"

def main() -> int:
    print("=== Removing implementation_presence from story front matter ===")
    count = 0

    for path in sorted(STORIES_DIR.glob("*.md")):
        text = path.read_text(encoding="utf-8")

        # Remove a line like: implementation_presence: false
        new_text = re.sub(
            r"^implementation_presence:\s*.*\n",
            "",
            text,
            flags=re.MULTILINE,
        )

        if new_text != text:
            path.write_text(new_text, encoding="utf-8")
            count += 1
            print(f"  cleaned {path.name}")

    print(f"Done. Updated {count} story files.")
    return 0

if __name__ == "__main__":
    raise SystemExit(main())


===== FILE: tools\cleanup_status_mappings.py =====
#!/usr/bin/env python
"""
Remove the accidental rollup mapping blocks:

- story_statuses: {...} from Feature files
- feature_statuses: {...} from Epic files

Run once, commit the changes, and they are gone.
"""

from __future__ import annotations

import re
from pathlib import Path

REPO_ROOT = Path(__file__).resolve().parents[1]
FEATURES_DIR = REPO_ROOT / "docs" / "mission_destination" / "features"
EPICS_DIR = REPO_ROOT / "docs" / "mission_destination" / "epics"


def _read(path: Path) -> str:
    return path.read_text(encoding="utf-8")


def _write(path: Path, text: str) -> None:
    path.write_text(text, encoding="utf-8")


def _remove_block(text: str, key: str) -> str:
    """
    Remove a YAML block starting with 'key:' up to the next top-level key or EOF.

    Matches both mapping and list blocks.
    """
    pattern = rf"^{key}:\s*.*?(?=^\S|\Z)"
    return re.sub(pattern, "", text, flags=re.MULTILINE | re.DOTALL)


def clean_features() -> int:
    changed = 0
    for path in sorted(FEATURES_DIR.glob("*.md")):
        original = _read(path)
        updated = _remove_block(original, "story_statuses")
        if updated != original:
            # Normalise multiple blank lines left behind
            updated = re.sub(r"\n{3,}", "\n\n", updated)
            _write(path, updated)
            changed += 1
            print(f">>> Cleaned story_statuses from {path.relative_to(REPO_ROOT)}")
    return changed


def clean_epics() -> int:
    changed = 0
    for path in sorted(EPICS_DIR.glob("*.md")):
        original = _read(path)
        updated = _remove_block(original, "feature_statuses")
        if updated != original:
            updated = re.sub(r"\n{3,}", "\n\n", updated)
            _write(path, updated)
            changed += 1
            print(f">>> Cleaned feature_statuses from {path.relative_to(REPO_ROOT)}")
    return changed


def main() -> int:
    print("=== Cleaning unwanted status mapping blocks ===")
    f = clean_features()
    e = clean_epics()
    print(f"Features cleaned: {f}")
    print(f"Epics cleaned:    {e}")
    print("=== Done ===")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())


===== FILE: tools\export-repo-clean.ps1 =====
<#
Safe & deterministic repo exporter.
- Only exports text-based files
- Excludes binary files automatically
- Excludes exports folder and any large caches
- Always outputs clean UTF-8 text
#>

param(
    [string]$OutputFile = "./exports/repo-export-clean.txt"
)

# Text-based extensions to include
$textExt = @(
    ".py", ".ts", ".tsx", ".js", ".jsx",
    ".json", ".yml", ".yaml",
    ".md", ".txt"
)

# Folders to exclude
$excludedDirs = @(
    ".git", "node_modules", "dist", "build",
    ".vscode", ".idea", "coverage", "out",
    "exports", ".venv", "__pycache__", ".pytest_cache"
)

$repoRoot = (Get-Location).Path
$outPath = Join-Path $repoRoot $OutputFile
$outDir = Split-Path $outPath -Parent

if (-not (Test-Path $outDir)) {
    New-Item -ItemType Directory -Path $outDir | Out-Null
}

# Remove old file
Remove-Item -ErrorAction SilentlyContinue $outPath

Write-Host "Exporting clean repo to $OutputFile ..."

Get-ChildItem -Recurse -File | ForEach-Object {

    $file = $_.FullName
    $ext  = $_.Extension.ToLower()

    # Skip excluded dirs
    foreach ($dir in $excludedDirs) {
        if ($file -like "*\$dir\*") { return }
    }

    # Only export known-safe text extensions
    if ($textExt -notcontains $ext) { return }

    # Never include the export file itself
    if ($file -eq $outPath) { return }

    # Relative path
    $rel = $file.Replace($repoRoot, "").TrimStart("\","/")

    "==================== FILE: $rel ====================" | Out-File $outPath -Append -Encoding UTF8
    Get-Content $_.FullName -Raw | Out-File $outPath -Append -Encoding UTF8
    "`n" | Out-File $outPath -Append -Encoding UTF8
}

Write-Host "Done."
Write-Host "Output saved to $outPath"


===== FILE: tools\export-repo-select.ps1 =====
<#
export-repo-select.ps1
Selective, chunked repo export for SCV-REPO.
Text-only, UTF-8 (no BOM), excludes venv/node_modules/caches.
#>

param(
  # FIX: Anchor repo root off the script location (/tools), not current working directory
  [string]$Root = (Resolve-Path (Join-Path $PSScriptRoot "..")).Path,
  [string]$OutDirName = "exports_clean",
  [int]$MaxPartBytes = 1600000
)

Set-StrictMode -Version Latest
$ErrorActionPreference = "Stop"

# -----------------------------
# Helpers
# -----------------------------
function Ensure-Dir([string]$Path) {
  if (-not (Test-Path $Path)) { New-Item -ItemType Directory -Path $Path | Out-Null }
}

function Write-Utf8NoBom([string]$Path, [string]$Text) {
  $utf8NoBom = New-Object System.Text.UTF8Encoding($false)
  [System.IO.File]::WriteAllText($Path, $Text, $utf8NoBom)
}

function Append-Utf8NoBom([string]$Path, [string]$Text) {
  $utf8NoBom = New-Object System.Text.UTF8Encoding($false)
  [System.IO.File]::AppendAllText($Path, $Text, $utf8NoBom)
}

# -----------------------------
# Include / Exclude rules
# -----------------------------
$IncludeDirs = @(
  "backend_v2",
  "app_backend",
  "app_frontend",
  "src",
  "tests",
  "tools",
  "infra",
  "docs",
  "missionlog"
)

$IncludeRootFiles = @(
  ".gitignore",
  "README.md",
  "requirements.txt",
  "run-dev.ps1",
  "SCV_CANONICAL_STATE.md",
  "story-map.json",
  "database.py",
  "test_db.py"
)

$ExcludeDirNames = @(
  ".git", ".github", ".vscode",
  ".venv", "venv", "node_modules",
  "__pycache__", ".pytest_cache", ".ruff_cache",
  "dist", "build", ".next",
  "exports", "exports_clean", "evidence"
)

$ExcludeExtensions = @(
  ".png", ".jpg", ".jpeg", ".gif", ".webp", ".ico",
  ".pdf", ".zip", ".7z", ".tar", ".gz",
  ".db", ".sqlite", ".sqlite3",
  ".exe", ".dll", ".pyd", ".pyc"
)

$AllowExtensions = @(
  ".py", ".js", ".jsx", ".ts", ".tsx",
  ".json", ".md", ".txt", ".yaml", ".yml",
  ".sql", ".ps1", ".psm1", ".toml", ".ini",
  ".css", ".scss", ".html", ".env", ".example"
)

function Is-ExcludedDir([System.IO.DirectoryInfo]$dir) {
  return $ExcludeDirNames -contains $dir.Name
}

function Should-IncludeFile([System.IO.FileInfo]$file) {
  $ext = $file.Extension.ToLowerInvariant()
  if ($ExcludeExtensions -contains $ext) { return $false }

  if ([string]::IsNullOrWhiteSpace($ext)) {
    return ($file.Name.ToLowerInvariant() -in @("dockerfile", "makefile"))
  }

  return ($AllowExtensions -contains $ext)
}

function Get-RelativePath($Full, $RootPath) {
  $Full = [System.IO.Path]::GetFullPath($Full)
  $RootPath = [System.IO.Path]::GetFullPath($RootPath)
  return $Full.Substring($RootPath.Length).TrimStart("\","/")
}

# -----------------------------
# Output setup
# -----------------------------
$OutDir = Join-Path $Root $OutDirName
Ensure-Dir $OutDir
Get-ChildItem $OutDir -Filter "repo_export_part_*.txt" -ErrorAction SilentlyContinue | Remove-Item -Force

$partIndex = 1
function Start-NewPart {
  param([int]$Index)
  $path = Join-Path $OutDir ("repo_export_part_{0:D2}.txt" -f $Index)
  $header = @(
    "CLEAN REPO EXPORT",
    "Generated: $((Get-Date).ToUniversalTime().ToString("yyyy-MM-dd HH:mm:ssZ"))",
    "Root: $Root",
    "",
    "============================================================",
    ""
  ) -join "`r`n"
  Write-Utf8NoBom $path $header
  return $path
}

$currentPart = Start-NewPart -Index $partIndex

function Append-Block($RelPath, $Content) {
  $block = @(
    "",
    "===== FILE: $RelPath =====",
    $Content,
    ""
  ) -join "`r`n"

  $size = [System.Text.Encoding]::UTF8.GetByteCount($block)
  if ((Get-Item $currentPart).Length + $size -gt $MaxPartBytes) {
    $script:partIndex++
    $script:currentPart = Start-NewPart -Index $script:partIndex
  }

  Append-Utf8NoBom $script:currentPart $block
}

# -----------------------------
# Collect files
# -----------------------------
$filesToExport = New-Object System.Collections.Generic.List[System.IO.FileInfo]

foreach ($rf in $IncludeRootFiles) {
  $p = Join-Path $Root $rf
  if (Test-Path $p) { $filesToExport.Add((Get-Item $p)) }
}

foreach ($d in $IncludeDirs) {
  $dirPath = Join-Path $Root $d
  if (-not (Test-Path $dirPath)) { continue }

  $stack = New-Object System.Collections.Generic.Stack[System.IO.DirectoryInfo]
  $stack.Push((Get-Item $dirPath))

  while ($stack.Count -gt 0) {
    $dir = $stack.Pop()
    if (Is-ExcludedDir $dir) { continue }

    foreach ($sd in $dir.GetDirectories()) {
      if (-not (Is-ExcludedDir $sd)) { $stack.Push($sd) }
    }

    foreach ($f in $dir.GetFiles()) {
      if (Should-IncludeFile $f) { $filesToExport.Add($f) }
    }
  }
}

# Force array even if only 1 item
$filesToExport = @($filesToExport | Sort-Object FullName)

Write-Host ("Exporting {0} files to {1}" -f $filesToExport.Length, $OutDir) -ForegroundColor Cyan

# -----------------------------
# Export
# -----------------------------
foreach ($f in $filesToExport) {
  $rel = Get-RelativePath $f.FullName $Root
  try {
    $content = Get-Content -LiteralPath $f.FullName -Raw
  } catch {
    $content = "[WARN] Could not read file as text."
  }
  Append-Block $rel $content
}

Write-Host ("Done. Created {0} part(s) in {1}" -f $partIndex, $OutDir) -ForegroundColor Green










===== FILE: tools\extract_MissionLog_evidence.py =====
#!/usr/bin/env python3
"""
Publish generated evidence from repo truth into MissionLog's public static folder.

Supports:
- Testing evidence
- Security evidence
- Quality (code quality) evidence
- Guardrails evidence

Testing source (generated by tools/run_story_tests.py):
  evidence/test_results/<STORY_ID>.json
Testing destination (served to MissionLog UI):
  app_frontend/public/missionlog/evidence/<STORY_ID>/testing.json

Security source (generated by tools/run_story_security.py):
  evidence/security/<STORY_ID>.json
Security destination (served to MissionLog UI):
  app_frontend/public/missionlog/evidence/<STORY_ID>/security.json

Quality source (generated by tools/run_story_lint.py):
  evidence/lint/<STORY_ID>.json
Quality destination (served to MissionLog UI):
  app_frontend/public/missionlog/evidence/<STORY_ID>/code_quality.json

Guardrails source (generated by tools/run_story_guardrails.py):
  evidence/guardrails/<STORY_ID>.json
Guardrails destination (served to MissionLog UI):
  app_frontend/public/missionlog/evidence/<STORY_ID>/guardrails.json

MissionLog fetches:
  /missionlog/evidence/<story_id>/<dimension>.json
Where dimensions include "testing", "security", "code_quality", "guardrails".
"""

from __future__ import annotations

import argparse
import json
import re
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, List, Tuple


# -----------------------------
# Repo root detection
# -----------------------------

def detect_repo_root() -> Path:
    """
    Detect repo root as the parent of the 'tools' directory.
    Matches tools/extract_MissionLog_story_defs.py behaviour.
    """
    here = Path(__file__).resolve()
    if here.parent.name != "tools":
        raise RuntimeError(
            f"Expected script to live in a 'tools' directory, but found: {here}"
        )
    return here.parent.parent


REPO_ROOT = detect_repo_root()


# -----------------------------
# Paths
# -----------------------------

TEST_SOURCE_DIR = REPO_ROOT / "evidence" / "test_results"
SECURITY_SOURCE_DIR = REPO_ROOT / "evidence" / "security"
LINT_SOURCE_DIR = REPO_ROOT / "evidence" / "lint"
GUARDRAILS_SOURCE_DIR = REPO_ROOT / "evidence" / "guardrails"

MISSIONLOG_PUBLIC_DIR = REPO_ROOT / "app_frontend" / "public" / "missionlog"
PUBLISH_ROOT = MISSIONLOG_PUBLIC_DIR / "evidence"  # /<story_id>/<dimension>.json


# -----------------------------
# Helpers
# -----------------------------

def utc_now_iso() -> str:
    return datetime.now(timezone.utc).replace(microsecond=0).isoformat().replace("+00:00", "Z")


def read_json(path: Path) -> Dict[str, Any]:
    try:
        return json.loads(path.read_text(encoding="utf-8"))
    except json.JSONDecodeError as e:
        raise RuntimeError(f"Invalid JSON in {path}: {e}") from e


def write_json(path: Path, payload: Dict[str, Any]) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(json.dumps(payload, indent=2, ensure_ascii=False) + "\n", encoding="utf-8")


def _scrub_repo_paths(obj: Any) -> Any:
    """
    Demo-safe sanitisation: remove absolute local paths from evidence payloads.
    Applied only at MissionLog extraction time.
    """
    repo_posix = REPO_ROOT.as_posix().rstrip("/")
    repo_win = str(REPO_ROOT).rstrip("\\")

    win_abs = re.compile(r"[A-Za-z]:\\[^ \n\r\t\"]+")
    repo_abs_posix = re.compile(re.escape(repo_posix) + r"(/[^ \n\r\t\"]*)?")

    if isinstance(obj, dict):
        return {k: _scrub_repo_paths(v) for k, v in obj.items()}

    if isinstance(obj, list):
        return [_scrub_repo_paths(v) for v in obj]

    if isinstance(obj, str):
        s = obj
        s = repo_abs_posix.sub("<repo>", s)
        if "\\" in s:
            s = s.replace(repo_win, "<repo>")
            s = win_abs.sub("<abs_path>", s)
        return s

    return obj


def _wrap_published(story_id: str, dimension: str, src: Path, evidence: Dict[str, Any]) -> Dict[str, Any]:
    return {
        "meta": {
            "story_id": story_id,
            "dimension": dimension,
            "published_at_utc": utc_now_iso(),
            "source_path": str(src.relative_to(REPO_ROOT)).replace("\\", "/"),
        },
        "payload": evidence,
    }


# -----------------------------
# Publish per-dimension
# -----------------------------

def publish_testing_evidence_for_story(story_id: str) -> Tuple[bool, str]:
    src = TEST_SOURCE_DIR / f"{story_id}.json"
    if not src.exists():
        return False, f"Missing testing evidence: {src.relative_to(REPO_ROOT)}"

    evidence = _scrub_repo_paths(read_json(src))
    dest = PUBLISH_ROOT / story_id / "testing.json"
    write_json(dest, _wrap_published(story_id, "testing", src, evidence))
    return True, f"Published testing evidence: {src.relative_to(REPO_ROOT)} -> {dest.relative_to(REPO_ROOT)}"


def publish_security_evidence_for_story(story_id: str) -> Tuple[bool, str]:
    src = SECURITY_SOURCE_DIR / f"{story_id}.json"
    if not src.exists():
        return False, f"Missing security evidence: {src.relative_to(REPO_ROOT)}"

    evidence = _scrub_repo_paths(read_json(src))
    dest = PUBLISH_ROOT / story_id / "security.json"
    write_json(dest, _wrap_published(story_id, "security", src, evidence))
    return True, f"Published security evidence: {src.relative_to(REPO_ROOT)} -> {dest.relative_to(REPO_ROOT)}"


def publish_code_quality_evidence_for_story(story_id: str) -> Tuple[bool, str]:
    src = LINT_SOURCE_DIR / f"{story_id}.json"
    if not src.exists():
        return False, f"Missing code-quality evidence: {src.relative_to(REPO_ROOT)}"

    evidence = _scrub_repo_paths(read_json(src))
    dest = PUBLISH_ROOT / story_id / "code_quality.json"
    write_json(dest, _wrap_published(story_id, "code_quality", src, evidence))
    return True, f"Published code-quality evidence: {src.relative_to(REPO_ROOT)} -> {dest.relative_to(REPO_ROOT)}"


def publish_guardrails_evidence_for_story(story_id: str) -> Tuple[bool, str]:
    """
    MissionLog guardrails badge uses evidenceDim "guardrails". :contentReference[oaicite:2]{index=2}
    Repo truth is produced by tools/run_story_guardrails.py in evidence/guardrails/<story>.json. :contentReference[oaicite:3]{index=3}
    """
    src = GUARDRAILS_SOURCE_DIR / f"{story_id}.json"
    if not src.exists():
        return False, f"Missing guardrails evidence: {src.relative_to(REPO_ROOT)}"

    evidence = _scrub_repo_paths(read_json(src))
    dest = PUBLISH_ROOT / story_id / "guardrails.json"
    write_json(dest, _wrap_published(story_id, "guardrails", src, evidence))
    return True, f"Published guardrails evidence: {src.relative_to(REPO_ROOT)} -> {dest.relative_to(REPO_ROOT)}"


def discover_story_ids() -> List[str]:
    """
    Discover story ids from any evidence source folders we support.
    """
    ids: set[str] = set()

    if TEST_SOURCE_DIR.exists():
        ids.update(p.stem for p in TEST_SOURCE_DIR.glob("ST-*.json"))

    if SECURITY_SOURCE_DIR.exists():
        ids.update(p.stem for p in SECURITY_SOURCE_DIR.glob("ST-*.json"))

    if LINT_SOURCE_DIR.exists():
        ids.update(p.stem for p in LINT_SOURCE_DIR.glob("ST-*.json"))

    if GUARDRAILS_SOURCE_DIR.exists():
        ids.update(p.stem for p in GUARDRAILS_SOURCE_DIR.glob("ST-*.json"))

    return sorted(ids)


# -----------------------------
# CLI
# -----------------------------

def main(argv: List[str] | None = None) -> int:
    parser = argparse.ArgumentParser(
        description="Extract MissionLog evidence (testing + security + quality + guardrails)."
    )
    g = parser.add_mutually_exclusive_group(required=True)
    g.add_argument("--story", help="Extract only this story ID (e.g., ST-05).")
    g.add_argument(
        "--all",
        action="store_true",
        help="Extract all stories that have evidence (testing/security/quality/guardrails).",
    )
    args = parser.parse_args(argv)

    if not MISSIONLOG_PUBLIC_DIR.exists():
        raise SystemExit(
            f"MissionLog public dir not found: {MISSIONLOG_PUBLIC_DIR.relative_to(REPO_ROOT)}"
        )

    if args.story:
        story_ids = [args.story.strip()]
    else:
        story_ids = discover_story_ids()
        if not story_ids:
            print(f"No evidence files found under {(REPO_ROOT / 'evidence').relative_to(REPO_ROOT)}")
            return 0

    ok_count = 0
    warn_count = 0

    for sid in story_ids:
        # Testing
        ok, msg = publish_testing_evidence_for_story(sid)
        if ok:
            ok_count += 1
            print(f">>> {msg}")
        else:
            warn_count += 1
            print(f"[WARN] {msg}")

        # Security
        ok, msg = publish_security_evidence_for_story(sid)
        if ok:
            ok_count += 1
            print(f">>> {msg}")
        else:
            warn_count += 1
            print(f"[WARN] {msg}")

        # Quality
        ok, msg = publish_code_quality_evidence_for_story(sid)
        if ok:
            ok_count += 1
            print(f">>> {msg}")
        else:
            warn_count += 1
            print(f"[WARN] {msg}")

        # Guardrails
        ok, msg = publish_guardrails_evidence_for_story(sid)
        if ok:
            ok_count += 1
            print(f">>> {msg}")
        else:
            warn_count += 1
            print(f"[WARN] {msg}")

    print(f"\nDone. Published artefacts: {ok_count}. Warnings: {warn_count}.")
    return 0 if warn_count == 0 else 2


if __name__ == "__main__":
    raise SystemExit(main())






===== FILE: tools\extract_MissionLog_story_defs.py =====
#!/usr/bin/env python3
"""
Export story markdown files into UI-consumable JSON for MissionLog.

Can be run from:
- repo root
- tools/ directory

Repo layout assumed:
  repo_root/
    docs/mission_destination/stories/
    app_frontend/public/missionlog/story_defs/
    tools/extract_MissionLog_story_defs.py
"""

from __future__ import annotations

import argparse
import json
import re
from dataclasses import dataclass
from datetime import datetime, timezone, date
from pathlib import Path
from typing import Any, Dict, Tuple

import yaml


# -----------------------------
# Repo root detection
# -----------------------------

def detect_repo_root() -> Path:
  """
  Detect repo root as the parent of the 'tools' directory.
  This allows the script to be run from anywhere.
  """
  here = Path(__file__).resolve()
  if here.parent.name != "tools":
    raise RuntimeError(
      f"Expected script to live in a 'tools' directory, but found: {here}"
    )
  return here.parent.parent


REPO_ROOT = detect_repo_root()


# -----------------------------
# JSON safety helpers
# -----------------------------

def json_safe(value):
  """
  Recursively convert values to JSON-serialisable forms.
  - datetime/date -> ISO 8601 string
  """
  if isinstance(value, datetime):
    return value.replace(microsecond=0).isoformat()
  if isinstance(value, date):
    return value.isoformat()
  if isinstance(value, dict):
    return {k: json_safe(v) for k, v in value.items()}
  if isinstance(value, list):
    return [json_safe(v) for v in value]
  return value


# -----------------------------
# Data model
# -----------------------------

@dataclass(frozen=True)
class StoryDoc:
  story_id: str
  slug: str
  source_path: str
  front_matter: Dict[str, Any]
  body_markdown: str
  exported_at_utc: str


FRONT_MATTER_RE = re.compile(r"^---\s*\n(.*?)\n---\s*\n(.*)$", re.DOTALL)


# -----------------------------
# Parsing helpers
# -----------------------------

def parse_story_markdown(md_text: str) -> Tuple[Dict[str, Any], str]:
  """
  Returns (front_matter_dict, body_markdown).
  If no front matter, returns ({}, full_text).
  """
  m = FRONT_MATTER_RE.match(md_text.strip() + "\n")
  if not m:
    return {}, md_text.strip()

  fm_raw = m.group(1)
  body = m.group(2).strip()

  front_matter = yaml.safe_load(fm_raw) or {}
  if not isinstance(front_matter, dict):
    raise ValueError("Front matter must be a YAML mapping/dict.")

  return front_matter, body


def infer_story_id(front_matter: Dict[str, Any], filename: str) -> str:
  for key in ("story_id", "id", "story"):
    if key in front_matter and front_matter[key]:
      return str(front_matter[key]).strip()

  m = re.match(r"^(ST-\d+)", filename, re.IGNORECASE)
  if m:
    return m.group(1).upper()

  raise ValueError(f"Could not infer story_id from front matter or filename: {filename}")


def slugify_filename(story_path: Path) -> str:
  return story_path.stem


def utc_now_iso() -> str:
  return datetime.now(timezone.utc).replace(microsecond=0).isoformat().replace("+00:00", "Z")


# -----------------------------
# Build + write
# -----------------------------

def build_story_doc(story_path: Path) -> StoryDoc:
  raw = story_path.read_text(encoding="utf-8")
  fm, body = parse_story_markdown(raw)
  story_id = infer_story_id(fm, story_path.name)

  return StoryDoc(
    story_id=story_id,
    slug=slugify_filename(story_path),
    source_path=str(story_path.relative_to(REPO_ROOT)).replace("\\", "/"),
    front_matter=fm,
    body_markdown=body,
    exported_at_utc=utc_now_iso(),
  )


def write_story_doc(out_dir: Path, doc: StoryDoc) -> Path:
  out_dir.mkdir(parents=True, exist_ok=True)
  out_path = out_dir / f"{doc.story_id}.json"

  payload = {
    "story_id": doc.story_id,
    "slug": doc.slug,
    "source_path": doc.source_path,
    "exported_at_utc": doc.exported_at_utc,
    "front_matter": json_safe(doc.front_matter),
    "body_markdown": doc.body_markdown,
  }

  out_path.write_text(
    json.dumps(payload, indent=2, ensure_ascii=False) + "\n",
    encoding="utf-8",
  )

  return out_path


# -----------------------------
# Main
# -----------------------------

def main() -> int:
  parser = argparse.ArgumentParser()
  parser.add_argument(
    "--stories_dir",
    default="docs/mission_destination/stories",
    help="Directory containing story markdown files (relative to repo root).",
  )
  parser.add_argument(
    "--out_dir",
    default="app_frontend/public/missionlog/story_defs",
    help="Output directory for per-story JSON files (relative to repo root).",
  )
  args = parser.parse_args()

  stories_dir = (REPO_ROOT / args.stories_dir).resolve()
  out_dir = (REPO_ROOT / args.out_dir).resolve()

  if not stories_dir.exists():
    raise SystemExit(f"Stories dir not found: {stories_dir}")

  md_files = sorted(stories_dir.glob("ST-*.md"))
  if not md_files:
    print(f"No story files found under {stories_dir}")
    return 0

  written = 0
  for p in md_files:
    try:
      doc = build_story_doc(p)
      write_story_doc(out_dir, doc)
      written += 1
    except Exception as e:
      print(f"[ERROR] {p.name}: {e}")

  print(f"Exported {written} story definition file(s) to {out_dir}")
  return 0


if __name__ == "__main__":
  raise SystemExit(main())



===== FILE: tools\generate_physical_data_model_json.py =====
import json
import re
from pathlib import Path


REPO_ROOT = Path(__file__).resolve().parents[1]
INPUT_PATH = REPO_ROOT / "docs" / "mission_destination" / "initial_database_schema.txt"
OUTPUT_PATH = REPO_ROOT / "app_frontend" / "src" / "data" / "initial_physical_data_model.json"


# ----------------------------
# 1) SQL DDL parsing (optional)
# ----------------------------
CREATE_TABLE_RE = re.compile(
    r"CREATE\s+TABLE\s+(?:IF\s+NOT\s+EXISTS\s+)?(?P<name>[^\s(]+)\s*\((?P<body>.*?)\)\s*;",
    re.IGNORECASE | re.DOTALL,
)
LINE_SPLIT_RE = re.compile(r",\s*(?![^()]*\))")  # split on commas not inside parentheses


def _normalise_table_name(raw: str) -> str:
    s = raw.strip().strip('"')
    s = s.replace('".\"', ".").replace('"."', ".").replace('."', ".")
    s = s.replace('"', "")
    return s


def _parse_column_def(line: str):
    parts = line.strip().split()
    if len(parts) < 2:
        return None

    col = parts[0].strip('"')
    constraint_keywords = {
        "not", "null", "default", "primary", "unique", "references", "check", "constraint", "generated", "collate"
    }

    type_tokens = []
    i = 1
    while i < len(parts):
        token = parts[i].lower()
        if token in constraint_keywords:
            break
        type_tokens.append(parts[i])
        i += 1

    col_type = " ".join(type_tokens).strip()
    rest = " ".join(parts[i:]).strip()

    nullable = True
    if re.search(r"\bNOT\s+NULL\b", rest, re.IGNORECASE):
        nullable = False

    default = None
    m = re.search(
        r"\bDEFAULT\b\s+(.+?)(?:\s+\bNOT\b\s+\bNULL\b|\s+\bNULL\b|\s+\bPRIMARY\b|\s+\bUNIQUE\b|\s+\bREFERENCES\b|$)",
        rest,
        re.IGNORECASE,
    )
    if m:
        default = m.group(1).strip()

    is_pk_inline = bool(re.search(r"\bPRIMARY\s+KEY\b", rest, re.IGNORECASE))
    is_unique_inline = bool(re.search(r"\bUNIQUE\b", rest, re.IGNORECASE))

    fk = None
    m = re.search(r"\bREFERENCES\b\s+([^\s(]+)\s*\(([^)]+)\)", rest, re.IGNORECASE)
    if m:
        fk = {
            "references_table": _normalise_table_name(m.group(1)),
            "references_columns": [c.strip().strip('"') for c in m.group(2).split(",")],
        }

    return {
        "name": col,
        "type": col_type or parts[1],
        "nullable": nullable,
        "default": default,
        "pk": is_pk_inline,
        "unique": is_unique_inline,
        "fk": fk,
        "raw": line.strip(),
    }


def _parse_table_body(body: str):
    items = [x.strip() for x in LINE_SPLIT_RE.split(body.strip()) if x.strip()]
    columns = []
    constraints = []

    for item in items:
        if re.match(r"^(CONSTRAINT|PRIMARY\s+KEY|FOREIGN\s+KEY|UNIQUE|CHECK)\b", item, re.IGNORECASE):
            constraints.append(item)
            continue
        col = _parse_column_def(item)
        if col:
            columns.append(col)
        else:
            constraints.append(item)

    pk_cols = set()
    for c in constraints:
        m = re.search(r"PRIMARY\s+KEY\s*\(([^)]+)\)", c, re.IGNORECASE)
        if m:
            pk_cols |= {x.strip().strip('"') for x in m.group(1).split(",")}

    for col in columns:
        if col["name"] in pk_cols:
            col["pk"] = True

    fks = []
    for c in constraints:
        m = re.search(
            r"FOREIGN\s+KEY\s*\(([^)]+)\)\s+REFERENCES\s+([^\s(]+)\s*\(([^)]+)\)",
            c,
            re.IGNORECASE,
        )
        if m:
            fks.append(
                {
                    "columns": [x.strip().strip('"') for x in m.group(1).split(",")],
                    "references_table": _normalise_table_name(m.group(2)),
                    "references_columns": [x.strip().strip('"') for x in m.group(3).split(",")],
                    "raw": c.strip(),
                }
            )

    return columns, constraints, fks


def _extract_tables_from_sql(text: str):
    tables = []
    for m in CREATE_TABLE_RE.finditer(text):
        raw_name = m.group("name")
        body = m.group("body")
        table_name = _normalise_table_name(raw_name)
        columns, constraints, fks = _parse_table_body(body)
        tables.append(
            {
                "table": table_name,
                "columns": columns,
                "constraints": constraints,
                "foreign_keys": fks,
            }
        )
    return tables


# --------------------------------
# 2) Markdown schema parsing (yours)
# --------------------------------
MD_TABLE_RE = re.compile(r"^###\s+\d+(?:\.\d+)*\s+`(?P<table>[^`]+)`\s*$", re.MULTILINE)

MD_SECTION_PK_RE = re.compile(r"^\*\*Primary key\*\*\s*$", re.MULTILINE)
MD_SECTION_FK_RE = re.compile(r"^\*\*Foreign keys\*\*\s*$", re.MULTILINE)
MD_SECTION_KEYS_RE = re.compile(r"^\*\*Key columns\*\*\s*$", re.MULTILINE)

MD_BULLET_COL_RE = re.compile(r"^\s*-\s*`(?P<col>[^`]+)`\s*$", re.MULTILINE)
MD_BULLET_FK_RE = re.compile(
    r"^\s*-\s*`(?P<col>[^`]+)`\s*[â†’-]\s*`(?P<ref_table>[^`.]+)\.(?P<ref_col>[^`]+)`\s*$",
    re.MULTILINE,
)


def _slice_block(text: str, start_idx: int, end_idx: int) -> str:
    return text[start_idx:end_idx].strip()


def _extract_tables_from_markdown(text: str):
    matches = list(MD_TABLE_RE.finditer(text))
    if not matches:
        return []

    tables = []
    for i, m in enumerate(matches):
        table_name = m.group("table").strip()
        start = m.end()
        end = matches[i + 1].start() if i + 1 < len(matches) else len(text)
        block = _slice_block(text, start, end)

        # PK
        pk_cols = set()
        pk_pos = MD_SECTION_PK_RE.search(block)
        if pk_pos:
            # take bullets after PK heading until blank line or next heading
            pk_block = block[pk_pos.end():]
            for b in MD_BULLET_COL_RE.finditer(pk_block):
                pk_cols.add(b.group("col").strip())

        # FK
        fks = []
        fk_pos = MD_SECTION_FK_RE.search(block)
        if fk_pos:
            fk_block = block[fk_pos.end():]
            for fkm in MD_BULLET_FK_RE.finditer(fk_block):
                col = fkm.group("col").strip()
                ref_table = fkm.group("ref_table").strip()
                ref_col = fkm.group("ref_col").strip()
                fks.append(
                    {
                        "columns": [col],
                        "references_table": ref_table,
                        "references_columns": [ref_col],
                        "raw": f"`{col}` -> `{ref_table}.{ref_col}`",
                    }
                )

        fk_map = {}
        for fk in fks:
            if fk["columns"]:
                fk_map[fk["columns"][0]] = {
                    "references_table": fk["references_table"],
                    "references_columns": fk["references_columns"],
                }

        # Key columns
        key_cols = []
        keys_pos = MD_SECTION_KEYS_RE.search(block)
        if keys_pos:
            keys_block = block[keys_pos.end():]
            for b in MD_BULLET_COL_RE.finditer(keys_block):
                key_cols.append(b.group("col").strip())

        # Build columns (minimal deterministic)
        cols = []
        seen = set()
        for c in key_cols:
            if c in seen:
                continue
            seen.add(c)
            cols.append(
                {
                    "name": c,
                    "type": "unknown",
                    "nullable": None,
                    "default": None,
                    "pk": c in pk_cols,
                    "unique": False,
                    "fk": fk_map.get(c),
                    "raw": c,
                }
            )

        tables.append(
            {
                "table": table_name,
                "columns": cols,
                "constraints": [],
                "foreign_keys": fks,
            }
        )

    return tables


def main():
    if not INPUT_PATH.exists():
        raise SystemExit(f"Input schema file not found: {INPUT_PATH}")

    text = INPUT_PATH.read_text(encoding="utf-8", errors="ignore")

    # Prefer real SQL if present
    tables = _extract_tables_from_sql(text)
    if not tables:
        # Fallback to MissionDestination markdown structure
        tables = _extract_tables_from_markdown(text)

    artefact = {
        "artifact_type": "physical_data_model",
        "artifact_version": "1.0",
        "source": {
            "authority": "MissionDestination",
            "derived_from": "docs/mission_destination/initial_database_schema.txt",
        },
        "tables": sorted(tables, key=lambda t: t["table"]),
    }

    OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)
    OUTPUT_PATH.write_text(json.dumps(artefact, indent=2), encoding="utf-8")
    print(f"Wrote: {OUTPUT_PATH}")
    print(f"Tables: {len(artefact['tables'])}")


if __name__ == "__main__":
    main()



===== FILE: tools\generate_story_config_snippets.py =====
#!/usr/bin/env python
"""
Generate STORY_CONFIG snippets for a new Story.

This does NOT modify any files.
It just prints the blocks you should paste into:

- tools/run_story_tests.py
- tools/run_story_lint.py
- tools/run_story_security.py

Usage:

  python tools/generate_story_config_snippets.py \\
      ST-00 \\
      docs/mission_destination/stories/ST-00-backend-api-availability.md \\
      tests/api/http/test_st_00_backend_api_availability.py \\
      app_backend/main.py

You can pass multiple targets as comma-separated lists, e.g.:

  python tools/generate_story_config_snippets.py \\
      ST-99 \\
      docs/mission_destination/stories/ST-99_some_story.md \\
      tests/services/foo/test_st_99_foo.py,tests/api/http/test_st_99_foo_api.py \\
      src/services/foo/service.py,src/domain/models/foo.py
"""

from __future__ import annotations

import sys
from pathlib import Path


def _path_to_reproot_expr(rel_path: str) -> str:
    """
    Turn 'docs/mission_destination/stories/ST-03_map_identity_fields.md'
    into:

        REPO_ROOT
        / "docs"
        / "mission_destination"
        / "stories"
        / "ST-03_map_identity_fields.md"
    """
    parts = rel_path.replace("\\", "/").split("/")
    indent = " " * 8
    joined = ('"\n' + indent + '/ "').join(parts)
    return f"REPO_ROOT\n{indent}/ \"{joined}\""


def _format_list(name: str, items: list[str], indent_base: int = 8) -> str:
    indent = " " * indent_base
    inner = "\n".join(f'{indent}    "{item}",' for item in items)
    return f'{indent}"{name}": [\n{inner}\n{indent}],'


def main(argv: list[str]) -> int:
    if len(argv) < 5:
        print(
            "Usage:\n"
            "  python tools/generate_story_config_snippets.py "
            "STORY_ID STORY_FILE_REL_PATH PYTEST_TARGETS LINT_TARGETS [SECURITY_TARGETS]\n\n"
            "Example:\n"
            "  python tools/generate_story_config_snippets.py \\\n"
            "      ST-00 \\\n"
            "      docs/mission_destination/stories/ST-00-backend-api-availability.md \\\n"
            "      tests/api/http/test_st_00_backend_api_availability.py \\\n"
            "      app_backend/main.py\n"
        )
        return 1

    story_id = argv[1].upper()
    story_file_rel = argv[2]

    pytest_targets = [t.strip() for t in argv[3].split(",") if t.strip()]
    lint_targets = [t.strip() for t in argv[4].split(",") if t.strip()]

    if len(argv) >= 6:
        security_targets = [t.strip() for t in argv[5].split(",") if t.strip()]
    else:
        # Default: use lint targets for security if not explicitly given.
        security_targets = list(lint_targets)

    story_file_expr = _path_to_reproot_expr(story_file_rel)

    print("\n" + "=" * 72)
    print(f"STORY CONFIG SNIPPETS FOR {story_id}")
    print("=" * 72 + "\n")

    # ------------------------------------------------------------------
    # run_story_tests.py
    # ------------------------------------------------------------------
    print("# Paste into tools/run_story_tests.py inside STORY_CONFIG:")
    print()
    print(f'    "{story_id}": {{')
    print(f"        \"story_file\": {story_file_expr},")
    print(_format_list("pytest_targets", pytest_targets, indent_base=8))
    print("    },")
    print()

    # ------------------------------------------------------------------
    # run_story_lint.py
    # ------------------------------------------------------------------
    print("# Paste into tools/run_story_lint.py inside STORY_CONFIG:")
    print()
    print(f'    "{story_id}": {{')
    print(f"        \"story_file\": {story_file_expr},")
    print(_format_list("lint_targets", lint_targets, indent_base=8))
    print("    },")
    print()

    # ------------------------------------------------------------------
    # run_story_security.py
    # ------------------------------------------------------------------
    print("# Paste into tools/run_story_security.py inside STORY_CONFIG:")
    print()
    print(f'    "{story_id}": {{')
    print(f"        \"story_file\": {story_file_expr},")
    print(_format_list("security_targets", security_targets, indent_base=8))
    print("    },")
    print()

    # ------------------------------------------------------------------
    # Guardrails note
    # ------------------------------------------------------------------
    print("# NOTE: run_story_guardrails.py uses explicit _register_story(...) calls.")
    print("# If this Story should have guardrails, add a _register_story(...) block")
    print("# there manually, choosing an appropriate check function.")
    print()

    return 0


if __name__ == "__main__":
    raise SystemExit(main(sys.argv))


===== FILE: tools\guardrails\generate_physical_data_model_by_domain.py =====
#!/usr/bin/env python3
"""
Generate a high-density Physical Data Model artefact from a Postgres schema SQL dump.

Outputs:
  app_frontend/src/data/physical_model_by_domain.json

Inputs:
  - database_schema12.sql (or any SQL file)
  - platform_domains.json (domain taxonomy, table assignments)

This generator is deterministic and grounded in the schema.
"""

from __future__ import annotations

import argparse
import json
import re
from dataclasses import dataclass, asdict
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple


# -----------------------------
# Regexes (Postgres-ish)
# -----------------------------

CREATE_TABLE_RE = re.compile(
    r"""
    CREATE\s+TABLE\s+(?:IF\s+NOT\s+EXISTS\s+)?
    (?P<name>(?:"[^"]+"|\w+)(?:\.(?:"[^"]+"|\w+))?)      # schema.table or table
    \s*\(
      (?P<body>.*?)
    \)
    \s*;
    """,
    re.IGNORECASE | re.DOTALL | re.VERBOSE,
)

ALTER_ADD_CONSTRAINT_RE = re.compile(
    r"""
    ALTER\s+TABLE\s+ONLY\s+(?P<table>(?:"[^"]+"|\w+)(?:\.(?:"[^"]+"|\w+))?)
    \s+ADD\s+CONSTRAINT\s+(?P<constraint>(?:"[^"]+"|\w+))
    \s+(?P<kind>PRIMARY\s+KEY|FOREIGN\s+KEY)
    \s*\((?P<cols>[^)]+)\)
    (?:
      \s+REFERENCES\s+(?P<ref_table>(?:"[^"]+"|\w+)(?:\.(?:"[^"]+"|\w+))?)
      \s*\((?P<ref_cols>[^)]+)\)
    )?
    \s*;
    """,
    re.IGNORECASE | re.DOTALL | re.VERBOSE,
)

# Inline FK inside column definition: col type REFERENCES table(col)
INLINE_FK_RE = re.compile(
    r"""
    REFERENCES\s+(?P<ref_table>(?:"[^"]+"|\w+)(?:\.(?:"[^"]+"|\w+))?)
    \s*\((?P<ref_cols>[^)]+)\)
    """,
    re.IGNORECASE | re.VERBOSE,
)

# Table-level FK constraint in CREATE TABLE body:
TABLE_FK_RE = re.compile(
    r"""
    (?:CONSTRAINT\s+(?P<cname>(?:"[^"]+"|\w+))\s+)?
    FOREIGN\s+KEY\s*\((?P<cols>[^)]+)\)
    \s+REFERENCES\s+(?P<ref_table>(?:"[^"]+"|\w+)(?:\.(?:"[^"]+"|\w+))?)
    \s*\((?P<ref_cols>[^)]+)\)
    """,
    re.IGNORECASE | re.DOTALL | re.VERBOSE,
)

# Table-level PK constraint in CREATE TABLE body:
TABLE_PK_RE = re.compile(
    r"""
    (?:CONSTRAINT\s+(?P<cname>(?:"[^"]+"|\w+))\s+)?
    PRIMARY\s+KEY\s*\((?P<cols>[^)]+)\)
    """,
    re.IGNORECASE | re.DOTALL | re.VERBOSE,
)

# CREATE [UNIQUE] INDEX name ON schema.table USING btree (col1, col2)
CREATE_INDEX_RE = re.compile(
    r"""
    CREATE\s+(?P<unique>UNIQUE\s+)?INDEX\s+(?P<name>(?:"[^"]+"|\w+))
    \s+ON\s+(?P<table>(?:"[^"]+"|\w+)(?:\.(?:"[^"]+"|\w+))?)
    (?:\s+USING\s+(?P<method>\w+))?
    \s*\((?P<cols>[^)]+)\)
    \s*;
    """,
    re.IGNORECASE | re.DOTALL | re.VERBOSE,
)

# Split on commas not inside parentheses (good enough for most DDL dumps)
COMMA_SPLIT_RE = re.compile(r",\s*(?![^()]*\))")


def unquote_ident(s: str) -> str:
    s = s.strip()
    if s.startswith('"') and s.endswith('"'):
        return s[1:-1]
    return s


def parse_qualified_name(raw: str) -> Tuple[str, str]:
    """
    Returns (schema, table). If schema missing, defaults to 'public'.
    Handles quoted identifiers.
    """
    raw = raw.strip()
    if "." in raw:
        left, right = raw.split(".", 1)
        return unquote_ident(left), unquote_ident(right)
    return "public", unquote_ident(raw)


def split_ident_list(raw: str) -> List[str]:
    return [unquote_ident(x.strip()) for x in raw.split(",") if x.strip()]


@dataclass
class FKRef:
    references_table: str
    references_columns: List[str]


@dataclass
class Column:
    name: str
    type: str
    nullable: Optional[bool]
    default: Optional[str]
    unique: bool
    pk: bool
    fk: Optional[FKRef]
    raw: str


@dataclass
class Index:
    name: str
    unique: bool
    method: str
    columns: List[str]


@dataclass
class ForeignKey:
    name: Optional[str]
    columns: List[str]
    references_table: str
    references_columns: List[str]
    raw: str


@dataclass
class TableModel:
    schema: str
    table: str
    columns: List[Column]
    primary_key: List[str]
    foreign_keys: List[ForeignKey]
    indexes: List[Index]
    create_constraints: List[str]


def parse_column_def(line: str) -> Optional[Column]:
    """
    Very tolerant column parser:
      col_name col_type [constraints...]
    """
    raw = line.strip()
    if not raw:
        return None

    # Skip constraints lines
    if re.match(r"^(CONSTRAINT|PRIMARY\s+KEY|FOREIGN\s+KEY|UNIQUE|CHECK)\b", raw, re.IGNORECASE):
        return None

    # Tokenize by whitespace, but keep type tokens until we hit constraint keywords
    parts = raw.split()
    if len(parts) < 2:
        return None

    col_name = unquote_ident(parts[0])

    constraint_keywords = {"not", "null", "default", "primary", "unique", "references", "check", "constraint"}
    type_tokens: List[str] = []
    i = 1
    while i < len(parts):
        if parts[i].lower() in constraint_keywords:
            break
        type_tokens.append(parts[i])
        i += 1
    col_type = " ".join(type_tokens).strip() or parts[1]

    rest = " ".join(parts[i:]).strip()

    # nullable (None if unknown, but we can usually infer)
    nullable: Optional[bool] = True
    if re.search(r"\bNOT\s+NULL\b", rest, re.IGNORECASE):
        nullable = False

    # default
    default = None
    m = re.search(r"\bDEFAULT\b\s+(.+?)(?=\s+\bNOT\b\s+\bNULL\b|\s+\bNULL\b|\s+\bPRIMARY\b|\s+\bUNIQUE\b|\s+\bREFERENCES\b|$)", rest, re.IGNORECASE)
    if m:
        default = m.group(1).strip().rstrip(",")

    unique = bool(re.search(r"\bUNIQUE\b", rest, re.IGNORECASE))
    pk = bool(re.search(r"\bPRIMARY\s+KEY\b", rest, re.IGNORECASE))

    fk = None
    m = INLINE_FK_RE.search(rest)
    if m:
        ref_schema, ref_table = parse_qualified_name(m.group("ref_table"))
        fk = FKRef(
            references_table=f"{ref_schema}.{ref_table}",
            references_columns=split_ident_list(m.group("ref_cols")),
        )

    return Column(
        name=col_name,
        type=col_type,
        nullable=nullable,
        default=default,
        unique=unique,
        pk=pk,
        fk=fk,
        raw=raw,
    )


def parse_create_table_body(body: str) -> Tuple[List[Column], List[str], List[str], List[ForeignKey]]:
    """
    Returns:
      columns, constraints_raw, pk_cols, fks
    """
    items = [x.strip() for x in COMMA_SPLIT_RE.split(body.strip()) if x.strip()]
    columns: List[Column] = []
    constraints_raw: List[str] = []

    # First pass: columns + raw constraints lines
    for item in items:
        col = parse_column_def(item)
        if col:
            columns.append(col)
        else:
            constraints_raw.append(item)

    # Table-level PK columns
    pk_cols: List[str] = []
    for c in constraints_raw:
        m = TABLE_PK_RE.search(c)
        if m:
            pk_cols = split_ident_list(m.group("cols"))
            break

    # Mark pk cols on columns
    if pk_cols:
        pk_set = set(pk_cols)
        for col in columns:
            if col.name in pk_set:
                col.pk = True

    # Table-level FKs
    fks: List[ForeignKey] = []
    for c in constraints_raw:
        m = TABLE_FK_RE.search(c)
        if not m:
            continue
        cname = m.group("cname")
        cols = split_ident_list(m.group("cols"))
        ref_schema, ref_table = parse_qualified_name(m.group("ref_table"))
        ref_cols = split_ident_list(m.group("ref_cols"))
        fks.append(
            ForeignKey(
                name=unquote_ident(cname) if cname else None,
                columns=cols,
                references_table=f"{ref_schema}.{ref_table}",
                references_columns=ref_cols,
                raw=c.strip(),
            )
        )

        # Mark inline on participating columns too
        fk_ref = FKRef(references_table=f"{ref_schema}.{ref_table}", references_columns=ref_cols)
        for col in columns:
            if col.name in set(cols) and col.fk is None:
                col.fk = fk_ref

    return columns, constraints_raw, pk_cols, fks


def load_platform_domains(path: Path) -> Dict[str, Any]:
    obj = json.loads(path.read_text(encoding="utf-8"))
    # Build table->domain mapping
    table_to_domain: Dict[str, str] = {}
    for d in obj.get("domains", []):
        dom = d.get("domain")
        for t in d.get("tables", []):
            table_to_domain[t] = dom
    return {"raw": obj, "table_to_domain": table_to_domain}


def infer_domain(table: str, table_to_domain: Dict[str, str]) -> str:
    """
    Domain assignment:
      1) explicit mapping from platform_domains.json (strongest)
      2) fallback heuristics (prefix / keywords)
      3) Unmapped
    """
    if table in table_to_domain:
        return table_to_domain[table]

    t = table.lower()
    if any(k in t for k in ["ingestion", "source_", "raw", "crm_", "trade_history", "transactions", "accounts"]):
        return "Ingestion"
    if any(k in t for k in ["cluster", "match_", "decision"]):
        return "Matching"
    if any(k in t for k in ["lineage", "dictionary", "precedence"]):
        return "Lineage & dictionary"
    if any(k in t for k in ["audit", "validation", "health", "error", "conflict"]):
        return "Assurance"
    if any(k in t for k in ["evidence"]):
        return "Evidence"
    if any(k in t for k in ["kyc", "risk", "regulatory"]):
        return "KYC & risk"
    if t in {"clients", "client_operational_state", "client_source_coverage"}:
        return "Client canonical"
    return "Unmapped"


def main() -> None:
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--sql",
        type=str,
        default="database_schema12.sql",
        help="Path to schema SQL dump (default: database_schema12.sql)",
    )
    parser.add_argument(
        "--domains",
        type=str,
        default="app_frontend/src/data/platform_domains.json",
        help="Path to platform_domains.json (default: app_frontend/src/data/platform_domains.json)",
    )
    parser.add_argument(
        "--out",
        type=str,
        default="app_frontend/src/data/physical_model_by_domain.json",
        help="Output JSON path (default: app_frontend/src/data/physical_model_by_domain.json)",
    )
    args = parser.parse_args()

    repo_root = Path.cwd()

    sql_path = (repo_root / args.sql).resolve() if not Path(args.sql).is_absolute() else Path(args.sql)
    domains_path = (repo_root / args.domains).resolve() if not Path(args.domains).is_absolute() else Path(args.domains)
    out_path = (repo_root / args.out).resolve() if not Path(args.out).is_absolute() else Path(args.out)

    if not sql_path.exists():
        raise SystemExit(f"SQL file not found: {sql_path}")
    if not domains_path.exists():
        raise SystemExit(f"platform_domains.json not found: {domains_path}")

    domain_data = load_platform_domains(domains_path)
    table_to_domain: Dict[str, str] = domain_data["table_to_domain"]
    platform_domains_raw = domain_data["raw"]

    sql_text = sql_path.read_text(encoding="utf-8", errors="ignore")

    # Parse CREATE TABLE blocks
    tables: Dict[str, TableModel] = {}

    for m in CREATE_TABLE_RE.finditer(sql_text):
        schema, table = parse_qualified_name(m.group("name"))
        body = m.group("body")
        columns, constraints_raw, pk_cols, fks = parse_create_table_body(body)

        fq = f"{schema}.{table}"
        tables[fq] = TableModel(
            schema=schema,
            table=table,
            columns=columns,
            primary_key=pk_cols if pk_cols else [c.name for c in columns if c.pk],
            foreign_keys=fks,
            indexes=[],
            create_constraints=constraints_raw,
        )

    # Parse ALTER TABLE constraints (PK/FK)
    for m in ALTER_ADD_CONSTRAINT_RE.finditer(sql_text):
        schema, table = parse_qualified_name(m.group("table"))
        fq = f"{schema}.{table}"
        if fq not in tables:
            # Some dumps include alters for tables not in this file; skip safely
            continue

        kind = m.group("kind").strip().upper()
        cols = split_ident_list(m.group("cols"))
        cname = unquote_ident(m.group("constraint"))

        if kind.startswith("PRIMARY"):
            # Add PK columns
            pk_set = set(tables[fq].primary_key or [])
            pk_set |= set(cols)
            tables[fq].primary_key = list(pk_set)
            # Mark pk on columns
            for col in tables[fq].columns:
                if col.name in pk_set:
                    col.pk = True

        elif kind.startswith("FOREIGN"):
            ref_table_raw = m.group("ref_table")
            ref_cols_raw = m.group("ref_cols")
            if not ref_table_raw or not ref_cols_raw:
                continue
            ref_schema, ref_table = parse_qualified_name(ref_table_raw)
            ref_cols = split_ident_list(ref_cols_raw)

            fk = ForeignKey(
                name=cname,
                columns=cols,
                references_table=f"{ref_schema}.{ref_table}",
                references_columns=ref_cols,
                raw=m.group(0).strip(),
            )
            tables[fq].foreign_keys.append(fk)

            fk_ref = FKRef(references_table=f"{ref_schema}.{ref_table}", references_columns=ref_cols)
            for col in tables[fq].columns:
                if col.name in set(cols) and col.fk is None:
                    col.fk = fk_ref

    # Parse indexes
    for m in CREATE_INDEX_RE.finditer(sql_text):
        schema, table = parse_qualified_name(m.group("table"))
        fq = f"{schema}.{table}"
        if fq not in tables:
            continue

        cols_raw = m.group("cols")
        cols = [unquote_ident(x.strip()) for x in cols_raw.split(",") if x.strip()]
        method = (m.group("method") or "btree").lower()
        ix = Index(
            name=unquote_ident(m.group("name")),
            unique=bool(m.group("unique")),
            method=method,
            columns=cols,
        )
        tables[fq].indexes.append(ix)

    # Build domain -> tables (with full details)
    domain_to_tables: Dict[str, List[Dict[str, Any]]] = {}

    for fq, tm in tables.items():
        dom = infer_domain(tm.table, table_to_domain)
        domain_to_tables.setdefault(dom, []).append(
            {
                "schema": tm.schema,
                "table": tm.table,
                "columns": [
                    {
                        "name": c.name,
                        "type": c.type,
                        "nullable": c.nullable,
                        "default": c.default,
                        "unique": c.unique,
                        "pk": c.pk,
                        "fk": (asdict(c.fk) if c.fk else None),
                        "raw": c.raw,
                    }
                    for c in tm.columns
                ],
                "primary_key": tm.primary_key,
                "foreign_keys": [
                    {
                        "name": fk.name,
                        "columns": fk.columns,
                        "references_table": fk.references_table,
                        "references_columns": fk.references_columns,
                        "raw": fk.raw,
                    }
                    for fk in tm.foreign_keys
                ],
                "indexes": [asdict(ix) for ix in tm.indexes],
                "create_constraints": tm.create_constraints,
            }
        )

    # Compose final artefact in the order of platform_domains.json (plus Unmapped at end)
    domains_out: List[Dict[str, Any]] = []
    used_domains = set()

    for d in platform_domains_raw.get("domains", []):
        dom_name = d["domain"]
        used_domains.add(dom_name)
        domains_out.append(
            {
                "domain": dom_name,
                "purpose": d.get("purpose", ""),
                "tables": sorted(domain_to_tables.get(dom_name, []), key=lambda x: x["table"]),
            }
        )

    if "Unmapped" in domain_to_tables:
        domains_out.append(
            {
                "domain": "Unmapped",
                "purpose": "Tables not yet assigned to a platform domain.",
                "tables": sorted(domain_to_tables["Unmapped"], key=lambda x: x["table"]),
            }
        )

    artefact = {
        "artifact_type": "physical_model_by_domain",
        "artifact_version": "1.0",
        "source": {
            "authority": "Postgres schema dump",
            "derived_from": str(sql_path),
        },
        "domains": domains_out,
        "summary": {
            "tables": len(tables),
            "domains": len(domains_out),
            "foreign_keys": sum(len(t["foreign_keys"]) for dom in domains_out for t in dom["tables"]),
            "indexes": sum(len(t["indexes"]) for dom in domains_out for t in dom["tables"]),
        },
    }

    out_path.parent.mkdir(parents=True, exist_ok=True)
    out_path.write_text(json.dumps(artefact, indent=2), encoding="utf-8")

    print(f"Wrote: {out_path}")
    print(json.dumps(artefact["summary"], indent=2))


if __name__ == "__main__":
    main()


===== FILE: tools\guardrails\run_g03_ldm.py =====
#!/usr/bin/env python3
from __future__ import annotations

import argparse
import json
import re
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List

import yaml
from jsonschema import Draft202012Validator


LDM_ID_RE = re.compile(
    r"^ldm://(?P<name>[a-zA-Z0-9_\-]+)/(?P<version>[0-9]+\.[0-9]+\.[0-9]+)$"
)


@dataclass(frozen=True)
class G03Config:
    ldm_contract: str
    artifact: str
    mode: str  # strict | lenient


def read_story_front_matter(story_path: Path) -> Dict[str, Any]:
    text = story_path.read_text(encoding="utf-8")

    if not text.startswith("---"):
        raise ValueError(f"No front matter found in story: {story_path}")

    parts = text.split("---", 2)
    if len(parts) < 3:
        raise ValueError(f"Malformed front matter in story: {story_path}")

    front_matter = yaml.safe_load(parts[1]) or {}
    if not isinstance(front_matter, dict):
        raise ValueError("Front matter must be a YAML mapping")

    return front_matter


def extract_g03_config(front_matter: Dict[str, Any]) -> G03Config:
    guardrails = front_matter.get("guardrails", {})
    g03 = guardrails.get("G03")

    if not isinstance(g03, dict):
        raise ValueError("guardrails.G03 must be declared as a mapping")

    ldm_contract = g03.get("ldm_contract")
    artifact = g03.get("artifact")
    mode = g03.get("mode", "strict")

    if not isinstance(ldm_contract, str) or not ldm_contract:
        raise ValueError("G03 requires a non-empty ldm_contract")
    if not isinstance(artifact, str) or not artifact:
        raise ValueError("G03 requires a non-empty artifact")
    if mode not in ("strict", "lenient"):
        raise ValueError("G03 mode must be 'strict' or 'lenient'")

    return G03Config(
        ldm_contract=ldm_contract,
        artifact=artifact,
        mode=mode,
    )


def resolve_contract_path(ldm_contract: str, repo_root: Path) -> Path:
    match = LDM_ID_RE.match(ldm_contract)
    if not match:
        raise ValueError(f"Invalid LDM contract id: {ldm_contract}")

    name = match.group("name")
    version = match.group("version")

    path = (
        repo_root
        / "docs"
        / "ldm"
        / "contracts"
        / name
        / version
        / "schema.json"
    )

    if not path.exists():
        raise FileNotFoundError(f"LDM schema not found: {path}")

    return path


def load_json(path: Path) -> Any:
    return json.loads(path.read_text(encoding="utf-8"))


def normalize_schema(schema: Dict[str, Any], mode: str) -> Dict[str, Any]:
    if mode == "strict":
        return schema

    def strip_additional_props(node: Any) -> Any:
        if isinstance(node, dict):
            out = {}
            for k, v in node.items():
                if k == "additionalProperties" and v is False:
                    continue
                out[k] = strip_additional_props(v)
            return out
        if isinstance(node, list):
            return [strip_additional_props(x) for x in node]
        return node

    return strip_additional_props(schema)


def validate_instance(schema: Dict[str, Any], instance: Any) -> List[Dict[str, str]]:
    validator = Draft202012Validator(schema)
    errors: List[Dict[str, str]] = []

    for err in sorted(validator.iter_errors(instance), key=lambda e: list(e.path)):
        path = "$"
        if err.path:
            for p in err.path:
                path += f".{p}" if isinstance(p, str) else f"[{p}]"

        errors.append(
            {
                "path": path,
                "rule": err.validator or "validation",
                "detail": err.message,
            }
        )

    return errors


def main() -> int:
    parser = argparse.ArgumentParser(description="G03 Guardrail â€” LDM Adherence")
    parser.add_argument("--story", required=True, help="Path to story markdown file")
    parser.add_argument("--repo-root", default=".", help="Repository root")
    parser.add_argument("--story-id", help="Override story_id")
    parser.add_argument("--out", help="Output path for guardrail result JSON")
    args = parser.parse_args()

    repo_root = Path(args.repo_root).resolve()
    story_path = Path(args.story).resolve()

    front_matter = read_story_front_matter(story_path)
    g03 = extract_g03_config(front_matter)

    story_id = args.story_id or front_matter.get("story_id") or story_path.stem

    schema_path = resolve_contract_path(g03.ldm_contract, repo_root)
    schema = load_json(schema_path)

    if schema.get("$id") != g03.ldm_contract:
        raise ValueError(
            f"Schema $id mismatch: expected {g03.ldm_contract}, "
            f"found {schema.get('$id')}"
        )

    schema = normalize_schema(schema, g03.mode)

    artifact_path = (
        repo_root
        / "evidence"
        / "runtime_outputs"
        / story_id
        / f"{g03.artifact}.json"
    )

    if not artifact_path.exists():
        raise FileNotFoundError(f"Runtime artifact not found: {artifact_path}")

    instance = load_json(artifact_path)
    errors = validate_instance(schema, instance)
    passed = len(errors) == 0

    result = {
        "guardrail_id": "G03",
        "passed": passed,
        "message": "LDM validation passed"
        if passed
        else f"LDM validation failed for {g03.ldm_contract}",
        "contract_id": g03.ldm_contract,
        "artifact_path": str(artifact_path.relative_to(repo_root)).replace("\\", "/"),
        "errors": errors,
        "warnings_count": 0,
        "warnings": [],
    }

    if args.out:
        out_path = Path(args.out).resolve()
        out_path.parent.mkdir(parents=True, exist_ok=True)
        out_path.write_text(json.dumps(result, indent=2), encoding="utf-8")
    else:
        print(json.dumps(result, indent=2))

    return 0 if passed else 2


if __name__ == "__main__":
    raise SystemExit(main())


===== FILE: tools\inspect_clients.py =====
import sys
from pathlib import Path

# Ensure repo root is on the Python path (must be BEFORE importing database)
REPO_ROOT = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(REPO_ROOT))

from sqlalchemy import text
from database import SessionLocal


def inspect_clients(limit: int = 5):
    db = SessionLocal()
    try:
        result = db.execute(
            text("SELECT * FROM clients LIMIT :limit"),
            {"limit": limit},
        )
        rows = result.fetchall()

        print(f"\nSample rows from clients (limit {limit}):\n")
        for row in rows:
            print(dict(row._mapping))

    finally:
        db.close()


if __name__ == "__main__":
    inspect_clients()



===== FILE: tools\inspect_db.py =====
import sys
from pathlib import Path

# Ensure repo root is on the Python path
REPO_ROOT = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(REPO_ROOT))

from sqlalchemy import text
from database import SessionLocal


def list_tables():
    db = SessionLocal()
    try:
        result = db.execute(
            text("""
                SELECT table_name
                FROM information_schema.tables
                WHERE table_schema = 'public'
                ORDER BY table_name;
            """)
        )

        tables = [row[0] for row in result.fetchall()]

        print("\nTables in SCV database:\n")
        for t in tables:
            print(f" - {t}")

        print(f"\nTotal tables: {len(tables)}")

    finally:
        db.close()


if __name__ == "__main__":
    list_tables()



===== FILE: tools\inspect_db_schema.py =====
#!/usr/bin/env python
"""
Inspect the current database schema for the SCV backend.

- Imports the SQLAlchemy Base and engine from app_backend.db
- Ensures the repo root is on sys.path so `app_backend` can be imported
- Reflects all tables and prints their columns, types, PK/FK flags, etc.

Usage (from repo root):

    # Human-readable text (default)
    python tools/inspect_db_schema.py

    # Markdown tables (good for docs)
    python tools/inspect_db_schema.py markdown

This script is READ-ONLY with respect to data. It may create tables if they
don't exist yet via `Base.metadata.create_all(bind=engine)`, but it does not
insert, update, or delete any rows.
"""

from __future__ import annotations

import sys
from pathlib import Path
from typing import Any, Dict, List

from sqlalchemy import inspect as sqla_inspect

# ---------------------------------------------------------------------------
# Repo root + sys.path so `app_backend` can be imported
# ---------------------------------------------------------------------------

REPO_ROOT = Path(__file__).resolve().parents[1]
if str(REPO_ROOT) not in sys.path:
    sys.path.insert(0, str(REPO_ROOT))

# Now we can safely import the backend DB objects
from app_backend.db import Base, engine  # type: ignore[import]

# ---------------------------------------------------------------------------
# Core inspection helpers
# ---------------------------------------------------------------------------


def describe_schema() -> Dict[str, List[Dict[str, Any]]]:
    """
    Reflect the database schema via SQLAlchemy's Inspector.

    Returns:
        {
          "table_name": [
            {
              "name": "column_name",
              "type": "VARCHAR(255)",
              "nullable": False,
              "primary_key": True/False,
              "default": <default or None>,
              "fk": "other_table.other_column" or None,
            },
            ...
          ],
          ...
        }
    """
    # Ensure all models have been created (no-op if already present)
    Base.metadata.create_all(bind=engine)

    inspector = sqla_inspect(engine)
    schema: Dict[str, List[Dict[str, Any]]] = {}

    for table_name in inspector.get_table_names():
        pk_info = inspector.get_pk_constraint(table_name) or {}
        pk_cols = set(pk_info.get("constrained_columns") or [])

        fk_map: Dict[str, str] = {}
        for fk in inspector.get_foreign_keys(table_name):
            ref_table = fk.get("referred_table")
            ref_cols = fk.get("referred_columns") or []
            constrained_cols = fk.get("constrained_columns") or []
            for col_name, ref_col in zip(constrained_cols, ref_cols):
                fk_map[col_name] = f"{ref_table}.{ref_col}"

        col_infos: List[Dict[str, Any]] = []
        for col in inspector.get_columns(table_name):
            name = col["name"]
            col_infos.append(
                {
                    "name": name,
                    "type": str(col["type"]),
                    "nullable": bool(col.get("nullable", True)),
                    "primary_key": name in pk_cols,
                    "default": col.get("default"),
                    "fk": fk_map.get(name),
                }
            )

        schema[table_name] = col_infos

    return schema


def print_text(schema: Dict[str, List[Dict[str, Any]]]) -> None:
    """Pretty, human-readable text output."""
    if not schema:
        print("No tables found in the database.")
        return

    for table_name in sorted(schema.keys()):
        print(f"\n=== {table_name} ===")
        for col in schema[table_name]:
            flags: List[str] = []
            if col["primary_key"]:
                flags.append("PK")
            if col["fk"]:
                flags.append(f"FK -> {col['fk']}")
            if not col["nullable"]:
                flags.append("NOT NULL")

            flag_part = f" ({', '.join(flags)})" if flags else ""
            print(f"- {col['name']}: {col['type']}{flag_part}")


def print_markdown(schema: Dict[str, List[Dict[str, Any]]]) -> None:
    """Markdown table output (useful for docs/MissionAtlas)."""
    if not schema:
        print("No tables found in the database.")
        return

    for table_name in sorted(schema.keys()):
        print(f"\n### {table_name}\n")
        print("| Column | Type | Flags | Default |")
        print("|--------|------|-------|---------|")
        for col in schema[table_name]:
            flags: List[str] = []
            if col["primary_key"]:
                flags.append("PK")
            if col["fk"]:
                flags.append(f"FK -> {col['fk']}")
            if not col["nullable"]:
                flags.append("NOT NULL")

            flag_str = ", ".join(flags) if flags else ""
            default_str = str(col["default"]) if col["default"] is not None else ""
            print(f"| {col['name']} | {col['type']} | {flag_str} | {default_str} |")


# ---------------------------------------------------------------------------
# Entrypoint
# ---------------------------------------------------------------------------


def main(argv: List[str]) -> int:
    fmt = (argv[0].lower() if argv else "text").strip()

    schema = describe_schema()
    if fmt == "markdown":
        print_markdown(schema)
    else:
        print_text(schema)

    return 0


if __name__ == "__main__":
    raise SystemExit(main(sys.argv[1:]))



===== FILE: tools\inspect_table_cols.py =====
import sys
from pathlib import Path

# Ensure repo root is on the Python path BEFORE imports
REPO_ROOT = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(REPO_ROOT))

from sqlalchemy import text
from database import SessionLocal


def show_columns(table_name: str):
    db = SessionLocal()
    try:
        rows = db.execute(
            text("""
                SELECT column_name, data_type
                FROM information_schema.columns
                WHERE table_schema = 'public'
                  AND table_name = :t
                ORDER BY ordinal_position
            """),
            {"t": table_name},
        ).fetchall()

        print(f"\nColumns for {table_name}:\n")
        for r in rows:
            print(f" - {r[0]} ({r[1]})")

    finally:
        db.close()


if __name__ == "__main__":
    for t in ["accounts", "client_operational_state", "match_decisions"]:
        show_columns(t)



===== FILE: tools\normalize_status_frontmatter_schema.py =====
#!/usr/bin/env python
"""
Normalize MissionDestination front matter and hierarchy:

1) Epics
   - Keep ONLY `overall_status` as a status field.
   - Remove other status/adherence fields (testing_status, guardrail_adherence, etc).
   - Regenerate `features:` list from Features' `epic` mappings
     (story -> feature -> epic is the golden source).

2) Features
   - Keep ONLY `overall_status` as a status field.
   - Remove other status/adherence fields and any old mapping blocks.
   - Regenerate `stories:` list from Stories' `feature` mappings.

3) Stories
   - Remove stray `status:` scalar if present (do NOT touch `overall_status`).
   - Ensure full status schema (MVP + non-MVP) exists in front matter:
       overall_status
       testing_status
       halo_adherence
       guardrail_adherence
       code_quality_adherence
       security_policy_adherence
       policy_adherence
       technology_lineage_adherence
       business_data_lineage_adherence
       self_healing_adherence
       analytics_adherence
     preserving existing values and only filling in defaults when missing.

This script is intended to be run manually:

    python tools/normalize_status_frontmatter_schema.py
"""

from __future__ import annotations

from pathlib import Path
from typing import Dict, List, Optional
import re

# ---------------------------------------------------------------------------
# Paths
# ---------------------------------------------------------------------------

REPO_ROOT = Path(__file__).resolve().parents[1]
EPICS_DIR = REPO_ROOT / "docs" / "mission_destination" / "epics"
FEATURES_DIR = REPO_ROOT / "docs" / "mission_destination" / "features"
STORIES_DIR = REPO_ROOT / "docs" / "mission_destination" / "stories"


# ---------------------------------------------------------------------------
# Basic helpers
# ---------------------------------------------------------------------------

def _read(path: Path) -> str:
    return path.read_text(encoding="utf-8")


def _write(path: Path, text: str) -> None:
    path.write_text(text, encoding="utf-8")


def _extract_scalar(text: str, key: str) -> Optional[str]:
    """
    Extract 'key: value' from front matter. Returns the value or None.
    Very simple line-based parser; assumes `key: value` is on a single line.
    """
    pattern = rf"^{re.escape(key)}:\s*(.+)$"
    m = re.search(pattern, text, flags=re.MULTILINE)
    if not m:
        return None
    val = m.group(1).strip()
    if val and val[0] in {"'", '"'} and val[-1:] == val[0]:
        val = val[1:-1]
    return val or None


def _replace_scalar(text: str, key: str, value: str) -> str:
    """
    Replace or insert 'key: value' in the front matter.

    - If the key exists, replace its first occurrence.
    - Otherwise insert before `last_updated:` if present, else append at end.
    """
    pattern = rf"^{re.escape(key)}:\s*.*$"
    replacement = f"{key}: {value}"

    if re.search(pattern, text, flags=re.MULTILINE):
        return re.sub(pattern, replacement, text, count=1, flags=re.MULTILINE)

    # Insert before last_updated: if present
    lu_pattern = r"^last_updated:\s*.*$"
    m = re.search(lu_pattern, text, flags=re.MULTILINE)
    if m:
        start = m.start()
        return text[:start] + replacement + "\n" + text[start:]

    # Fallback: append
    if not text.endswith("\n"):
        text += "\n"
    return text + replacement + "\n"


def _remove_block(text: str, key: str) -> str:
    """
    Remove a scalar or YAML block starting with `key:` at the beginning of a line.

    Matches, for example:

      key: something
        child1: ...
        - list item
      <stops when a non-indented line is reached>
    """
    pattern = rf"^{re.escape(key)}:.*\n(?:^[ \t].*\n)*"
    return re.sub(pattern, "", text, flags=re.MULTILINE)


def _extract_yaml_list(text: str, key: str) -> List[str]:
    """
    Extract:

      key:
        - item1
        - item2

    Returns ['item1', 'item2'].
    """
    pattern = rf"^{re.escape(key)}:\s*\n(?P<body>(?:\s+- .*\n)+)"
    m = re.search(pattern, text, flags=re.MULTILINE)
    if not m:
        return []
    body = m.group("body")
    items: List[str] = []
    for line in body.splitlines():
        s = line.strip()
        if s.startswith("- "):
            val = s[2:].strip()
            if val:
                items.append(val)
    return items


def _replace_yaml_list(text: str, key: str, items: List[str]) -> str:
    """
    Replace or insert a YAML list block:

      key:
        - item1
        - item2

    If `items` is empty, any existing block is removed.
    """
    block_pattern = rf"^{re.escape(key)}:\s*\n(?:\s+- .*\n)*"

    if not items:
        # Remove any existing list block for this key
        return re.sub(block_pattern, "", text, flags=re.MULTILINE)

    new_block = key + ":\n" + "".join(f"  - {item}\n" for item in items)

    if re.search(block_pattern, text, flags=re.MULTILINE):
        return re.sub(block_pattern, new_block + "\n", text, count=1, flags=re.MULTILINE)

    # Insert before overall_status if present, otherwise before last_updated,
    # otherwise append near the top.
    os_pattern = r"^overall_status:\s*.*$"
    m = re.search(os_pattern, text, flags=re.MULTILINE)
    if m:
        start = m.start()
        return text[:start] + new_block + "\n" + text[start:]

    lu_pattern = r"^last_updated:\s*.*$"
    m = re.search(lu_pattern, text, flags=re.MULTILINE)
    if m:
        start = m.start()
        return text[:start] + new_block + "\n" + text[start:]

    # Fallback: append after first line of front matter
    return text + ("\n" if not text.endswith("\n") else "") + new_block + "\n"


# ---------------------------------------------------------------------------
# 1. Normalise Epics
# ---------------------------------------------------------------------------

EPIC_STATUS_KEYS_TO_REMOVE = {
    "testing_status",
    "halo_adherence",
    "guardrail_adherence",
    "code_quality_adherence",
    "security_policy_adherence",
    "feature_statuses",   # old rollup mapping
}


def normalize_epic_frontmatter() -> int:
    print(f"=== Normalising Epic front matter in {EPICS_DIR} ===")
    updated = 0

    for path in sorted(EPICS_DIR.glob("*.md")):
        text = _read(path)
        original = text

        # Strip non-overall status fields
        for key in EPIC_STATUS_KEYS_TO_REMOVE:
            text = _remove_block(text, key)

        if text != original:
            _write(path, text)
            updated += 1
            print(f"  updated {path.relative_to(REPO_ROOT)}")

    print(f"Epics updated (status cleanup): {updated}")
    return updated


# ---------------------------------------------------------------------------
# 2. Normalise Features
# ---------------------------------------------------------------------------

FEATURE_STATUS_KEYS_TO_REMOVE = {
    "testing_status",
    "halo_adherence",
    "guardrail_adherence",
    "code_quality_adherence",
    "security_policy_adherence",
    "story_statuses",     # old rollup mapping
}


def normalize_feature_frontmatter() -> int:
    print(f"=== Normalising Feature front matter in {FEATURES_DIR} ===")
    updated = 0

    for path in sorted(FEATURES_DIR.glob("*.md")):
        text = _read(path)
        original = text

        for key in FEATURE_STATUS_KEYS_TO_REMOVE:
            text = _remove_block(text, key)

        if text != original:
            _write(path, text)
            updated += 1
            print(f"  updated {path.relative_to(REPO_ROOT)}")

    print(f"Features updated (status cleanup): {updated}")
    return updated


# ---------------------------------------------------------------------------
# 3. Normalise Stories
# ---------------------------------------------------------------------------

STORY_STATUS_DEFAULTS: Dict[str, str] = {
    # Overall status of story (Planned / In Progress / Complete)
    "overall_status": "Planned",

    # MVP status dimensions
    "testing_status": "not_run",
    # For MVP, halo is effectively defaulted to not_run
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",

    # Non-MVP but part of full schema (all default 'not_run')
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
}


def normalize_story_frontmatter() -> int:
    print(f"=== Normalising Story front matter in {STORIES_DIR} ===")
    updated = 0

    for path in sorted(STORIES_DIR.glob("*.md")):
        text = _read(path)
        original = text

        story_id = _extract_scalar(text, "story_id")
        if not story_id:
            continue  # ignore non-story docs

        # Remove stray 'status:' scalar (do NOT touch overall_status)
        text = re.sub(
            r"^status:\s*.*\n",
            "",
            text,
            flags=re.MULTILINE,
        )

        # Ensure all status fields exist, do not overwrite existing values
        for key, default in STORY_STATUS_DEFAULTS.items():
            existing = _extract_scalar(text, key)
            if existing is None:
                text = _replace_scalar(text, key, default)

        if text != original:
            _write(path, text)
            updated += 1
            print(f"  updated {path.relative_to(REPO_ROOT)}")

    print(f"Stories updated (status schema + stray status): {updated}")
    return updated


# ---------------------------------------------------------------------------
# 4. Sync hierarchy lists using golden mapping
# ---------------------------------------------------------------------------

def sync_hierarchy_lists() -> None:
    """
    Make `features:` lists in Epics and `stories:` lists in Features consistent
    with the golden mapping:

        Story.frontmatter.feature  -> Feature.feature_id
        Feature.frontmatter.epic   -> Epic.epic_id
    """
    print("=== Syncing Epic.features and Feature.stories from golden mapping ===")

    # Build feature_id -> epic_id mapping and epic_id -> [feature_ids]
    feature_to_epic: Dict[str, str] = {}
    epic_to_features: Dict[str, List[str]] = {}

    for path in sorted(FEATURES_DIR.glob("*.md")):
        text = _read(path)
        feature_id = _extract_scalar(text, "feature_id")
        epic_id = _extract_scalar(text, "epic")
        if not feature_id or not epic_id:
            continue
        feature_to_epic[feature_id] = epic_id
        epic_to_features.setdefault(epic_id, []).append(feature_id)

    # Build story_id -> feature_id mapping and feature_id -> [story_ids]
    feature_to_stories: Dict[str, List[str]] = {}

    for path in sorted(STORIES_DIR.glob("*.md")):
        text = _read(path)
        story_id = _extract_scalar(text, "story_id")
        feature_id = _extract_scalar(text, "feature")
        if not story_id or not feature_id:
            continue
        feature_to_stories.setdefault(feature_id, []).append(story_id)

    # Normalise ordering
    for eid, lst in epic_to_features.items():
        epic_to_features[eid] = sorted(set(lst))
    for fid, lst in feature_to_stories.items():
        feature_to_stories[fid] = sorted(set(lst))

    # Update Epics: features list
    epic_updates = 0
    for path in sorted(EPICS_DIR.glob("*.md")):
        text = _read(path)
        original = text

        epic_id = _extract_scalar(text, "epic_id")
        if not epic_id:
            continue

        features_list = epic_to_features.get(epic_id, [])
        text = _replace_yaml_list(text, "features", features_list)

        if text != original:
            _write(path, text)
            epic_updates += 1
            print(f"  synced features list for epic {epic_id} ({path.relative_to(REPO_ROOT)})")

    # Update Features: stories list
    feature_updates = 0
    for path in sorted(FEATURES_DIR.glob("*.md")):
        text = _read(path)
        original = text

        feature_id = _extract_scalar(text, "feature_id")
        if not feature_id:
            continue

        stories_list = feature_to_stories.get(feature_id, [])
        text = _replace_yaml_list(text, "stories", stories_list)

        if text != original:
            _write(path, text)
            feature_updates += 1
            print(f"  synced stories list for feature {feature_id} ({path.relative_to(REPO_ROOT)})")

    print(f"Hierarchy sync complete: epics_updated={epic_updates}, features_updated={feature_updates}")


# ---------------------------------------------------------------------------
# CLI
# ---------------------------------------------------------------------------

def main() -> int:
    print("=== Normalising MissionDestination front matter & hierarchy ===")
    print(f"Repo root: {REPO_ROOT}")

    normalize_epic_frontmatter()
    normalize_feature_frontmatter()
    normalize_story_frontmatter()
    sync_hierarchy_lists()

    print("=== Done normalising ===")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())


===== FILE: tools\normalize_story_frontmatter.py =====
#!/usr/bin/env python

from pathlib import Path
import re

REPO_ROOT = Path(__file__).resolve().parents[1]
STORIES_DIR = REPO_ROOT / "docs" / "mission_destination" / "stories"


def remove_implementation_presence(text: str) -> str:
    """
    Remove lines like:
      implementation_presence: false
    from the front matter.
    """
    return re.sub(
        r"^implementation_presence:\s*.*\n",
        "",
        text,
        flags=re.MULTILINE,
    )


def ensure_halo_pass(text: str) -> str:
    """
    Ensure there's a line:
      halo_adherence: pass

    - If halo_adherence already exists, set it to 'pass'.
    - If not, insert it before last_updated: if present,
      otherwise append near the end of the front matter.
    """
    pattern = r"^halo_adherence:\s*.*$"
    replacement = "halo_adherence: pass"

    # Case 1: replace existing line
    if re.search(pattern, text, flags=re.MULTILINE):
        return re.sub(pattern, replacement, text, count=1, flags=re.MULTILINE)

    # Case 2: insert before last_updated if present
    lu_pattern = r"^last_updated:\s*.*$"
    m = re.search(lu_pattern, text, flags=re.MULTILINE)
    if m:
        start = m.start()
        return text[:start] + replacement + "\n" + text[start:]

    # Case 3: append at end
    if not text.endswith("\n"):
        text += "\n"
    return text + replacement + "\n"


def main() -> int:
    print("=== Normalising story front matter ===")
    print(f"Stories dir: {STORIES_DIR}")

    updated = 0

    for path in sorted(STORIES_DIR.glob("*.md")):
        text = path.read_text(encoding="utf-8")
        new_text = remove_implementation_presence(text)
        new_text = ensure_halo_pass(new_text)

        if new_text != text:
            path.write_text(new_text, encoding="utf-8")
            updated += 1
            print(f"  updated {path.name}")

    print(f"Done. Updated {updated} story files.")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())


===== FILE: tools\repo_sync_one_liner.txt =====
git checkout main
git pull
git add .
git commit -m "Sync"
git push



===== FILE: tools\reset_overall_status_planned.py =====
#!/usr/bin/env python
"""
Reset all MissionDestination Story overall_status to 'Planned'.

We will then manually update a small number of stories to 'In Progress'
or 'Complete' and let rollup_statuses.py aggregate from there.
"""

from __future__ import annotations

import re
from pathlib import Path
from typing import Optional

REPO_ROOT = Path(__file__).resolve().parents[1]
STORIES_DIR = REPO_ROOT / "docs" / "mission_destination" / "stories"


def _read(path: Path) -> str:
    return path.read_text(encoding="utf-8")


def _write(path: Path, text: str) -> None:
    path.write_text(text, encoding="utf-8")


def _extract_scalar(text: str, key: str) -> Optional[str]:
    pattern = rf"^{re.escape(key)}:\s*(.+)$"
    m = re.search(pattern, text, flags=re.MULTILINE)
    if not m:
        return None
    val = m.group(1).strip()
    if val and val[0] in {"'", '"'} and val[-1:] == val[0]:
        val = val[1:-1]
    return val or None


def _replace_scalar(text: str, key: str, value: str) -> str:
    pattern = rf"^{re.escape(key)}:\s*.*$"
    replacement = f"{key}: {value}"

    if re.search(pattern, text, flags=re.MULTILINE):
        return re.sub(pattern, replacement, text, count=1, flags=re.MULTILINE)

    # insert before last_updated: if present
    lu_pattern = r"^last_updated:\s*.*$"
    m = re.search(lu_pattern, text, flags=re.MULTILINE)
    if m:
        start = m.start()
        return text[:start] + replacement + "\n" + text[start:]

    # else append at end
    if not text.endswith("\n"):
        text += "\n"
    return text + replacement + "\n"


def main() -> int:
    print("=== Resetting Story overall_status to Planned ===")
    print(f"Stories dir: {STORIES_DIR}")

    for path in sorted(STORIES_DIR.glob("*.md")):
        text = _read(path)
        story_id = _extract_scalar(text, "story_id")
        if not story_id:
            continue

        new_text = _replace_scalar(text, "overall_status", "Planned")
        if new_text != text:
            _write(path, new_text)
            print(f">>> {story_id}: overall_status -> Planned")

    print("=== Done ===")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())


===== FILE: tools\reset_story_statuses_not_run.py =====
#!/usr/bin/env python
"""
Reset ALL Story status/adherence dimensions to 'not_run' across MissionDestination.

Scope: docs/mission_destination/stories/*.md only
Edits: YAML front matter only (between first two '---' lines)

Fields reset:
- testing_status
- halo_adherence
- guardrail_adherence
- code_quality_adherence
- security_policy_adherence
- policy_adherence
- technology_lineage_adherence
- business_data_lineage_adherence
- self_healing_adherence
- analytics_adherence

Also sets overall_status to Planned (consistent with roll-up normalisation rules).
We do NOT touch Features/Epics here; rollup_statuses.py will handle those.
"""

from __future__ import annotations

import re
from pathlib import Path
from typing import Dict, Tuple

REPO_ROOT = Path(__file__).resolve().parents[1]
STORIES_DIR = REPO_ROOT / "docs" / "mission_destination" / "stories"

RESET_KEYS: Dict[str, str] = {
    "testing_status": "not_run",
    "halo_adherence": "not_run",
    "guardrail_adherence": "not_run",
    "code_quality_adherence": "not_run",
    "security_policy_adherence": "not_run",
    "policy_adherence": "not_run",
    "technology_lineage_adherence": "not_run",
    "business_data_lineage_adherence": "not_run",
    "self_healing_adherence": "not_run",
    "analytics_adherence": "not_run",
}

def split_front_matter(text: str) -> Tuple[str, str, str]:
    """
    Returns (fm, body_prefix, body) where:
      fm = front matter including the wrapping --- lines
      body_prefix = "" (kept for clarity)
      body = rest of doc
    If no front matter found, returns ("", "", original_text).
    """
    # front matter must start at beginning
    if not text.startswith("---"):
        return "", "", text

    # find second --- on its own line
    m = re.search(r"^---\s*$", text, flags=re.MULTILINE)
    if not m:
        return "", "", text

    # first delimiter is at pos 0; find the next delimiter after first line
    m2 = re.search(r"^---\s*$", text[m.end():], flags=re.MULTILINE)
    if not m2:
        return "", "", text

    end = m.end() + m2.end()
    fm = text[:end]
    body = text[end:]
    return fm, "", body

def replace_or_insert_scalar(fm: str, key: str, value: str) -> str:
    """
    Replace first occurrence of '^key: ...' in front matter.
    If missing, insert before 'last_updated:' if present, else append before closing '---'.
    """
    pattern = rf"^(?P<k>{re.escape(key)}:\s*).*$"
    if re.search(pattern, fm, flags=re.MULTILINE):
        return re.sub(pattern, rf"\g<k>{value}", fm, count=1, flags=re.MULTILINE)

    # insert before last_updated if present
    lu = re.search(r"^last_updated:\s*.*$", fm, flags=re.MULTILINE)
    insertion = f"{key}: {value}\n"
    if lu:
        return fm[: lu.start()] + insertion + fm[lu.start():]

    # otherwise insert just before the closing '---' (the second delimiter)
    parts = fm.splitlines(True)
    # find last line that is '---'
    for i in range(len(parts) - 1, -1, -1):
        if parts[i].strip() == "---":
            parts.insert(i, insertion)
            return "".join(parts)

    # fallback: append
    if not fm.endswith("\n"):
        fm += "\n"
    return fm + insertion

def main() -> int:
    if not STORIES_DIR.exists():
        print(f"ERROR: Stories dir not found: {STORIES_DIR}")
        return 1

    updated = 0
    scanned = 0

    for path in sorted(STORIES_DIR.glob("*.md")):
        text = path.read_text(encoding="utf-8")
        fm, _, body = split_front_matter(text)
        if not fm:
            continue

        # only touch real stories
        if not re.search(r"^story_id:\s*.+$", fm, flags=re.MULTILINE):
            continue

        scanned += 1
        new_fm = fm

        # Force baseline overall_status (roll-up maps not_run dims -> Planned anyway)
        new_fm = replace_or_insert_scalar(new_fm, "overall_status", "Planned")

        for k, v in RESET_KEYS.items():
            new_fm = replace_or_insert_scalar(new_fm, k, v)

        new_text = new_fm + body
        if new_text != text:
            path.write_text(new_text, encoding="utf-8")
            updated += 1
            rel = path.relative_to(REPO_ROOT)
            print(f"updated {rel}")

    print(f"\nDone. Scanned stories: {scanned}, Updated: {updated}")
    return 0

if __name__ == "__main__":
    raise SystemExit(main())


===== FILE: tools\rollup_statuses.py =====
#!/usr/bin/env python
"""
Mission Control Overall Status Roll-up

Responsibilities:
- For each Story:
    - Derive overall_status from its testing / halo / guardrail /
      code-quality / security fields (MVP dimensions only).
- Aggregate Story overall_status up to Feature overall_status.
- Aggregate Feature overall_status up to Epic overall_status.

Rules
=====

Story overall_status (MVP):

Let dims = {
  testing_status,
  halo_adherence,
  guardrail_adherence,
  code_quality_adherence,
  security_policy_adherence
}

Normalise each dim:
  - pass / ok / success / compliant     -> Complete
  - fail / error / non_compliant        -> In Progress
  - not_run / planned / empty / missing -> Planned

Then:
  - Complete  if all dims Complete
  - Planned   if all dims Planned
  - In Progress otherwise

Feature overall_status:
  - Planned   if all child Stories Planned
  - Complete  if all child Stories Complete
  - In Progress otherwise

Epic overall_status:
  - Planned   if all child Features Planned
  - Complete  if all child Features Complete
  - In Progress otherwise

IMPORTANT:
- We ONLY ever write 'overall_status' + 'last_updated' fields.
- We NEVER touch the individual Story dimensions directly.
- We NEVER change the Storyâ†’Feature or Featureâ†’Epic mapping;
  we only *read*:
    - Story.frontmatter.feature
    - Feature.frontmatter.epic
"""

from __future__ import annotations

import re
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Optional

REPO_ROOT = Path(__file__).resolve().parents[1]

STORIES_DIR = REPO_ROOT / "docs" / "mission_destination" / "stories"
FEATURES_DIR = REPO_ROOT / "docs" / "mission_destination" / "features"
EPICS_DIR = REPO_ROOT / "docs" / "mission_destination" / "epics"


# -------------------- basic helpers -------------------- #


def _read(path: Path) -> str:
    return path.read_text(encoding="utf-8")


def _write(path: Path, text: str) -> None:
    path.write_text(text, encoding="utf-8")


def _extract_scalar(text: str, key: str) -> Optional[str]:
    """
    Extract 'key: value' from front matter. Returns value or None.
    Very simple line-based parser; assumes `key: value` is on one line.
    """
    pattern = rf"^{re.escape(key)}:\s*(.+)$"
    m = re.search(pattern, text, flags=re.MULTILINE)
    if not m:
        return None
    val = m.group(1).strip()
    # strip simple quotes
    if val and val[0] in {'"', "'"} and val[-1:] == val[0]:
        val = val[1:-1]
    return val or None


def _replace_scalar(text: str, key: str, value: str) -> str:
    """
    Replace or insert 'key: value' in the front matter.
    We always insert before 'last_updated' if present, otherwise append.
    """
    pattern = rf"^{re.escape(key)}:\s*.*$"
    replacement = f"{key}: {value}"

    if re.search(pattern, text, flags=re.MULTILINE):
        return re.sub(pattern, replacement, text, count=1, flags=re.MULTILINE)

    # Insert before last_updated: if present
    lu_pattern = r"^last_updated:\s*.*$"
    m = re.search(lu_pattern, text, flags=re.MULTILINE)
    if m:
        start = m.start()
        return text[:start] + replacement + "\n" + text[start:]

    # Fallback: append at end
    if not text.endswith("\n"):
        text += "\n"
    return text + replacement + "\n"


def _now_iso_utc() -> str:
    """
    Current time in ISO UTC, matching the status model docs, e.g.
    2025-01-01T12:00:00Z
    """
    return datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")


def _touch_last_updated(text: str) -> str:
    """
    Ensure last_updated is set to "now" in ISO UTC.
    """
    return _replace_scalar(text, "last_updated", _now_iso_utc())


# -------------------- status helpers -------------------- #


def _norm_overall(raw: Optional[str]) -> str:
    """
    Normalise an overall_status value to:

        Planned | In Progress | Complete
    """
    if raw is None:
        return "Planned"

    t = raw.strip().strip("\"'")
    tl = t.lower()

    if tl == "planned":
        return "Planned"
    if tl in {"in progress", "in_progress", "in-progress", "active"}:
        return "In Progress"
    if tl in {"complete", "completed", "done"}:
        return "Complete"
    return "Planned"


def _aggregate_overall(child_statuses: List[str]) -> Optional[str]:
    """
    Roll-up:

    - Planned   if all children Planned
    - Complete  if all children Complete
    - In Progress otherwise

    Returns None if there are no children.
    """
    if not child_statuses:
        return None
    s = set(child_statuses)
    if s == {"Planned"}:
        return "Planned"
    if s == {"Complete"}:
        return "Complete"
    return "In Progress"


def _norm_dim(raw: Optional[str]) -> str:
    """
    Normalise a Story dimension value into one of:
        Planned | In Progress | Complete

    Used for:
      testing_status
      halo_adherence
      guardrail_adherence
      code_quality_adherence
      security_policy_adherence
    """
    if raw is None:
        return "Planned"

    t = raw.strip().strip("\"'")
    tl = t.lower()

    if tl in {"pass", "ok", "success", "successful", "compliant"}:
        return "Complete"

    if tl in {"fail", "failed", "error", "errors", "non_compliant", "non-compliant"}:
        return "In Progress"

    # Treat not_run, planned, empty, and unknown as Planned (no evidence yet)
    if tl in {"not_run", "not-run", "pending", "planned", ""}:
        return "Planned"

    # Default safely to "In Progress" if it's something unexpected but non-empty
    return "In Progress"


def _derive_story_overall(text: str) -> str:
    """
    Derive Story overall_status from the 5 MVP dimensions.
    """
    dims_keys = [
        "testing_status",
        "halo_adherence",
        "guardrail_adherence",
        "code_quality_adherence",
        "security_policy_adherence",
    ]

    dim_states: List[str] = []
    for key in dims_keys:
        raw = _extract_scalar(text, key)
        dim_states.append(_norm_dim(raw))

    # Aggregate those Planned/In Progress/Complete values
    agg = _aggregate_overall(dim_states)
    if agg is None:
        # shouldn't happen (we always have 5 dims) but be defensive
        return "Planned"
    return agg


# -------------------- roll-up implementation -------------------- #


def rollup_stories() -> Dict[str, Dict[str, str]]:
    """
    Process Stories:

    - Derive Story overall_status from dimension fields.
    - Update overall_status + last_updated when it changes.
    - Build mapping Story -> Feature and Story overall_status.

    Returns:
        {
          "story_status": {story_id: overall_status},
          "story_feature": {story_id: feature_id},
        }
    """
    story_status: Dict[str, str] = {}
    story_feature: Dict[str, str] = {}

    print(">>> Rolling up Story statuses...")
    for path in sorted(STORIES_DIR.glob("*.md")):
        text = _read(path)
        story_id = _extract_scalar(text, "story_id")
        if not story_id:
            continue

        feature_id = _extract_scalar(text, "feature")
        if not feature_id:
            # If a Story is not mapped to a Feature, we skip it for roll-up
            print(f"    [WARN] Story {story_id} has no 'feature' mapping; skipping.")
            continue

        old_overall_raw = _extract_scalar(text, "overall_status")
        old_overall = _norm_overall(old_overall_raw)
        new_overall = _derive_story_overall(text)

        if new_overall != old_overall:
            new_text = _replace_scalar(text, "overall_status", new_overall)
            new_text = _touch_last_updated(new_text)
            _write(path, new_text)
            print(f"    Story {story_id}: {old_overall} -> {new_overall}")
        else:
            # still ensure we store the normalised value
            new_overall = old_overall

        story_status[story_id] = new_overall
        story_feature[story_id] = feature_id

    return {
        "story_status": story_status,
        "story_feature": story_feature,
    }


def rollup_features(story_status: Dict[str, str], story_feature: Dict[str, str]) -> Dict[str, Dict[str, str]]:
    """
    Process Features:

    - Determine child Stories from the Story->Feature mapping.
    - Aggregate their overall_status to Feature overall_status.
    - Update Feature overall_status + last_updated when it changes.
    - Build mapping Feature -> Epic and Feature overall_status.

    Returns:
        {
          "feature_status": {feature_id: overall_status},
          "feature_epic": {feature_id: epic_id},
        }
    """
    # Build feature -> [story_id] from story_feature mapping
    stories_by_feature: Dict[str, List[str]] = {}
    for sid, fid in story_feature.items():
        stories_by_feature.setdefault(fid, []).append(sid)

    feature_status: Dict[str, str] = {}
    feature_epic: Dict[str, str] = {}

    print(">>> Rolling up Feature statuses...")
    for path in sorted(FEATURES_DIR.glob("*.md")):
        text = _read(path)
        feature_id = _extract_scalar(text, "feature_id")
        if not feature_id:
            continue

        epic_id = _extract_scalar(text, "epic")
        if epic_id:
            feature_epic[feature_id] = epic_id

        child_story_ids = stories_by_feature.get(feature_id, [])
        child_overalls = [story_status[sid] for sid in child_story_ids if sid in story_status]

        agg = _aggregate_overall(child_overalls)
        if agg is None:
            # No child stories mapped; leave overall_status as-is
            old = _norm_overall(_extract_scalar(text, "overall_status"))
            feature_status[feature_id] = old
            if not child_story_ids:
                print(f"    [WARN] Feature {feature_id} has no mapped Stories; leaving status as {old}.")
            else:
                print(f"    [WARN] Feature {feature_id} has Stories but none with known status; leaving as {old}.")
            continue

        old_overall = _norm_overall(_extract_scalar(text, "overall_status"))
        new_overall = agg

        if new_overall != old_overall:
            new_text = _replace_scalar(text, "overall_status", new_overall)
            new_text = _touch_last_updated(new_text)
            _write(path, new_text)
            print(f"    Feature {feature_id}: {old_overall} -> {new_overall}")
        else:
            new_overall = old_overall

        feature_status[feature_id] = new_overall

    return {
        "feature_status": feature_status,
        "feature_epic": feature_epic,
    }


def rollup_epics(feature_status: Dict[str, str], feature_epic: Dict[str, str]) -> None:
    """
    Process Epics:

    - Determine child Features from the Feature->Epic mapping.
    - Aggregate their overall_status to Epic overall_status.
    - Update Epic overall_status + last_updated when it changes.
    """
    # Build epic -> [feature_id] from feature_epic mapping
    features_by_epic: Dict[str, List[str]] = {}
    for fid, eid in feature_epic.items():
        features_by_epic.setdefault(eid, []).append(fid)

    print(">>> Rolling up Epic statuses...")
    for path in sorted(EPICS_DIR.glob("*.md")):
        text = _read(path)
        epic_id = _extract_scalar(text, "epic_id")
        if not epic_id:
            continue

        child_feature_ids = features_by_epic.get(epic_id, [])
        child_overalls = [feature_status[fid] for fid in child_feature_ids if fid in feature_status]

        agg = _aggregate_overall(child_overalls)
        if agg is None:
            old = _norm_overall(_extract_scalar(text, "overall_status"))
            if not child_feature_ids:
                print(f"    [WARN] Epic {epic_id} has no mapped Features; leaving status as {old}.")
            else:
                print(f"    [WARN] Epic {epic_id} has Features but none with known status; leaving as {old}.")
            continue

        old_overall = _norm_overall(_extract_scalar(text, "overall_status"))
        new_overall = agg

        if new_overall != old_overall:
            new_text = _replace_scalar(text, "overall_status", new_overall)
            new_text = _touch_last_updated(new_text)
            _write(path, new_text)
            print(f"    Epic {epic_id}: {old_overall} -> {new_overall}")


# -------------------- CLI -------------------- #


def main() -> int:
    print("=== Mission Control Overall Status Roll-up ===")
    print(f"Repo root: {REPO_ROOT}")

    story_maps = rollup_stories()
    feature_maps = rollup_features(
        story_status=story_maps["story_status"],
        story_feature=story_maps["story_feature"],
    )
    rollup_epics(
        feature_status=feature_maps["feature_status"],
        feature_epic=feature_maps["feature_epic"],
    )

    print("=== Roll-up complete. ===")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())


===== FILE: tools\run_story_guardrails.py =====
#!/usr/bin/env python
"""
Run guardrail checks for one or more Stories.

MVP principles:
- MissionLog is a renderer, not a runner.
- Guardrails are global.
- Applicability is story-scoped (a Story binds to global guardrails via front matter).
- If a guardrail is not applicable, the Story still "passes" guardrails for demo purposes:
  it has not violated any applicable guardrail.

MVP implementation:
- Supports only G03 (LDM adherence) using tools/guardrails/run_g03_ldm.py logic.
- Writes evidence to evidence/guardrails/<STORY_ID>.json
- Updates guardrail_adherence: pass|fail in Story front matter.
"""

from __future__ import annotations

import dataclasses
import json
import re
import sys
from pathlib import Path
from typing import Any, Dict, List, Tuple, Optional

import os
import sys
from pathlib import Path

REPO_ROOT = Path(__file__).resolve().parents[1]
BACKEND_ROOT = REPO_ROOT / "backend_v2"

# Ensure backend_v2 is on PYTHONPATH so `import app` works
sys.path.insert(0, str(BACKEND_ROOT))
os.environ["PYTHONPATH"] = str(BACKEND_ROOT)



# ---------------------------------------------------------------------------
# Repo root + sys.path
# ---------------------------------------------------------------------------

REPO_ROOT = Path(__file__).resolve().parents[1]
if str(REPO_ROOT) not in sys.path:
    sys.path.insert(0, str(REPO_ROOT))

STORIES_DIR = REPO_ROOT / "docs" / "mission_destination" / "stories"


# ---------------------------------------------------------------------------
# Evidence writer
# ---------------------------------------------------------------------------

def write_guardrail_evidence(
    story_id: str,
    passed: bool,
    message: str,
    guardrails_checked: List[str],
    warnings: List[Dict[str, Any]] | None = None,
    warnings_count: int | None = None,
    guardrail_results: List[Dict[str, Any]] | None = None,
) -> Path:
    results_dir = REPO_ROOT / "evidence" / "guardrails"
    results_dir.mkdir(parents=True, exist_ok=True)

    evidence_path = results_dir / f"{story_id}.json"
    payload: Dict[str, Any] = {
        "story_id": story_id,
        "passed": passed,
        "message": message,
        "guardrails_checked": guardrails_checked,
        "warnings_count": int(warnings_count or 0),
        "warnings": warnings or [],
    }

    # Optional: richer detail (MissionLog should tolerate additional fields)
    if guardrail_results is not None:
        payload["guardrail_results"] = guardrail_results

    evidence_path.write_text(json.dumps(payload, indent=2), encoding="utf-8")
    print(
        f">>> Wrote guardrail evidence for {story_id} to "
        f"{evidence_path.relative_to(REPO_ROOT)}"
    )
    return evidence_path


# ---------------------------------------------------------------------------
# Story discovery + front matter access
# ---------------------------------------------------------------------------

def _extract_front_matter_block(text: str) -> str:
    if not text.startswith("---"):
        return ""
    parts = text.split("---", 2)
    if len(parts) < 3:
        return ""
    return parts[1]


def _extract_scalar_from_front_matter(text: str, key: str) -> Optional[str]:
    fm = _extract_front_matter_block(text)
    if not fm:
        return None
    m = re.search(rf"^{re.escape(key)}:\s*(.+)\s*$", fm, flags=re.MULTILINE)
    if not m:
        return None
    return m.group(1).strip().strip('"').strip("'")


def find_story_file_by_id(story_id: str) -> Path:
    if not STORIES_DIR.exists():
        raise FileNotFoundError(f"Stories dir not found: {STORIES_DIR}")

    target = story_id.upper().strip()
    for path in sorted(STORIES_DIR.glob("*.md")):
        try:
            text = path.read_text(encoding="utf-8")
        except Exception:
            continue
        sid = _extract_scalar_from_front_matter(text, "story_id")
        if sid and sid.upper().strip() == target:
            return path

    raise FileNotFoundError(f"Story {target!r} not found under {STORIES_DIR.relative_to(REPO_ROOT)}")


def discover_non_planned_story_ids() -> List[str]:
    """
    Default run scope for demo safety:
    run guardrails only for stories that are not Planned.
    """
    ids: List[str] = []
    if not STORIES_DIR.exists():
        return ids

    for path in sorted(STORIES_DIR.glob("*.md")):
        try:
            text = path.read_text(encoding="utf-8")
        except Exception:
            continue

        sid = _extract_scalar_from_front_matter(text, "story_id")
        if not sid:
            continue

        overall = _extract_scalar_from_front_matter(text, "overall_status") or "Planned"
        if overall.strip().lower() != "planned":
            ids.append(sid.upper().strip())

    return ids


# ---------------------------------------------------------------------------
# Front matter updater
# ---------------------------------------------------------------------------

def update_story_guardrail_adherence(story_file: Path, passed: bool) -> None:
    status = "pass" if passed else "fail"

    text = story_file.read_text(encoding="utf-8")
    pattern = r"(^guardrail_adherence:\s*).*$"
    replacement = rf"\1{status}"
    new_text, count = re.subn(pattern, replacement, text, count=1, flags=re.MULTILINE)

    if count == 0:
        raise RuntimeError(
            f"Story file {story_file} does not contain a guardrail_adherence line."
        )

    story_file.write_text(new_text, encoding="utf-8")
    print(
        f">>> Updated {story_file.relative_to(REPO_ROOT)} -> guardrail_adherence: {status}"
    )


# ---------------------------------------------------------------------------
# Global guardrail: G03 (LDM adherence)
# ---------------------------------------------------------------------------

def run_g03_if_applicable(story_id: str, story_file: Path) -> Tuple[bool, str, List[str], List[Dict[str, Any]]]:
    """
    Returns:
      (passed, message, guardrails_checked, guardrail_results)

    Policy:
    - If G03 is NOT declared in story front matter, it's NOT APPLICABLE -> treated as PASS.
    - If declared, run the validation logic and PASS/FAIL accordingly.
    """
    # We import the helper functions from the existing G03 script (no subprocess).
    from tools.guardrails.run_g03_ldm import (
        read_story_front_matter,
        extract_g03_config,
        resolve_contract_path,
        load_json,
        normalize_schema,
        validate_instance,
    )

    guardrails_checked: List[str] = []
    guardrail_results: List[Dict[str, Any]] = []

    try:
        front_matter = read_story_front_matter(story_file)
    except Exception as exc:
        # If we can't parse front matter, that's a guardrail framework failure.
        guardrails_checked.append("G03 (framework error)")
        return False, f"Failed to read story front matter: {exc!r}", guardrails_checked, guardrail_results

    guardrails_block = front_matter.get("guardrails", {})
    g03_decl = guardrails_block.get("G03") if isinstance(guardrails_block, dict) else None

    if not isinstance(g03_decl, dict):
        # Not applicable -> pass
        guardrails_checked.append("G03 (not applicable)")
        result = {
            "guardrail_id": "G03",
            "applicable": False,
            "passed": True,
            "message": "G03 not declared for this Story; treated as not applicable.",
            "warnings_count": 0,
            "warnings": [],
        }
        guardrail_results.append(result)
        return True, "No applicable guardrails for this Story (G03 not declared).", guardrails_checked, guardrail_results

    # Applicable: run validation
    guardrails_checked.append("G03 (LDM adherence)")

    try:
        g03 = extract_g03_config(front_matter)

        schema_path = resolve_contract_path(g03.ldm_contract, REPO_ROOT)
        schema = load_json(schema_path)

        if schema.get("$id") != g03.ldm_contract:
            raise ValueError(
                f"Schema $id mismatch: expected {g03.ldm_contract}, found {schema.get('$id')}"
            )

        schema = normalize_schema(schema, g03.mode)

        artifact_path = (
            REPO_ROOT
            / "evidence"
            / "runtime_outputs"
            / story_id
            / f"{g03.artifact}.json"
        )

        if not artifact_path.exists():
            raise FileNotFoundError(f"Runtime artifact not found: {artifact_path}")

        instance = load_json(artifact_path)
        errors = validate_instance(schema, instance)
        passed = len(errors) == 0

        result = {
            "guardrail_id": "G03",
            "applicable": True,
            "passed": passed,
            "message": "LDM validation passed" if passed else f"LDM validation failed for {g03.ldm_contract}",
            "contract_id": g03.ldm_contract,
            "artifact_path": str(artifact_path.relative_to(REPO_ROOT)).replace("\\", "/"),
            "errors": errors,
            "warnings_count": 0,
            "warnings": [],
        }
        guardrail_results.append(result)

        return passed, result["message"], guardrails_checked, guardrail_results

    except Exception as exc:
        # Applicable but evaluation failed -> fail
        result = {
            "guardrail_id": "G03",
            "applicable": True,
            "passed": False,
            "message": f"G03 evaluation error: {exc!r}",
            "warnings_count": 0,
            "warnings": [],
        }
        guardrail_results.append(result)
        return False, result["message"], guardrails_checked, guardrail_results


# ---------------------------------------------------------------------------
# Orchestration
# ---------------------------------------------------------------------------

def run_guardrails_for_story(story_id: str) -> Tuple[bool, str]:
    story_id = story_id.upper().strip()
    story_file = find_story_file_by_id(story_id)

    # MVP: run only G03 (global guardrail catalogue)
    passed, msg, checked, results = run_g03_if_applicable(story_id, story_file)

    write_guardrail_evidence(
        story_id=story_id,
        passed=passed,
        message=msg,
        guardrails_checked=checked,
        warnings=[],
        warnings_count=0,
        guardrail_results=results,
    )

    update_story_guardrail_adherence(story_file, passed)
    return passed, msg


def main(argv: List[str]) -> int:
    """
    Usage:
      python tools/run_story_guardrails.py            # run for all non-Planned Stories
      python tools/run_story_guardrails.py ST-05      # run for a single Story
    """
    if len(argv) > 1:
        requested_ids = [argv[1].upper().strip()]
    else:
        requested_ids = discover_non_planned_story_ids()

    if not requested_ids:
        print("No eligible Stories found (non-Planned). Nothing to do.")
        return 0

    overall_exit = 0
    for sid in requested_ids:
        print(f"\n=== Guardrails for Story {sid} ===")
        passed, message = run_guardrails_for_story(sid)
        print(f">>> {sid}: {'PASS' if passed else 'FAIL'} â€” {message}")
        if not passed:
            overall_exit = 1

    return overall_exit


if __name__ == "__main__":
    raise SystemExit(main(sys.argv))






===== FILE: tools\run_story_lint.py =====
#!/usr/bin/env python
"""
Run linting for one or more Stories and update code_quality_adherence
in each Story's front matter.

MVP:
- Use Ruff to lint the Story's Python files.
- If any issues are reported, mark as fail.
- Otherwise mark as pass.
"""

from __future__ import annotations

import json
import re
import subprocess
import sys
from pathlib import Path
from typing import Any, Dict, List, Tuple

import os
import sys
from pathlib import Path

REPO_ROOT = Path(__file__).resolve().parents[1]
BACKEND_ROOT = REPO_ROOT / "backend_v2"

# Ensure backend_v2 is on PYTHONPATH so `import app` works
sys.path.insert(0, str(BACKEND_ROOT))
os.environ["PYTHONPATH"] = str(BACKEND_ROOT)


# ---------------------------------------------------------------------------
# Repo root + sys.path
# ---------------------------------------------------------------------------

REPO_ROOT = Path(__file__).resolve().parents[1]
if str(REPO_ROOT) not in sys.path:
    sys.path.insert(0, str(REPO_ROOT))


# ---------------------------------------------------------------------------
# Story configuration
# ---------------------------------------------------------------------------

# For each Story:
# - story_file: markdown Story file
# - lint_targets: list of Python files to lint with Ruff
STORY_CONFIG: Dict[str, Dict[str, Any]] = {
    "ST-03": {
        "story_file": REPO_ROOT
        / "docs"
        / "mission_destination"
        / "stories"
        / "ST-03_map_identity_fields.md",
        "lint_targets": [
            "src/services/client_profile/service.py",
            "src/domain/models/client_profile.py",
        ],
    },
    "ST-04": {
        "story_file": REPO_ROOT
        / "docs"
        / "mission_destination"
        / "stories"
        / "ST-04_map_identifiers.md",
        "lint_targets": [
            "src/services/client_profile/service.py",
            "src/domain/models/client_profile.py",
        ],
    },
    "ST-05": {
        "story_file": REPO_ROOT
        / "docs"
        / "mission_destination"
        / "stories"
        / "ST-05_bulk_load_crm.md",
        "lint_targets": [
            r"backend_v2\app\services\crm_bulk_load_service.py",
        ],
    },
    "ST-09": {
        "story_file": REPO_ROOT
        / "docs"
        / "mission_destination"
        / "stories"
        / "ST-09_match_by_tax_id.md",
        "lint_targets": [
            "src/services/client_profile/service.py",
        ],
    },
    "ST-20": {
        "story_file": REPO_ROOT
        / "docs"
        / "mission_destination"
        / "stories"
        / "ST-20_assemble_base_profile.md",
        "lint_targets": [
            "src/services/client_profile/service.py",
            "src/domain/models/client_profile.py",
        ],
    },
    "ST-30": {
        "story_file": REPO_ROOT
        / "docs"
        / "mission_destination"
        / "stories"
        / "ST-30_audit_ingestion.md",
        "lint_targets": [
            "src/services/audit/service.py",
        ],
    },
    "ST-00": {
        "story_file": REPO_ROOT
        / "docs"
        / "mission_destination"
        / "stories"
        / "ST-00-backend-api-availability.md",
        "lint_targets": [
            r"backend_v2\app\main.py",
        ],
    },
    "ST-00-FRONTEND-UI-SHELL": {
        "story_file": REPO_ROOT
        / "docs"
        / "mission_destination"
        / "stories"
        / "ST-00-frontend-ui-shell.md",
        "lint_targets": [
            r"backend_v2\app\main.py",
        ],
    },
}


# ---------------------------------------------------------------------------
# Rule-family evidence (new)
# ---------------------------------------------------------------------------

RUFF_RULE_FAMILIES: List[Dict[str, str]] = [
    {
        "check": "Pyflakes â€“ error & bug detection",
        "examples": "Undefined variables, unused imports, redefined names, incorrect __all__",
    },
    {
        "check": "Pycodestyle â€“ error-level correctness",
        "examples": "Syntax/indentation errors, invalid escapes, is vs == misuse, ambiguous names",
    },
    {
        "check": "Import sorting (isort-equivalent)",
        "examples": "Import grouping, ordering, duplicates",
    },
    {
        "check": "Bugbear â€“ high-risk constructs (subset)",
        "examples": "Mutable defaults, risky asserts, loop variable capture, fragile except blocks",
    },
    {
        "check": "Naming & shadowing issues",
        "examples": "Shadowing built-ins, conflicting imports, suspicious name reuse",
    },
    {
        "check": "Safe autofix candidates",
        "examples": "Unused import removal, import sorting, safe simplifications (when run with --fix)",
    },
]


def build_rule_family_results(passed: bool) -> List[Dict[str, str]]:
    """
    We mark each rule family pass/fail based on the Ruff run outcome.

    This is truthful because Ruff's non-zero exit indicates at least one enabled rule failed;
    a zero exit indicates all enabled rules passed.
    """
    status = "pass" if passed else "fail"
    results: List[Dict[str, str]] = []
    for item in RUFF_RULE_FAMILIES:
        results.append(
            {
                "check": item["check"],
                "status": status,
                "examples": item["examples"],
            }
        )
    return results


# ---------------------------------------------------------------------------
# Core helpers
# ---------------------------------------------------------------------------

def run_ruff_for_targets(targets: List[str]) -> Tuple[bool, str, List[Dict[str, Any]]]:
    """
    Run Ruff on the given Python files.

    Returns:
      (passed, message, issues)

    Where issues is a minimal list of findings (code, message, location).
    """
    cmd = [
        sys.executable,
        "-m",
        "ruff",
        "check",
        "--output-format",
        "json",
        *targets,
    ]
    print(f">>> Running Ruff: {' '.join(cmd)}")
    try:
        proc = subprocess.run(
            cmd,
            cwd=REPO_ROOT,
            capture_output=True,
            text=True,
            check=False,
        )
    except FileNotFoundError as exc:
        # Ruff not installed / importable in this environment
        return (
            False,
            f"Ruff not available: {exc!r}. Install ruff in this environment.",
            [],
        )

    stdout = proc.stdout or ""
    stderr = proc.stderr or ""

    if not stdout.strip():
        # No JSON output â€“ treat as failure with diagnostic
        return (
            False,
            f"Ruff did not produce JSON output. rc={proc.returncode}, stderr={stderr.strip()}",
            [],
        )

    try:
        data = json.loads(stdout)
    except json.JSONDecodeError as exc:
        return (
            False,
            f"Failed to parse Ruff JSON output: {exc!r}",
            [],
        )

    # Ruff JSON is a list of diagnostics
    issues: List[Dict[str, Any]] = []
    for diag in data:
        issues.append(
            {
                "filename": diag.get("filename"),
                "code": diag.get("code"),
                "message": diag.get("message"),
                "location": diag.get("location"),
            }
        )

    if issues:
        return (
            False,
            f"Ruff reported {len(issues)} code-quality issue(s).",
            issues,
        )

    return True, "No code-quality issues reported by Ruff.", issues


def write_lint_evidence(
    story_id: str,
    targets: List[str],
    passed: bool,
    message: str,
    issues: List[Dict[str, Any]],
) -> Path:
    """
    Write JSON evidence file for lint/code-quality adherence for this Story.
    """
    results_dir = REPO_ROOT / "evidence" / "lint"
    results_dir.mkdir(parents=True, exist_ok=True)

    evidence_path = results_dir / f"{story_id}.json"

    # New: rule-family pass evidence
    rule_family_results = build_rule_family_results(passed)

    payload = {
        "story_id": story_id,
        "targets": targets,
        "passed": passed,
        "message": message,
        "issues": issues,
        # New fields (rule-family pass evidence)
        "rule_family_basis": (
            "Ruff exit code 0 indicates all enabled Ruff rules passed; "
            "non-zero indicates at least one enabled rule failed."
        ),
        "rule_family_results": rule_family_results,
    }
    evidence_path.write_text(json.dumps(payload, indent=2), encoding="utf-8")
    print(
        f">>> Wrote lint evidence for {story_id} to {evidence_path.relative_to(REPO_ROOT)}"
    )
    return evidence_path


def update_story_code_quality_status(story_file: Path, passed: bool) -> None:
    """
    Replace the first 'code_quality_adherence: ...' line in the Story's front matter.
    """
    if not story_file.exists():
        raise FileNotFoundError(f"Story file not found: {story_file}")

    status = "pass" if passed else "fail"

    text = story_file.read_text(encoding="utf-8")

    pattern = r"(^code_quality_adherence:\s*).*$"
    replacement = rf"\1{status}"
    new_text, count = re.subn(pattern, replacement, text, count=1, flags=re.MULTILINE)

    if count == 0:
        raise RuntimeError(
            f"Story file {story_file} does not contain a code_quality_adherence line to update."
        )

    story_file.write_text(new_text, encoding="utf-8")
    rel = story_file.relative_to(REPO_ROOT)
    print(f">>> Updated {rel} -> code_quality_adherence: {status}")


def run_lint_for_story(story_id: str) -> Tuple[bool, str]:
    """
    Run linting for a single Story:
    - execute Ruff on its targets
    - write evidence
    - update front matter

    Returns (passed, message).
    """
    config = STORY_CONFIG[story_id]
    story_file: Path = config["story_file"]  # type: ignore[assignment]
    targets: List[str] = config["lint_targets"]  # type: ignore[assignment]

    print(f">>> Running lint/code-quality checks for Story {story_id}")
    passed, message, issues = run_ruff_for_targets(targets)

    write_lint_evidence(story_id, targets, passed, message, issues)
    update_story_code_quality_status(story_file, passed)

    status = "pass" if passed else "fail"
    print(f">>> Story {story_id} code_quality_adherence set to {status}: {message}")
    return passed, message


# ---------------------------------------------------------------------------
# CLI entrypoint
# ---------------------------------------------------------------------------

def main(argv: List[str]) -> int:
    """
    Usage:
      python tools/run_story_lint.py          # run for all configured Stories
      python tools/run_story_lint.py ST-03    # run for a single Story
    """
    if len(argv) > 1:
        story_id = argv[1].upper()
        if story_id not in STORY_CONFIG:
            print(f"ERROR: Story {story_id!r} is not configured in STORY_CONFIG.")
            print(f"Known stories: {', '.join(sorted(STORY_CONFIG.keys()))}")
            return 1
        requested_ids = [story_id]
    else:
        requested_ids = sorted(STORY_CONFIG.keys())

    overall_exit = 0
    for sid in requested_ids:
        print(f"\n=== Lint/code-quality for Story {sid} ===")
        passed, _ = run_lint_for_story(sid)
        if not passed:
            overall_exit = 1

    return overall_exit


if __name__ == "__main__":
    raise SystemExit(main(sys.argv))



===== FILE: tools\run_story_security.py =====
#!/usr/bin/env python
"""
Run security checks for one or more Stories and update security_policy_adherence
in each Story's front matter.

MVP:
- Use Bandit to scan the Story's Python files for security issues.
- If any Medium/High severity issues are found (and confidence is Medium/High), mark as fail.
- Otherwise mark as pass.
"""

from __future__ import annotations

import json
import re
import subprocess
import sys
from pathlib import Path
from typing import Any, Dict, List, Tuple

import os
import sys
from pathlib import Path

REPO_ROOT = Path(__file__).resolve().parents[1]
BACKEND_ROOT = REPO_ROOT / "backend_v2"

# Ensure backend_v2 is on PYTHONPATH so `import app` works
sys.path.insert(0, str(BACKEND_ROOT))
os.environ["PYTHONPATH"] = str(BACKEND_ROOT)


# ---------------------------------------------------------------------------
# Repo root + sys.path
# ---------------------------------------------------------------------------

REPO_ROOT = Path(__file__).resolve().parents[1]
if str(REPO_ROOT) not in sys.path:
    sys.path.insert(0, str(REPO_ROOT))


# ---------------------------------------------------------------------------
# Story configuration
# ---------------------------------------------------------------------------

# For each Story:
# - story_file: markdown Story file
# - security_targets: list of Python files to scan with Bandit
STORY_CONFIG: Dict[str, Dict[str, Any]] = {
    "ST-03": {
        "story_file": REPO_ROOT
        / "docs"
        / "mission_destination"
        / "stories"
        / "ST-03_map_identity_fields.md",
        "security_targets": [
            "src/services/client_profile/service.py",
            "src/domain/models/client_profile.py",
        ],
    },
    "ST-04": {
        "story_file": REPO_ROOT
        / "docs"
        / "mission_destination"
        / "stories"
        / "ST-04_map_identifiers.md",
        "security_targets": [
            "src/services/client_profile/service.py",
            "src/domain/models/client_profile.py",
        ],
    },
    "ST-05": {
        "story_file": REPO_ROOT
        / "docs"
        / "mission_destination"
        / "stories"
        / "ST-05_bulk_load_crm.md",
        "security_targets": [
            r"backend_v2\app\services\crm_bulk_load_service.py",
        ],
    },
    "ST-09": {
        "story_file": REPO_ROOT
        / "docs"
        / "mission_destination"
        / "stories"
        / "ST-09_match_by_tax_id.md",
        "security_targets": [
            "src/services/client_profile/service.py",
        ],
    },
    "ST-20": {
        "story_file": REPO_ROOT
        / "docs"
        / "mission_destination"
        / "stories"
        / "ST-20_assemble_base_profile.md",
        "security_targets": [
            "src/services/client_profile/service.py",
            "src/domain/models/client_profile.py",
        ],
    },
    "ST-30": {
        "story_file": REPO_ROOT
        / "docs"
        / "mission_destination"
        / "stories"
        / "ST-30_audit_ingestion.md",
        "security_targets": [
            "src/services/audit/service.py",
        ],
    },
    "ST-00": {
        "story_file": REPO_ROOT
        / "docs"
        / "mission_destination"
        / "stories"
        / "ST-00-backend-api-availability.md",
        "security_targets": [
            "app_backend/main.py",
        ],
    },
    "ST-00-FRONTEND-UI-SHELL": {
        "story_file": REPO_ROOT
        / "docs"
        / "mission_destination"
        / "stories"
        / "ST-00-frontend-ui-shell.md",
        "security_targets": [
            "app_backend/main.py",
        ],
    },
}


# ---------------------------------------------------------------------------
# Rule-family evidence (new)
# ---------------------------------------------------------------------------

BANDIT_RULE_FAMILIES: List[Dict[str, str]] = [
    {
        "check": "High-risk function usage (injection & execution)",
        "examples": "eval, exec, compile, pickle.loads, os.system, os.popen",
    },
    {
        "check": "OS command injection risks",
        "examples": "subprocess usage with shell=True or unsafe command construction",
    },
    {
        "check": "Hardcoded secrets & credentials",
        "examples": "hardcoded passwords, tokens, API keys, basic auth strings",
    },
    {
        "check": "Insecure cryptography",
        "examples": "weak hashes (md5/sha1), insecure randomness, weak SSL/TLS settings",
    },
    {
        "check": "Unsafe deserialization",
        "examples": "pickle, marshal, yaml.load without SafeLoader",
    },
    {
        "check": "SQL injection patterns",
        "examples": "string concatenation / formatting used to build SQL",
    },
    {
        "check": "XML / YAML parser vulnerabilities",
        "examples": "unsafe XML parsing patterns, unsafe yaml.load usage",
    },
    {
        "check": "Temporary file insecurity",
        "examples": "tempfile.mktemp, predictable temp filenames, race-prone patterns",
    },
    {
        "check": "Network & transport security",
        "examples": "disabled certificate validation, weak TLS settings",
    },
    {
        "check": "Debug & information disclosure",
        "examples": "debug flags enabled, risky asserts for security checks, leaking secrets",
    },
    {
        "check": "Permissions & file access risks",
        "examples": "overly permissive chmod, unsafe file writes, world-writable paths",
    },
    {
        "check": "Miscellaneous unsafe patterns",
        "examples": "deprecated security APIs and other high-risk constructs",
    },
]


def build_rule_family_results(passed: bool) -> List[Dict[str, str]]:
    """
    Mark each security rule family pass/fail based on our security gate.

    Important: this repo's security gate is "no Medium/High severity AND Medium/High confidence findings".
    So 'pass' here means "no medium/high findings detected in this category" (not "no findings at all").
    """
    status = "pass" if passed else "fail"
    qualifier = (
        "no medium/high findings" if passed else "one or more medium/high findings"
    )

    results: List[Dict[str, str]] = []
    for item in BANDIT_RULE_FAMILIES:
        results.append(
            {
                "check": item["check"],
                "status": status,
                "detail": qualifier,
                "examples": item["examples"],
            }
        )
    return results


# ---------------------------------------------------------------------------
# Core helpers
# ---------------------------------------------------------------------------

def run_bandit_for_targets(targets: List[str]) -> Tuple[bool, str, List[Dict[str, Any]]]:
    """
    Run Bandit on the given Python files.

    Returns:
      (passed, message, issues)

    Where issues is a minimal list of findings we care about.
    """
    cmd = [
        sys.executable,
        "-m",
        "bandit",
        "-q",        # quiet banner
        "-f",
        "json",      # JSON output
        "-o",
        "-",         # write JSON to stdout
        *targets,
    ]
    print(f">>> Running Bandit: {' '.join(cmd)}")
    try:
        proc = subprocess.run(
            cmd,
            cwd=REPO_ROOT,
            capture_output=True,
            text=True,
            check=False,
        )
    except FileNotFoundError as exc:
        # bandit not installed / not importable
        return (
            False,
            f"Bandit not available: {exc!r}. Install bandit in this environment.",
            [],
        )

    stdout = proc.stdout or ""
    stderr = proc.stderr or ""

    # Bandit often returns 0 when no issues, 1 when issues found.
    # We don't rely solely on returncode; we parse JSON.
    if not stdout.strip():
        return (
            False,
            f"Bandit did not produce JSON output. rc={proc.returncode}, stderr={stderr.strip()}",
            [],
        )

    try:
        data = json.loads(stdout)
    except json.JSONDecodeError as exc:
        return (
            False,
            f"Failed to parse Bandit JSON output: {exc!r}",
            [],
        )

    raw_results = data.get("results", []) or []

    # Keep only medium/high severity & confidence findings.
    issues: List[Dict[str, Any]] = []
    for r in raw_results:
        severity = (r.get("issue_severity") or "").upper()
        confidence = (r.get("issue_confidence") or "").upper()
        if severity in {"MEDIUM", "HIGH"} and confidence in {"MEDIUM", "HIGH"}:
            issues.append(
                {
                    "filename": r.get("filename"),
                    "line_number": r.get("line_number"),
                    "test_id": r.get("test_id"),
                    "issue_severity": severity,
                    "issue_confidence": confidence,
                    "issue_text": r.get("issue_text"),
                }
            )

    if issues:
        return (
            False,
            f"Bandit found {len(issues)} medium/high security issue(s).",
            issues,
        )

    return True, "No medium/high security issues found by Bandit.", issues


def write_security_evidence(
    story_id: str,
    targets: List[str],
    passed: bool,
    message: str,
    issues: List[Dict[str, Any]],
) -> Path:
    """
    Write JSON evidence file for security adherence for this Story.
    """
    results_dir = REPO_ROOT / "evidence" / "security"
    results_dir.mkdir(parents=True, exist_ok=True)

    evidence_path = results_dir / f"{story_id}.json"

    # New: rule-family pass evidence
    rule_family_results = build_rule_family_results(passed)

    payload = {
        "story_id": story_id,
        "targets": targets,
        "passed": passed,
        "message": message,
        "issues": issues,
        # New fields (rule-family pass evidence)
        "rule_family_basis": (
            "Security gate for this repo is: no Bandit findings with "
            "severity in {MEDIUM,HIGH} and confidence in {MEDIUM,HIGH}. "
            "If the gate passes, each enabled security rule family is recorded as "
            "'pass (no medium/high findings)'."
        ),
        "rule_family_results": rule_family_results,
    }

    evidence_path.write_text(json.dumps(payload, indent=2), encoding="utf-8")
    print(
        f">>> Wrote security evidence for {story_id} to {evidence_path.relative_to(REPO_ROOT)}"
    )
    return evidence_path


def update_story_security_status(story_file: Path, passed: bool) -> None:
    """
    Replace the first 'security_policy_adherence: ...' line in the Story's front matter.
    """
    if not story_file.exists():
        raise FileNotFoundError(f"Story file not found: {story_file}")

    status = "pass" if passed else "fail"

    text = story_file.read_text(encoding="utf-8")

    pattern = r"(^security_policy_adherence:\s*).*$"
    replacement = rf"\1{status}"
    new_text, count = re.subn(pattern, replacement, text, count=1, flags=re.MULTILINE)

    if count == 0:
        raise RuntimeError(
            f"Story file {story_file} does not contain a security_policy_adherence line to update."
        )

    story_file.write_text(new_text, encoding="utf-8")
    rel = story_file.relative_to(REPO_ROOT)
    print(f">>> Updated {rel} -> security_policy_adherence: {status}")


def run_security_for_story(story_id: str) -> Tuple[bool, str]:
    """
    Run security scan for a single Story:
    - execute Bandit on its targets
    - write evidence
    - update front matter

    Returns (passed, message).
    """
    config = STORY_CONFIG[story_id]
    story_file: Path = config["story_file"]  # type: ignore[assignment]
    targets: List[str] = config["security_targets"]  # type: ignore[assignment]

    print(f">>> Running security checks for Story {story_id}")
    passed, message, issues = run_bandit_for_targets(targets)

    write_security_evidence(story_id, targets, passed, message, issues)
    update_story_security_status(story_file, passed)

    status = "pass" if passed else "fail"
    print(f">>> Story {story_id} security_policy_adherence set to {status}: {message}")
    return passed, message


# ---------------------------------------------------------------------------
# CLI entrypoint
# ---------------------------------------------------------------------------

def main(argv: List[str]) -> int:
    """
    Usage:
      python tools/run_story_security.py          # run for all configured Stories
      python tools/run_story_security.py ST-03    # run for a single Story
    """
    if len(argv) > 1:
        story_id = argv[1].upper()
        if story_id not in STORY_CONFIG:
            print(f"ERROR: Story {story_id!r} is not configured in STORY_CONFIG.")
            print(f"Known stories: {', '.join(sorted(STORY_CONFIG.keys()))}")
            return 1
        requested_ids = [story_id]
    else:
        requested_ids = sorted(STORY_CONFIG.keys())

    overall_exit = 0
    for sid in requested_ids:
        print(f"\n=== Security for Story {sid} ===")
        passed, _ = run_security_for_story(sid)
        if not passed:
            overall_exit = 1

    return overall_exit


if __name__ == "__main__":
    raise SystemExit(main(sys.argv))



===== FILE: tools\run_story_tests.py =====
#!/usr/bin/env python
"""
Run tests for one or more Stories, record results, and update testing_status
in each Story's front-matter.

For each Story:
- Run pytest on its configured targets
- Write evidence to evidence/test_results/<ST-XX>.json
- Update testing_status: pass|fail in the Story markdown front matter
"""

from __future__ import annotations

import json
import os
import re
import subprocess
import sys
from pathlib import Path
from typing import Dict, List, Tuple, Any

import yaml  # mapping-driven scope (repo already uses PyYAML)

import os
import sys
from pathlib import Path

REPO_ROOT = Path(__file__).resolve().parents[1]
BACKEND_ROOT = REPO_ROOT / "backend_v2"

# Ensure backend_v2 is on PYTHONPATH so `import app` works
sys.path.insert(0, str(BACKEND_ROOT))
os.environ["PYTHONPATH"] = str(BACKEND_ROOT)


# Repo root = parent of /tools
REPO_ROOT = Path(__file__).resolve().parents[1]

# Story -> Service mapping (governing artefact)
STORY_SERVICE_MAPPING_PATH = (
    REPO_ROOT / "docs" / "mission_destination" / "story_service_mapping.yaml"
)
GOVERNED_BY = "docs/mission_destination/story_service_mapping.yaml"


# ---------------------------------------------------------------------------
# Story configuration
# ---------------------------------------------------------------------------

# As more Stories gain real tests, add them here.
STORY_CONFIG: Dict[str, Dict[str, object]] = {
    "ST-03": {
        "story_file": REPO_ROOT
        / "docs"
        / "mission_destination"
        / "stories"
        / "ST-03_map_identity_fields.md",
        "pytest_targets": [
            "tests/services/client_profile/test_client_profile_service.py",
        ],
    },
    "ST-04": {
        "story_file": REPO_ROOT
        / "docs"
        / "mission_destination"
        / "stories"
        / "ST-04_map_identifiers.md",
        "pytest_targets": [
            "tests/services/client_profile/test_st_04_map_identifiers.py",
        ],
    },
    "ST-05": {
        "story_file": REPO_ROOT
        / "docs"
        / "mission_destination"
        / "stories"
        / "ST-05_bulk_load_crm.md",
       "pytest_targets": [
            r"tests/services/ingestion/test_st_05_bulk_load_crm.py",
        ],
    },
    "ST-09": {
        "story_file": REPO_ROOT
        / "docs"
        / "mission_destination"
        / "stories"
        / "ST-09_match_by_tax_id.md",
        "pytest_targets": [
            "tests/services/client_profile/test_st_09_match_by_tax_id.py",
        ],
    },
    "ST-20": {
        "story_file": REPO_ROOT
        / "docs"
        / "mission_destination"
        / "stories"
        / "ST-20_assemble_base_profile.md",
        "pytest_targets": [
            "tests/services/client_profile/test_st_20_assemble_base_profile.py",
        ],
    },
    "ST-30": {
        "story_file": REPO_ROOT
        / "docs"
        / "mission_destination"
        / "stories"
        / "ST-30_audit_ingestion.md",
        "pytest_targets": [
            "tests/services/audit/test_st_30_audit_ingestion.py",
        ],
    },
    "ST-00": {
        "story_file": REPO_ROOT
        / "docs"
        / "mission_destination"
        / "stories"
        / "ST-00-backend-api-availability.md",
        "pytest_targets": [
            "tests/api/http/test_st_00_backend_api_availability.py",
        ],
    },
    "ST-00-FRONTEND-UI-SHELL": {
        "story_file": REPO_ROOT
        / "docs"
        / "mission_destination"
        / "stories"
        / "ST-00-frontend-ui-shell.md",
        "pytest_targets": [
            "tests/api/http/test_st_00_frontend_ui_shell.py",
        ],
    },
}


# ---------------------------------------------------------------------------
# Mapping-driven scope helpers (additions only)
# ---------------------------------------------------------------------------

def load_story_service_mapping() -> Dict[str, Any]:
    if not STORY_SERVICE_MAPPING_PATH.exists():
        raise FileNotFoundError(f"Mapping file not found: {STORY_SERVICE_MAPPING_PATH}")
    return yaml.safe_load(STORY_SERVICE_MAPPING_PATH.read_text(encoding="utf-8")) or {}


def resolve_scope_for_story(story_key: str, mapping: Dict[str, Any]) -> Dict[str, Any]:
    """
    Resolve owning service + implementation file from the governing story->service mapping.

    story_key is the key used in STORY_CONFIG (e.g. ST-05, ST-00, ST-00-FRONTEND-UI-SHELL).
    The mapping file keys include ST-00-backend and ST-00-frontend, so we bridge those.
    """
    key_aliases = {
        "ST-00": "ST-00-backend",
        "ST-00-FRONTEND-UI-SHELL": "ST-00-frontend",
    }
    mapping_key = key_aliases.get(story_key, story_key)

    entry = mapping.get(mapping_key)
    if isinstance(entry, dict):
        return {
            "owning_service": entry.get("service"),
            "implementation_file": entry.get("code_file"),
            "governed_by": GOVERNED_BY,
        }

    # Fallback: match by embedded story_id field (for resilience if keys change)
    for _, maybe in mapping.items():
        if isinstance(maybe, dict) and maybe.get("story_id") == story_key:
            return {
                "owning_service": maybe.get("service"),
                "implementation_file": maybe.get("code_file"),
                "governed_by": GOVERNED_BY,
            }

    return {
        "owning_service": None,
        "implementation_file": None,
        "governed_by": GOVERNED_BY,
        "warning": f"No mapping entry found for {story_key}",
    }


# ---------------------------------------------------------------------------
# Core helpers
# ---------------------------------------------------------------------------

def run_pytest_for_story(story_id: str, pytest_targets: List[str]) -> Tuple[int, str]:
    """
    Run pytest for the given Story and return (exit_code, combined_output).

    Uses `sys.executable -m pytest` so it works reliably on Windows, Mac, Linux.
    """
    cmd = [sys.executable, "-m", "pytest", "-q", "-r", "w", *pytest_targets]
    print(f">>> Running tests for {story_id}: {' '.join(cmd)}")

    # Ensure backend_v2 is on PYTHONPATH so tests can import `app.*`
    env = os.environ.copy()
    backend_v2_path = str(REPO_ROOT / "backend_v2")
    existing = env.get("PYTHONPATH", "")
    env["PYTHONPATH"] = (
        backend_v2_path if not existing else backend_v2_path + os.pathsep + existing
    )

    result = subprocess.run(
        cmd,
        cwd=REPO_ROOT,
        capture_output=True,
        text=True,
        check=False,
        env=env,
    )

    combined_output = (result.stdout or "") + (
        "\n" + result.stderr if result.stderr else ""
    )

    if result.stdout:
        print(result.stdout, end="" if result.stdout.endswith("\n") else "\n")
    if result.stderr:
        print(result.stderr, end="" if result.stderr.endswith("\n") else "\n")

    print(f">>> {story_id} pytest exit code: {result.returncode}")
    return result.returncode, combined_output


def parse_warnings_count(pytest_output: str) -> int:
    m = re.search(r"\b(\d+)\s+warnings?\b", pytest_output)
    return int(m.group(1)) if m else 0


def extract_pytest_summary(pytest_output: str) -> str:
    for line in pytest_output.splitlines():
        if "passed" in line and (
            "warning in" in line or "warnings in" in line
        ):
            return line.strip()
        if "passed" in line and " in " in line:
            return line.strip()
    for line in reversed(pytest_output.splitlines()):
        if line.strip():
            return line.strip()
    return ""


def extract_warnings_block(pytest_output: str) -> str:
    """
    Extract the pytest 'warnings summary' block, if present.
    """
    m = re.search(
        r"(=+\s*warnings summary\s*=+.*?)(?:\n=+\s*|$)",
        pytest_output,
        flags=re.IGNORECASE | re.DOTALL,
    )
    return m.group(1).strip() if m else ""


def write_test_result_evidence(
    story_id: str,
    pytest_targets: List[str],
    exit_code: int,
    status: str,
    warnings_count: int,
    pytest_summary: str,
    warnings: str,
    scope: Dict[str, Any],
) -> Path:
    """
    Write a small JSON evidence file with the Story's test result.
    """
    results_dir = REPO_ROOT / "evidence" / "test_results"
    results_dir.mkdir(parents=True, exist_ok=True)

    evidence_path = results_dir / f"{story_id}.json"
    payload = {
        "story_id": story_id,
        "pytest_targets": pytest_targets,
        "exit_code": exit_code,
        "status": status,
        "warnings_count": warnings_count,
        "pytest_summary": pytest_summary,
        "warnings": warnings,
        # mapping-driven scope additions only
        "scope": scope,
    }
    evidence_path.write_text(json.dumps(payload, indent=2), encoding="utf-8")
    print(
        ">>> Wrote test evidence for "
        f"{story_id} to {evidence_path.relative_to(REPO_ROOT)}"
    )
    return evidence_path


def update_story_testing_status(story_file: Path, status: str) -> None:
    """
    Replace the first 'testing_status: ...' line in the Story's front-matter.
    """
    if status not in {"pass", "fail"}:
        raise ValueError(f"Invalid status {status!r}; expected 'pass' or 'fail'")

    if not story_file.exists():
        raise FileNotFoundError(f"Story file not found: {story_file}")

    text = story_file.read_text(encoding="utf-8")

    pattern = r"(^testing_status:\s*).*$"
    replacement = rf"\1{status}"
    new_text, count = re.subn(pattern, replacement, text, count=1, flags=re.MULTILINE)

    if count == 0:
        raise RuntimeError(
            f"Story file {story_file} does not contain a testing_status line to update."
        )

    story_file.write_text(new_text, encoding="utf-8")
    rel = story_file.relative_to(REPO_ROOT)
    print(f">>> Updated {rel} -> testing_status: {status}")


def run_for_story(story_id: str, mapping: Dict[str, Any]) -> Tuple[int, str]:
    """
    Execute end-to-end for a single Story:
    - run pytest on its configured targets
    - derive status
    - write evidence
    - update front matter

    Returns (exit_code, status).
    """
    config = STORY_CONFIG[story_id]
    story_file: Path = config["story_file"]  # type: ignore[assignment]
    pytest_targets: List[str] = config["pytest_targets"]  # type: ignore[assignment]

    exit_code, output = run_pytest_for_story(story_id, pytest_targets)
    status = "pass" if exit_code == 0 else "fail"

    warnings_count = parse_warnings_count(output)
    pytest_summary = extract_pytest_summary(output)
    warnings_block = extract_warnings_block(output)

    scope = resolve_scope_for_story(story_id, mapping)

    write_test_result_evidence(
        story_id,
        pytest_targets,
        exit_code,
        status,
        warnings_count,
        pytest_summary,
        warnings_block,
        scope,
    )
    update_story_testing_status(story_file, status)

    print(f">>> Story {story_id} testing_status set to {status}")
    return exit_code, status


# ---------------------------------------------------------------------------
# CLI entrypoint
# ---------------------------------------------------------------------------

def main(argv: List[str]) -> int:
    """
    Usage:
      python tools/run_story_tests.py          # run for all configured Stories
      python tools/run_story_tests.py ST-03    # run for a single Story
    """
    mapping = load_story_service_mapping()

    if len(argv) > 1:
        story_id = argv[1].upper()
        if story_id not in STORY_CONFIG:
            print(f"ERROR: Story {story_id!r} is not configured in STORY_CONFIG.")
            print(f"Known stories: {', '.join(sorted(STORY_CONFIG.keys()))}")
            return 1
        requested_ids = [story_id]
    else:
        requested_ids = sorted(STORY_CONFIG.keys())

    overall_exit = 0
    for sid in requested_ids:
        print(f"\n=== Running tests for Story {sid} ===")
        exit_code, _ = run_for_story(sid, mapping)
        overall_exit = max(overall_exit, exit_code)

    return overall_exit


if __name__ == "__main__":
    raise SystemExit(main(sys.argv))





===== FILE: tools\seed_demo_data.py =====
#!/usr/bin/env python
"""
Seed additional demo clients into the SCV database via the /ingest endpoint.

NOTE:
- This script ONLY creates NEW clients:
    - C-004, C-005, C-006, C-007
- It does NOT touch C-001, C-002, C-003 that you have already created.

Clients:

- C-004: Delta Manufacturing
    - CRM + KYC + VENDOR (external) sources
    - Slight differences in names, emails, addresses

- C-005: Eastbridge Holdings
    - Single CRM record with slightly messy data

- C-006: Flextronics / Flextronix
    - CRM + KYC with shared tax_id="TAX-777"
    - Great example for ST-09 match-by-tax-id

- C-007: GreyLake Partners
    - CRM + KYC + VENDOR sources
    - Conflicting emails, address formats, country codes

Run (from repo root, with backend running on 127.0.0.1:8000):

    python tools/seed_demo_data.py
"""

import requests

BACKEND_BASE_URL = "http://127.0.0.1:8000"
INGEST_URL = f"{BACKEND_BASE_URL}/ingest"


def ingest_record(rec: dict):
    """Send a single record to the backend /ingest endpoint."""
    wire_payload = {
        "client_id": rec["client_id"],
        "system": rec["system"],
        "payload": rec["payload"],  # dict, not JSON string
    }

    print(f"---> Ingesting {rec['system']} record for client {rec['client_id']}")

    resp = requests.post(INGEST_URL, json=wire_payload)

    if not resp.ok:
        print(f"!! Failed ({resp.status_code}): {resp.text}")
        resp.raise_for_status()

    data = resp.json()
    print(f"     OK: id={data.get('id')} system={data.get('system')}")
    return data


def main():
    print("=== Seeding EXTRA SCV demo data via /ingest ===")
    print(f"Target backend: {BACKEND_BASE_URL}\n")

    demo_records = [
        # ------------------------------------------------------------------
        # C-004 â€” Delta Manufacturing (rich multi-source example)
        # ------------------------------------------------------------------
        {
            "client_id": "C-004",
            "system": "CRM",
            "payload": {
                "_source": "CRM",
                "client_id": "C-004",
                "name": "Delta Manufacturing Ltd",
                "email": "info@delta-mfg.com",
                "phone": "+44 20 8000 4004",
                "country": "GB",
                "tax_id": "TAX-004",
                "registration_number": "REG-DELTA-01",
                "address_line1": "10 Industry Way",
                "address_city": "Birmingham",
                "postcode": "B1 2AA",
            },
        },
        {
            "client_id": "C-004",
            "system": "KYC",
            "payload": {
                "_source": "KYC",
                "client_id": "C-004",
                "name": "Delta MFG Limited",
                "email": "kyc@delta-mfg.com",
                "country": "UK",
                "tax_id": "TAX-004",
                "kyc_risk_rating": "LOW",
                "address_line1": "10 Industry Way",
                "address_city": "Birmingham",
                "postcode": "B1 2AA",
            },
        },
        {
            "client_id": "C-004",
            "system": "VENDOR",
            "payload": {
                "_source": "VENDOR",
                "client_id": "C-004",
                "name": "Delta Manufacturing Limited",
                "email": "compliance@delta-mfg.com",
                "country": "GBR",
                "tax_id": "TAX-004",
                "external_reference": "VEN-DELTA-2025",
            },
        },

        # ------------------------------------------------------------------
        # C-005 â€” Eastbridge Holdings (messy CRM-only)
        # ------------------------------------------------------------------
        {
            "client_id": "C-005",
            "system": "CRM",
            "payload": {
                "_source": "CRM",
                "client_id": "C-005",
                "name": "EASTBRIDGE HOLDINGS PLC",  # upper case
                "email": "contact@eastbridge-holdings.com",
                "phone": "+44 20 7005 5005",
                "country": "GB",
                "tax_id": None,  # intentionally missing tax id
                "registration_number": "REG-EAST-01",
                "identifier_1": "CRM-EAST-001",
                "identifier_2": "ALT-EAST-XYZ",
            },
        },

        # ------------------------------------------------------------------
        # C-006 â€” Flextronics / Flextronix (tax-id merge demo)
        # ------------------------------------------------------------------
        {
            "client_id": "C-006",
            "system": "CRM",
            "payload": {
                "_source": "CRM",
                "client_id": "C-006",
                "name": "Flextronics PLC",
                "email": "info@flextronics.com",
                "phone": "+44 20 7010 6006",
                "country": "GB",
                "tax_id": "TAX-777",
                "registration_number": "REG-FLEX-01",
            },
        },
        {
            "client_id": "C-006",
            "system": "KYC",
            "payload": {
                "_source": "KYC",
                "client_id": "C-006",
                "name": "Flextronix Plc",  # slight name variation
                "email": "kyc@flextronix.com",
                "country": "UK",
                "tax_id": "TAX-777",  # shared tax id â†’ ST-09 demo
                "kyc_risk_rating": "MEDIUM",
            },
        },

        # ------------------------------------------------------------------
        # C-007 â€” GreyLake Partners (three conflicting sources)
        # ------------------------------------------------------------------
        {
            "client_id": "C-007",
            "system": "CRM",
            "payload": {
                "_source": "CRM",
                "client_id": "C-007",
                "name": "Greylake Partners LLP",
                "email": "info@greylakepartners.co.uk",
                "phone": "+44 20 7020 7007",
                "country": "GB",
                "tax_id": "TAX-007",
                "registration_number": "REG-GREY-01",
                "address_line1": "50 Riverside Walk",
                "address_city": "London",
                "postcode": "EC2R 8AH",
            },
        },
        {
            "client_id": "C-007",
            "system": "KYC",
            "payload": {
                "_source": "KYC",
                "client_id": "C-007",
                "name": "GreyLake Partners LLP",  # different capitalisation
                "email": "kyc@greylakepartners.com",
                "country": "UK",
                "tax_id": "TAX-007",
                "kyc_risk_rating": "HIGH",
                "address_line1": "50 Riverside Walk",
                "address_city": "London",
                "postcode": "EC2R 8AH",
            },
        },
        {
            "client_id": "C-007",
            "system": "VENDOR",
            "payload": {
                "_source": "VENDOR",
                "client_id": "C-007",
                "name": "Greylake Partners LLP",
                "email": "operations@greylakepartners.com",
                "country": "GBR",
                "tax_id": "TAX-007",
                "external_reference": "VEN-GREY-2025",
            },
        },
    ]

    for rec in demo_records:
        ingest_record(rec)

    print("\n=== Extra demo data seeded successfully ===")
    print("You now have additional clients:")
    print("  â€¢ C-004  (Delta Manufacturing â€“ rich multi-source)")
    print("  â€¢ C-005  (Eastbridge Holdings â€“ messy CRM-only)")
    print("  â€¢ C-006  (Flextronics/Flextronix â€“ tax-id match demo)")
    print("  â€¢ C-007  (GreyLake Partners â€“ conflicting multi-source)")
    print()


if __name__ == "__main__":
    main()




===== FILE: tools\status_snapshot.py =====
#!/usr/bin/env python
"""
Mission Control Status Snapshot

Reads epics, features, and stories and writes:

  missionlog/status/status_snapshot.md     (Markdown tables for humans)
  app_frontend/public/missionlog/status_snapshot.json  (JSON for MissionLog UI)

Markdown contains three tables:
- Epics:    Epic | Name | Overall
- Features: Feature | Epic | Name | Overall | Stories
- Stories:  Story | Feature | Name | Overall

JSON contains a nested structure:

{
  "generated_at": "...",
  "epics": [
    {
      "epic_id": "...",
      "name": "...",
      "overall_status": "...",
      "features": [
        {
          "feature_id": "...",
          "name": "...",
          "epic_id": "...",
          "overall_status": "...",
          "stories": [
            {
              "story_id": "...",
              "name": "...",
              "feature_id": "...",
              "overall_status": "...",
              "testing_status": "...",
              "halo_adherence": "...",
              "guardrail_adherence": "...",
              "code_quality_adherence": "...",
              "security_policy_adherence": "..."
            }
          ]
        }
      ]
    }
  ]
}
"""

from __future__ import annotations

import json
import re
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional

REPO_ROOT = Path(__file__).resolve().parents[1]

EPICS_DIR = REPO_ROOT / "docs" / "mission_destination" / "epics"
FEATURES_DIR = REPO_ROOT / "docs" / "mission_destination" / "features"
STORIES_DIR = REPO_ROOT / "docs" / "mission_destination" / "stories"

SNAPSHOT_DIR = REPO_ROOT / "missionlog" / "status"
SNAPSHOT_PATH = SNAPSHOT_DIR / "status_snapshot.md"

PUBLIC_STATUS_DIR = REPO_ROOT / "app_frontend" / "public" / "missionlog"
PUBLIC_STATUS_JSON = PUBLIC_STATUS_DIR / "status_snapshot.json"


# -------------------- helpers -------------------- #

def _read(path: Path) -> str:
    return path.read_text(encoding="utf-8")


def _extract_scalar(text: str, key: str) -> Optional[str]:
    pattern = rf"^{re.escape(key)}:\s*(.+)$"
    m = re.search(pattern, text, flags=re.MULTILINE)
    if not m:
        return None
    val = m.group(1).strip()
    if val and val[0] in {"'", '"'} and val[-1:] == val[0]:
        val = val[1:-1]
    return val or None


def _extract_yaml_list(text: str, key: str) -> List[str]:
    pattern = rf"^{re.escape(key)}:\s*\n(?P<body>(?:\s+- .*\n)+)"
    m = re.search(pattern, text, flags=re.MULTILINE)
    if not m:
        return []
    body = m.group("body")
    items: List[str] = []
    for line in body.splitlines():
        s = line.strip()
        if s.startswith("- "):
            val = s[2:].strip()
            if val:
                items.append(val)
    return items


def _safe_overall(val: Optional[str]) -> str:
    if not val:
        return ""
    t = val.strip().strip('"\'')
    lookup = {
        "planned": "Planned",
        "in progress": "In Progress",
        "in_progress": "In Progress",
        "in-progress": "In Progress",
        "complete": "Complete",
        "completed": "Complete",
        "done": "Complete",
    }
    return lookup.get(t.lower(), t)


def _safe_dim(val: Optional[str]) -> str:
    """
    Normalise dimension statuses to: pass / fail / not_run.
    """
    if not val:
        return "not_run"
    t = val.strip().strip('"\'').lower()
    if t in {"pass", "ok", "success", "compliant"}:
        return "pass"
    if t in {"fail", "error", "non_compliant", "non-compliant"}:
        return "fail"
    if t in {"not_run", "not run", "pending", "planned"}:
        return "not_run"
    return t


# -------------------- data structures -------------------- #

@dataclass
class EpicRow:
    epic_id: str
    name: str
    overall: str


@dataclass
class FeatureRow:
    feature_id: str
    epic_id: str
    name: str
    overall: str
    stories: List[str]


@dataclass
class StoryRow:
    story_id: str
    feature_id: str
    name: str
    overall: str
    testing_status: str
    halo_adherence: str
    guardrail_adherence: str
    code_quality_adherence: str
    security_policy_adherence: str


# -------------------- collectors -------------------- #

def collect_epics() -> Dict[str, EpicRow]:
    rows: Dict[str, EpicRow] = {}

    for path in sorted(EPICS_DIR.glob("*.md")):
        text = _read(path)

        epic_id = _extract_scalar(text, "epic_id")
        if not epic_id:
            continue

        name = _extract_scalar(text, "name") or path.stem
        overall = _safe_overall(_extract_scalar(text, "overall_status"))

        rows[epic_id] = EpicRow(
            epic_id=epic_id,
            name=name,
            overall=overall,
        )

    return rows


def collect_features() -> Dict[str, FeatureRow]:
    rows: Dict[str, FeatureRow] = {}

    for path in sorted(FEATURES_DIR.glob("*.md")):
        text = _read(path)

        feature_id = _extract_scalar(text, "feature_id")
        if not feature_id:
            continue

        epic_id = _extract_scalar(text, "epic") or ""
        name = _extract_scalar(text, "name") or path.stem
        overall = _safe_overall(_extract_scalar(text, "overall_status"))
        stories = _extract_yaml_list(text, "stories")

        rows[feature_id] = FeatureRow(
            feature_id=feature_id,
            epic_id=epic_id,
            name=name,
            overall=overall,
            stories=stories,
        )

    return rows


def collect_stories() -> Dict[str, StoryRow]:
    rows: Dict[str, StoryRow] = {}

    for path in sorted(STORIES_DIR.glob("*.md")):
        text = _read(path)

        story_id = _extract_scalar(text, "story_id")
        if not story_id:
            continue

        feature_id = _extract_scalar(text, "feature")
        name = _extract_scalar(text, "name") or path.stem
        overall = _safe_overall(_extract_scalar(text, "overall_status"))

        testing = _safe_dim(_extract_scalar(text, "testing_status"))
        halo = _safe_dim(_extract_scalar(text, "halo_adherence"))
        guardrail = _safe_dim(_extract_scalar(text, "guardrail_adherence"))
        code_quality = _safe_dim(_extract_scalar(text, "code_quality_adherence"))
        security = _safe_dim(_extract_scalar(text, "security_policy_adherence"))

        rows[story_id] = StoryRow(
            story_id=story_id,
            feature_id=feature_id or "",
            name=name,
            overall=overall,
            testing_status=testing,
            halo_adherence=halo,
            guardrail_adherence=guardrail,
            code_quality_adherence=code_quality,
            security_policy_adherence=security,
        )

    return rows


# -------------------- Markdown renderers -------------------- #

def _render_epics_table(epics: Dict[str, EpicRow]) -> str:
    if not epics:
        return "_No epics found._\n"

    lines: List[str] = []
    lines.append("| Epic | Name | Overall |")
    lines.append("|------|------|---------|")

    for eid in sorted(epics.keys()):
        e = epics[eid]
        lines.append(f"| {e.epic_id} | {e.name} | {e.overall} |")

    return "\n".join(lines) + "\n"


def _render_features_table(features: Dict[str, FeatureRow],
                           feature_to_story_ids: Dict[str, List[str]]) -> str:
    if not features:
        return "_No features found._\n"

    lines: List[str] = []
    lines.append("| Feature | Epic | Name | Overall | Stories |")
    lines.append("|---------|------|------|---------|---------|")

    for fid in sorted(features.keys()):
        f = features[fid]
        story_ids = feature_to_story_ids.get(fid, f.stories or [])
        stories_str = ", ".join(sorted(story_ids)) if story_ids else ""
        lines.append(
            f"| {f.feature_id} | {f.epic_id} | {f.name} | {f.overall} | {stories_str} |"
        )

    return "\n".join(lines) + "\n"


def _render_stories_table(stories: Dict[str, StoryRow]) -> str:
    if not stories:
        return "_No stories found._\n"

    lines: List[str] = []
    lines.append("| Story | Feature | Name | Overall |")
    lines.append("|-------|---------|------|---------|")

    for sid in sorted(stories.keys()):
        s = stories[sid]
        lines.append(f"| {s.story_id} | {s.feature_id} | {s.name} | {s.overall} |")

    return "\n".join(lines) + "\n"


def build_snapshot_markdown() -> str:
    epics = collect_epics()
    features = collect_features()
    stories = collect_stories()

    # Golden mapping: story.feature_id drives which stories belong to a feature.
    feature_to_story_ids: Dict[str, List[str]] = {}
    for s in stories.values():
        if not s.feature_id:
            continue
        feature_to_story_ids.setdefault(s.feature_id, []).append(s.story_id)

    parts: List[str] = []
    parts.append("# Mission Control Status Snapshot\n")

    parts.append("## Epics\n")
    parts.append(_render_epics_table(epics))

    parts.append("\n## Features\n")
    parts.append(_render_features_table(features, feature_to_story_ids))

    parts.append("\n## Stories\n")
    parts.append(_render_stories_table(stories))

    return "\n".join(parts)


# -------------------- JSON snapshot for MissionLog -------------------- #

def build_snapshot_json() -> Dict[str, object]:
    epics = collect_epics()
    features = collect_features()
    stories = collect_stories()

    # Map feature -> [StoryRow] via golden mapping (Story.feature_id)
    feature_to_stories: Dict[str, List[StoryRow]] = {}
    for s in stories.values():
        if not s.feature_id:
            continue
        feature_to_stories.setdefault(s.feature_id, []).append(s)

    # Map epic -> [FeatureRow] via Feature.epic_id
    epic_to_features: Dict[str, List[FeatureRow]] = {}
    for f in features.values():
        if not f.epic_id:
            continue
        epic_to_features.setdefault(f.epic_id, []).append(f)

    epics_payload: List[Dict[str, object]] = []

    for eid in sorted(epics.keys()):
        e = epics[eid]
        feature_rows = sorted(
            epic_to_features.get(eid, []),
            key=lambda fr: fr.feature_id,
        )

        features_payload: List[Dict[str, object]] = []
        for f in feature_rows:
            story_rows = sorted(
                feature_to_stories.get(f.feature_id, []),
                key=lambda sr: sr.story_id,
            )
            stories_payload: List[Dict[str, object]] = []
            for s in story_rows:
                stories_payload.append(
                    {
                        "story_id": s.story_id,
                        "name": s.name,
                        "feature_id": s.feature_id,
                        "overall_status": s.overall,
                        "testing_status": s.testing_status,
                        "halo_adherence": s.halo_adherence,
                        "guardrail_adherence": s.guardrail_adherence,
                        "code_quality_adherence": s.code_quality_adherence,
                        "security_policy_adherence": s.security_policy_adherence,
                    }
                )

            features_payload.append(
                {
                    "feature_id": f.feature_id,
                    "name": f.name,
                    "epic_id": f.epic_id,
                    "overall_status": f.overall,
                    "stories": stories_payload,
                }
            )

        epics_payload.append(
            {
                "epic_id": e.epic_id,
                "name": e.name,
                "overall_status": e.overall,
                "features": features_payload,
            }
        )

    return {
        "generated_at": datetime.utcnow().isoformat(timespec="seconds") + "Z",
        "epics": epics_payload,
    }


# -------------------- CLI -------------------- #

def main() -> int:
    print("=== Generating Mission Control Status Snapshot (overall + JSON) ===")
    print(f"Repo root: {REPO_ROOT}")

    SNAPSHOT_DIR.mkdir(parents=True, exist_ok=True)
    PUBLIC_STATUS_DIR.mkdir(parents=True, exist_ok=True)

    # Markdown snapshot (for the repo / docs)
    markdown = build_snapshot_markdown()
    SNAPSHOT_PATH.write_text(markdown, encoding="utf-8")
    print(f"Wrote Markdown snapshot to {SNAPSHOT_PATH.relative_to(REPO_ROOT)}")

    # JSON snapshot (for MissionLog UI)
    json_data = build_snapshot_json()
    PUBLIC_STATUS_JSON.write_text(
        json.dumps(json_data, indent=2),
        encoding="utf-8",
    )
    print(f"Wrote JSON snapshot to {PUBLIC_STATUS_JSON.relative_to(REPO_ROOT)}")

    print("=== Done ===")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())


===== FILE: tools\update_story_field.py =====
#!/usr/bin/env python
"""
Update a single front-matter field in a story markdown file.

Usage:
  python tools/update_story_field.py --story ST-05 --field halo_adherence --value pass
"""

import argparse
import sys
from pathlib import Path

import yaml


def parse_args():
    parser = argparse.ArgumentParser(description="Update a story front-matter field")
    parser.add_argument("--story", required=True, help="Story ID (e.g. ST-05)")
    parser.add_argument("--field", required=True, help="Front-matter field to update")
    parser.add_argument("--value", required=True, help="Value to set")
    return parser.parse_args()


def find_story_file(story_id: str) -> Path:
    stories_dir = Path("docs/mission_destination/stories")
    if not stories_dir.exists():
        raise FileNotFoundError(f"Stories directory not found: {stories_dir}")

    matches = list(stories_dir.glob(f"{story_id}_*.md"))
    if not matches:
        raise FileNotFoundError(f"No story file found for {story_id}")
    if len(matches) > 1:
        raise RuntimeError(f"Multiple story files found for {story_id}: {matches}")

    return matches[0]


def load_front_matter(text: str):
    if not text.startswith("---"):
        raise ValueError("Story file does not start with front matter ('---')")

    parts = text.split("---", 2)
    if len(parts) < 3:
        raise ValueError("Malformed front matter")

    front_matter = yaml.safe_load(parts[1]) or {}
    body = parts[2]

    return front_matter, body


def main():
    args = parse_args()

    story_file = find_story_file(args.story)

    raw = story_file.read_text(encoding="utf-8")
    front_matter, body = load_front_matter(raw)

    old_value = front_matter.get(args.field)
    front_matter[args.field] = args.value

    new_front = yaml.safe_dump(
        front_matter,
        sort_keys=False,
        default_flow_style=False,
    ).strip()

    updated = f"---\n{new_front}\n---{body}"

    story_file.write_text(updated, encoding="utf-8")

    print(
        f">>> Updated {story_file} -> "
        f"{args.field}: {old_value} -> {args.value}"
    )


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"ERROR: {e}", file=sys.stderr)
        sys.exit(1)


===== FILE: tools\update_story_overall_status.py =====
#!/usr/bin/env python
"""
Derive Story overall_status from testing / guardrail / code / security.

Rule per story:

1. Normalise each dimension:

   - pass / ok / success / compliant  -> Complete
   - fail / error / non_compliant     -> In Progress
   - not_run / pending / empty        -> Planned

2. overall_status:

   - Complete  if all four dims are Complete
   - Planned   if all four dims are Planned
   - In Progress otherwise

This script ONLY updates Story frontmatter.
Features/Epics are still rolled up by rollup_statuses.py.
"""

from __future__ import annotations

import re
from pathlib import Path
from typing import Optional, List, Dict

REPO_ROOT = Path(__file__).resolve().parents[1]
STORIES_DIR = REPO_ROOT / "docs" / "mission_destination" / "stories"


# ----------------- helpers ----------------- #

def _read(path: Path) -> str:
    return path.read_text(encoding="utf-8")


def _write(path: Path, text: str) -> None:
    path.write_text(text, encoding="utf-8")


def _extract_scalar(text: str, key: str) -> Optional[str]:
    pattern = rf"^{re.escape(key)}:\s*(.+)$"
    m = re.search(pattern, text, flags=re.MULTILINE)
    if not m:
        return None
    val = m.group(1).strip()
    if val and val[0] in {"'", '"'} and val[-1:] == val[0]:
        val = val[1:-1]
    return val or None


def _replace_scalar(text: str, key: str, value: str) -> str:
    pattern = rf"^{re.escape(key)}:\s*.*$"
    replacement = f"{key}: {value}"

    if re.search(pattern, text, flags=re.MULTILINE):
        return re.sub(pattern, replacement, text, count=1, flags=re.MULTILINE)

    # insert before last_updated if present
    lu_pattern = r"^last_updated:\s*.*$"
    m = re.search(lu_pattern, text, flags=re.MULTILINE)
    if m:
        start = m.start()
        return text[:start] + replacement + "\n" + text[start:]

    # else append at end of front matter
    if not text.endswith("\n"):
        text += "\n"
    return text + replacement + "\n"


def _norm_dim(raw: Optional[str]) -> str:
    """
    Normalise a dimension value to:

        Planned | In Progress | Complete
    """
    if raw is None:
        return "Planned"

    t = raw.strip().strip('"\'')
    tl = t.lower()

    # already canonical?
    if tl in {"planned"}:
        return "Planned"
    if tl in {"in progress", "in_progress", "in-progress"}:
        return "In Progress"
    if tl in {"complete", "completed"}:
        return "Complete"

    # pass-ish
    if tl in {"pass", "passed", "ok", "success", "succeeded", "compliant", "true", "yes"}:
        return "Complete"

    # fail-ish
    if tl in {"fail", "failed", "error", "non_compliant", "non-compliant", "false", "no"}:
        return "In Progress"

    # not-run / unknown â†’ planned
    if tl in {"not_run", "not-run", "not run", "pending", "todo", "tbd", "unknown", "n/a", "na", ""}:
        return "Planned"

    # default: treat as in progress
    return "In Progress"


def _derive_overall(dim_values: List[str]) -> str:
    """
    dim_values is a list of 4 statuses (Planned/IP/Complete).

    - Complete  if all Complete
    - Planned   if all Planned
    - In Progress otherwise
    """
    s = set(dim_values)
    if s == {"Complete"}:
        return "Complete"
    if s == {"Planned"}:
        return "Planned"
    return "In Progress"


# ----------------- main ----------------- #

def update_stories() -> None:
    for path in sorted(STORIES_DIR.glob("*.md")):
        text = _read(path)

        story_id = _extract_scalar(text, "story_id")
        if not story_id:
            continue  # skip non-Mission stories

        testing = _norm_dim(_extract_scalar(text, "testing_status"))
        guardrail = _norm_dim(_extract_scalar(text, "guardrail_adherence"))
        code_quality = _norm_dim(_extract_scalar(text, "code_quality_adherence"))
        security = _norm_dim(_extract_scalar(text, "security_policy_adherence"))

        dims = [testing, guardrail, code_quality, security]
        overall = _derive_overall(dims)

        new_text = _replace_scalar(text, "overall_status", overall)

        if new_text != text:
            _write(path, new_text)
            print(f">>> Story {story_id}: overall_status -> {overall}")


def main() -> int:
    print("=== Deriving Story overall_status from test/guardrail/code/security ===")
    print(f"Repo root: {REPO_ROOT}")
    update_stories()
    print("=== Done ===")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())


===== FILE: tools\update_testing_status.py =====
import sys
from pathlib import Path
import re

def main():
    if len(sys.argv) != 3:
        print("Usage: update_testing_status.py <story_path> <status>")
        sys.exit(1)

    story_path = Path(sys.argv[1])
    status = sys.argv[2]

    if status not in {"not_run", "pass", "fail"}:
        print(f"Invalid status: {status}")
        sys.exit(1)

    text = story_path.read_text(encoding="utf-8")

    # Replace the first occurrence of 'testing_status: ...'
    pattern = r"(^testing_status:\s*).*$"
    replacement = rf"\1{status}"
    new_text, count = re.subn(pattern, replacement, text, count=1, flags=re.MULTILINE)

    if count == 0:
        print("No testing_status line found to update.")
        sys.exit(1)

    story_path.write_text(new_text, encoding="utf-8")

if __name__ == "__main__":
    main()

